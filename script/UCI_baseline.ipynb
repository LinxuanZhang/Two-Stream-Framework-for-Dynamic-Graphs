{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFmnbM5n8fFk",
        "outputId": "99b8b831-32ba-4098-a196-94915286e1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/mlds\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/mlds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9rULJX1_8jW4"
      },
      "outputs": [],
      "source": [
        "import data_UCI as uci\n",
        "import tasker_link_prediction as t_lp\n",
        "from splitter import splitter\n",
        "from models import Baseline_node2vec\n",
        "from trainer import Trainer\n",
        "import yaml\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvGXFPFi825w",
        "outputId": "82cd8bbd-6247-41ba-df21-296b9bcfbe0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_config': {'adam_beta_1': 0.9,\n",
              "  'adam_beta_2': 0.999,\n",
              "  'adam_epsilon': 1e-07,\n",
              "  'adam_learning_rate': 0.005},\n",
              " 'model_path': 'models/UCI_N2V_baseline/',\n",
              " 'classifier_hidden_size': 24,\n",
              " 'ffn_fusion_size': 12,\n",
              " 'ffn_hidden_size': 12,\n",
              " 'gcn_fusion_size': 24,\n",
              " 'spatial_hidden_size': 24,\n",
              " 'spatial_input_dim': 64,\n",
              " 'temporal_hidden_size': 24,\n",
              " 'temporal_input_dim': 60,\n",
              " 'num_epochs': 1000,\n",
              " 'patience': 10,\n",
              " 'major_threshold': None,\n",
              " 'train_proportion': 0.71,\n",
              " 'dev_proportion': 0.1,\n",
              " 'data_path': 'data/UCI/',\n",
              " 'prep_data_path': 'prep_data/UCI_neg/'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "prep = False\n",
        "\n",
        "with open('config/config_UCI_baseline.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "model_path = config['model_path']\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "    os.mkdir(model_path + \"best_checkpoints/\")\n",
        "    os.mkdir(model_path + \"latest_checkpoints/\")\n",
        "\n",
        "with open(model_path + 'config.yaml', 'w') as file:\n",
        "    yaml.dump(config, file)\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n2tmk8H89Sw",
        "outputId": "7a2535f4-9708-4093-9b0d-ca74b348f040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits sizes:  train 53 dev 9 test 17\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "data = uci.UC_Irvine_Dataset(config['data_path'])\n",
        "tasker = t_lp.Link_Pred_Tasker(data, path=config['prep_data_path'], prep=prep,\n",
        "                               embs_dim=config['spatial_input_dim'], temp_dim=int(config['temporal_input_dim']/10),\n",
        "                               major_threshold=config['major_threshold'], smart_neg_sampling=True)\n",
        "\n",
        "splitter_as = splitter(tasker, train_proportion = config['train_proportion'], dev_proportion = config['dev_proportion'])\n",
        "\n",
        "model= Baseline_node2vec(config['spatial_input_dim'])\n",
        "\n",
        "trainer = Trainer(model=model, splitter=splitter_as, model_path=model_path, adam_config=config['adam_config'], patience=config['patience'])\n",
        "print(trainer.patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeDJaNaz9BxO",
        "outputId": "d72aae85-0f48-4f15-f365-2ee0588c0045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 1, Loss: 0.10255007445812225\n",
            "Epoch 1, Step 2, Loss: 0.0997573658823967\n",
            "Epoch 1, Step 3, Loss: 0.07204446196556091\n",
            "Epoch 1, Step 4, Loss: 0.052311886101961136\n",
            "Epoch 1, Step 5, Loss: 0.051578495651483536\n",
            "Epoch 1, Step 6, Loss: 0.05000925064086914\n",
            "Epoch 1, Step 7, Loss: 0.05103997141122818\n",
            "Epoch 1, Step 8, Loss: 0.04373118653893471\n",
            "Epoch 1, Step 9, Loss: 0.06669381260871887\n",
            "Epoch 1, Step 10, Loss: 0.03523719683289528\n",
            "Epoch 1, Step 11, Loss: 0.02712569385766983\n",
            "Epoch 1, Step 12, Loss: 0.034706879407167435\n",
            "Epoch 1, Step 13, Loss: 0.03359895199537277\n",
            "Epoch 1, Step 14, Loss: 0.029371801763772964\n",
            "Epoch 1, Step 15, Loss: 0.03791135922074318\n",
            "Epoch 1, Step 16, Loss: 0.045834414660930634\n",
            "Epoch 1, Step 17, Loss: 0.03293456882238388\n",
            "Epoch 1, Step 18, Loss: 0.03444503992795944\n",
            "Epoch 1, Step 19, Loss: 0.022374775260686874\n",
            "Epoch 1, Step 20, Loss: 0.03182318061590195\n",
            "Epoch 1, Step 21, Loss: 0.02940092794597149\n",
            "Epoch 1, Step 22, Loss: 0.030493443831801414\n",
            "Epoch 1, Step 23, Loss: 0.025781016796827316\n",
            "Epoch 1, Step 24, Loss: 0.034196607768535614\n",
            "Epoch 1, Step 25, Loss: 0.03390852361917496\n",
            "Epoch 1, Step 26, Loss: 0.032362960278987885\n",
            "Epoch 1, Step 27, Loss: 0.03287943825125694\n",
            "Epoch 1, Step 28, Loss: 0.03916088864207268\n",
            "Epoch 1, Step 29, Loss: 0.041966576129198074\n",
            "Epoch 1, Step 30, Loss: 0.029342714697122574\n",
            "Epoch 1, Step 31, Loss: 0.03179934248328209\n",
            "Epoch 1, Step 32, Loss: 0.02774786576628685\n",
            "Epoch 1, Step 33, Loss: 0.018022026866674423\n",
            "Epoch 1, Step 34, Loss: 0.03159017488360405\n",
            "Epoch 1, Step 35, Loss: 0.03190240263938904\n",
            "Epoch 1, Step 36, Loss: 0.02501075528562069\n",
            "Epoch 1, Step 37, Loss: 0.03855099901556969\n",
            "Epoch 1, Step 38, Loss: 0.029903072863817215\n",
            "Epoch 1, Step 39, Loss: 0.03280849754810333\n",
            "Epoch 1, Step 40, Loss: 0.029361220076680183\n",
            "Epoch 1, Step 41, Loss: 0.034275494515895844\n",
            "Epoch 1, Step 42, Loss: 0.030830159783363342\n",
            "Epoch 1, Step 43, Loss: 0.025870101526379585\n",
            "Epoch 1, Step 44, Loss: 0.029763024300336838\n",
            "Epoch 1, Step 45, Loss: 0.02955738827586174\n",
            "Epoch 1, Step 46, Loss: 0.027126960456371307\n",
            "Epoch 1, Step 47, Loss: 0.03393460065126419\n",
            "Epoch 1, Step 48, Loss: 0.0471976175904274\n",
            "Epoch 1, Step 49, Loss: 0.040715865790843964\n",
            "Epoch 1, Step 50, Loss: 0.034019023180007935\n",
            "Epoch 1, Step 51, Loss: 0.035743821412324905\n",
            "Epoch 1, Step 52, Loss: 0.033450011163949966\n",
            "Epoch 1, Step 53, Loss: 0.03522830083966255\n",
            "Train Metric MRRs: 0.016748137759612137\n",
            "Train Metric MAPs: 0.017063445104598698\n",
            "Validation Metric MRRs: 0.048406674475360296\n",
            "Validation Metric MAPs: 0.09847882031161918\n",
            "Epoch 2, Step 1, Loss: 0.04165077954530716\n",
            "Epoch 2, Step 2, Loss: 0.05164564028382301\n",
            "Epoch 2, Step 3, Loss: 0.04127990081906319\n",
            "Epoch 2, Step 4, Loss: 0.030095238238573074\n",
            "Epoch 2, Step 5, Loss: 0.036713533103466034\n",
            "Epoch 2, Step 6, Loss: 0.037313029170036316\n",
            "Epoch 2, Step 7, Loss: 0.03572036325931549\n",
            "Epoch 2, Step 8, Loss: 0.032004907727241516\n",
            "Epoch 2, Step 9, Loss: 0.04864729568362236\n",
            "Epoch 2, Step 10, Loss: 0.029170965775847435\n",
            "Epoch 2, Step 11, Loss: 0.019791169092059135\n",
            "Epoch 2, Step 12, Loss: 0.020961115136742592\n",
            "Epoch 2, Step 13, Loss: 0.023382626473903656\n",
            "Epoch 2, Step 14, Loss: 0.017777331173419952\n",
            "Epoch 2, Step 15, Loss: 0.0221281535923481\n",
            "Epoch 2, Step 16, Loss: 0.027591150254011154\n",
            "Epoch 2, Step 17, Loss: 0.018311895430088043\n",
            "Epoch 2, Step 18, Loss: 0.022211888805031776\n",
            "Epoch 2, Step 19, Loss: 0.012494023889303207\n",
            "Epoch 2, Step 20, Loss: 0.012641435489058495\n",
            "Epoch 2, Step 21, Loss: 0.011152236722409725\n",
            "Epoch 2, Step 22, Loss: 0.011749917641282082\n",
            "Epoch 2, Step 23, Loss: 0.01065774168819189\n",
            "Epoch 2, Step 24, Loss: 0.022843090817332268\n",
            "Epoch 2, Step 25, Loss: 0.019936123862862587\n",
            "Epoch 2, Step 26, Loss: 0.02204732596874237\n",
            "Epoch 2, Step 27, Loss: 0.02002429962158203\n",
            "Epoch 2, Step 28, Loss: 0.0251912921667099\n",
            "Epoch 2, Step 29, Loss: 0.026538429781794548\n",
            "Epoch 2, Step 30, Loss: 0.023078951984643936\n",
            "Epoch 2, Step 31, Loss: 0.022304436191916466\n",
            "Epoch 2, Step 32, Loss: 0.017318014055490494\n",
            "Epoch 2, Step 33, Loss: 0.011989381164312363\n",
            "Epoch 2, Step 34, Loss: 0.022767020389437675\n",
            "Epoch 2, Step 35, Loss: 0.021600155159831047\n",
            "Epoch 2, Step 36, Loss: 0.0175612922757864\n",
            "Epoch 2, Step 37, Loss: 0.027404233813285828\n",
            "Epoch 2, Step 38, Loss: 0.025006189942359924\n",
            "Epoch 2, Step 39, Loss: 0.02605580724775791\n",
            "Epoch 2, Step 40, Loss: 0.023327885195612907\n",
            "Epoch 2, Step 41, Loss: 0.029923507943749428\n",
            "Epoch 2, Step 42, Loss: 0.026861581951379776\n",
            "Epoch 2, Step 43, Loss: 0.021575389429926872\n",
            "Epoch 2, Step 44, Loss: 0.026265157386660576\n",
            "Epoch 2, Step 45, Loss: 0.02410043403506279\n",
            "Epoch 2, Step 46, Loss: 0.023108331486582756\n",
            "Epoch 2, Step 47, Loss: 0.0315701998770237\n",
            "Epoch 2, Step 48, Loss: 0.03298541158437729\n",
            "Epoch 2, Step 49, Loss: 0.03283235430717468\n",
            "Epoch 2, Step 50, Loss: 0.02965991571545601\n",
            "Epoch 2, Step 51, Loss: 0.029607536271214485\n",
            "Epoch 2, Step 52, Loss: 0.025832150131464005\n",
            "Epoch 2, Step 53, Loss: 0.0338386595249176\n",
            "Train Metric MRRs: 0.03210815346090533\n",
            "Train Metric MAPs: 0.03677980174341522\n",
            "Validation Metric MRRs: 0.08282847649676969\n",
            "Validation Metric MAPs: 0.16352534856320675\n",
            "Epoch 3, Step 1, Loss: 0.03485114872455597\n",
            "Epoch 3, Step 2, Loss: 0.040977269411087036\n",
            "Epoch 3, Step 3, Loss: 0.032891735434532166\n",
            "Epoch 3, Step 4, Loss: 0.025827698409557343\n",
            "Epoch 3, Step 5, Loss: 0.033419765532016754\n",
            "Epoch 3, Step 6, Loss: 0.03263457491993904\n",
            "Epoch 3, Step 7, Loss: 0.0331965908408165\n",
            "Epoch 3, Step 8, Loss: 0.03052034042775631\n",
            "Epoch 3, Step 9, Loss: 0.04305639490485191\n",
            "Epoch 3, Step 10, Loss: 0.027114612981677055\n",
            "Epoch 3, Step 11, Loss: 0.01896803267300129\n",
            "Epoch 3, Step 12, Loss: 0.018722625449299812\n",
            "Epoch 3, Step 13, Loss: 0.020474174991250038\n",
            "Epoch 3, Step 14, Loss: 0.015576183795928955\n",
            "Epoch 3, Step 15, Loss: 0.019725002348423004\n",
            "Epoch 3, Step 16, Loss: 0.024907635524868965\n",
            "Epoch 3, Step 17, Loss: 0.016146648675203323\n",
            "Epoch 3, Step 18, Loss: 0.018465911969542503\n",
            "Epoch 3, Step 19, Loss: 0.010570242069661617\n",
            "Epoch 3, Step 20, Loss: 0.009181651286780834\n",
            "Epoch 3, Step 21, Loss: 0.007872373796999454\n",
            "Epoch 3, Step 22, Loss: 0.008838986046612263\n",
            "Epoch 3, Step 23, Loss: 0.008502849377691746\n",
            "Epoch 3, Step 24, Loss: 0.02292386256158352\n",
            "Epoch 3, Step 25, Loss: 0.01758129894733429\n",
            "Epoch 3, Step 26, Loss: 0.02026285231113434\n",
            "Epoch 3, Step 27, Loss: 0.018049640581011772\n",
            "Epoch 3, Step 28, Loss: 0.023324819281697273\n",
            "Epoch 3, Step 29, Loss: 0.024245241656899452\n",
            "Epoch 3, Step 30, Loss: 0.02209152840077877\n",
            "Epoch 3, Step 31, Loss: 0.020255545154213905\n",
            "Epoch 3, Step 32, Loss: 0.015203939750790596\n",
            "Epoch 3, Step 33, Loss: 0.010907502844929695\n",
            "Epoch 3, Step 34, Loss: 0.02061040699481964\n",
            "Epoch 3, Step 35, Loss: 0.01900806836783886\n",
            "Epoch 3, Step 36, Loss: 0.01612691953778267\n",
            "Epoch 3, Step 37, Loss: 0.025501519441604614\n",
            "Epoch 3, Step 38, Loss: 0.023161061108112335\n",
            "Epoch 3, Step 39, Loss: 0.023353364318609238\n",
            "Epoch 3, Step 40, Loss: 0.02237549237906933\n",
            "Epoch 3, Step 41, Loss: 0.028037507086992264\n",
            "Epoch 3, Step 42, Loss: 0.023040657863020897\n",
            "Epoch 3, Step 43, Loss: 0.020390119403600693\n",
            "Epoch 3, Step 44, Loss: 0.02581171505153179\n",
            "Epoch 3, Step 45, Loss: 0.02184664085507393\n",
            "Epoch 3, Step 46, Loss: 0.0226728618144989\n",
            "Epoch 3, Step 47, Loss: 0.028027767315506935\n",
            "Epoch 3, Step 48, Loss: 0.030708905309438705\n",
            "Epoch 3, Step 49, Loss: 0.030179422348737717\n",
            "Epoch 3, Step 50, Loss: 0.02821570448577404\n",
            "Epoch 3, Step 51, Loss: 0.02804473787546158\n",
            "Epoch 3, Step 52, Loss: 0.023661602288484573\n",
            "Epoch 3, Step 53, Loss: 0.0289605762809515\n",
            "Train Metric MRRs: 0.04389829989271177\n",
            "Train Metric MAPs: 0.05668594423514701\n",
            "Validation Metric MRRs: 0.09597999829677117\n",
            "Validation Metric MAPs: 0.1941514908046344\n",
            "Epoch 4, Step 1, Loss: 0.03110283613204956\n",
            "Epoch 4, Step 2, Loss: 0.03833017498254776\n",
            "Epoch 4, Step 3, Loss: 0.029879024252295494\n",
            "Epoch 4, Step 4, Loss: 0.023395348340272903\n",
            "Epoch 4, Step 5, Loss: 0.0315479151904583\n",
            "Epoch 4, Step 6, Loss: 0.030377300456166267\n",
            "Epoch 4, Step 7, Loss: 0.029908422380685806\n",
            "Epoch 4, Step 8, Loss: 0.02736472152173519\n",
            "Epoch 4, Step 9, Loss: 0.04069799184799194\n",
            "Epoch 4, Step 10, Loss: 0.02353673055768013\n",
            "Epoch 4, Step 11, Loss: 0.01697334088385105\n",
            "Epoch 4, Step 12, Loss: 0.017306828871369362\n",
            "Epoch 4, Step 13, Loss: 0.019487790763378143\n",
            "Epoch 4, Step 14, Loss: 0.015343442559242249\n",
            "Epoch 4, Step 15, Loss: 0.01910080388188362\n",
            "Epoch 4, Step 16, Loss: 0.02295556291937828\n",
            "Epoch 4, Step 17, Loss: 0.015025706961750984\n",
            "Epoch 4, Step 18, Loss: 0.01621742732822895\n",
            "Epoch 4, Step 19, Loss: 0.009586513973772526\n",
            "Epoch 4, Step 20, Loss: 0.008259257301688194\n",
            "Epoch 4, Step 21, Loss: 0.006943750660866499\n",
            "Epoch 4, Step 22, Loss: 0.008014664053916931\n",
            "Epoch 4, Step 23, Loss: 0.007769257295876741\n",
            "Epoch 4, Step 24, Loss: 0.02353786490857601\n",
            "Epoch 4, Step 25, Loss: 0.016618113964796066\n",
            "Epoch 4, Step 26, Loss: 0.01841624826192856\n",
            "Epoch 4, Step 27, Loss: 0.017333775758743286\n",
            "Epoch 4, Step 28, Loss: 0.021799810230731964\n",
            "Epoch 4, Step 29, Loss: 0.022713875398039818\n",
            "Epoch 4, Step 30, Loss: 0.021549759432673454\n",
            "Epoch 4, Step 31, Loss: 0.01922016218304634\n",
            "Epoch 4, Step 32, Loss: 0.014298650436103344\n",
            "Epoch 4, Step 33, Loss: 0.010633554309606552\n",
            "Epoch 4, Step 34, Loss: 0.02027878351509571\n",
            "Epoch 4, Step 35, Loss: 0.018278267234563828\n",
            "Epoch 4, Step 36, Loss: 0.015215740539133549\n",
            "Epoch 4, Step 37, Loss: 0.024545032531023026\n",
            "Epoch 4, Step 38, Loss: 0.021732645109295845\n",
            "Epoch 4, Step 39, Loss: 0.02279244363307953\n",
            "Epoch 4, Step 40, Loss: 0.021954858675599098\n",
            "Epoch 4, Step 41, Loss: 0.02715262770652771\n",
            "Epoch 4, Step 42, Loss: 0.020560819655656815\n",
            "Epoch 4, Step 43, Loss: 0.019936049357056618\n",
            "Epoch 4, Step 44, Loss: 0.025547834113240242\n",
            "Epoch 4, Step 45, Loss: 0.021142413839697838\n",
            "Epoch 4, Step 46, Loss: 0.02230396308004856\n",
            "Epoch 4, Step 47, Loss: 0.026712510734796524\n",
            "Epoch 4, Step 48, Loss: 0.028836671262979507\n",
            "Epoch 4, Step 49, Loss: 0.029460595920681953\n",
            "Epoch 4, Step 50, Loss: 0.027470476925373077\n",
            "Epoch 4, Step 51, Loss: 0.027860408648848534\n",
            "Epoch 4, Step 52, Loss: 0.022434063255786896\n",
            "Epoch 4, Step 53, Loss: 0.026330871507525444\n",
            "Train Metric MRRs: 0.05690477488883269\n",
            "Train Metric MAPs: 0.07023796165497642\n",
            "Validation Metric MRRs: 0.11762064275253156\n",
            "Validation Metric MAPs: 0.20115189659732682\n",
            "Epoch 5, Step 1, Loss: 0.028922418132424355\n",
            "Epoch 5, Step 2, Loss: 0.03595025837421417\n",
            "Epoch 5, Step 3, Loss: 0.02815966121852398\n",
            "Epoch 5, Step 4, Loss: 0.022143492475152016\n",
            "Epoch 5, Step 5, Loss: 0.03037814050912857\n",
            "Epoch 5, Step 6, Loss: 0.02920064702630043\n",
            "Epoch 5, Step 7, Loss: 0.02876121550798416\n",
            "Epoch 5, Step 8, Loss: 0.0254724882543087\n",
            "Epoch 5, Step 9, Loss: 0.039444223046302795\n",
            "Epoch 5, Step 10, Loss: 0.0218356866389513\n",
            "Epoch 5, Step 11, Loss: 0.016087891533970833\n",
            "Epoch 5, Step 12, Loss: 0.016480304300785065\n",
            "Epoch 5, Step 13, Loss: 0.018861770629882812\n",
            "Epoch 5, Step 14, Loss: 0.015093672089278698\n",
            "Epoch 5, Step 15, Loss: 0.018814321607351303\n",
            "Epoch 5, Step 16, Loss: 0.021595792844891548\n",
            "Epoch 5, Step 17, Loss: 0.01449348870664835\n",
            "Epoch 5, Step 18, Loss: 0.015307683497667313\n",
            "Epoch 5, Step 19, Loss: 0.009012002497911453\n",
            "Epoch 5, Step 20, Loss: 0.00787154771387577\n",
            "Epoch 5, Step 21, Loss: 0.006496206857264042\n",
            "Epoch 5, Step 22, Loss: 0.007662012707442045\n",
            "Epoch 5, Step 23, Loss: 0.007238838821649551\n",
            "Epoch 5, Step 24, Loss: 0.024027295410633087\n",
            "Epoch 5, Step 25, Loss: 0.016128098592162132\n",
            "Epoch 5, Step 26, Loss: 0.016967015340924263\n",
            "Epoch 5, Step 27, Loss: 0.01720452308654785\n",
            "Epoch 5, Step 28, Loss: 0.020878270268440247\n",
            "Epoch 5, Step 29, Loss: 0.02220156043767929\n",
            "Epoch 5, Step 30, Loss: 0.021321481093764305\n",
            "Epoch 5, Step 31, Loss: 0.019003380089998245\n",
            "Epoch 5, Step 32, Loss: 0.013733426108956337\n",
            "Epoch 5, Step 33, Loss: 0.010498102754354477\n",
            "Epoch 5, Step 34, Loss: 0.02021743357181549\n",
            "Epoch 5, Step 35, Loss: 0.018063025549054146\n",
            "Epoch 5, Step 36, Loss: 0.014518587850034237\n",
            "Epoch 5, Step 37, Loss: 0.024114584550261497\n",
            "Epoch 5, Step 38, Loss: 0.020773015916347504\n",
            "Epoch 5, Step 39, Loss: 0.022693244740366936\n",
            "Epoch 5, Step 40, Loss: 0.02176634408533573\n",
            "Epoch 5, Step 41, Loss: 0.02669679746031761\n",
            "Epoch 5, Step 42, Loss: 0.019230622798204422\n",
            "Epoch 5, Step 43, Loss: 0.01959342323243618\n",
            "Epoch 5, Step 44, Loss: 0.024640411138534546\n",
            "Epoch 5, Step 45, Loss: 0.020647862926125526\n",
            "Epoch 5, Step 46, Loss: 0.02188941463828087\n",
            "Epoch 5, Step 47, Loss: 0.025842368602752686\n",
            "Epoch 5, Step 48, Loss: 0.027741679921746254\n",
            "Epoch 5, Step 49, Loss: 0.028698330745100975\n",
            "Epoch 5, Step 50, Loss: 0.026820151135325432\n",
            "Epoch 5, Step 51, Loss: 0.02786494791507721\n",
            "Epoch 5, Step 52, Loss: 0.02198738604784012\n",
            "Epoch 5, Step 53, Loss: 0.02512414939701557\n",
            "Train Metric MRRs: 0.06773831835035644\n",
            "Train Metric MAPs: 0.0798373508230053\n",
            "Validation Metric MRRs: 0.12837748309855807\n",
            "Validation Metric MAPs: 0.20777996304659166\n",
            "Epoch 6, Step 1, Loss: 0.02775631472468376\n",
            "Epoch 6, Step 2, Loss: 0.03344831243157387\n",
            "Epoch 6, Step 3, Loss: 0.02703004516661167\n",
            "Epoch 6, Step 4, Loss: 0.02147001214325428\n",
            "Epoch 6, Step 5, Loss: 0.029212364926934242\n",
            "Epoch 6, Step 6, Loss: 0.028683055192232132\n",
            "Epoch 6, Step 7, Loss: 0.028161847963929176\n",
            "Epoch 6, Step 8, Loss: 0.02469760924577713\n",
            "Epoch 6, Step 9, Loss: 0.03846749663352966\n",
            "Epoch 6, Step 10, Loss: 0.020942924544215202\n",
            "Epoch 6, Step 11, Loss: 0.015589441172778606\n",
            "Epoch 6, Step 12, Loss: 0.015905288979411125\n",
            "Epoch 6, Step 13, Loss: 0.018535474315285683\n",
            "Epoch 6, Step 14, Loss: 0.014674173668026924\n",
            "Epoch 6, Step 15, Loss: 0.018529511988162994\n",
            "Epoch 6, Step 16, Loss: 0.02060617506504059\n",
            "Epoch 6, Step 17, Loss: 0.014287016354501247\n",
            "Epoch 6, Step 18, Loss: 0.015045835636556149\n",
            "Epoch 6, Step 19, Loss: 0.00862486008554697\n",
            "Epoch 6, Step 20, Loss: 0.007766737136989832\n",
            "Epoch 6, Step 21, Loss: 0.006311385426670313\n",
            "Epoch 6, Step 22, Loss: 0.007539654150605202\n",
            "Epoch 6, Step 23, Loss: 0.0070383017882704735\n",
            "Epoch 6, Step 24, Loss: 0.024255238473415375\n",
            "Epoch 6, Step 25, Loss: 0.015926966443657875\n",
            "Epoch 6, Step 26, Loss: 0.0162055566906929\n",
            "Epoch 6, Step 27, Loss: 0.016628727316856384\n",
            "Epoch 6, Step 28, Loss: 0.020527424290776253\n",
            "Epoch 6, Step 29, Loss: 0.021793212741613388\n",
            "Epoch 6, Step 30, Loss: 0.021169543266296387\n",
            "Epoch 6, Step 31, Loss: 0.018784163519740105\n",
            "Epoch 6, Step 32, Loss: 0.013134912587702274\n",
            "Epoch 6, Step 33, Loss: 0.010321175679564476\n",
            "Epoch 6, Step 34, Loss: 0.02000734768807888\n",
            "Epoch 6, Step 35, Loss: 0.01737271063029766\n",
            "Epoch 6, Step 36, Loss: 0.013996932655572891\n",
            "Epoch 6, Step 37, Loss: 0.023824559524655342\n",
            "Epoch 6, Step 38, Loss: 0.020129067823290825\n",
            "Epoch 6, Step 39, Loss: 0.022398360073566437\n",
            "Epoch 6, Step 40, Loss: 0.02144605666399002\n",
            "Epoch 6, Step 41, Loss: 0.026308223605155945\n",
            "Epoch 6, Step 42, Loss: 0.01874382235109806\n",
            "Epoch 6, Step 43, Loss: 0.0192806888371706\n",
            "Epoch 6, Step 44, Loss: 0.02395549975335598\n",
            "Epoch 6, Step 45, Loss: 0.02029498852789402\n",
            "Epoch 6, Step 46, Loss: 0.021702613681554794\n",
            "Epoch 6, Step 47, Loss: 0.025388475507497787\n",
            "Epoch 6, Step 48, Loss: 0.026923280209302902\n",
            "Epoch 6, Step 49, Loss: 0.02762681059539318\n",
            "Epoch 6, Step 50, Loss: 0.026353998109698296\n",
            "Epoch 6, Step 51, Loss: 0.027512237429618835\n",
            "Epoch 6, Step 52, Loss: 0.021531181409955025\n",
            "Epoch 6, Step 53, Loss: 0.02450542524456978\n",
            "Train Metric MRRs: 0.07622071390385891\n",
            "Train Metric MAPs: 0.08620265137730229\n",
            "Validation Metric MRRs: 0.12925887880960654\n",
            "Validation Metric MAPs: 0.21504811807262986\n",
            "Epoch 7, Step 1, Loss: 0.027528012171387672\n",
            "Epoch 7, Step 2, Loss: 0.03198646008968353\n",
            "Epoch 7, Step 3, Loss: 0.026328381150960922\n",
            "Epoch 7, Step 4, Loss: 0.021176103502511978\n",
            "Epoch 7, Step 5, Loss: 0.02821286953985691\n",
            "Epoch 7, Step 6, Loss: 0.02829396352171898\n",
            "Epoch 7, Step 7, Loss: 0.0278650913387537\n",
            "Epoch 7, Step 8, Loss: 0.024416623637080193\n",
            "Epoch 7, Step 9, Loss: 0.03746875375509262\n",
            "Epoch 7, Step 10, Loss: 0.020387077704072\n",
            "Epoch 7, Step 11, Loss: 0.015296313911676407\n",
            "Epoch 7, Step 12, Loss: 0.01564948260784149\n",
            "Epoch 7, Step 13, Loss: 0.018317531794309616\n",
            "Epoch 7, Step 14, Loss: 0.014185164123773575\n",
            "Epoch 7, Step 15, Loss: 0.018247315660119057\n",
            "Epoch 7, Step 16, Loss: 0.02001303993165493\n",
            "Epoch 7, Step 17, Loss: 0.014122497290372849\n",
            "Epoch 7, Step 18, Loss: 0.014937356114387512\n",
            "Epoch 7, Step 19, Loss: 0.008281322196125984\n",
            "Epoch 7, Step 20, Loss: 0.007745915092527866\n",
            "Epoch 7, Step 21, Loss: 0.006235607899725437\n",
            "Epoch 7, Step 22, Loss: 0.007482430431991816\n",
            "Epoch 7, Step 23, Loss: 0.006983335129916668\n",
            "Epoch 7, Step 24, Loss: 0.024327348917722702\n",
            "Epoch 7, Step 25, Loss: 0.015702541917562485\n",
            "Epoch 7, Step 26, Loss: 0.015681816264986992\n",
            "Epoch 7, Step 27, Loss: 0.01605549268424511\n",
            "Epoch 7, Step 28, Loss: 0.02017606981098652\n",
            "Epoch 7, Step 29, Loss: 0.021396974101662636\n",
            "Epoch 7, Step 30, Loss: 0.02108107879757881\n",
            "Epoch 7, Step 31, Loss: 0.018586358055472374\n",
            "Epoch 7, Step 32, Loss: 0.012739598751068115\n",
            "Epoch 7, Step 33, Loss: 0.010213286615908146\n",
            "Epoch 7, Step 34, Loss: 0.019502226263284683\n",
            "Epoch 7, Step 35, Loss: 0.01648879051208496\n",
            "Epoch 7, Step 36, Loss: 0.013606471940875053\n",
            "Epoch 7, Step 37, Loss: 0.023619376122951508\n",
            "Epoch 7, Step 38, Loss: 0.019757401198148727\n",
            "Epoch 7, Step 39, Loss: 0.022095996886491776\n",
            "Epoch 7, Step 40, Loss: 0.021097609773278236\n",
            "Epoch 7, Step 41, Loss: 0.025947144255042076\n",
            "Epoch 7, Step 42, Loss: 0.018250996246933937\n",
            "Epoch 7, Step 43, Loss: 0.019015293568372726\n",
            "Epoch 7, Step 44, Loss: 0.02358594909310341\n",
            "Epoch 7, Step 45, Loss: 0.019827790558338165\n",
            "Epoch 7, Step 46, Loss: 0.02154948189854622\n",
            "Epoch 7, Step 47, Loss: 0.025123033672571182\n",
            "Epoch 7, Step 48, Loss: 0.02591083012521267\n",
            "Epoch 7, Step 49, Loss: 0.02690599113702774\n",
            "Epoch 7, Step 50, Loss: 0.02609054371714592\n",
            "Epoch 7, Step 51, Loss: 0.02670309506356716\n",
            "Epoch 7, Step 52, Loss: 0.020656533539295197\n",
            "Epoch 7, Step 53, Loss: 0.024045554921030998\n",
            "Train Metric MRRs: 0.08338200919062531\n",
            "Train Metric MAPs: 0.09147959530440367\n",
            "Validation Metric MRRs: 0.13083971358557095\n",
            "Validation Metric MAPs: 0.2215401468064076\n",
            "Epoch 8, Step 1, Loss: 0.0268800500780344\n",
            "Epoch 8, Step 2, Loss: 0.031041882932186127\n",
            "Epoch 8, Step 3, Loss: 0.026064127683639526\n",
            "Epoch 8, Step 4, Loss: 0.020917747169733047\n",
            "Epoch 8, Step 5, Loss: 0.02763059176504612\n",
            "Epoch 8, Step 6, Loss: 0.02790672704577446\n",
            "Epoch 8, Step 7, Loss: 0.027143917977809906\n",
            "Epoch 8, Step 8, Loss: 0.02410096488893032\n",
            "Epoch 8, Step 9, Loss: 0.03675876930356026\n",
            "Epoch 8, Step 10, Loss: 0.019899684935808182\n",
            "Epoch 8, Step 11, Loss: 0.015131240710616112\n",
            "Epoch 8, Step 12, Loss: 0.015328056178987026\n",
            "Epoch 8, Step 13, Loss: 0.018126055598258972\n",
            "Epoch 8, Step 14, Loss: 0.013835342600941658\n",
            "Epoch 8, Step 15, Loss: 0.018077775835990906\n",
            "Epoch 8, Step 16, Loss: 0.019734539091587067\n",
            "Epoch 8, Step 17, Loss: 0.013967293314635754\n",
            "Epoch 8, Step 18, Loss: 0.014810360036790371\n",
            "Epoch 8, Step 19, Loss: 0.008030385710299015\n",
            "Epoch 8, Step 20, Loss: 0.007733390666544437\n",
            "Epoch 8, Step 21, Loss: 0.006203334312886\n",
            "Epoch 8, Step 22, Loss: 0.007437020540237427\n",
            "Epoch 8, Step 23, Loss: 0.006984115578234196\n",
            "Epoch 8, Step 24, Loss: 0.02436770498752594\n",
            "Epoch 8, Step 25, Loss: 0.015527285635471344\n",
            "Epoch 8, Step 26, Loss: 0.01528032124042511\n",
            "Epoch 8, Step 27, Loss: 0.015631934627890587\n",
            "Epoch 8, Step 28, Loss: 0.019919399172067642\n",
            "Epoch 8, Step 29, Loss: 0.021081244572997093\n",
            "Epoch 8, Step 30, Loss: 0.020889822393655777\n",
            "Epoch 8, Step 31, Loss: 0.018305160105228424\n",
            "Epoch 8, Step 32, Loss: 0.012497925199568272\n",
            "Epoch 8, Step 33, Loss: 0.01006716676056385\n",
            "Epoch 8, Step 34, Loss: 0.01891823671758175\n",
            "Epoch 8, Step 35, Loss: 0.015992596745491028\n",
            "Epoch 8, Step 36, Loss: 0.013322161510586739\n",
            "Epoch 8, Step 37, Loss: 0.023477226495742798\n",
            "Epoch 8, Step 38, Loss: 0.019500527530908585\n",
            "Epoch 8, Step 39, Loss: 0.02164698764681816\n",
            "Epoch 8, Step 40, Loss: 0.020865043625235558\n",
            "Epoch 8, Step 41, Loss: 0.025537824258208275\n",
            "Epoch 8, Step 42, Loss: 0.017771996557712555\n",
            "Epoch 8, Step 43, Loss: 0.018748078495264053\n",
            "Epoch 8, Step 44, Loss: 0.02335670404136181\n",
            "Epoch 8, Step 45, Loss: 0.01910978928208351\n",
            "Epoch 8, Step 46, Loss: 0.021358439698815346\n",
            "Epoch 8, Step 47, Loss: 0.024862632155418396\n",
            "Epoch 8, Step 48, Loss: 0.025086870416998863\n",
            "Epoch 8, Step 49, Loss: 0.026549993082880974\n",
            "Epoch 8, Step 50, Loss: 0.02587859146296978\n",
            "Epoch 8, Step 51, Loss: 0.026190606877207756\n",
            "Epoch 8, Step 52, Loss: 0.019885465502738953\n",
            "Epoch 8, Step 53, Loss: 0.02377721294760704\n",
            "Train Metric MRRs: 0.08727736761701493\n",
            "Train Metric MAPs: 0.09527317721846405\n",
            "Validation Metric MRRs: 0.13302199323073635\n",
            "Validation Metric MAPs: 0.22468682209436436\n",
            "Epoch 9, Step 1, Loss: 0.026469651609659195\n",
            "Epoch 9, Step 2, Loss: 0.030274799093604088\n",
            "Epoch 9, Step 3, Loss: 0.025768902152776718\n",
            "Epoch 9, Step 4, Loss: 0.02068232372403145\n",
            "Epoch 9, Step 5, Loss: 0.027293797582387924\n",
            "Epoch 9, Step 6, Loss: 0.027624551206827164\n",
            "Epoch 9, Step 7, Loss: 0.02661651186645031\n",
            "Epoch 9, Step 8, Loss: 0.02379692532122135\n",
            "Epoch 9, Step 9, Loss: 0.03612348064780235\n",
            "Epoch 9, Step 10, Loss: 0.019579069688916206\n",
            "Epoch 9, Step 11, Loss: 0.0150175541639328\n",
            "Epoch 9, Step 12, Loss: 0.015103192068636417\n",
            "Epoch 9, Step 13, Loss: 0.017969083040952682\n",
            "Epoch 9, Step 14, Loss: 0.013666406273841858\n",
            "Epoch 9, Step 15, Loss: 0.017873402684926987\n",
            "Epoch 9, Step 16, Loss: 0.01958802342414856\n",
            "Epoch 9, Step 17, Loss: 0.013764714822173119\n",
            "Epoch 9, Step 18, Loss: 0.014651842415332794\n",
            "Epoch 9, Step 19, Loss: 0.007898217998445034\n",
            "Epoch 9, Step 20, Loss: 0.00768243707716465\n",
            "Epoch 9, Step 21, Loss: 0.00618702033534646\n",
            "Epoch 9, Step 22, Loss: 0.007413093466311693\n",
            "Epoch 9, Step 23, Loss: 0.006989751011133194\n",
            "Epoch 9, Step 24, Loss: 0.024396834895014763\n",
            "Epoch 9, Step 25, Loss: 0.015352749265730381\n",
            "Epoch 9, Step 26, Loss: 0.015065819956362247\n",
            "Epoch 9, Step 27, Loss: 0.015494667924940586\n",
            "Epoch 9, Step 28, Loss: 0.01971621811389923\n",
            "Epoch 9, Step 29, Loss: 0.020787030458450317\n",
            "Epoch 9, Step 30, Loss: 0.020690180361270905\n",
            "Epoch 9, Step 31, Loss: 0.017963571473956108\n",
            "Epoch 9, Step 32, Loss: 0.01227171253412962\n",
            "Epoch 9, Step 33, Loss: 0.009728158824145794\n",
            "Epoch 9, Step 34, Loss: 0.018521683290600777\n",
            "Epoch 9, Step 35, Loss: 0.015718473121523857\n",
            "Epoch 9, Step 36, Loss: 0.013110586442053318\n",
            "Epoch 9, Step 37, Loss: 0.023335935547947884\n",
            "Epoch 9, Step 38, Loss: 0.019340304657816887\n",
            "Epoch 9, Step 39, Loss: 0.021282386034727097\n",
            "Epoch 9, Step 40, Loss: 0.02066749706864357\n",
            "Epoch 9, Step 41, Loss: 0.025136087089776993\n",
            "Epoch 9, Step 42, Loss: 0.017520001158118248\n",
            "Epoch 9, Step 43, Loss: 0.01856391504406929\n",
            "Epoch 9, Step 44, Loss: 0.023143751546740532\n",
            "Epoch 9, Step 45, Loss: 0.018435679376125336\n",
            "Epoch 9, Step 46, Loss: 0.021119749173521996\n",
            "Epoch 9, Step 47, Loss: 0.024600228294730186\n",
            "Epoch 9, Step 48, Loss: 0.02443116158246994\n",
            "Epoch 9, Step 49, Loss: 0.026160364970564842\n",
            "Epoch 9, Step 50, Loss: 0.025682775303721428\n",
            "Epoch 9, Step 51, Loss: 0.025797273963689804\n",
            "Epoch 9, Step 52, Loss: 0.019352266564965248\n",
            "Epoch 9, Step 53, Loss: 0.023542730137705803\n",
            "Train Metric MRRs: 0.0929645260194724\n",
            "Train Metric MAPs: 0.09846822796293771\n",
            "Validation Metric MRRs: 0.1376562398110372\n",
            "Validation Metric MAPs: 0.22673509582994797\n",
            "Epoch 10, Step 1, Loss: 0.026067372411489487\n",
            "Epoch 10, Step 2, Loss: 0.029855851083993912\n",
            "Epoch 10, Step 3, Loss: 0.025547023862600327\n",
            "Epoch 10, Step 4, Loss: 0.020476454868912697\n",
            "Epoch 10, Step 5, Loss: 0.026958120986819267\n",
            "Epoch 10, Step 6, Loss: 0.0274210125207901\n",
            "Epoch 10, Step 7, Loss: 0.026276420801877975\n",
            "Epoch 10, Step 8, Loss: 0.023470988497138023\n",
            "Epoch 10, Step 9, Loss: 0.03560858219861984\n",
            "Epoch 10, Step 10, Loss: 0.01937701553106308\n",
            "Epoch 10, Step 11, Loss: 0.014882278628647327\n",
            "Epoch 10, Step 12, Loss: 0.014988281764090061\n",
            "Epoch 10, Step 13, Loss: 0.017834872007369995\n",
            "Epoch 10, Step 14, Loss: 0.013570674695074558\n",
            "Epoch 10, Step 15, Loss: 0.017616644501686096\n",
            "Epoch 10, Step 16, Loss: 0.019421782344579697\n",
            "Epoch 10, Step 17, Loss: 0.013593535870313644\n",
            "Epoch 10, Step 18, Loss: 0.01453497726470232\n",
            "Epoch 10, Step 19, Loss: 0.007725563365966082\n",
            "Epoch 10, Step 20, Loss: 0.007667724974453449\n",
            "Epoch 10, Step 21, Loss: 0.0061928145587444305\n",
            "Epoch 10, Step 22, Loss: 0.007408833596855402\n",
            "Epoch 10, Step 23, Loss: 0.007014520466327667\n",
            "Epoch 10, Step 24, Loss: 0.02439872734248638\n",
            "Epoch 10, Step 25, Loss: 0.015175845474004745\n",
            "Epoch 10, Step 26, Loss: 0.014822307042777538\n",
            "Epoch 10, Step 27, Loss: 0.015484217554330826\n",
            "Epoch 10, Step 28, Loss: 0.019555451348423958\n",
            "Epoch 10, Step 29, Loss: 0.020471567288041115\n",
            "Epoch 10, Step 30, Loss: 0.02054232358932495\n",
            "Epoch 10, Step 31, Loss: 0.017716549336910248\n",
            "Epoch 10, Step 32, Loss: 0.012185337021946907\n",
            "Epoch 10, Step 33, Loss: 0.009470139630138874\n",
            "Epoch 10, Step 34, Loss: 0.01824761927127838\n",
            "Epoch 10, Step 35, Loss: 0.015545815229415894\n",
            "Epoch 10, Step 36, Loss: 0.012898541055619717\n",
            "Epoch 10, Step 37, Loss: 0.023108402267098427\n",
            "Epoch 10, Step 38, Loss: 0.01928337663412094\n",
            "Epoch 10, Step 39, Loss: 0.020852040499448776\n",
            "Epoch 10, Step 40, Loss: 0.020549973472952843\n",
            "Epoch 10, Step 41, Loss: 0.02476116456091404\n",
            "Epoch 10, Step 42, Loss: 0.01737663522362709\n",
            "Epoch 10, Step 43, Loss: 0.01839541643857956\n",
            "Epoch 10, Step 44, Loss: 0.02290131151676178\n",
            "Epoch 10, Step 45, Loss: 0.017840608954429626\n",
            "Epoch 10, Step 46, Loss: 0.020862992852926254\n",
            "Epoch 10, Step 47, Loss: 0.024357587099075317\n",
            "Epoch 10, Step 48, Loss: 0.023870138451457024\n",
            "Epoch 10, Step 49, Loss: 0.025945620611310005\n",
            "Epoch 10, Step 50, Loss: 0.025470469146966934\n",
            "Epoch 10, Step 51, Loss: 0.02550293318927288\n",
            "Epoch 10, Step 52, Loss: 0.019204365089535713\n",
            "Epoch 10, Step 53, Loss: 0.023320620879530907\n",
            "Train Metric MRRs: 0.09574202660442992\n",
            "Train Metric MAPs: 0.10092049496624747\n",
            "Validation Metric MRRs: 0.14337501557888138\n",
            "Validation Metric MAPs: 0.22641983938962787\n",
            "Epoch 11, Step 1, Loss: 0.02566060982644558\n",
            "Epoch 11, Step 2, Loss: 0.029500499367713928\n",
            "Epoch 11, Step 3, Loss: 0.025539610534906387\n",
            "Epoch 11, Step 4, Loss: 0.02019375190138817\n",
            "Epoch 11, Step 5, Loss: 0.026705292984843254\n",
            "Epoch 11, Step 6, Loss: 0.027319716289639473\n",
            "Epoch 11, Step 7, Loss: 0.02605162374675274\n",
            "Epoch 11, Step 8, Loss: 0.02334279753267765\n",
            "Epoch 11, Step 9, Loss: 0.03511016070842743\n",
            "Epoch 11, Step 10, Loss: 0.019202370196580887\n",
            "Epoch 11, Step 11, Loss: 0.014805802144110203\n",
            "Epoch 11, Step 12, Loss: 0.014976484701037407\n",
            "Epoch 11, Step 13, Loss: 0.01782163791358471\n",
            "Epoch 11, Step 14, Loss: 0.01362532377243042\n",
            "Epoch 11, Step 15, Loss: 0.017534801736474037\n",
            "Epoch 11, Step 16, Loss: 0.019276604056358337\n",
            "Epoch 11, Step 17, Loss: 0.013533511199057102\n",
            "Epoch 11, Step 18, Loss: 0.014445729553699493\n",
            "Epoch 11, Step 19, Loss: 0.007638812996447086\n",
            "Epoch 11, Step 20, Loss: 0.0076525830663740635\n",
            "Epoch 11, Step 21, Loss: 0.00620872201398015\n",
            "Epoch 11, Step 22, Loss: 0.007418769411742687\n",
            "Epoch 11, Step 23, Loss: 0.007027567829936743\n",
            "Epoch 11, Step 24, Loss: 0.024374332278966904\n",
            "Epoch 11, Step 25, Loss: 0.015104968100786209\n",
            "Epoch 11, Step 26, Loss: 0.014661439694464207\n",
            "Epoch 11, Step 27, Loss: 0.01525560487061739\n",
            "Epoch 11, Step 28, Loss: 0.019369512796401978\n",
            "Epoch 11, Step 29, Loss: 0.02020554058253765\n",
            "Epoch 11, Step 30, Loss: 0.020401347428560257\n",
            "Epoch 11, Step 31, Loss: 0.01763400435447693\n",
            "Epoch 11, Step 32, Loss: 0.011966410093009472\n",
            "Epoch 11, Step 33, Loss: 0.009263377636671066\n",
            "Epoch 11, Step 34, Loss: 0.018168050795793533\n",
            "Epoch 11, Step 35, Loss: 0.01545228436589241\n",
            "Epoch 11, Step 36, Loss: 0.012772917747497559\n",
            "Epoch 11, Step 37, Loss: 0.02309643290936947\n",
            "Epoch 11, Step 38, Loss: 0.0191507525742054\n",
            "Epoch 11, Step 39, Loss: 0.020757149904966354\n",
            "Epoch 11, Step 40, Loss: 0.020375587046146393\n",
            "Epoch 11, Step 41, Loss: 0.024462608620524406\n",
            "Epoch 11, Step 42, Loss: 0.017149705439805984\n",
            "Epoch 11, Step 43, Loss: 0.018444161862134933\n",
            "Epoch 11, Step 44, Loss: 0.02279510535299778\n",
            "Epoch 11, Step 45, Loss: 0.01738247461616993\n",
            "Epoch 11, Step 46, Loss: 0.020627805963158607\n",
            "Epoch 11, Step 47, Loss: 0.02459503337740898\n",
            "Epoch 11, Step 48, Loss: 0.023557499051094055\n",
            "Epoch 11, Step 49, Loss: 0.025477923452854156\n",
            "Epoch 11, Step 50, Loss: 0.025391893461346626\n",
            "Epoch 11, Step 51, Loss: 0.025191424414515495\n",
            "Epoch 11, Step 52, Loss: 0.01861189305782318\n",
            "Epoch 11, Step 53, Loss: 0.023357665166258812\n",
            "Train Metric MRRs: 0.10261241820598217\n",
            "Train Metric MAPs: 0.10247995815486274\n",
            "Validation Metric MRRs: 0.14783813215445232\n",
            "Validation Metric MAPs: 0.2278318243948477\n",
            "Epoch 12, Step 1, Loss: 0.024906747043132782\n",
            "Epoch 12, Step 2, Loss: 0.029462773352861404\n",
            "Epoch 12, Step 3, Loss: 0.025343244895339012\n",
            "Epoch 12, Step 4, Loss: 0.02010629139840603\n",
            "Epoch 12, Step 5, Loss: 0.026237932965159416\n",
            "Epoch 12, Step 6, Loss: 0.027043793350458145\n",
            "Epoch 12, Step 7, Loss: 0.025996167212724686\n",
            "Epoch 12, Step 8, Loss: 0.0230539720505476\n",
            "Epoch 12, Step 9, Loss: 0.03535819053649902\n",
            "Epoch 12, Step 10, Loss: 0.019368991255760193\n",
            "Epoch 12, Step 11, Loss: 0.014699149876832962\n",
            "Epoch 12, Step 12, Loss: 0.014973168261349201\n",
            "Epoch 12, Step 13, Loss: 0.017786623910069466\n",
            "Epoch 12, Step 14, Loss: 0.013568999245762825\n",
            "Epoch 12, Step 15, Loss: 0.01727171242237091\n",
            "Epoch 12, Step 16, Loss: 0.019161829724907875\n",
            "Epoch 12, Step 17, Loss: 0.013401753269135952\n",
            "Epoch 12, Step 18, Loss: 0.014354328624904156\n",
            "Epoch 12, Step 19, Loss: 0.007581163197755814\n",
            "Epoch 12, Step 20, Loss: 0.007622529286891222\n",
            "Epoch 12, Step 21, Loss: 0.006232058629393578\n",
            "Epoch 12, Step 22, Loss: 0.0074189030565321445\n",
            "Epoch 12, Step 23, Loss: 0.007075315807014704\n",
            "Epoch 12, Step 24, Loss: 0.02440095692873001\n",
            "Epoch 12, Step 25, Loss: 0.014829091727733612\n",
            "Epoch 12, Step 26, Loss: 0.01476222649216652\n",
            "Epoch 12, Step 27, Loss: 0.015672367066144943\n",
            "Epoch 12, Step 28, Loss: 0.019392943009734154\n",
            "Epoch 12, Step 29, Loss: 0.020089805126190186\n",
            "Epoch 12, Step 30, Loss: 0.020556170493364334\n",
            "Epoch 12, Step 31, Loss: 0.01748337224125862\n",
            "Epoch 12, Step 32, Loss: 0.012349837459623814\n",
            "Epoch 12, Step 33, Loss: 0.009150253608822823\n",
            "Epoch 12, Step 34, Loss: 0.018132496625185013\n",
            "Epoch 12, Step 35, Loss: 0.01546989195048809\n",
            "Epoch 12, Step 36, Loss: 0.012731237336993217\n",
            "Epoch 12, Step 37, Loss: 0.022811252623796463\n",
            "Epoch 12, Step 38, Loss: 0.01932935230433941\n",
            "Epoch 12, Step 39, Loss: 0.020353591069579124\n",
            "Epoch 12, Step 40, Loss: 0.020470356568694115\n",
            "Epoch 12, Step 41, Loss: 0.02421030029654503\n",
            "Epoch 12, Step 42, Loss: 0.017232738435268402\n",
            "Epoch 12, Step 43, Loss: 0.018206194043159485\n",
            "Epoch 12, Step 44, Loss: 0.022916268557310104\n",
            "Epoch 12, Step 45, Loss: 0.01710136979818344\n",
            "Epoch 12, Step 46, Loss: 0.020466474816203117\n",
            "Epoch 12, Step 47, Loss: 0.02543460577726364\n",
            "Epoch 12, Step 48, Loss: 0.02317662537097931\n",
            "Epoch 12, Step 49, Loss: 0.02593154087662697\n",
            "Epoch 12, Step 50, Loss: 0.02502978779375553\n",
            "Epoch 12, Step 51, Loss: 0.025021489709615707\n",
            "Epoch 12, Step 52, Loss: 0.019252395257353783\n",
            "Epoch 12, Step 53, Loss: 0.023778097704052925\n",
            "Train Metric MRRs: 0.10510665741879227\n",
            "Train Metric MAPs: 0.10428378854400144\n",
            "Validation Metric MRRs: 0.14432724989047144\n",
            "Validation Metric MAPs: 0.22285044204571464\n",
            "Epoch 13, Step 1, Loss: 0.02551339752972126\n",
            "Epoch 13, Step 2, Loss: 0.032003626227378845\n",
            "Epoch 13, Step 3, Loss: 0.025960247963666916\n",
            "Epoch 13, Step 4, Loss: 0.02045431174337864\n",
            "Epoch 13, Step 5, Loss: 0.02735607512295246\n",
            "Epoch 13, Step 6, Loss: 0.027551867067813873\n",
            "Epoch 13, Step 7, Loss: 0.026628637686371803\n",
            "Epoch 13, Step 8, Loss: 0.023356465622782707\n",
            "Epoch 13, Step 9, Loss: 0.03507963567972183\n",
            "Epoch 13, Step 10, Loss: 0.019589891657233238\n",
            "Epoch 13, Step 11, Loss: 0.015227086842060089\n",
            "Epoch 13, Step 12, Loss: 0.015175116248428822\n",
            "Epoch 13, Step 13, Loss: 0.0181264691054821\n",
            "Epoch 13, Step 14, Loss: 0.014135786332190037\n",
            "Epoch 13, Step 15, Loss: 0.017521312460303307\n",
            "Epoch 13, Step 16, Loss: 0.019541768357157707\n",
            "Epoch 13, Step 17, Loss: 0.013720695860683918\n",
            "Epoch 13, Step 18, Loss: 0.014309145510196686\n",
            "Epoch 13, Step 19, Loss: 0.007586294785141945\n",
            "Epoch 13, Step 20, Loss: 0.007758579682558775\n",
            "Epoch 13, Step 21, Loss: 0.006347606889903545\n",
            "Epoch 13, Step 22, Loss: 0.007485577370971441\n",
            "Epoch 13, Step 23, Loss: 0.007086919154971838\n",
            "Epoch 13, Step 24, Loss: 0.024246307089924812\n",
            "Epoch 13, Step 25, Loss: 0.015275753103196621\n",
            "Epoch 13, Step 26, Loss: 0.015445593744516373\n",
            "Epoch 13, Step 27, Loss: 0.01485426351428032\n",
            "Epoch 13, Step 28, Loss: 0.019349554553627968\n",
            "Epoch 13, Step 29, Loss: 0.020152008160948753\n",
            "Epoch 13, Step 30, Loss: 0.020287996158003807\n",
            "Epoch 13, Step 31, Loss: 0.017995033413171768\n",
            "Epoch 13, Step 32, Loss: 0.012049335055053234\n",
            "Epoch 13, Step 33, Loss: 0.009173098020255566\n",
            "Epoch 13, Step 34, Loss: 0.01821725443005562\n",
            "Epoch 13, Step 35, Loss: 0.015561618842184544\n",
            "Epoch 13, Step 36, Loss: 0.012761510908603668\n",
            "Epoch 13, Step 37, Loss: 0.023111356422305107\n",
            "Epoch 13, Step 38, Loss: 0.01970885880291462\n",
            "Epoch 13, Step 39, Loss: 0.020866941660642624\n",
            "Epoch 13, Step 40, Loss: 0.020405152812600136\n",
            "Epoch 13, Step 41, Loss: 0.024141721427440643\n",
            "Epoch 13, Step 42, Loss: 0.016994396224617958\n",
            "Epoch 13, Step 43, Loss: 0.019134053960442543\n",
            "Epoch 13, Step 44, Loss: 0.026000622659921646\n",
            "Epoch 13, Step 45, Loss: 0.017195304855704308\n",
            "Epoch 13, Step 46, Loss: 0.02065049484372139\n",
            "Epoch 13, Step 47, Loss: 0.03278502821922302\n",
            "Epoch 13, Step 48, Loss: 0.02401670068502426\n",
            "Epoch 13, Step 49, Loss: 0.0269069354981184\n",
            "Epoch 13, Step 50, Loss: 0.026005063205957413\n",
            "Epoch 13, Step 51, Loss: 0.02513952925801277\n",
            "Epoch 13, Step 52, Loss: 0.018247053027153015\n",
            "Epoch 13, Step 53, Loss: 0.026606090366840363\n",
            "Train Metric MRRs: 0.09872488383542193\n",
            "Train Metric MAPs: 0.10139770559068834\n",
            "Validation Metric MRRs: 0.13961728618974215\n",
            "Validation Metric MAPs: 0.21351402809468387\n",
            "Epoch 14, Step 1, Loss: 0.025853442028164864\n",
            "Epoch 14, Step 2, Loss: 0.032547369599342346\n",
            "Epoch 14, Step 3, Loss: 0.026169143617153168\n",
            "Epoch 14, Step 4, Loss: 0.021943142637610435\n",
            "Epoch 14, Step 5, Loss: 0.02722329832613468\n",
            "Epoch 14, Step 6, Loss: 0.027998201549053192\n",
            "Epoch 14, Step 7, Loss: 0.027121538296341896\n",
            "Epoch 14, Step 8, Loss: 0.02407529018819332\n",
            "Epoch 14, Step 9, Loss: 0.03738641366362572\n",
            "Epoch 14, Step 10, Loss: 0.020356159657239914\n",
            "Epoch 14, Step 11, Loss: 0.015144016593694687\n",
            "Epoch 14, Step 12, Loss: 0.015267618000507355\n",
            "Epoch 14, Step 13, Loss: 0.01852802373468876\n",
            "Epoch 14, Step 14, Loss: 0.01454116776585579\n",
            "Epoch 14, Step 15, Loss: 0.017212800681591034\n",
            "Epoch 14, Step 16, Loss: 0.020392559468746185\n",
            "Epoch 14, Step 17, Loss: 0.014218189753592014\n",
            "Epoch 14, Step 18, Loss: 0.01486877165734768\n",
            "Epoch 14, Step 19, Loss: 0.007927723228931427\n",
            "Epoch 14, Step 20, Loss: 0.007900035008788109\n",
            "Epoch 14, Step 21, Loss: 0.006522160489112139\n",
            "Epoch 14, Step 22, Loss: 0.0076480405405163765\n",
            "Epoch 14, Step 23, Loss: 0.007450855802744627\n",
            "Epoch 14, Step 24, Loss: 0.02399498037993908\n",
            "Epoch 14, Step 25, Loss: 0.015025083906948566\n",
            "Epoch 14, Step 26, Loss: 0.017272602766752243\n",
            "Epoch 14, Step 27, Loss: 0.01706252060830593\n",
            "Epoch 14, Step 28, Loss: 0.02031872794032097\n",
            "Epoch 14, Step 29, Loss: 0.020537342876195908\n",
            "Epoch 14, Step 30, Loss: 0.021210405975580215\n",
            "Epoch 14, Step 31, Loss: 0.017707552760839462\n",
            "Epoch 14, Step 32, Loss: 0.013375909067690372\n",
            "Epoch 14, Step 33, Loss: 0.009255390614271164\n",
            "Epoch 14, Step 34, Loss: 0.01828116551041603\n",
            "Epoch 14, Step 35, Loss: 0.015659665688872337\n",
            "Epoch 14, Step 36, Loss: 0.013193945400416851\n",
            "Epoch 14, Step 37, Loss: 0.02297486737370491\n",
            "Epoch 14, Step 38, Loss: 0.020022116601467133\n",
            "Epoch 14, Step 39, Loss: 0.020592866465449333\n",
            "Epoch 14, Step 40, Loss: 0.020989641547203064\n",
            "Epoch 14, Step 41, Loss: 0.02444191835820675\n",
            "Epoch 14, Step 42, Loss: 0.017975719645619392\n",
            "Epoch 14, Step 43, Loss: 0.01860164850950241\n",
            "Epoch 14, Step 44, Loss: 0.026227381080389023\n",
            "Epoch 14, Step 45, Loss: 0.01751483790576458\n",
            "Epoch 14, Step 46, Loss: 0.02074618451297283\n",
            "Epoch 14, Step 47, Loss: 0.029283864423632622\n",
            "Epoch 14, Step 48, Loss: 0.023427622392773628\n",
            "Epoch 14, Step 49, Loss: 0.03127896413207054\n",
            "Epoch 14, Step 50, Loss: 0.025159800425171852\n",
            "Epoch 14, Step 51, Loss: 0.02541300840675831\n",
            "Epoch 14, Step 52, Loss: 0.020351413637399673\n",
            "Epoch 14, Step 53, Loss: 0.025509769096970558\n",
            "Train Metric MRRs: 0.09213223097803501\n",
            "Train Metric MAPs: 0.0944363683926521\n",
            "Validation Metric MRRs: 0.13075519517643874\n",
            "Validation Metric MAPs: 0.21917105842250154\n",
            "Epoch 15, Step 1, Loss: 0.026297900825738907\n",
            "Epoch 15, Step 2, Loss: 0.03471530228853226\n",
            "Epoch 15, Step 3, Loss: 0.027123598381876945\n",
            "Epoch 15, Step 4, Loss: 0.022294001653790474\n",
            "Epoch 15, Step 5, Loss: 0.02939435839653015\n",
            "Epoch 15, Step 6, Loss: 0.02883852645754814\n",
            "Epoch 15, Step 7, Loss: 0.028781602159142494\n",
            "Epoch 15, Step 8, Loss: 0.025944720953702927\n",
            "Epoch 15, Step 9, Loss: 0.039644818753004074\n",
            "Epoch 15, Step 10, Loss: 0.02008136361837387\n",
            "Epoch 15, Step 11, Loss: 0.014859700575470924\n",
            "Epoch 15, Step 12, Loss: 0.015398411080241203\n",
            "Epoch 15, Step 13, Loss: 0.018893804401159286\n",
            "Epoch 15, Step 14, Loss: 0.015177393332123756\n",
            "Epoch 15, Step 15, Loss: 0.018093323335051537\n",
            "Epoch 15, Step 16, Loss: 0.0200829915702343\n",
            "Epoch 15, Step 17, Loss: 0.013963952660560608\n",
            "Epoch 15, Step 18, Loss: 0.01453845202922821\n",
            "Epoch 15, Step 19, Loss: 0.008801947347819805\n",
            "Epoch 15, Step 20, Loss: 0.008309951983392239\n",
            "Epoch 15, Step 21, Loss: 0.0067894416861236095\n",
            "Epoch 15, Step 22, Loss: 0.007878064177930355\n",
            "Epoch 15, Step 23, Loss: 0.007480354979634285\n",
            "Epoch 15, Step 24, Loss: 0.02366284653544426\n",
            "Epoch 15, Step 25, Loss: 0.015451024286448956\n",
            "Epoch 15, Step 26, Loss: 0.01489547360688448\n",
            "Epoch 15, Step 27, Loss: 0.014847032725811005\n",
            "Epoch 15, Step 28, Loss: 0.01936039701104164\n",
            "Epoch 15, Step 29, Loss: 0.02028263732790947\n",
            "Epoch 15, Step 30, Loss: 0.020406058058142662\n",
            "Epoch 15, Step 31, Loss: 0.018041977658867836\n",
            "Epoch 15, Step 32, Loss: 0.012089784257113934\n",
            "Epoch 15, Step 33, Loss: 0.009164443239569664\n",
            "Epoch 15, Step 34, Loss: 0.018987711519002914\n",
            "Epoch 15, Step 35, Loss: 0.01649554818868637\n",
            "Epoch 15, Step 36, Loss: 0.013097316026687622\n",
            "Epoch 15, Step 37, Loss: 0.024241501465439796\n",
            "Epoch 15, Step 38, Loss: 0.020127959549427032\n",
            "Epoch 15, Step 39, Loss: 0.02131536230444908\n",
            "Epoch 15, Step 40, Loss: 0.020529456436634064\n",
            "Epoch 15, Step 41, Loss: 0.02401362732052803\n",
            "Epoch 15, Step 42, Loss: 0.017232296988368034\n",
            "Epoch 15, Step 43, Loss: 0.019365619868040085\n",
            "Epoch 15, Step 44, Loss: 0.02495879866182804\n",
            "Epoch 15, Step 45, Loss: 0.01727919466793537\n",
            "Epoch 15, Step 46, Loss: 0.020429495722055435\n",
            "Epoch 15, Step 47, Loss: 0.026506688445806503\n",
            "Epoch 15, Step 48, Loss: 0.024810198694467545\n",
            "Epoch 15, Step 49, Loss: 0.027700163424015045\n",
            "Epoch 15, Step 50, Loss: 0.02517259493470192\n",
            "Epoch 15, Step 51, Loss: 0.025442583486437798\n",
            "Epoch 15, Step 52, Loss: 0.018588801845908165\n",
            "Epoch 15, Step 53, Loss: 0.02604190818965435\n",
            "Train Metric MRRs: 0.09260357582865088\n",
            "Train Metric MAPs: 0.09083437924411175\n",
            "Validation Metric MRRs: 0.13952289950633634\n",
            "Validation Metric MAPs: 0.20803581944649616\n",
            "Epoch 16, Step 1, Loss: 0.024139001965522766\n",
            "Epoch 16, Step 2, Loss: 0.031637828797101974\n",
            "Epoch 16, Step 3, Loss: 0.024737268686294556\n",
            "Epoch 16, Step 4, Loss: 0.021144524216651917\n",
            "Epoch 16, Step 5, Loss: 0.026317419484257698\n",
            "Epoch 16, Step 6, Loss: 0.027128467336297035\n",
            "Epoch 16, Step 7, Loss: 0.02607523463666439\n",
            "Epoch 16, Step 8, Loss: 0.023836061358451843\n",
            "Epoch 16, Step 9, Loss: 0.03526546433568001\n",
            "Epoch 16, Step 10, Loss: 0.019444655627012253\n",
            "Epoch 16, Step 11, Loss: 0.014752855524420738\n",
            "Epoch 16, Step 12, Loss: 0.015121116302907467\n",
            "Epoch 16, Step 13, Loss: 0.018221965059638023\n",
            "Epoch 16, Step 14, Loss: 0.013877102173864841\n",
            "Epoch 16, Step 15, Loss: 0.01717207580804825\n",
            "Epoch 16, Step 16, Loss: 0.01959877833724022\n",
            "Epoch 16, Step 17, Loss: 0.014430499635636806\n",
            "Epoch 16, Step 18, Loss: 0.014684304594993591\n",
            "Epoch 16, Step 19, Loss: 0.007771718315780163\n",
            "Epoch 16, Step 20, Loss: 0.007921339944005013\n",
            "Epoch 16, Step 21, Loss: 0.006451909430325031\n",
            "Epoch 16, Step 22, Loss: 0.00762403616681695\n",
            "Epoch 16, Step 23, Loss: 0.00727964797988534\n",
            "Epoch 16, Step 24, Loss: 0.0241229385137558\n",
            "Epoch 16, Step 25, Loss: 0.014785979874432087\n",
            "Epoch 16, Step 26, Loss: 0.014942635782063007\n",
            "Epoch 16, Step 27, Loss: 0.01487426832318306\n",
            "Epoch 16, Step 28, Loss: 0.01995423249900341\n",
            "Epoch 16, Step 29, Loss: 0.019939064979553223\n",
            "Epoch 16, Step 30, Loss: 0.020434880629181862\n",
            "Epoch 16, Step 31, Loss: 0.017459692433476448\n",
            "Epoch 16, Step 32, Loss: 0.01220760215073824\n",
            "Epoch 16, Step 33, Loss: 0.009080384857952595\n",
            "Epoch 16, Step 34, Loss: 0.017847254872322083\n",
            "Epoch 16, Step 35, Loss: 0.015179337002336979\n",
            "Epoch 16, Step 36, Loss: 0.012850855477154255\n",
            "Epoch 16, Step 37, Loss: 0.023163285106420517\n",
            "Epoch 16, Step 38, Loss: 0.018911192193627357\n",
            "Epoch 16, Step 39, Loss: 0.0204238910228014\n",
            "Epoch 16, Step 40, Loss: 0.020745309069752693\n",
            "Epoch 16, Step 41, Loss: 0.024738874286413193\n",
            "Epoch 16, Step 42, Loss: 0.01804160699248314\n",
            "Epoch 16, Step 43, Loss: 0.01852927729487419\n",
            "Epoch 16, Step 44, Loss: 0.023894159123301506\n",
            "Epoch 16, Step 45, Loss: 0.016974586993455887\n",
            "Epoch 16, Step 46, Loss: 0.020535610616207123\n",
            "Epoch 16, Step 47, Loss: 0.024060217663645744\n",
            "Epoch 16, Step 48, Loss: 0.023773198947310448\n",
            "Epoch 16, Step 49, Loss: 0.02692187763750553\n",
            "Epoch 16, Step 50, Loss: 0.0252066757529974\n",
            "Epoch 16, Step 51, Loss: 0.02570732682943344\n",
            "Epoch 16, Step 52, Loss: 0.019890664145350456\n",
            "Epoch 16, Step 53, Loss: 0.022949181497097015\n",
            "Train Metric MRRs: 0.10275250144624208\n",
            "Train Metric MAPs: 0.09913175090586299\n",
            "Validation Metric MRRs: 0.13160848284952698\n",
            "Validation Metric MAPs: 0.21259538721243063\n",
            "Epoch 17, Step 1, Loss: 0.024628538638353348\n",
            "Epoch 17, Step 2, Loss: 0.0298603568226099\n",
            "Epoch 17, Step 3, Loss: 0.026023337617516518\n",
            "Epoch 17, Step 4, Loss: 0.020535655319690704\n",
            "Epoch 17, Step 5, Loss: 0.026409609243273735\n",
            "Epoch 17, Step 6, Loss: 0.028697941452264786\n",
            "Epoch 17, Step 7, Loss: 0.027278564870357513\n",
            "Epoch 17, Step 8, Loss: 0.024623364210128784\n",
            "Epoch 17, Step 9, Loss: 0.03636462986469269\n",
            "Epoch 17, Step 10, Loss: 0.019010722637176514\n",
            "Epoch 17, Step 11, Loss: 0.014682633802294731\n",
            "Epoch 17, Step 12, Loss: 0.015372914262115955\n",
            "Epoch 17, Step 13, Loss: 0.018050435930490494\n",
            "Epoch 17, Step 14, Loss: 0.014464355073869228\n",
            "Epoch 17, Step 15, Loss: 0.017609111964702606\n",
            "Epoch 17, Step 16, Loss: 0.019410843029618263\n",
            "Epoch 17, Step 17, Loss: 0.013697926886379719\n",
            "Epoch 17, Step 18, Loss: 0.014684467576444149\n",
            "Epoch 17, Step 19, Loss: 0.008326280862092972\n",
            "Epoch 17, Step 20, Loss: 0.008143829181790352\n",
            "Epoch 17, Step 21, Loss: 0.006645661313086748\n",
            "Epoch 17, Step 22, Loss: 0.0077592465095222\n",
            "Epoch 17, Step 23, Loss: 0.00730161601677537\n",
            "Epoch 17, Step 24, Loss: 0.023867495357990265\n",
            "Epoch 17, Step 25, Loss: 0.014707068912684917\n",
            "Epoch 17, Step 26, Loss: 0.014302253723144531\n",
            "Epoch 17, Step 27, Loss: 0.014686915092170238\n",
            "Epoch 17, Step 28, Loss: 0.019214464351534843\n",
            "Epoch 17, Step 29, Loss: 0.01978321373462677\n",
            "Epoch 17, Step 30, Loss: 0.020497795194387436\n",
            "Epoch 17, Step 31, Loss: 0.017941230908036232\n",
            "Epoch 17, Step 32, Loss: 0.011842451989650726\n",
            "Epoch 17, Step 33, Loss: 0.009041404351592064\n",
            "Epoch 17, Step 34, Loss: 0.01894855685532093\n",
            "Epoch 17, Step 35, Loss: 0.01558238361030817\n",
            "Epoch 17, Step 36, Loss: 0.012689908035099506\n",
            "Epoch 17, Step 37, Loss: 0.024428322911262512\n",
            "Epoch 17, Step 38, Loss: 0.01947908289730549\n",
            "Epoch 17, Step 39, Loss: 0.021102741360664368\n",
            "Epoch 17, Step 40, Loss: 0.020206939429044724\n",
            "Epoch 17, Step 41, Loss: 0.024094920605421066\n",
            "Epoch 17, Step 42, Loss: 0.016856800764799118\n",
            "Epoch 17, Step 43, Loss: 0.018904872238636017\n",
            "Epoch 17, Step 44, Loss: 0.022380493581295013\n",
            "Epoch 17, Step 45, Loss: 0.01675269566476345\n",
            "Epoch 17, Step 46, Loss: 0.020165713503956795\n",
            "Epoch 17, Step 47, Loss: 0.02414407767355442\n",
            "Epoch 17, Step 48, Loss: 0.024413475766777992\n",
            "Epoch 17, Step 49, Loss: 0.0256196241825819\n",
            "Epoch 17, Step 50, Loss: 0.02484838292002678\n",
            "Epoch 17, Step 51, Loss: 0.024856097996234894\n",
            "Epoch 17, Step 52, Loss: 0.01813947968184948\n",
            "Epoch 17, Step 53, Loss: 0.023675713688135147\n",
            "Train Metric MRRs: 0.10408812236558507\n",
            "Train Metric MAPs: 0.09893813024163708\n",
            "Validation Metric MRRs: 0.1427583354836924\n",
            "Validation Metric MAPs: 0.20717163862388033\n",
            "Epoch 18, Step 1, Loss: 0.023302311077713966\n",
            "Epoch 18, Step 2, Loss: 0.02891690284013748\n",
            "Epoch 18, Step 3, Loss: 0.024335406720638275\n",
            "Epoch 18, Step 4, Loss: 0.020052289590239525\n",
            "Epoch 18, Step 5, Loss: 0.02560286782681942\n",
            "Epoch 18, Step 6, Loss: 0.02722674421966076\n",
            "Epoch 18, Step 7, Loss: 0.02578599564731121\n",
            "Epoch 18, Step 8, Loss: 0.022568756714463234\n",
            "Epoch 18, Step 9, Loss: 0.03434963524341583\n",
            "Epoch 18, Step 10, Loss: 0.0188725795596838\n",
            "Epoch 18, Step 11, Loss: 0.014345075935125351\n",
            "Epoch 18, Step 12, Loss: 0.014731035567820072\n",
            "Epoch 18, Step 13, Loss: 0.017466193065047264\n",
            "Epoch 18, Step 14, Loss: 0.013505966402590275\n",
            "Epoch 18, Step 15, Loss: 0.01698211207985878\n",
            "Epoch 18, Step 16, Loss: 0.018849823623895645\n",
            "Epoch 18, Step 17, Loss: 0.014532238245010376\n",
            "Epoch 18, Step 18, Loss: 0.015039862133562565\n",
            "Epoch 18, Step 19, Loss: 0.007983584888279438\n",
            "Epoch 18, Step 20, Loss: 0.007927932776510715\n",
            "Epoch 18, Step 21, Loss: 0.006414676550775766\n",
            "Epoch 18, Step 22, Loss: 0.007566387765109539\n",
            "Epoch 18, Step 23, Loss: 0.0072178347036242485\n",
            "Epoch 18, Step 24, Loss: 0.024212226271629333\n",
            "Epoch 18, Step 25, Loss: 0.014489689841866493\n",
            "Epoch 18, Step 26, Loss: 0.014498300850391388\n",
            "Epoch 18, Step 27, Loss: 0.014390409924089909\n",
            "Epoch 18, Step 28, Loss: 0.019112158566713333\n",
            "Epoch 18, Step 29, Loss: 0.019897468388080597\n",
            "Epoch 18, Step 30, Loss: 0.020208794623613358\n",
            "Epoch 18, Step 31, Loss: 0.017458966001868248\n",
            "Epoch 18, Step 32, Loss: 0.012056478299200535\n",
            "Epoch 18, Step 33, Loss: 0.008695053867995739\n",
            "Epoch 18, Step 34, Loss: 0.017695482820272446\n",
            "Epoch 18, Step 35, Loss: 0.01470494270324707\n",
            "Epoch 18, Step 36, Loss: 0.012490161694586277\n",
            "Epoch 18, Step 37, Loss: 0.022861212491989136\n",
            "Epoch 18, Step 38, Loss: 0.01863018050789833\n",
            "Epoch 18, Step 39, Loss: 0.020008325576782227\n",
            "Epoch 18, Step 40, Loss: 0.02031916193664074\n",
            "Epoch 18, Step 41, Loss: 0.024274615570902824\n",
            "Epoch 18, Step 42, Loss: 0.01684172824025154\n",
            "Epoch 18, Step 43, Loss: 0.018102677538990974\n",
            "Epoch 18, Step 44, Loss: 0.022548111155629158\n",
            "Epoch 18, Step 45, Loss: 0.016479674726724625\n",
            "Epoch 18, Step 46, Loss: 0.020535839721560478\n",
            "Epoch 18, Step 47, Loss: 0.024045201018452644\n",
            "Epoch 18, Step 48, Loss: 0.02409369871020317\n",
            "Epoch 18, Step 49, Loss: 0.026540270075201988\n",
            "Epoch 18, Step 50, Loss: 0.02498619817197323\n",
            "Epoch 18, Step 51, Loss: 0.024700144305825233\n",
            "Epoch 18, Step 52, Loss: 0.018585121259093285\n",
            "Epoch 18, Step 53, Loss: 0.022512763738632202\n",
            "Train Metric MRRs: 0.10787600234769826\n",
            "Train Metric MAPs: 0.10217841235635332\n",
            "Validation Metric MRRs: 0.13296218078749927\n",
            "Validation Metric MAPs: 0.21085522746244623\n",
            "Epoch 19, Step 1, Loss: 0.023089826107025146\n",
            "Epoch 19, Step 2, Loss: 0.028793729841709137\n",
            "Epoch 19, Step 3, Loss: 0.02452179789543152\n",
            "Epoch 19, Step 4, Loss: 0.019815487787127495\n",
            "Epoch 19, Step 5, Loss: 0.025509916245937347\n",
            "Epoch 19, Step 6, Loss: 0.026669910177588463\n",
            "Epoch 19, Step 7, Loss: 0.02604658529162407\n",
            "Epoch 19, Step 8, Loss: 0.023244962096214294\n",
            "Epoch 19, Step 9, Loss: 0.035754669457674026\n",
            "Epoch 19, Step 10, Loss: 0.018676089122891426\n",
            "Epoch 19, Step 11, Loss: 0.014271624386310577\n",
            "Epoch 19, Step 12, Loss: 0.014993599615991116\n",
            "Epoch 19, Step 13, Loss: 0.017461499199271202\n",
            "Epoch 19, Step 14, Loss: 0.013442674651741982\n",
            "Epoch 19, Step 15, Loss: 0.01699676550924778\n",
            "Epoch 19, Step 16, Loss: 0.018836427479982376\n",
            "Epoch 19, Step 17, Loss: 0.01367184054106474\n",
            "Epoch 19, Step 18, Loss: 0.014441395178437233\n",
            "Epoch 19, Step 19, Loss: 0.00826936587691307\n",
            "Epoch 19, Step 20, Loss: 0.008116304874420166\n",
            "Epoch 19, Step 21, Loss: 0.006628713570535183\n",
            "Epoch 19, Step 22, Loss: 0.007751705124974251\n",
            "Epoch 19, Step 23, Loss: 0.007294076960533857\n",
            "Epoch 19, Step 24, Loss: 0.02381839230656624\n",
            "Epoch 19, Step 25, Loss: 0.014750905334949493\n",
            "Epoch 19, Step 26, Loss: 0.014138495549559593\n",
            "Epoch 19, Step 27, Loss: 0.014590228907763958\n",
            "Epoch 19, Step 28, Loss: 0.018557507544755936\n",
            "Epoch 19, Step 29, Loss: 0.019564537331461906\n",
            "Epoch 19, Step 30, Loss: 0.020182693377137184\n",
            "Epoch 19, Step 31, Loss: 0.017221352085471153\n",
            "Epoch 19, Step 32, Loss: 0.011402866803109646\n",
            "Epoch 19, Step 33, Loss: 0.008497149683535099\n",
            "Epoch 19, Step 34, Loss: 0.01807386428117752\n",
            "Epoch 19, Step 35, Loss: 0.014836959540843964\n",
            "Epoch 19, Step 36, Loss: 0.012462968938052654\n",
            "Epoch 19, Step 37, Loss: 0.022973356768488884\n",
            "Epoch 19, Step 38, Loss: 0.018609018996357918\n",
            "Epoch 19, Step 39, Loss: 0.02062809467315674\n",
            "Epoch 19, Step 40, Loss: 0.020148323848843575\n",
            "Epoch 19, Step 41, Loss: 0.023709772154688835\n",
            "Epoch 19, Step 42, Loss: 0.016948435455560684\n",
            "Epoch 19, Step 43, Loss: 0.018182899802923203\n",
            "Epoch 19, Step 44, Loss: 0.02170173078775406\n",
            "Epoch 19, Step 45, Loss: 0.016123203560709953\n",
            "Epoch 19, Step 46, Loss: 0.020112963393330574\n",
            "Epoch 19, Step 47, Loss: 0.023854892700910568\n",
            "Epoch 19, Step 48, Loss: 0.02315772883594036\n",
            "Epoch 19, Step 49, Loss: 0.024746345356106758\n",
            "Epoch 19, Step 50, Loss: 0.024669092148542404\n",
            "Epoch 19, Step 51, Loss: 0.024273622781038284\n",
            "Epoch 19, Step 52, Loss: 0.017937015742063522\n",
            "Epoch 19, Step 53, Loss: 0.023686470463871956\n",
            "Train Metric MRRs: 0.10803961285727386\n",
            "Train Metric MAPs: 0.10328885721199484\n",
            "Validation Metric MRRs: 0.14205971557507463\n",
            "Validation Metric MAPs: 0.20629519280901315\n",
            "Epoch 20, Step 1, Loss: 0.02253393828868866\n",
            "Epoch 20, Step 2, Loss: 0.02831491455435753\n",
            "Epoch 20, Step 3, Loss: 0.024004193022847176\n",
            "Epoch 20, Step 4, Loss: 0.019223997369408607\n",
            "Epoch 20, Step 5, Loss: 0.02455785684287548\n",
            "Epoch 20, Step 6, Loss: 0.0264178104698658\n",
            "Epoch 20, Step 7, Loss: 0.02513059601187706\n",
            "Epoch 20, Step 8, Loss: 0.02247941866517067\n",
            "Epoch 20, Step 9, Loss: 0.033850230276584625\n",
            "Epoch 20, Step 10, Loss: 0.018542863428592682\n",
            "Epoch 20, Step 11, Loss: 0.01430832501500845\n",
            "Epoch 20, Step 12, Loss: 0.014737679623067379\n",
            "Epoch 20, Step 13, Loss: 0.01756528578698635\n",
            "Epoch 20, Step 14, Loss: 0.013157143257558346\n",
            "Epoch 20, Step 15, Loss: 0.01674650050699711\n",
            "Epoch 20, Step 16, Loss: 0.018929842859506607\n",
            "Epoch 20, Step 17, Loss: 0.0134958541020751\n",
            "Epoch 20, Step 18, Loss: 0.014481048099696636\n",
            "Epoch 20, Step 19, Loss: 0.007832199335098267\n",
            "Epoch 20, Step 20, Loss: 0.007929702289402485\n",
            "Epoch 20, Step 21, Loss: 0.006525595672428608\n",
            "Epoch 20, Step 22, Loss: 0.007675463799387217\n",
            "Epoch 20, Step 23, Loss: 0.007381313946098089\n",
            "Epoch 20, Step 24, Loss: 0.023914247751235962\n",
            "Epoch 20, Step 25, Loss: 0.014466535300016403\n",
            "Epoch 20, Step 26, Loss: 0.014341514557600021\n",
            "Epoch 20, Step 27, Loss: 0.014238806441426277\n",
            "Epoch 20, Step 28, Loss: 0.01858353056013584\n",
            "Epoch 20, Step 29, Loss: 0.019266916438937187\n",
            "Epoch 20, Step 30, Loss: 0.020002935081720352\n",
            "Epoch 20, Step 31, Loss: 0.01686207763850689\n",
            "Epoch 20, Step 32, Loss: 0.011553477495908737\n",
            "Epoch 20, Step 33, Loss: 0.008655502460896969\n",
            "Epoch 20, Step 34, Loss: 0.0174398310482502\n",
            "Epoch 20, Step 35, Loss: 0.014654140919446945\n",
            "Epoch 20, Step 36, Loss: 0.012315637432038784\n",
            "Epoch 20, Step 37, Loss: 0.02240944653749466\n",
            "Epoch 20, Step 38, Loss: 0.018555467948317528\n",
            "Epoch 20, Step 39, Loss: 0.019925972446799278\n",
            "Epoch 20, Step 40, Loss: 0.020101312547922134\n",
            "Epoch 20, Step 41, Loss: 0.023733312264084816\n",
            "Epoch 20, Step 42, Loss: 0.01662248745560646\n",
            "Epoch 20, Step 43, Loss: 0.0180258397012949\n",
            "Epoch 20, Step 44, Loss: 0.02220587246119976\n",
            "Epoch 20, Step 45, Loss: 0.015994807705283165\n",
            "Epoch 20, Step 46, Loss: 0.02021191082894802\n",
            "Epoch 20, Step 47, Loss: 0.02390880510210991\n",
            "Epoch 20, Step 48, Loss: 0.022767722606658936\n",
            "Epoch 20, Step 49, Loss: 0.026019573211669922\n",
            "Epoch 20, Step 50, Loss: 0.02470346726477146\n",
            "Epoch 20, Step 51, Loss: 0.02411222830414772\n",
            "Epoch 20, Step 52, Loss: 0.01810852810740471\n",
            "Epoch 20, Step 53, Loss: 0.021972430869936943\n",
            "Train Metric MRRs: 0.10925299329302683\n",
            "Train Metric MAPs: 0.10422204661230261\n",
            "Validation Metric MRRs: 0.13596543257550378\n",
            "Validation Metric MAPs: 0.21223720956597117\n",
            "Epoch 21, Step 1, Loss: 0.02240217663347721\n",
            "Epoch 21, Step 2, Loss: 0.027422603219747543\n",
            "Epoch 21, Step 3, Loss: 0.02383156679570675\n",
            "Epoch 21, Step 4, Loss: 0.019180653616786003\n",
            "Epoch 21, Step 5, Loss: 0.02485181763768196\n",
            "Epoch 21, Step 6, Loss: 0.026340311393141747\n",
            "Epoch 21, Step 7, Loss: 0.02538284659385681\n",
            "Epoch 21, Step 8, Loss: 0.022402547299861908\n",
            "Epoch 21, Step 9, Loss: 0.034487396478652954\n",
            "Epoch 21, Step 10, Loss: 0.018269777297973633\n",
            "Epoch 21, Step 11, Loss: 0.014160904102027416\n",
            "Epoch 21, Step 12, Loss: 0.014822456054389477\n",
            "Epoch 21, Step 13, Loss: 0.017370425164699554\n",
            "Epoch 21, Step 14, Loss: 0.013125941157341003\n",
            "Epoch 21, Step 15, Loss: 0.0168265700340271\n",
            "Epoch 21, Step 16, Loss: 0.01833948865532875\n",
            "Epoch 21, Step 17, Loss: 0.013216868974268436\n",
            "Epoch 21, Step 18, Loss: 0.013995331712067127\n",
            "Epoch 21, Step 19, Loss: 0.0075971814803779125\n",
            "Epoch 21, Step 20, Loss: 0.007923737168312073\n",
            "Epoch 21, Step 21, Loss: 0.006525551434606314\n",
            "Epoch 21, Step 22, Loss: 0.00766023900359869\n",
            "Epoch 21, Step 23, Loss: 0.007220912724733353\n",
            "Epoch 21, Step 24, Loss: 0.023918194696307182\n",
            "Epoch 21, Step 25, Loss: 0.014439142309129238\n",
            "Epoch 21, Step 26, Loss: 0.013899997808039188\n",
            "Epoch 21, Step 27, Loss: 0.014264902099967003\n",
            "Epoch 21, Step 28, Loss: 0.01823575608432293\n",
            "Epoch 21, Step 29, Loss: 0.01916101761162281\n",
            "Epoch 21, Step 30, Loss: 0.019771169871091843\n",
            "Epoch 21, Step 31, Loss: 0.016873205080628395\n",
            "Epoch 21, Step 32, Loss: 0.011282267048954964\n",
            "Epoch 21, Step 33, Loss: 0.0084912134334445\n",
            "Epoch 21, Step 34, Loss: 0.017562782391905785\n",
            "Epoch 21, Step 35, Loss: 0.014560963958501816\n",
            "Epoch 21, Step 36, Loss: 0.012196645140647888\n",
            "Epoch 21, Step 37, Loss: 0.022418085485696793\n",
            "Epoch 21, Step 38, Loss: 0.018301429226994514\n",
            "Epoch 21, Step 39, Loss: 0.02002410963177681\n",
            "Epoch 21, Step 40, Loss: 0.019950425252318382\n",
            "Epoch 21, Step 41, Loss: 0.0232196357101202\n",
            "Epoch 21, Step 42, Loss: 0.016907237470149994\n",
            "Epoch 21, Step 43, Loss: 0.01790040358901024\n",
            "Epoch 21, Step 44, Loss: 0.021642426028847694\n",
            "Epoch 21, Step 45, Loss: 0.015719490125775337\n",
            "Epoch 21, Step 46, Loss: 0.019872337579727173\n",
            "Epoch 21, Step 47, Loss: 0.02374950982630253\n",
            "Epoch 21, Step 48, Loss: 0.02263198420405388\n",
            "Epoch 21, Step 49, Loss: 0.024469461292028427\n",
            "Epoch 21, Step 50, Loss: 0.02439599111676216\n",
            "Epoch 21, Step 51, Loss: 0.023839909583330154\n",
            "Epoch 21, Step 52, Loss: 0.017899896949529648\n",
            "Epoch 21, Step 53, Loss: 0.02308986335992813\n",
            "Train Metric MRRs: 0.11243901425775056\n",
            "Train Metric MAPs: 0.10599228428677515\n",
            "Validation Metric MRRs: 0.14764989681182242\n",
            "Validation Metric MAPs: 0.21469147125377677\n",
            "Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "trainer.train(config['num_epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZHIu_eBzX_eC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab5185c-ec01-4f59-a331-636bd5add4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metric MRRs: 0.14783813215445232\n",
            "Validation Metric MAPs: 0.2278318243948477\n",
            "Test Metric MRRs: 0.16334140958806345\n",
            "Test Metric MAPs: 0.11934162018561566\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.16334140958806345, 0.11934162018561566)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainer.restore_best_checkpoint()\n",
        "trainer.validate('Validation')\n",
        "trainer.validate('Test')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}