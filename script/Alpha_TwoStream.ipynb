{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFmnbM5n8fFk",
        "outputId": "2624b86d-509b-4bef-8957-aaeaa7fc42cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/mlds\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/mlds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9rULJX1_8jW4"
      },
      "outputs": [],
      "source": [
        "import data_bitcoin as btc\n",
        "import tasker_link_prediction as t_lp\n",
        "from splitter import splitter\n",
        "from models import TwoStream_GCN\n",
        "from trainer import Trainer\n",
        "import yaml\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvGXFPFi825w",
        "outputId": "0d38e410-ab09-498b-9852-cc59738f71bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_config': {'adam_beta_1': 0.9,\n",
              "  'adam_beta_2': 0.999,\n",
              "  'adam_epsilon': 1e-07,\n",
              "  'adam_learning_rate': 0.005},\n",
              " 'model_path': 'models/BTC_ALPHA_TwoStream/',\n",
              " 'classifier_hidden_size': 16,\n",
              " 'ffn_fusion_size': 8,\n",
              " 'ffn_hidden_size': 8,\n",
              " 'gcn_fusion_size': 16,\n",
              " 'spatial_hidden_size': 16,\n",
              " 'spatial_input_dim': 128,\n",
              " 'temporal_hidden_size': 16,\n",
              " 'temporal_input_dim': 100,\n",
              " 'num_epochs': 1000,\n",
              " 'patience': 10,\n",
              " 'major_threshold': None,\n",
              " 'train_proportion': 0.7,\n",
              " 'dev_proportion': 0.1,\n",
              " 'data_path': 'data/BTC-ALPHA/',\n",
              " 'prep_data_path': 'prep_data/BTC_Alpha_neg/'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "prep = False\n",
        "\n",
        "with open('config/config_BTC_Alpha.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "model_path = config['model_path']\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "    os.mkdir(model_path + \"best_checkpoints/\")\n",
        "    os.mkdir(model_path + \"latest_checkpoints/\")\n",
        "\n",
        "with open(model_path + 'config.yaml', 'w') as file:\n",
        "    yaml.dump(config, file)\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n2tmk8H89Sw",
        "outputId": "ab387f51-2393-4452-bd6d-ec3208b89a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits sizes:  train 85 dev 14 test 28\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "data = btc.Bitcoin_Dataset(config['data_path'])\n",
        "tasker = t_lp.Link_Pred_Tasker(data, path=config['prep_data_path'], prep=prep,\n",
        "                               embs_dim=config['spatial_input_dim'], temp_dim=int(config['temporal_input_dim']/10),\n",
        "                               major_threshold=config['major_threshold'], smart_neg_sampling=True)\n",
        "\n",
        "splitter_as = splitter(tasker, train_proportion = config['train_proportion'], dev_proportion = config['dev_proportion'])\n",
        "\n",
        "model= TwoStream_GCN(spatial_input_dim=config['spatial_input_dim'],\n",
        "                 temporal_input_dim=config['temporal_input_dim'],\n",
        "                 spatial_hidden_size=config['spatial_hidden_size'],\n",
        "                 temporal_hidden_size=config['temporal_hidden_size'],\n",
        "                 classifier_hidden_size=config['classifier_hidden_size'],\n",
        "                 gcn_fusion_size=config['gcn_fusion_size'],\n",
        "                 ffn_fusion_size=config['ffn_fusion_size'],\n",
        "                 ffn_hiden_size=config['ffn_hidden_size'])\n",
        "\n",
        "trainer = Trainer(model=model, splitter=splitter_as, model_path=model_path, adam_config=config['adam_config'], patience=config['patience'])\n",
        "print(trainer.patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeDJaNaz9BxO",
        "outputId": "3556af35-c40c-439e-e5dd-8f3069ea153b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x786658182c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x786658182c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 1, Loss: 0.1733287125825882\n",
            "Epoch 1, Step 2, Loss: 0.10458362102508545\n",
            "Epoch 1, Step 3, Loss: 0.062306445091962814\n",
            "Epoch 1, Step 4, Loss: 0.04302606359124184\n",
            "Epoch 1, Step 5, Loss: 0.03300022333860397\n",
            "Epoch 1, Step 6, Loss: 0.02978115901350975\n",
            "Epoch 1, Step 7, Loss: 0.022732138633728027\n",
            "Epoch 1, Step 8, Loss: 0.025269048288464546\n",
            "Epoch 1, Step 9, Loss: 0.028072645887732506\n",
            "Epoch 1, Step 10, Loss: 0.02765924111008644\n",
            "Epoch 1, Step 11, Loss: 0.02749880775809288\n",
            "Epoch 1, Step 12, Loss: 0.025049634277820587\n",
            "Epoch 1, Step 13, Loss: 0.02298593707382679\n",
            "Epoch 1, Step 14, Loss: 0.024360191076993942\n",
            "Epoch 1, Step 15, Loss: 0.019532203674316406\n",
            "Epoch 1, Step 16, Loss: 0.023162880912423134\n",
            "Epoch 1, Step 17, Loss: 0.03698485344648361\n",
            "Epoch 1, Step 18, Loss: 0.03641583025455475\n",
            "Epoch 1, Step 19, Loss: 0.04554881528019905\n",
            "Epoch 1, Step 20, Loss: 0.04745347425341606\n",
            "Epoch 1, Step 21, Loss: 0.030330508947372437\n",
            "Epoch 1, Step 22, Loss: 0.03368528559803963\n",
            "Epoch 1, Step 23, Loss: 0.03253630921244621\n",
            "Epoch 1, Step 24, Loss: 0.03321035951375961\n",
            "Epoch 1, Step 25, Loss: 0.025741074234247208\n",
            "Epoch 1, Step 26, Loss: 0.026949407532811165\n",
            "Epoch 1, Step 27, Loss: 0.023322181776165962\n",
            "Epoch 1, Step 28, Loss: 0.02164987474679947\n",
            "Epoch 1, Step 29, Loss: 0.02240009792149067\n",
            "Epoch 1, Step 30, Loss: 0.02324630320072174\n",
            "Epoch 1, Step 31, Loss: 0.023529037833213806\n",
            "Epoch 1, Step 32, Loss: 0.022398730739951134\n",
            "Epoch 1, Step 33, Loss: 0.02208642289042473\n",
            "Epoch 1, Step 34, Loss: 0.022278599441051483\n",
            "Epoch 1, Step 35, Loss: 0.02032969333231449\n",
            "Epoch 1, Step 36, Loss: 0.01713402569293976\n",
            "Epoch 1, Step 37, Loss: 0.01905134506523609\n",
            "Epoch 1, Step 38, Loss: 0.016502156853675842\n",
            "Epoch 1, Step 39, Loss: 0.018693726509809494\n",
            "Epoch 1, Step 40, Loss: 0.018773972988128662\n",
            "Epoch 1, Step 41, Loss: 0.01605232246220112\n",
            "Epoch 1, Step 42, Loss: 0.013627363368868828\n",
            "Epoch 1, Step 43, Loss: 0.014274475164711475\n",
            "Epoch 1, Step 44, Loss: 0.014533366076648235\n",
            "Epoch 1, Step 45, Loss: 0.016209641471505165\n",
            "Epoch 1, Step 46, Loss: 0.014282608404755592\n",
            "Epoch 1, Step 47, Loss: 0.015267647802829742\n",
            "Epoch 1, Step 48, Loss: 0.014537794515490532\n",
            "Epoch 1, Step 49, Loss: 0.014943948946893215\n",
            "Epoch 1, Step 50, Loss: 0.016673201695084572\n",
            "Epoch 1, Step 51, Loss: 0.01568474806845188\n",
            "Epoch 1, Step 52, Loss: 0.015055103227496147\n",
            "Epoch 1, Step 53, Loss: 0.0185091570019722\n",
            "Epoch 1, Step 54, Loss: 0.012695014476776123\n",
            "Epoch 1, Step 55, Loss: 0.012186247855424881\n",
            "Epoch 1, Step 56, Loss: 0.01288231834769249\n",
            "Epoch 1, Step 57, Loss: 0.01171207521110773\n",
            "Epoch 1, Step 58, Loss: 0.011946258135139942\n",
            "Epoch 1, Step 59, Loss: 0.011165133677423\n",
            "Epoch 1, Step 60, Loss: 0.011141478084027767\n",
            "Epoch 1, Step 61, Loss: 0.01437261514365673\n",
            "Epoch 1, Step 62, Loss: 0.01155142579227686\n",
            "Epoch 1, Step 63, Loss: 0.012658223509788513\n",
            "Epoch 1, Step 64, Loss: 0.012188305146992207\n",
            "Epoch 1, Step 65, Loss: 0.012222806923091412\n",
            "Epoch 1, Step 66, Loss: 0.01254083402454853\n",
            "Epoch 1, Step 67, Loss: 0.014873916283249855\n",
            "Epoch 1, Step 68, Loss: 0.013187352567911148\n",
            "Epoch 1, Step 69, Loss: 0.01480159256607294\n",
            "Epoch 1, Step 70, Loss: 0.01718544401228428\n",
            "Epoch 1, Step 71, Loss: 0.01611713133752346\n",
            "Epoch 1, Step 72, Loss: 0.015137297101318836\n",
            "Epoch 1, Step 73, Loss: 0.013540727086365223\n",
            "Epoch 1, Step 74, Loss: 0.013049979694187641\n",
            "Epoch 1, Step 75, Loss: 0.01371877919882536\n",
            "Epoch 1, Step 76, Loss: 0.015144758857786655\n",
            "Epoch 1, Step 77, Loss: 0.014299893751740456\n",
            "Epoch 1, Step 78, Loss: 0.013437170535326004\n",
            "Epoch 1, Step 79, Loss: 0.015652665868401527\n",
            "Epoch 1, Step 80, Loss: 0.013811441138386726\n",
            "Epoch 1, Step 81, Loss: 0.023457765579223633\n",
            "Epoch 1, Step 82, Loss: 0.016176192089915276\n",
            "Epoch 1, Step 83, Loss: 0.01757749915122986\n",
            "Epoch 1, Step 84, Loss: 0.01698177494108677\n",
            "Epoch 1, Step 85, Loss: 0.018454086035490036\n",
            "Train Metric MRRs: 0.0663950734746907\n",
            "Train Metric MAPs: 0.010723442848422344\n",
            "Validation Metric MRRs: 0.027500008349170376\n",
            "Validation Metric MAPs: 0.006594227525223094\n",
            "Epoch 2, Step 1, Loss: 0.06346805393695831\n",
            "Epoch 2, Step 2, Loss: 0.045536261051893234\n",
            "Epoch 2, Step 3, Loss: 0.038525741547346115\n",
            "Epoch 2, Step 4, Loss: 0.030810218304395676\n",
            "Epoch 2, Step 5, Loss: 0.027013907209038734\n",
            "Epoch 2, Step 6, Loss: 0.025212235748767853\n",
            "Epoch 2, Step 7, Loss: 0.02277177758514881\n",
            "Epoch 2, Step 8, Loss: 0.019608138129115105\n",
            "Epoch 2, Step 9, Loss: 0.0167966578155756\n",
            "Epoch 2, Step 10, Loss: 0.014131362549960613\n",
            "Epoch 2, Step 11, Loss: 0.01299714483320713\n",
            "Epoch 2, Step 12, Loss: 0.011197916232049465\n",
            "Epoch 2, Step 13, Loss: 0.010863367468118668\n",
            "Epoch 2, Step 14, Loss: 0.009190661832690239\n",
            "Epoch 2, Step 15, Loss: 0.00830569677054882\n",
            "Epoch 2, Step 16, Loss: 0.00944559182971716\n",
            "Epoch 2, Step 17, Loss: 0.013820651918649673\n",
            "Epoch 2, Step 18, Loss: 0.014846816658973694\n",
            "Epoch 2, Step 19, Loss: 0.020276803523302078\n",
            "Epoch 2, Step 20, Loss: 0.020563924685120583\n",
            "Epoch 2, Step 21, Loss: 0.017267117276787758\n",
            "Epoch 2, Step 22, Loss: 0.020415501669049263\n",
            "Epoch 2, Step 23, Loss: 0.024414584040641785\n",
            "Epoch 2, Step 24, Loss: 0.024283068254590034\n",
            "Epoch 2, Step 25, Loss: 0.02060203067958355\n",
            "Epoch 2, Step 26, Loss: 0.019106168299913406\n",
            "Epoch 2, Step 27, Loss: 0.015571982599794865\n",
            "Epoch 2, Step 28, Loss: 0.016326116397976875\n",
            "Epoch 2, Step 29, Loss: 0.01628231443464756\n",
            "Epoch 2, Step 30, Loss: 0.01433086208999157\n",
            "Epoch 2, Step 31, Loss: 0.016234468668699265\n",
            "Epoch 2, Step 32, Loss: 0.014762289822101593\n",
            "Epoch 2, Step 33, Loss: 0.015108827501535416\n",
            "Epoch 2, Step 34, Loss: 0.014225062914192677\n",
            "Epoch 2, Step 35, Loss: 0.014850222505629063\n",
            "Epoch 2, Step 36, Loss: 0.013648338615894318\n",
            "Epoch 2, Step 37, Loss: 0.014886045828461647\n",
            "Epoch 2, Step 38, Loss: 0.013894450850784779\n",
            "Epoch 2, Step 39, Loss: 0.014325269497931004\n",
            "Epoch 2, Step 40, Loss: 0.014609087258577347\n",
            "Epoch 2, Step 41, Loss: 0.013115900568664074\n",
            "Epoch 2, Step 42, Loss: 0.011589225381612778\n",
            "Epoch 2, Step 43, Loss: 0.011376171372830868\n",
            "Epoch 2, Step 44, Loss: 0.01168785709887743\n",
            "Epoch 2, Step 45, Loss: 0.01271883025765419\n",
            "Epoch 2, Step 46, Loss: 0.011487741023302078\n",
            "Epoch 2, Step 47, Loss: 0.012079322710633278\n",
            "Epoch 2, Step 48, Loss: 0.011252538301050663\n",
            "Epoch 2, Step 49, Loss: 0.01076128426939249\n",
            "Epoch 2, Step 50, Loss: 0.011213489808142185\n",
            "Epoch 2, Step 51, Loss: 0.011353000067174435\n",
            "Epoch 2, Step 52, Loss: 0.011752489022910595\n",
            "Epoch 2, Step 53, Loss: 0.015403209254145622\n",
            "Epoch 2, Step 54, Loss: 0.01068933680653572\n",
            "Epoch 2, Step 55, Loss: 0.010103562846779823\n",
            "Epoch 2, Step 56, Loss: 0.010751117020845413\n",
            "Epoch 2, Step 57, Loss: 0.009675025939941406\n",
            "Epoch 2, Step 58, Loss: 0.009490683674812317\n",
            "Epoch 2, Step 59, Loss: 0.009254428558051586\n",
            "Epoch 2, Step 60, Loss: 0.009273515082895756\n",
            "Epoch 2, Step 61, Loss: 0.011812252923846245\n",
            "Epoch 2, Step 62, Loss: 0.009704171679913998\n",
            "Epoch 2, Step 63, Loss: 0.010301955044269562\n",
            "Epoch 2, Step 64, Loss: 0.010064372792840004\n",
            "Epoch 2, Step 65, Loss: 0.010468579828739166\n",
            "Epoch 2, Step 66, Loss: 0.010733459144830704\n",
            "Epoch 2, Step 67, Loss: 0.012592575512826443\n",
            "Epoch 2, Step 68, Loss: 0.011114484630525112\n",
            "Epoch 2, Step 69, Loss: 0.012354100123047829\n",
            "Epoch 2, Step 70, Loss: 0.015000155195593834\n",
            "Epoch 2, Step 71, Loss: 0.013875461183488369\n",
            "Epoch 2, Step 72, Loss: 0.013713530264794827\n",
            "Epoch 2, Step 73, Loss: 0.011508037336170673\n",
            "Epoch 2, Step 74, Loss: 0.011105065234005451\n",
            "Epoch 2, Step 75, Loss: 0.011806055903434753\n",
            "Epoch 2, Step 76, Loss: 0.01264798641204834\n",
            "Epoch 2, Step 77, Loss: 0.012944014742970467\n",
            "Epoch 2, Step 78, Loss: 0.011046355590224266\n",
            "Epoch 2, Step 79, Loss: 0.011736312881112099\n",
            "Epoch 2, Step 80, Loss: 0.012102175503969193\n",
            "Epoch 2, Step 81, Loss: 0.018149610608816147\n",
            "Epoch 2, Step 82, Loss: 0.014430317096412182\n",
            "Epoch 2, Step 83, Loss: 0.013762806542217731\n",
            "Epoch 2, Step 84, Loss: 0.014443759806454182\n",
            "Epoch 2, Step 85, Loss: 0.016778158023953438\n",
            "Train Metric MRRs: 0.025550044474647204\n",
            "Train Metric MAPs: 0.007754880289343218\n",
            "Validation Metric MRRs: 0.04065440525657497\n",
            "Validation Metric MAPs: 0.008928686160848397\n",
            "Epoch 3, Step 1, Loss: 0.051162105053663254\n",
            "Epoch 3, Step 2, Loss: 0.039540305733680725\n",
            "Epoch 3, Step 3, Loss: 0.036186110228300095\n",
            "Epoch 3, Step 4, Loss: 0.026523642241954803\n",
            "Epoch 3, Step 5, Loss: 0.020899979397654533\n",
            "Epoch 3, Step 6, Loss: 0.018959609791636467\n",
            "Epoch 3, Step 7, Loss: 0.015602849423885345\n",
            "Epoch 3, Step 8, Loss: 0.013840843923389912\n",
            "Epoch 3, Step 9, Loss: 0.012881328351795673\n",
            "Epoch 3, Step 10, Loss: 0.011857765726745129\n",
            "Epoch 3, Step 11, Loss: 0.01106980349868536\n",
            "Epoch 3, Step 12, Loss: 0.010060276836156845\n",
            "Epoch 3, Step 13, Loss: 0.010182885453104973\n",
            "Epoch 3, Step 14, Loss: 0.008469211868941784\n",
            "Epoch 3, Step 15, Loss: 0.007638882379978895\n",
            "Epoch 3, Step 16, Loss: 0.008370118215680122\n",
            "Epoch 3, Step 17, Loss: 0.011122909374535084\n",
            "Epoch 3, Step 18, Loss: 0.012354560196399689\n",
            "Epoch 3, Step 19, Loss: 0.015907419845461845\n",
            "Epoch 3, Step 20, Loss: 0.016153274103999138\n",
            "Epoch 3, Step 21, Loss: 0.014604530297219753\n",
            "Epoch 3, Step 22, Loss: 0.016329890117049217\n",
            "Epoch 3, Step 23, Loss: 0.018286142498254776\n",
            "Epoch 3, Step 24, Loss: 0.018633248284459114\n",
            "Epoch 3, Step 25, Loss: 0.018325984477996826\n",
            "Epoch 3, Step 26, Loss: 0.016857055947184563\n",
            "Epoch 3, Step 27, Loss: 0.013564432971179485\n",
            "Epoch 3, Step 28, Loss: 0.015258322469890118\n",
            "Epoch 3, Step 29, Loss: 0.014873235486447811\n",
            "Epoch 3, Step 30, Loss: 0.01334321592003107\n",
            "Epoch 3, Step 31, Loss: 0.01511783804744482\n",
            "Epoch 3, Step 32, Loss: 0.014147828333079815\n",
            "Epoch 3, Step 33, Loss: 0.014363891445100307\n",
            "Epoch 3, Step 34, Loss: 0.01267101988196373\n",
            "Epoch 3, Step 35, Loss: 0.013690555468201637\n",
            "Epoch 3, Step 36, Loss: 0.012171801179647446\n",
            "Epoch 3, Step 37, Loss: 0.013941645622253418\n",
            "Epoch 3, Step 38, Loss: 0.012464833445847034\n",
            "Epoch 3, Step 39, Loss: 0.01331844087690115\n",
            "Epoch 3, Step 40, Loss: 0.013830376788973808\n",
            "Epoch 3, Step 41, Loss: 0.012346538715064526\n",
            "Epoch 3, Step 42, Loss: 0.011087617836892605\n",
            "Epoch 3, Step 43, Loss: 0.010432920418679714\n",
            "Epoch 3, Step 44, Loss: 0.01091777253895998\n",
            "Epoch 3, Step 45, Loss: 0.012062122114002705\n",
            "Epoch 3, Step 46, Loss: 0.010797226801514626\n",
            "Epoch 3, Step 47, Loss: 0.011250805109739304\n",
            "Epoch 3, Step 48, Loss: 0.010763464495539665\n",
            "Epoch 3, Step 49, Loss: 0.010353641584515572\n",
            "Epoch 3, Step 50, Loss: 0.010459003038704395\n",
            "Epoch 3, Step 51, Loss: 0.010606693103909492\n",
            "Epoch 3, Step 52, Loss: 0.010691333562135696\n",
            "Epoch 3, Step 53, Loss: 0.014208176173269749\n",
            "Epoch 3, Step 54, Loss: 0.00989267323166132\n",
            "Epoch 3, Step 55, Loss: 0.009456203319132328\n",
            "Epoch 3, Step 56, Loss: 0.010234424844384193\n",
            "Epoch 3, Step 57, Loss: 0.009293434210121632\n",
            "Epoch 3, Step 58, Loss: 0.00933669414371252\n",
            "Epoch 3, Step 59, Loss: 0.008779621683061123\n",
            "Epoch 3, Step 60, Loss: 0.008699995465576649\n",
            "Epoch 3, Step 61, Loss: 0.011397087015211582\n",
            "Epoch 3, Step 62, Loss: 0.008981027640402317\n",
            "Epoch 3, Step 63, Loss: 0.009992650710046291\n",
            "Epoch 3, Step 64, Loss: 0.009623642079532146\n",
            "Epoch 3, Step 65, Loss: 0.009869799017906189\n",
            "Epoch 3, Step 66, Loss: 0.010269325226545334\n",
            "Epoch 3, Step 67, Loss: 0.01187894493341446\n",
            "Epoch 3, Step 68, Loss: 0.010871120728552341\n",
            "Epoch 3, Step 69, Loss: 0.011979848146438599\n",
            "Epoch 3, Step 70, Loss: 0.014228962361812592\n",
            "Epoch 3, Step 71, Loss: 0.013258327730000019\n",
            "Epoch 3, Step 72, Loss: 0.012304471805691719\n",
            "Epoch 3, Step 73, Loss: 0.010840569622814655\n",
            "Epoch 3, Step 74, Loss: 0.010616501793265343\n",
            "Epoch 3, Step 75, Loss: 0.01140510756522417\n",
            "Epoch 3, Step 76, Loss: 0.012127308174967766\n",
            "Epoch 3, Step 77, Loss: 0.012345635332167149\n",
            "Epoch 3, Step 78, Loss: 0.010248695500195026\n",
            "Epoch 3, Step 79, Loss: 0.010879036039113998\n",
            "Epoch 3, Step 80, Loss: 0.011512727476656437\n",
            "Epoch 3, Step 81, Loss: 0.016697287559509277\n",
            "Epoch 3, Step 82, Loss: 0.014042336493730545\n",
            "Epoch 3, Step 83, Loss: 0.013006524182856083\n",
            "Epoch 3, Step 84, Loss: 0.013614768162369728\n",
            "Epoch 3, Step 85, Loss: 0.01591426320374012\n",
            "Train Metric MRRs: 0.04411207078941047\n",
            "Train Metric MAPs: 0.0132777054586956\n",
            "Validation Metric MRRs: 0.05188112775949914\n",
            "Validation Metric MAPs: 0.013707988770441343\n",
            "Epoch 4, Step 1, Loss: 0.044033732265233994\n",
            "Epoch 4, Step 2, Loss: 0.03733937069773674\n",
            "Epoch 4, Step 3, Loss: 0.03458438441157341\n",
            "Epoch 4, Step 4, Loss: 0.02455447055399418\n",
            "Epoch 4, Step 5, Loss: 0.019020451232790947\n",
            "Epoch 4, Step 6, Loss: 0.01670488715171814\n",
            "Epoch 4, Step 7, Loss: 0.013035766780376434\n",
            "Epoch 4, Step 8, Loss: 0.011731318198144436\n",
            "Epoch 4, Step 9, Loss: 0.010927485302090645\n",
            "Epoch 4, Step 10, Loss: 0.010321890003979206\n",
            "Epoch 4, Step 11, Loss: 0.010254143737256527\n",
            "Epoch 4, Step 12, Loss: 0.009380245581269264\n",
            "Epoch 4, Step 13, Loss: 0.009784482419490814\n",
            "Epoch 4, Step 14, Loss: 0.007887797430157661\n",
            "Epoch 4, Step 15, Loss: 0.007681956514716148\n",
            "Epoch 4, Step 16, Loss: 0.008057926781475544\n",
            "Epoch 4, Step 17, Loss: 0.010817970149219036\n",
            "Epoch 4, Step 18, Loss: 0.012027738615870476\n",
            "Epoch 4, Step 19, Loss: 0.015378212556242943\n",
            "Epoch 4, Step 20, Loss: 0.015581784769892693\n",
            "Epoch 4, Step 21, Loss: 0.014779421500861645\n",
            "Epoch 4, Step 22, Loss: 0.015718381851911545\n",
            "Epoch 4, Step 23, Loss: 0.017894241958856583\n",
            "Epoch 4, Step 24, Loss: 0.01791287399828434\n",
            "Epoch 4, Step 25, Loss: 0.017160817980766296\n",
            "Epoch 4, Step 26, Loss: 0.01579335331916809\n",
            "Epoch 4, Step 27, Loss: 0.012961729429662228\n",
            "Epoch 4, Step 28, Loss: 0.01437725592404604\n",
            "Epoch 4, Step 29, Loss: 0.014339507557451725\n",
            "Epoch 4, Step 30, Loss: 0.013069135136902332\n",
            "Epoch 4, Step 31, Loss: 0.014718374237418175\n",
            "Epoch 4, Step 32, Loss: 0.013670689426362514\n",
            "Epoch 4, Step 33, Loss: 0.013892124406993389\n",
            "Epoch 4, Step 34, Loss: 0.01213011797517538\n",
            "Epoch 4, Step 35, Loss: 0.013420655392110348\n",
            "Epoch 4, Step 36, Loss: 0.011755620129406452\n",
            "Epoch 4, Step 37, Loss: 0.013483104296028614\n",
            "Epoch 4, Step 38, Loss: 0.011860824190080166\n",
            "Epoch 4, Step 39, Loss: 0.012878429144620895\n",
            "Epoch 4, Step 40, Loss: 0.013322822749614716\n",
            "Epoch 4, Step 41, Loss: 0.011548582464456558\n",
            "Epoch 4, Step 42, Loss: 0.010745513252913952\n",
            "Epoch 4, Step 43, Loss: 0.009977413341403008\n",
            "Epoch 4, Step 44, Loss: 0.010406190529465675\n",
            "Epoch 4, Step 45, Loss: 0.011565336026251316\n",
            "Epoch 4, Step 46, Loss: 0.010457316413521767\n",
            "Epoch 4, Step 47, Loss: 0.010823042131960392\n",
            "Epoch 4, Step 48, Loss: 0.010283323936164379\n",
            "Epoch 4, Step 49, Loss: 0.010072296485304832\n",
            "Epoch 4, Step 50, Loss: 0.009973617270588875\n",
            "Epoch 4, Step 51, Loss: 0.01034344732761383\n",
            "Epoch 4, Step 52, Loss: 0.010117159225046635\n",
            "Epoch 4, Step 53, Loss: 0.0132905887439847\n",
            "Epoch 4, Step 54, Loss: 0.009355220943689346\n",
            "Epoch 4, Step 55, Loss: 0.009114474058151245\n",
            "Epoch 4, Step 56, Loss: 0.009883909486234188\n",
            "Epoch 4, Step 57, Loss: 0.009021244011819363\n",
            "Epoch 4, Step 58, Loss: 0.009112977422773838\n",
            "Epoch 4, Step 59, Loss: 0.008490031585097313\n",
            "Epoch 4, Step 60, Loss: 0.008398852311074734\n",
            "Epoch 4, Step 61, Loss: 0.01105129811912775\n",
            "Epoch 4, Step 62, Loss: 0.00863880105316639\n",
            "Epoch 4, Step 63, Loss: 0.009552615694701672\n",
            "Epoch 4, Step 64, Loss: 0.009093964472413063\n",
            "Epoch 4, Step 65, Loss: 0.009406324476003647\n",
            "Epoch 4, Step 66, Loss: 0.009983088821172714\n",
            "Epoch 4, Step 67, Loss: 0.01153426431119442\n",
            "Epoch 4, Step 68, Loss: 0.010617122985422611\n",
            "Epoch 4, Step 69, Loss: 0.011624157428741455\n",
            "Epoch 4, Step 70, Loss: 0.013533573597669601\n",
            "Epoch 4, Step 71, Loss: 0.012863371521234512\n",
            "Epoch 4, Step 72, Loss: 0.0115826316177845\n",
            "Epoch 4, Step 73, Loss: 0.010449811816215515\n",
            "Epoch 4, Step 74, Loss: 0.010511422529816628\n",
            "Epoch 4, Step 75, Loss: 0.01132331881672144\n",
            "Epoch 4, Step 76, Loss: 0.011656317859888077\n",
            "Epoch 4, Step 77, Loss: 0.012018824927508831\n",
            "Epoch 4, Step 78, Loss: 0.009623744525015354\n",
            "Epoch 4, Step 79, Loss: 0.010396036319434643\n",
            "Epoch 4, Step 80, Loss: 0.010846315883100033\n",
            "Epoch 4, Step 81, Loss: 0.0158197320997715\n",
            "Epoch 4, Step 82, Loss: 0.013365569524466991\n",
            "Epoch 4, Step 83, Loss: 0.012347836047410965\n",
            "Epoch 4, Step 84, Loss: 0.012986375950276852\n",
            "Epoch 4, Step 85, Loss: 0.015400728210806847\n",
            "Train Metric MRRs: 0.05838671442958923\n",
            "Train Metric MAPs: 0.0181155037683458\n",
            "Validation Metric MRRs: 0.06299900051043378\n",
            "Validation Metric MAPs: 0.03166345116295067\n",
            "Epoch 5, Step 1, Loss: 0.036282770335674286\n",
            "Epoch 5, Step 2, Loss: 0.03448925167322159\n",
            "Epoch 5, Step 3, Loss: 0.03282168507575989\n",
            "Epoch 5, Step 4, Loss: 0.022769389674067497\n",
            "Epoch 5, Step 5, Loss: 0.016776105388998985\n",
            "Epoch 5, Step 6, Loss: 0.01445602998137474\n",
            "Epoch 5, Step 7, Loss: 0.010972809046506882\n",
            "Epoch 5, Step 8, Loss: 0.010657663457095623\n",
            "Epoch 5, Step 9, Loss: 0.010052830912172794\n",
            "Epoch 5, Step 10, Loss: 0.009282533079385757\n",
            "Epoch 5, Step 11, Loss: 0.00913967564702034\n",
            "Epoch 5, Step 12, Loss: 0.008244019001722336\n",
            "Epoch 5, Step 13, Loss: 0.007745963986963034\n",
            "Epoch 5, Step 14, Loss: 0.006633884739130735\n",
            "Epoch 5, Step 15, Loss: 0.006817078683525324\n",
            "Epoch 5, Step 16, Loss: 0.007178057916462421\n",
            "Epoch 5, Step 17, Loss: 0.009641996584832668\n",
            "Epoch 5, Step 18, Loss: 0.01065769698470831\n",
            "Epoch 5, Step 19, Loss: 0.013951567001640797\n",
            "Epoch 5, Step 20, Loss: 0.013684417121112347\n",
            "Epoch 5, Step 21, Loss: 0.013102470897138119\n",
            "Epoch 5, Step 22, Loss: 0.014129960909485817\n",
            "Epoch 5, Step 23, Loss: 0.016063246876001358\n",
            "Epoch 5, Step 24, Loss: 0.015618124976754189\n",
            "Epoch 5, Step 25, Loss: 0.0153153445571661\n",
            "Epoch 5, Step 26, Loss: 0.014577225781977177\n",
            "Epoch 5, Step 27, Loss: 0.012191930785775185\n",
            "Epoch 5, Step 28, Loss: 0.013876753859221935\n",
            "Epoch 5, Step 29, Loss: 0.013306484557688236\n",
            "Epoch 5, Step 30, Loss: 0.011777760460972786\n",
            "Epoch 5, Step 31, Loss: 0.013557285070419312\n",
            "Epoch 5, Step 32, Loss: 0.012437526136636734\n",
            "Epoch 5, Step 33, Loss: 0.012809565290808678\n",
            "Epoch 5, Step 34, Loss: 0.011631441302597523\n",
            "Epoch 5, Step 35, Loss: 0.012484068050980568\n",
            "Epoch 5, Step 36, Loss: 0.010732319205999374\n",
            "Epoch 5, Step 37, Loss: 0.012392660602927208\n",
            "Epoch 5, Step 38, Loss: 0.011083979159593582\n",
            "Epoch 5, Step 39, Loss: 0.011908471584320068\n",
            "Epoch 5, Step 40, Loss: 0.012631737627089024\n",
            "Epoch 5, Step 41, Loss: 0.010441740974783897\n",
            "Epoch 5, Step 42, Loss: 0.01001905556768179\n",
            "Epoch 5, Step 43, Loss: 0.009151761420071125\n",
            "Epoch 5, Step 44, Loss: 0.009441911242902279\n",
            "Epoch 5, Step 45, Loss: 0.010657993145287037\n",
            "Epoch 5, Step 46, Loss: 0.009908100590109825\n",
            "Epoch 5, Step 47, Loss: 0.010072543285787106\n",
            "Epoch 5, Step 48, Loss: 0.009515582583844662\n",
            "Epoch 5, Step 49, Loss: 0.009326240047812462\n",
            "Epoch 5, Step 50, Loss: 0.00914559792727232\n",
            "Epoch 5, Step 51, Loss: 0.009450615383684635\n",
            "Epoch 5, Step 52, Loss: 0.008721858263015747\n",
            "Epoch 5, Step 53, Loss: 0.011768707074224949\n",
            "Epoch 5, Step 54, Loss: 0.008340269327163696\n",
            "Epoch 5, Step 55, Loss: 0.008619830943644047\n",
            "Epoch 5, Step 56, Loss: 0.008991464041173458\n",
            "Epoch 5, Step 57, Loss: 0.008401216939091682\n",
            "Epoch 5, Step 58, Loss: 0.008561471477150917\n",
            "Epoch 5, Step 59, Loss: 0.007844529114663601\n",
            "Epoch 5, Step 60, Loss: 0.007900860160589218\n",
            "Epoch 5, Step 61, Loss: 0.010549117811024189\n",
            "Epoch 5, Step 62, Loss: 0.008230502717196941\n",
            "Epoch 5, Step 63, Loss: 0.008983799256384373\n",
            "Epoch 5, Step 64, Loss: 0.008267542347311974\n",
            "Epoch 5, Step 65, Loss: 0.008737473748624325\n",
            "Epoch 5, Step 66, Loss: 0.0094235148280859\n",
            "Epoch 5, Step 67, Loss: 0.0110278045758605\n",
            "Epoch 5, Step 68, Loss: 0.009852314367890358\n",
            "Epoch 5, Step 69, Loss: 0.01061796210706234\n",
            "Epoch 5, Step 70, Loss: 0.011949945241212845\n",
            "Epoch 5, Step 71, Loss: 0.011668210849165916\n",
            "Epoch 5, Step 72, Loss: 0.010592086240649223\n",
            "Epoch 5, Step 73, Loss: 0.009727904573082924\n",
            "Epoch 5, Step 74, Loss: 0.009862402454018593\n",
            "Epoch 5, Step 75, Loss: 0.0109756113961339\n",
            "Epoch 5, Step 76, Loss: 0.01075859647244215\n",
            "Epoch 5, Step 77, Loss: 0.011121870949864388\n",
            "Epoch 5, Step 78, Loss: 0.00857558660209179\n",
            "Epoch 5, Step 79, Loss: 0.00970061868429184\n",
            "Epoch 5, Step 80, Loss: 0.009647781029343605\n",
            "Epoch 5, Step 81, Loss: 0.014328636229038239\n",
            "Epoch 5, Step 82, Loss: 0.012078528292477131\n",
            "Epoch 5, Step 83, Loss: 0.011106645688414574\n",
            "Epoch 5, Step 84, Loss: 0.012310841120779514\n",
            "Epoch 5, Step 85, Loss: 0.013833881355822086\n",
            "Train Metric MRRs: 0.10546966954069811\n",
            "Train Metric MAPs: 0.0563846111383822\n",
            "Validation Metric MRRs: 0.16640230869283962\n",
            "Validation Metric MAPs: 0.09859815892688624\n",
            "Epoch 6, Step 1, Loss: 0.031006714329123497\n",
            "Epoch 6, Step 2, Loss: 0.029148656874895096\n",
            "Epoch 6, Step 3, Loss: 0.027040116488933563\n",
            "Epoch 6, Step 4, Loss: 0.019738471135497093\n",
            "Epoch 6, Step 5, Loss: 0.01393822580575943\n",
            "Epoch 6, Step 6, Loss: 0.011445721611380577\n",
            "Epoch 6, Step 7, Loss: 0.00885048322379589\n",
            "Epoch 6, Step 8, Loss: 0.008720649406313896\n",
            "Epoch 6, Step 9, Loss: 0.008307578042149544\n",
            "Epoch 6, Step 10, Loss: 0.007436956744641066\n",
            "Epoch 6, Step 11, Loss: 0.007919173687696457\n",
            "Epoch 6, Step 12, Loss: 0.007278212811797857\n",
            "Epoch 6, Step 13, Loss: 0.00678145932033658\n",
            "Epoch 6, Step 14, Loss: 0.005837788339704275\n",
            "Epoch 6, Step 15, Loss: 0.0062062400393188\n",
            "Epoch 6, Step 16, Loss: 0.006422025617212057\n",
            "Epoch 6, Step 17, Loss: 0.008449438028037548\n",
            "Epoch 6, Step 18, Loss: 0.009217498824000359\n",
            "Epoch 6, Step 19, Loss: 0.0128945242613554\n",
            "Epoch 6, Step 20, Loss: 0.011609566397964954\n",
            "Epoch 6, Step 21, Loss: 0.01164145115762949\n",
            "Epoch 6, Step 22, Loss: 0.012473559007048607\n",
            "Epoch 6, Step 23, Loss: 0.0132190752774477\n",
            "Epoch 6, Step 24, Loss: 0.013229573145508766\n",
            "Epoch 6, Step 25, Loss: 0.013219162821769714\n",
            "Epoch 6, Step 26, Loss: 0.011967317201197147\n",
            "Epoch 6, Step 27, Loss: 0.010412264615297318\n",
            "Epoch 6, Step 28, Loss: 0.011645897291600704\n",
            "Epoch 6, Step 29, Loss: 0.011264637112617493\n",
            "Epoch 6, Step 30, Loss: 0.0098826102912426\n",
            "Epoch 6, Step 31, Loss: 0.011974445544183254\n",
            "Epoch 6, Step 32, Loss: 0.010327202267944813\n",
            "Epoch 6, Step 33, Loss: 0.011098706163465977\n",
            "Epoch 6, Step 34, Loss: 0.010257883928716183\n",
            "Epoch 6, Step 35, Loss: 0.011018810793757439\n",
            "Epoch 6, Step 36, Loss: 0.009231291711330414\n",
            "Epoch 6, Step 37, Loss: 0.010603789240121841\n",
            "Epoch 6, Step 38, Loss: 0.009785319678485394\n",
            "Epoch 6, Step 39, Loss: 0.010124080814421177\n",
            "Epoch 6, Step 40, Loss: 0.011100055649876595\n",
            "Epoch 6, Step 41, Loss: 0.008644904009997845\n",
            "Epoch 6, Step 42, Loss: 0.008643906563520432\n",
            "Epoch 6, Step 43, Loss: 0.008080117404460907\n",
            "Epoch 6, Step 44, Loss: 0.008242371492087841\n",
            "Epoch 6, Step 45, Loss: 0.009358379989862442\n",
            "Epoch 6, Step 46, Loss: 0.008720258250832558\n",
            "Epoch 6, Step 47, Loss: 0.008638223633170128\n",
            "Epoch 6, Step 48, Loss: 0.00812535546720028\n",
            "Epoch 6, Step 49, Loss: 0.008274894207715988\n",
            "Epoch 6, Step 50, Loss: 0.007967215962707996\n",
            "Epoch 6, Step 51, Loss: 0.007981555536389351\n",
            "Epoch 6, Step 52, Loss: 0.007272788323462009\n",
            "Epoch 6, Step 53, Loss: 0.009374509565532207\n",
            "Epoch 6, Step 54, Loss: 0.0067833890207111835\n",
            "Epoch 6, Step 55, Loss: 0.007496485952287912\n",
            "Epoch 6, Step 56, Loss: 0.0077490611001849174\n",
            "Epoch 6, Step 57, Loss: 0.006951834540814161\n",
            "Epoch 6, Step 58, Loss: 0.0073968651704490185\n",
            "Epoch 6, Step 59, Loss: 0.006794323679059744\n",
            "Epoch 6, Step 60, Loss: 0.007020462770015001\n",
            "Epoch 6, Step 61, Loss: 0.009710402227938175\n",
            "Epoch 6, Step 62, Loss: 0.006927309557795525\n",
            "Epoch 6, Step 63, Loss: 0.008265452459454536\n",
            "Epoch 6, Step 64, Loss: 0.007267321925610304\n",
            "Epoch 6, Step 65, Loss: 0.007771830074489117\n",
            "Epoch 6, Step 66, Loss: 0.008413977921009064\n",
            "Epoch 6, Step 67, Loss: 0.009943236596882343\n",
            "Epoch 6, Step 68, Loss: 0.008849713951349258\n",
            "Epoch 6, Step 69, Loss: 0.009686663746833801\n",
            "Epoch 6, Step 70, Loss: 0.009906220249831676\n",
            "Epoch 6, Step 71, Loss: 0.01039528101682663\n",
            "Epoch 6, Step 72, Loss: 0.009256793186068535\n",
            "Epoch 6, Step 73, Loss: 0.00863857101649046\n",
            "Epoch 6, Step 74, Loss: 0.008692918345332146\n",
            "Epoch 6, Step 75, Loss: 0.009948303923010826\n",
            "Epoch 6, Step 76, Loss: 0.009351801127195358\n",
            "Epoch 6, Step 77, Loss: 0.009930847212672234\n",
            "Epoch 6, Step 78, Loss: 0.007495880126953125\n",
            "Epoch 6, Step 79, Loss: 0.00853564590215683\n",
            "Epoch 6, Step 80, Loss: 0.008872617036104202\n",
            "Epoch 6, Step 81, Loss: 0.012579979375004768\n",
            "Epoch 6, Step 82, Loss: 0.010498409159481525\n",
            "Epoch 6, Step 83, Loss: 0.0096895731985569\n",
            "Epoch 6, Step 84, Loss: 0.011444414965808392\n",
            "Epoch 6, Step 85, Loss: 0.011759183369576931\n",
            "Train Metric MRRs: 0.24365603162982177\n",
            "Train Metric MAPs: 0.1999166777777017\n",
            "Validation Metric MRRs: 0.21581873375037092\n",
            "Validation Metric MAPs: 0.20269022571311304\n",
            "Epoch 7, Step 1, Loss: 0.027057906612753868\n",
            "Epoch 7, Step 2, Loss: 0.025416569784283638\n",
            "Epoch 7, Step 3, Loss: 0.020335055887699127\n",
            "Epoch 7, Step 4, Loss: 0.01610984466969967\n",
            "Epoch 7, Step 5, Loss: 0.011083941906690598\n",
            "Epoch 7, Step 6, Loss: 0.008822089992463589\n",
            "Epoch 7, Step 7, Loss: 0.006882696878165007\n",
            "Epoch 7, Step 8, Loss: 0.006874785292893648\n",
            "Epoch 7, Step 9, Loss: 0.006206432357430458\n",
            "Epoch 7, Step 10, Loss: 0.005854377988725901\n",
            "Epoch 7, Step 11, Loss: 0.00681027676910162\n",
            "Epoch 7, Step 12, Loss: 0.00616016099229455\n",
            "Epoch 7, Step 13, Loss: 0.005766160320490599\n",
            "Epoch 7, Step 14, Loss: 0.004944422747939825\n",
            "Epoch 7, Step 15, Loss: 0.0054915775544941425\n",
            "Epoch 7, Step 16, Loss: 0.0057345908135175705\n",
            "Epoch 7, Step 17, Loss: 0.007113488856703043\n",
            "Epoch 7, Step 18, Loss: 0.007830928079783916\n",
            "Epoch 7, Step 19, Loss: 0.0110377361997962\n",
            "Epoch 7, Step 20, Loss: 0.00999018456786871\n",
            "Epoch 7, Step 21, Loss: 0.010404023341834545\n",
            "Epoch 7, Step 22, Loss: 0.01094477903097868\n",
            "Epoch 7, Step 23, Loss: 0.01125260442495346\n",
            "Epoch 7, Step 24, Loss: 0.012336557731032372\n",
            "Epoch 7, Step 25, Loss: 0.01277549471706152\n",
            "Epoch 7, Step 26, Loss: 0.011020966805517673\n",
            "Epoch 7, Step 27, Loss: 0.009588420391082764\n",
            "Epoch 7, Step 28, Loss: 0.010815723799169064\n",
            "Epoch 7, Step 29, Loss: 0.01048723142594099\n",
            "Epoch 7, Step 30, Loss: 0.008780579082667828\n",
            "Epoch 7, Step 31, Loss: 0.011122600175440311\n",
            "Epoch 7, Step 32, Loss: 0.009594921953976154\n",
            "Epoch 7, Step 33, Loss: 0.010521448217332363\n",
            "Epoch 7, Step 34, Loss: 0.00957429688423872\n",
            "Epoch 7, Step 35, Loss: 0.010171049274504185\n",
            "Epoch 7, Step 36, Loss: 0.00883098877966404\n",
            "Epoch 7, Step 37, Loss: 0.010039807297289371\n",
            "Epoch 7, Step 38, Loss: 0.009365006349980831\n",
            "Epoch 7, Step 39, Loss: 0.009402411989867687\n",
            "Epoch 7, Step 40, Loss: 0.010323324240744114\n",
            "Epoch 7, Step 41, Loss: 0.00789677444845438\n",
            "Epoch 7, Step 42, Loss: 0.008078024722635746\n",
            "Epoch 7, Step 43, Loss: 0.007567239925265312\n",
            "Epoch 7, Step 44, Loss: 0.007847308181226254\n",
            "Epoch 7, Step 45, Loss: 0.008924035355448723\n",
            "Epoch 7, Step 46, Loss: 0.008249797858297825\n",
            "Epoch 7, Step 47, Loss: 0.008380724117159843\n",
            "Epoch 7, Step 48, Loss: 0.007646594196557999\n",
            "Epoch 7, Step 49, Loss: 0.007762022782117128\n",
            "Epoch 7, Step 50, Loss: 0.007478943560272455\n",
            "Epoch 7, Step 51, Loss: 0.0076298825442790985\n",
            "Epoch 7, Step 52, Loss: 0.0070055704563856125\n",
            "Epoch 7, Step 53, Loss: 0.008969651535153389\n",
            "Epoch 7, Step 54, Loss: 0.0062809959053993225\n",
            "Epoch 7, Step 55, Loss: 0.007255705539137125\n",
            "Epoch 7, Step 56, Loss: 0.007460072170943022\n",
            "Epoch 7, Step 57, Loss: 0.006711894646286964\n",
            "Epoch 7, Step 58, Loss: 0.00694182189181447\n",
            "Epoch 7, Step 59, Loss: 0.006720439996570349\n",
            "Epoch 7, Step 60, Loss: 0.006830339320003986\n",
            "Epoch 7, Step 61, Loss: 0.009433820843696594\n",
            "Epoch 7, Step 62, Loss: 0.006810275372117758\n",
            "Epoch 7, Step 63, Loss: 0.008117699064314365\n",
            "Epoch 7, Step 64, Loss: 0.00700045982375741\n",
            "Epoch 7, Step 65, Loss: 0.007511400617659092\n",
            "Epoch 7, Step 66, Loss: 0.008103507570922375\n",
            "Epoch 7, Step 67, Loss: 0.009626967832446098\n",
            "Epoch 7, Step 68, Loss: 0.008637182414531708\n",
            "Epoch 7, Step 69, Loss: 0.009431341663002968\n",
            "Epoch 7, Step 70, Loss: 0.009798585437238216\n",
            "Epoch 7, Step 71, Loss: 0.010174795053899288\n",
            "Epoch 7, Step 72, Loss: 0.008867232128977776\n",
            "Epoch 7, Step 73, Loss: 0.008425450883805752\n",
            "Epoch 7, Step 74, Loss: 0.008624549023807049\n",
            "Epoch 7, Step 75, Loss: 0.009612459689378738\n",
            "Epoch 7, Step 76, Loss: 0.008904973044991493\n",
            "Epoch 7, Step 77, Loss: 0.009720569476485252\n",
            "Epoch 7, Step 78, Loss: 0.007399405352771282\n",
            "Epoch 7, Step 79, Loss: 0.008047695271670818\n",
            "Epoch 7, Step 80, Loss: 0.008756870403885841\n",
            "Epoch 7, Step 81, Loss: 0.011929496191442013\n",
            "Epoch 7, Step 82, Loss: 0.010256853885948658\n",
            "Epoch 7, Step 83, Loss: 0.00921868346631527\n",
            "Epoch 7, Step 84, Loss: 0.010988064110279083\n",
            "Epoch 7, Step 85, Loss: 0.011593589559197426\n",
            "Train Metric MRRs: 0.27154288935344334\n",
            "Train Metric MAPs: 0.28456194135604584\n",
            "Validation Metric MRRs: 0.22131076645799208\n",
            "Validation Metric MAPs: 0.2055770573163892\n",
            "Epoch 8, Step 1, Loss: 0.026214752346277237\n",
            "Epoch 8, Step 2, Loss: 0.024170786142349243\n",
            "Epoch 8, Step 3, Loss: 0.019782744348049164\n",
            "Epoch 8, Step 4, Loss: 0.016002479940652847\n",
            "Epoch 8, Step 5, Loss: 0.011129752732813358\n",
            "Epoch 8, Step 6, Loss: 0.008524843491613865\n",
            "Epoch 8, Step 7, Loss: 0.006580113898962736\n",
            "Epoch 8, Step 8, Loss: 0.0067379530519247055\n",
            "Epoch 8, Step 9, Loss: 0.006260075140744448\n",
            "Epoch 8, Step 10, Loss: 0.006043002475053072\n",
            "Epoch 8, Step 11, Loss: 0.00676730927079916\n",
            "Epoch 8, Step 12, Loss: 0.006114140618592501\n",
            "Epoch 8, Step 13, Loss: 0.0057366820983588696\n",
            "Epoch 8, Step 14, Loss: 0.004709586035460234\n",
            "Epoch 8, Step 15, Loss: 0.00517489667981863\n",
            "Epoch 8, Step 16, Loss: 0.0054540387354791164\n",
            "Epoch 8, Step 17, Loss: 0.006895118393003941\n",
            "Epoch 8, Step 18, Loss: 0.008032167330384254\n",
            "Epoch 8, Step 19, Loss: 0.010514630004763603\n",
            "Epoch 8, Step 20, Loss: 0.009871723130345345\n",
            "Epoch 8, Step 21, Loss: 0.010401174426078796\n",
            "Epoch 8, Step 22, Loss: 0.010670359246432781\n",
            "Epoch 8, Step 23, Loss: 0.01114738266915083\n",
            "Epoch 8, Step 24, Loss: 0.011881153099238873\n",
            "Epoch 8, Step 25, Loss: 0.012562400661408901\n",
            "Epoch 8, Step 26, Loss: 0.010886800475418568\n",
            "Epoch 8, Step 27, Loss: 0.009425049647688866\n",
            "Epoch 8, Step 28, Loss: 0.010592981241643429\n",
            "Epoch 8, Step 29, Loss: 0.010407356545329094\n",
            "Epoch 8, Step 30, Loss: 0.00856324564665556\n",
            "Epoch 8, Step 31, Loss: 0.010992520488798618\n",
            "Epoch 8, Step 32, Loss: 0.009448775090277195\n",
            "Epoch 8, Step 33, Loss: 0.010490811429917812\n",
            "Epoch 8, Step 34, Loss: 0.009452099911868572\n",
            "Epoch 8, Step 35, Loss: 0.010137634351849556\n",
            "Epoch 8, Step 36, Loss: 0.008653405122458935\n",
            "Epoch 8, Step 37, Loss: 0.009794892743229866\n",
            "Epoch 8, Step 38, Loss: 0.009138944558799267\n",
            "Epoch 8, Step 39, Loss: 0.009380613453686237\n",
            "Epoch 8, Step 40, Loss: 0.009924821555614471\n",
            "Epoch 8, Step 41, Loss: 0.007791789714246988\n",
            "Epoch 8, Step 42, Loss: 0.007901613600552082\n",
            "Epoch 8, Step 43, Loss: 0.00741030415520072\n",
            "Epoch 8, Step 44, Loss: 0.007725188508629799\n",
            "Epoch 8, Step 45, Loss: 0.008796618320047855\n",
            "Epoch 8, Step 46, Loss: 0.00810331478714943\n",
            "Epoch 8, Step 47, Loss: 0.008097754791378975\n",
            "Epoch 8, Step 48, Loss: 0.007520732469856739\n",
            "Epoch 8, Step 49, Loss: 0.007565125823020935\n",
            "Epoch 8, Step 50, Loss: 0.00735130812972784\n",
            "Epoch 8, Step 51, Loss: 0.007526627276092768\n",
            "Epoch 8, Step 52, Loss: 0.006934592500329018\n",
            "Epoch 8, Step 53, Loss: 0.008848234079778194\n",
            "Epoch 8, Step 54, Loss: 0.006102994550019503\n",
            "Epoch 8, Step 55, Loss: 0.007036611437797546\n",
            "Epoch 8, Step 56, Loss: 0.0074536451138556\n",
            "Epoch 8, Step 57, Loss: 0.006528910715132952\n",
            "Epoch 8, Step 58, Loss: 0.006816114764660597\n",
            "Epoch 8, Step 59, Loss: 0.006590141914784908\n",
            "Epoch 8, Step 60, Loss: 0.0067499554716050625\n",
            "Epoch 8, Step 61, Loss: 0.00929797813296318\n",
            "Epoch 8, Step 62, Loss: 0.006635359488427639\n",
            "Epoch 8, Step 63, Loss: 0.007887373678386211\n",
            "Epoch 8, Step 64, Loss: 0.0068541937507689\n",
            "Epoch 8, Step 65, Loss: 0.007476211991161108\n",
            "Epoch 8, Step 66, Loss: 0.008075211197137833\n",
            "Epoch 8, Step 67, Loss: 0.009343736805021763\n",
            "Epoch 8, Step 68, Loss: 0.00838327594101429\n",
            "Epoch 8, Step 69, Loss: 0.009083235636353493\n",
            "Epoch 8, Step 70, Loss: 0.009676588699221611\n",
            "Epoch 8, Step 71, Loss: 0.01004092488437891\n",
            "Epoch 8, Step 72, Loss: 0.008649439550936222\n",
            "Epoch 8, Step 73, Loss: 0.008199203759431839\n",
            "Epoch 8, Step 74, Loss: 0.008423573337495327\n",
            "Epoch 8, Step 75, Loss: 0.009334880858659744\n",
            "Epoch 8, Step 76, Loss: 0.008667088113725185\n",
            "Epoch 8, Step 77, Loss: 0.009548870846629143\n",
            "Epoch 8, Step 78, Loss: 0.007181486114859581\n",
            "Epoch 8, Step 79, Loss: 0.008038314059376717\n",
            "Epoch 8, Step 80, Loss: 0.008544939570128918\n",
            "Epoch 8, Step 81, Loss: 0.011794885620474815\n",
            "Epoch 8, Step 82, Loss: 0.01007063314318657\n",
            "Epoch 8, Step 83, Loss: 0.0089695630595088\n",
            "Epoch 8, Step 84, Loss: 0.011137052439153194\n",
            "Epoch 8, Step 85, Loss: 0.011553453281521797\n",
            "Train Metric MRRs: 0.2765743193152528\n",
            "Train Metric MAPs: 0.2888265312935737\n",
            "Validation Metric MRRs: 0.22015052068307794\n",
            "Validation Metric MAPs: 0.2091704427682647\n",
            "Epoch 9, Step 1, Loss: 0.02594640478491783\n",
            "Epoch 9, Step 2, Loss: 0.023771101608872414\n",
            "Epoch 9, Step 3, Loss: 0.019849276170134544\n",
            "Epoch 9, Step 4, Loss: 0.01695585809648037\n",
            "Epoch 9, Step 5, Loss: 0.011867625638842583\n",
            "Epoch 9, Step 6, Loss: 0.008339728228747845\n",
            "Epoch 9, Step 7, Loss: 0.006164561491459608\n",
            "Epoch 9, Step 8, Loss: 0.006242179777473211\n",
            "Epoch 9, Step 9, Loss: 0.0058989995159208775\n",
            "Epoch 9, Step 10, Loss: 0.006015424150973558\n",
            "Epoch 9, Step 11, Loss: 0.006910108029842377\n",
            "Epoch 9, Step 12, Loss: 0.006246674805879593\n",
            "Epoch 9, Step 13, Loss: 0.005970030091702938\n",
            "Epoch 9, Step 14, Loss: 0.005092210602015257\n",
            "Epoch 9, Step 15, Loss: 0.005223676562309265\n",
            "Epoch 9, Step 16, Loss: 0.005548983812332153\n",
            "Epoch 9, Step 17, Loss: 0.006960100028663874\n",
            "Epoch 9, Step 18, Loss: 0.007757117506116629\n",
            "Epoch 9, Step 19, Loss: 0.010625779628753662\n",
            "Epoch 9, Step 20, Loss: 0.009890965186059475\n",
            "Epoch 9, Step 21, Loss: 0.01032279897481203\n",
            "Epoch 9, Step 22, Loss: 0.010913717560470104\n",
            "Epoch 9, Step 23, Loss: 0.010957470163702965\n",
            "Epoch 9, Step 24, Loss: 0.011861493811011314\n",
            "Epoch 9, Step 25, Loss: 0.012537920847535133\n",
            "Epoch 9, Step 26, Loss: 0.01082761399447918\n",
            "Epoch 9, Step 27, Loss: 0.009394168853759766\n",
            "Epoch 9, Step 28, Loss: 0.010511199943721294\n",
            "Epoch 9, Step 29, Loss: 0.010257936082780361\n",
            "Epoch 9, Step 30, Loss: 0.008653160184621811\n",
            "Epoch 9, Step 31, Loss: 0.010891510173678398\n",
            "Epoch 9, Step 32, Loss: 0.009364889934659004\n",
            "Epoch 9, Step 33, Loss: 0.010388076305389404\n",
            "Epoch 9, Step 34, Loss: 0.009467710740864277\n",
            "Epoch 9, Step 35, Loss: 0.009969253093004227\n",
            "Epoch 9, Step 36, Loss: 0.0086516123265028\n",
            "Epoch 9, Step 37, Loss: 0.009631856344640255\n",
            "Epoch 9, Step 38, Loss: 0.009051721543073654\n",
            "Epoch 9, Step 39, Loss: 0.009231149218976498\n",
            "Epoch 9, Step 40, Loss: 0.009886926040053368\n",
            "Epoch 9, Step 41, Loss: 0.007692962419241667\n",
            "Epoch 9, Step 42, Loss: 0.007863378152251244\n",
            "Epoch 9, Step 43, Loss: 0.007376824971288443\n",
            "Epoch 9, Step 44, Loss: 0.0077163600362837315\n",
            "Epoch 9, Step 45, Loss: 0.008745212107896805\n",
            "Epoch 9, Step 46, Loss: 0.008104097098112106\n",
            "Epoch 9, Step 47, Loss: 0.008135229349136353\n",
            "Epoch 9, Step 48, Loss: 0.0074824439361691475\n",
            "Epoch 9, Step 49, Loss: 0.00748051144182682\n",
            "Epoch 9, Step 50, Loss: 0.007210176438093185\n",
            "Epoch 9, Step 51, Loss: 0.007333863992244005\n",
            "Epoch 9, Step 52, Loss: 0.006779665593057871\n",
            "Epoch 9, Step 53, Loss: 0.008839917369186878\n",
            "Epoch 9, Step 54, Loss: 0.005986154079437256\n",
            "Epoch 9, Step 55, Loss: 0.006965473294258118\n",
            "Epoch 9, Step 56, Loss: 0.007374025881290436\n",
            "Epoch 9, Step 57, Loss: 0.006470006424933672\n",
            "Epoch 9, Step 58, Loss: 0.006781578529626131\n",
            "Epoch 9, Step 59, Loss: 0.006556123029440641\n",
            "Epoch 9, Step 60, Loss: 0.006707256659865379\n",
            "Epoch 9, Step 61, Loss: 0.009220903739333153\n",
            "Epoch 9, Step 62, Loss: 0.006635858677327633\n",
            "Epoch 9, Step 63, Loss: 0.007768560200929642\n",
            "Epoch 9, Step 64, Loss: 0.006830495782196522\n",
            "Epoch 9, Step 65, Loss: 0.00739508168771863\n",
            "Epoch 9, Step 66, Loss: 0.007884773425757885\n",
            "Epoch 9, Step 67, Loss: 0.009034051559865475\n",
            "Epoch 9, Step 68, Loss: 0.008282367140054703\n",
            "Epoch 9, Step 69, Loss: 0.008979487232863903\n",
            "Epoch 9, Step 70, Loss: 0.009461836889386177\n",
            "Epoch 9, Step 71, Loss: 0.009964413940906525\n",
            "Epoch 9, Step 72, Loss: 0.008472652174532413\n",
            "Epoch 9, Step 73, Loss: 0.008044282905757427\n",
            "Epoch 9, Step 74, Loss: 0.008131802082061768\n",
            "Epoch 9, Step 75, Loss: 0.009285787120461464\n",
            "Epoch 9, Step 76, Loss: 0.008823097683489323\n",
            "Epoch 9, Step 77, Loss: 0.009282011538743973\n",
            "Epoch 9, Step 78, Loss: 0.007076989393681288\n",
            "Epoch 9, Step 79, Loss: 0.00786296371370554\n",
            "Epoch 9, Step 80, Loss: 0.008315375074744225\n",
            "Epoch 9, Step 81, Loss: 0.011398589238524437\n",
            "Epoch 9, Step 82, Loss: 0.009926384314894676\n",
            "Epoch 9, Step 83, Loss: 0.008894005790352821\n",
            "Epoch 9, Step 84, Loss: 0.010834292508661747\n",
            "Epoch 9, Step 85, Loss: 0.011289196088910103\n",
            "Train Metric MRRs: 0.278172227077635\n",
            "Train Metric MAPs: 0.29428494862422505\n",
            "Validation Metric MRRs: 0.22158609115594777\n",
            "Validation Metric MAPs: 0.2064473143387185\n",
            "Epoch 10, Step 1, Loss: 0.025390710681676865\n",
            "Epoch 10, Step 2, Loss: 0.02462180145084858\n",
            "Epoch 10, Step 3, Loss: 0.019039541482925415\n",
            "Epoch 10, Step 4, Loss: 0.015411688014864922\n",
            "Epoch 10, Step 5, Loss: 0.01153600588440895\n",
            "Epoch 10, Step 6, Loss: 0.008681809529662132\n",
            "Epoch 10, Step 7, Loss: 0.006387915462255478\n",
            "Epoch 10, Step 8, Loss: 0.006329062860459089\n",
            "Epoch 10, Step 9, Loss: 0.00598968006670475\n",
            "Epoch 10, Step 10, Loss: 0.005634727422147989\n",
            "Epoch 10, Step 11, Loss: 0.006347957532852888\n",
            "Epoch 10, Step 12, Loss: 0.00592907564714551\n",
            "Epoch 10, Step 13, Loss: 0.005643179640173912\n",
            "Epoch 10, Step 14, Loss: 0.005060860887169838\n",
            "Epoch 10, Step 15, Loss: 0.005353078246116638\n",
            "Epoch 10, Step 16, Loss: 0.005802773870527744\n",
            "Epoch 10, Step 17, Loss: 0.007331351283937693\n",
            "Epoch 10, Step 18, Loss: 0.00809834711253643\n",
            "Epoch 10, Step 19, Loss: 0.010015365667641163\n",
            "Epoch 10, Step 20, Loss: 0.009684744291007519\n",
            "Epoch 10, Step 21, Loss: 0.010043039917945862\n",
            "Epoch 10, Step 22, Loss: 0.010563177987933159\n",
            "Epoch 10, Step 23, Loss: 0.010798594914376736\n",
            "Epoch 10, Step 24, Loss: 0.011781536042690277\n",
            "Epoch 10, Step 25, Loss: 0.012850922532379627\n",
            "Epoch 10, Step 26, Loss: 0.010993235744535923\n",
            "Epoch 10, Step 27, Loss: 0.00935620442032814\n",
            "Epoch 10, Step 28, Loss: 0.010563597083091736\n",
            "Epoch 10, Step 29, Loss: 0.010300012305378914\n",
            "Epoch 10, Step 30, Loss: 0.008550661616027355\n",
            "Epoch 10, Step 31, Loss: 0.010819187387824059\n",
            "Epoch 10, Step 32, Loss: 0.009359755553305149\n",
            "Epoch 10, Step 33, Loss: 0.010429675690829754\n",
            "Epoch 10, Step 34, Loss: 0.009678659029304981\n",
            "Epoch 10, Step 35, Loss: 0.009970000945031643\n",
            "Epoch 10, Step 36, Loss: 0.00854562222957611\n",
            "Epoch 10, Step 37, Loss: 0.009560245089232922\n",
            "Epoch 10, Step 38, Loss: 0.009012713097035885\n",
            "Epoch 10, Step 39, Loss: 0.009075270034372807\n",
            "Epoch 10, Step 40, Loss: 0.009947715327143669\n",
            "Epoch 10, Step 41, Loss: 0.007752422709017992\n",
            "Epoch 10, Step 42, Loss: 0.0077546751126646996\n",
            "Epoch 10, Step 43, Loss: 0.007240154780447483\n",
            "Epoch 10, Step 44, Loss: 0.0076538207940757275\n",
            "Epoch 10, Step 45, Loss: 0.008681997656822205\n",
            "Epoch 10, Step 46, Loss: 0.00798485055565834\n",
            "Epoch 10, Step 47, Loss: 0.007957806810736656\n",
            "Epoch 10, Step 48, Loss: 0.007417399436235428\n",
            "Epoch 10, Step 49, Loss: 0.007375124841928482\n",
            "Epoch 10, Step 50, Loss: 0.007131797261536121\n",
            "Epoch 10, Step 51, Loss: 0.007385591976344585\n",
            "Epoch 10, Step 52, Loss: 0.006695724558085203\n",
            "Epoch 10, Step 53, Loss: 0.008726228959858418\n",
            "Epoch 10, Step 54, Loss: 0.00595199316740036\n",
            "Epoch 10, Step 55, Loss: 0.006910097785294056\n",
            "Epoch 10, Step 56, Loss: 0.007338316645473242\n",
            "Epoch 10, Step 57, Loss: 0.00651316624134779\n",
            "Epoch 10, Step 58, Loss: 0.006702017039060593\n",
            "Epoch 10, Step 59, Loss: 0.0066379462368786335\n",
            "Epoch 10, Step 60, Loss: 0.006632666569203138\n",
            "Epoch 10, Step 61, Loss: 0.009222159162163734\n",
            "Epoch 10, Step 62, Loss: 0.006578315049409866\n",
            "Epoch 10, Step 63, Loss: 0.007697803899645805\n",
            "Epoch 10, Step 64, Loss: 0.006704093422740698\n",
            "Epoch 10, Step 65, Loss: 0.007436813320964575\n",
            "Epoch 10, Step 66, Loss: 0.007827592082321644\n",
            "Epoch 10, Step 67, Loss: 0.009027275256812572\n",
            "Epoch 10, Step 68, Loss: 0.008302330039441586\n",
            "Epoch 10, Step 69, Loss: 0.008881716057658195\n",
            "Epoch 10, Step 70, Loss: 0.009470860473811626\n",
            "Epoch 10, Step 71, Loss: 0.009799908846616745\n",
            "Epoch 10, Step 72, Loss: 0.008361262269318104\n",
            "Epoch 10, Step 73, Loss: 0.007904116995632648\n",
            "Epoch 10, Step 74, Loss: 0.007872502319514751\n",
            "Epoch 10, Step 75, Loss: 0.009206268936395645\n",
            "Epoch 10, Step 76, Loss: 0.008464866317808628\n",
            "Epoch 10, Step 77, Loss: 0.009240740910172462\n",
            "Epoch 10, Step 78, Loss: 0.006975509691983461\n",
            "Epoch 10, Step 79, Loss: 0.0077903675846755505\n",
            "Epoch 10, Step 80, Loss: 0.008219283074140549\n",
            "Epoch 10, Step 81, Loss: 0.011019046418368816\n",
            "Epoch 10, Step 82, Loss: 0.009704232215881348\n",
            "Epoch 10, Step 83, Loss: 0.008632602170109749\n",
            "Epoch 10, Step 84, Loss: 0.010551082901656628\n",
            "Epoch 10, Step 85, Loss: 0.010984714142978191\n",
            "Train Metric MRRs: 0.28044777983373903\n",
            "Train Metric MAPs: 0.2951437292129617\n",
            "Validation Metric MRRs: 0.2199182014387484\n",
            "Validation Metric MAPs: 0.2099694643480963\n",
            "Epoch 11, Step 1, Loss: 0.024394934996962547\n",
            "Epoch 11, Step 2, Loss: 0.023579031229019165\n",
            "Epoch 11, Step 3, Loss: 0.018584012985229492\n",
            "Epoch 11, Step 4, Loss: 0.015000556595623493\n",
            "Epoch 11, Step 5, Loss: 0.011001677252352238\n",
            "Epoch 11, Step 6, Loss: 0.008110986091196537\n",
            "Epoch 11, Step 7, Loss: 0.005981087684631348\n",
            "Epoch 11, Step 8, Loss: 0.006029409822076559\n",
            "Epoch 11, Step 9, Loss: 0.005596857517957687\n",
            "Epoch 11, Step 10, Loss: 0.005401076748967171\n",
            "Epoch 11, Step 11, Loss: 0.006130270194262266\n",
            "Epoch 11, Step 12, Loss: 0.005760498344898224\n",
            "Epoch 11, Step 13, Loss: 0.005452638957649469\n",
            "Epoch 11, Step 14, Loss: 0.004770374856889248\n",
            "Epoch 11, Step 15, Loss: 0.004929376766085625\n",
            "Epoch 11, Step 16, Loss: 0.005582258105278015\n",
            "Epoch 11, Step 17, Loss: 0.006900520529597998\n",
            "Epoch 11, Step 18, Loss: 0.007881835103034973\n",
            "Epoch 11, Step 19, Loss: 0.009736035019159317\n",
            "Epoch 11, Step 20, Loss: 0.009471822530031204\n",
            "Epoch 11, Step 21, Loss: 0.009885731153190136\n",
            "Epoch 11, Step 22, Loss: 0.010076748207211494\n",
            "Epoch 11, Step 23, Loss: 0.010820196941494942\n",
            "Epoch 11, Step 24, Loss: 0.011349561624228954\n",
            "Epoch 11, Step 25, Loss: 0.012560785748064518\n",
            "Epoch 11, Step 26, Loss: 0.011018873192369938\n",
            "Epoch 11, Step 27, Loss: 0.009114278480410576\n",
            "Epoch 11, Step 28, Loss: 0.010448931716382504\n",
            "Epoch 11, Step 29, Loss: 0.010198170319199562\n",
            "Epoch 11, Step 30, Loss: 0.00840647704899311\n",
            "Epoch 11, Step 31, Loss: 0.010793996043503284\n",
            "Epoch 11, Step 32, Loss: 0.009221251122653484\n",
            "Epoch 11, Step 33, Loss: 0.010361962020397186\n",
            "Epoch 11, Step 34, Loss: 0.009674957022070885\n",
            "Epoch 11, Step 35, Loss: 0.00992642529308796\n",
            "Epoch 11, Step 36, Loss: 0.008528955280780792\n",
            "Epoch 11, Step 37, Loss: 0.009512354619801044\n",
            "Epoch 11, Step 38, Loss: 0.008880669251084328\n",
            "Epoch 11, Step 39, Loss: 0.009214004501700401\n",
            "Epoch 11, Step 40, Loss: 0.009863748215138912\n",
            "Epoch 11, Step 41, Loss: 0.007649078033864498\n",
            "Epoch 11, Step 42, Loss: 0.007707526441663504\n",
            "Epoch 11, Step 43, Loss: 0.00704226503148675\n",
            "Epoch 11, Step 44, Loss: 0.007534790318459272\n",
            "Epoch 11, Step 45, Loss: 0.008568081073462963\n",
            "Epoch 11, Step 46, Loss: 0.007883666083216667\n",
            "Epoch 11, Step 47, Loss: 0.007848304696381092\n",
            "Epoch 11, Step 48, Loss: 0.007322143297642469\n",
            "Epoch 11, Step 49, Loss: 0.0073859067633748055\n",
            "Epoch 11, Step 50, Loss: 0.00705597922205925\n",
            "Epoch 11, Step 51, Loss: 0.00729616591706872\n",
            "Epoch 11, Step 52, Loss: 0.006614629179239273\n",
            "Epoch 11, Step 53, Loss: 0.00865892693400383\n",
            "Epoch 11, Step 54, Loss: 0.005942517425864935\n",
            "Epoch 11, Step 55, Loss: 0.006903462577611208\n",
            "Epoch 11, Step 56, Loss: 0.007270041387528181\n",
            "Epoch 11, Step 57, Loss: 0.006362087558954954\n",
            "Epoch 11, Step 58, Loss: 0.0066188606433570385\n",
            "Epoch 11, Step 59, Loss: 0.006567982491105795\n",
            "Epoch 11, Step 60, Loss: 0.006595501210540533\n",
            "Epoch 11, Step 61, Loss: 0.009185193106532097\n",
            "Epoch 11, Step 62, Loss: 0.006481577642261982\n",
            "Epoch 11, Step 63, Loss: 0.007583980448544025\n",
            "Epoch 11, Step 64, Loss: 0.006692187860608101\n",
            "Epoch 11, Step 65, Loss: 0.00735577754676342\n",
            "Epoch 11, Step 66, Loss: 0.007789009716361761\n",
            "Epoch 11, Step 67, Loss: 0.00891956314444542\n",
            "Epoch 11, Step 68, Loss: 0.00832144170999527\n",
            "Epoch 11, Step 69, Loss: 0.008810289204120636\n",
            "Epoch 11, Step 70, Loss: 0.009411170147359371\n",
            "Epoch 11, Step 71, Loss: 0.009740111418068409\n",
            "Epoch 11, Step 72, Loss: 0.008342255838215351\n",
            "Epoch 11, Step 73, Loss: 0.007758147083222866\n",
            "Epoch 11, Step 74, Loss: 0.00761803612112999\n",
            "Epoch 11, Step 75, Loss: 0.009108814410865307\n",
            "Epoch 11, Step 76, Loss: 0.008411003276705742\n",
            "Epoch 11, Step 77, Loss: 0.009149007499217987\n",
            "Epoch 11, Step 78, Loss: 0.006829837802797556\n",
            "Epoch 11, Step 79, Loss: 0.007682148367166519\n",
            "Epoch 11, Step 80, Loss: 0.008224126882851124\n",
            "Epoch 11, Step 81, Loss: 0.010820810683071613\n",
            "Epoch 11, Step 82, Loss: 0.009521505795419216\n",
            "Epoch 11, Step 83, Loss: 0.008478893898427486\n",
            "Epoch 11, Step 84, Loss: 0.01043665874749422\n",
            "Epoch 11, Step 85, Loss: 0.010914142243564129\n",
            "Train Metric MRRs: 0.2836083336829764\n",
            "Train Metric MAPs: 0.29943950668779173\n",
            "Validation Metric MRRs: 0.21952106551619208\n",
            "Validation Metric MAPs: 0.2103299319336428\n",
            "Epoch 12, Step 1, Loss: 0.023700613528490067\n",
            "Epoch 12, Step 2, Loss: 0.023198813199996948\n",
            "Epoch 12, Step 3, Loss: 0.018525902181863785\n",
            "Epoch 12, Step 4, Loss: 0.014932493679225445\n",
            "Epoch 12, Step 5, Loss: 0.011145259253680706\n",
            "Epoch 12, Step 6, Loss: 0.008219481445848942\n",
            "Epoch 12, Step 7, Loss: 0.005999617278575897\n",
            "Epoch 12, Step 8, Loss: 0.006084266118705273\n",
            "Epoch 12, Step 9, Loss: 0.005662610754370689\n",
            "Epoch 12, Step 10, Loss: 0.005417546723037958\n",
            "Epoch 12, Step 11, Loss: 0.006058963481336832\n",
            "Epoch 12, Step 12, Loss: 0.005745935719460249\n",
            "Epoch 12, Step 13, Loss: 0.005360612645745277\n",
            "Epoch 12, Step 14, Loss: 0.004731760360300541\n",
            "Epoch 12, Step 15, Loss: 0.0049328431487083435\n",
            "Epoch 12, Step 16, Loss: 0.005489646922796965\n",
            "Epoch 12, Step 17, Loss: 0.006863388232886791\n",
            "Epoch 12, Step 18, Loss: 0.007938421331346035\n",
            "Epoch 12, Step 19, Loss: 0.00966227799654007\n",
            "Epoch 12, Step 20, Loss: 0.009379054419696331\n",
            "Epoch 12, Step 21, Loss: 0.009785197675228119\n",
            "Epoch 12, Step 22, Loss: 0.010064646601676941\n",
            "Epoch 12, Step 23, Loss: 0.010584849864244461\n",
            "Epoch 12, Step 24, Loss: 0.011158149689435959\n",
            "Epoch 12, Step 25, Loss: 0.012466627173125744\n",
            "Epoch 12, Step 26, Loss: 0.010845301672816277\n",
            "Epoch 12, Step 27, Loss: 0.009124912321567535\n",
            "Epoch 12, Step 28, Loss: 0.010530362837016582\n",
            "Epoch 12, Step 29, Loss: 0.010276954621076584\n",
            "Epoch 12, Step 30, Loss: 0.008317230269312859\n",
            "Epoch 12, Step 31, Loss: 0.01074758917093277\n",
            "Epoch 12, Step 32, Loss: 0.009007219225168228\n",
            "Epoch 12, Step 33, Loss: 0.010146007873117924\n",
            "Epoch 12, Step 34, Loss: 0.009570920839905739\n",
            "Epoch 12, Step 35, Loss: 0.01013896893709898\n",
            "Epoch 12, Step 36, Loss: 0.008723089471459389\n",
            "Epoch 12, Step 37, Loss: 0.009651376865804195\n",
            "Epoch 12, Step 38, Loss: 0.008851100690662861\n",
            "Epoch 12, Step 39, Loss: 0.009027979336678982\n",
            "Epoch 12, Step 40, Loss: 0.00958825834095478\n",
            "Epoch 12, Step 41, Loss: 0.007610132452100515\n",
            "Epoch 12, Step 42, Loss: 0.007669677492231131\n",
            "Epoch 12, Step 43, Loss: 0.007056075148284435\n",
            "Epoch 12, Step 44, Loss: 0.007553210947662592\n",
            "Epoch 12, Step 45, Loss: 0.00873411726206541\n",
            "Epoch 12, Step 46, Loss: 0.007843609899282455\n",
            "Epoch 12, Step 47, Loss: 0.00783013179898262\n",
            "Epoch 12, Step 48, Loss: 0.00726034352555871\n",
            "Epoch 12, Step 49, Loss: 0.0072052860632538795\n",
            "Epoch 12, Step 50, Loss: 0.006988835521042347\n",
            "Epoch 12, Step 51, Loss: 0.007221362553536892\n",
            "Epoch 12, Step 52, Loss: 0.00661111855879426\n",
            "Epoch 12, Step 53, Loss: 0.00859859213232994\n",
            "Epoch 12, Step 54, Loss: 0.005938570946455002\n",
            "Epoch 12, Step 55, Loss: 0.006871023681014776\n",
            "Epoch 12, Step 56, Loss: 0.007266397587954998\n",
            "Epoch 12, Step 57, Loss: 0.006322005297988653\n",
            "Epoch 12, Step 58, Loss: 0.006596479099243879\n",
            "Epoch 12, Step 59, Loss: 0.006556043867021799\n",
            "Epoch 12, Step 60, Loss: 0.006579129491001368\n",
            "Epoch 12, Step 61, Loss: 0.009237575344741344\n",
            "Epoch 12, Step 62, Loss: 0.006455619819462299\n",
            "Epoch 12, Step 63, Loss: 0.00749264657497406\n",
            "Epoch 12, Step 64, Loss: 0.006556229665875435\n",
            "Epoch 12, Step 65, Loss: 0.007349712308496237\n",
            "Epoch 12, Step 66, Loss: 0.007726650685071945\n",
            "Epoch 12, Step 67, Loss: 0.008907351642847061\n",
            "Epoch 12, Step 68, Loss: 0.008271749131381512\n",
            "Epoch 12, Step 69, Loss: 0.00868311244994402\n",
            "Epoch 12, Step 70, Loss: 0.009329114109277725\n",
            "Epoch 12, Step 71, Loss: 0.009668400511145592\n",
            "Epoch 12, Step 72, Loss: 0.008392500691115856\n",
            "Epoch 12, Step 73, Loss: 0.007712789345532656\n",
            "Epoch 12, Step 74, Loss: 0.007551505230367184\n",
            "Epoch 12, Step 75, Loss: 0.00891195423901081\n",
            "Epoch 12, Step 76, Loss: 0.008356194011867046\n",
            "Epoch 12, Step 77, Loss: 0.00910116359591484\n",
            "Epoch 12, Step 78, Loss: 0.006787448190152645\n",
            "Epoch 12, Step 79, Loss: 0.0076324306428432465\n",
            "Epoch 12, Step 80, Loss: 0.008161414414644241\n",
            "Epoch 12, Step 81, Loss: 0.010738353244960308\n",
            "Epoch 12, Step 82, Loss: 0.009611060842871666\n",
            "Epoch 12, Step 83, Loss: 0.008292117156088352\n",
            "Epoch 12, Step 84, Loss: 0.010314920917153358\n",
            "Epoch 12, Step 85, Loss: 0.010858097113668919\n",
            "Train Metric MRRs: 0.28773020995670257\n",
            "Train Metric MAPs: 0.2965616359017964\n",
            "Validation Metric MRRs: 0.2185328513365053\n",
            "Validation Metric MAPs: 0.2092041822241072\n",
            "Epoch 13, Step 1, Loss: 0.02352828159928322\n",
            "Epoch 13, Step 2, Loss: 0.022833799943327904\n",
            "Epoch 13, Step 3, Loss: 0.018651273101568222\n",
            "Epoch 13, Step 4, Loss: 0.014649268239736557\n",
            "Epoch 13, Step 5, Loss: 0.010748790577054024\n",
            "Epoch 13, Step 6, Loss: 0.007983728311955929\n",
            "Epoch 13, Step 7, Loss: 0.005858784541487694\n",
            "Epoch 13, Step 8, Loss: 0.005963076371699572\n",
            "Epoch 13, Step 9, Loss: 0.0055768126621842384\n",
            "Epoch 13, Step 10, Loss: 0.005371830891817808\n",
            "Epoch 13, Step 11, Loss: 0.006056557409465313\n",
            "Epoch 13, Step 12, Loss: 0.0056987339630723\n",
            "Epoch 13, Step 13, Loss: 0.005384845659136772\n",
            "Epoch 13, Step 14, Loss: 0.004612956196069717\n",
            "Epoch 13, Step 15, Loss: 0.0047729830257594585\n",
            "Epoch 13, Step 16, Loss: 0.005407340358942747\n",
            "Epoch 13, Step 17, Loss: 0.006818900350481272\n",
            "Epoch 13, Step 18, Loss: 0.007889469154179096\n",
            "Epoch 13, Step 19, Loss: 0.00959436409175396\n",
            "Epoch 13, Step 20, Loss: 0.009383747354149818\n",
            "Epoch 13, Step 21, Loss: 0.00977250188589096\n",
            "Epoch 13, Step 22, Loss: 0.00999092310667038\n",
            "Epoch 13, Step 23, Loss: 0.010417573153972626\n",
            "Epoch 13, Step 24, Loss: 0.010994486510753632\n",
            "Epoch 13, Step 25, Loss: 0.012363304384052753\n",
            "Epoch 13, Step 26, Loss: 0.010782746598124504\n",
            "Epoch 13, Step 27, Loss: 0.009115546941757202\n",
            "Epoch 13, Step 28, Loss: 0.010540900751948357\n",
            "Epoch 13, Step 29, Loss: 0.01023921463638544\n",
            "Epoch 13, Step 30, Loss: 0.008338512852787971\n",
            "Epoch 13, Step 31, Loss: 0.010678467340767384\n",
            "Epoch 13, Step 32, Loss: 0.008930548094213009\n",
            "Epoch 13, Step 33, Loss: 0.010169635526835918\n",
            "Epoch 13, Step 34, Loss: 0.009533853270113468\n",
            "Epoch 13, Step 35, Loss: 0.010031203739345074\n",
            "Epoch 13, Step 36, Loss: 0.008859182707965374\n",
            "Epoch 13, Step 37, Loss: 0.009649557992815971\n",
            "Epoch 13, Step 38, Loss: 0.008917730301618576\n",
            "Epoch 13, Step 39, Loss: 0.008966398425400257\n",
            "Epoch 13, Step 40, Loss: 0.009439232759177685\n",
            "Epoch 13, Step 41, Loss: 0.007462284993380308\n",
            "Epoch 13, Step 42, Loss: 0.007519157137721777\n",
            "Epoch 13, Step 43, Loss: 0.0068686348386108875\n",
            "Epoch 13, Step 44, Loss: 0.007446833420544863\n",
            "Epoch 13, Step 45, Loss: 0.008660771884024143\n",
            "Epoch 13, Step 46, Loss: 0.007959323935210705\n",
            "Epoch 13, Step 47, Loss: 0.007928264327347279\n",
            "Epoch 13, Step 48, Loss: 0.007225793786346912\n",
            "Epoch 13, Step 49, Loss: 0.007203145883977413\n",
            "Epoch 13, Step 50, Loss: 0.007010662462562323\n",
            "Epoch 13, Step 51, Loss: 0.007150726392865181\n",
            "Epoch 13, Step 52, Loss: 0.006544897332787514\n",
            "Epoch 13, Step 53, Loss: 0.008536476641893387\n",
            "Epoch 13, Step 54, Loss: 0.005938039161264896\n",
            "Epoch 13, Step 55, Loss: 0.006954274605959654\n",
            "Epoch 13, Step 56, Loss: 0.0073560308665037155\n",
            "Epoch 13, Step 57, Loss: 0.006408174987882376\n",
            "Epoch 13, Step 58, Loss: 0.00667417049407959\n",
            "Epoch 13, Step 59, Loss: 0.006558574270457029\n",
            "Epoch 13, Step 60, Loss: 0.006577083375304937\n",
            "Epoch 13, Step 61, Loss: 0.009105459786951542\n",
            "Epoch 13, Step 62, Loss: 0.006466757971793413\n",
            "Epoch 13, Step 63, Loss: 0.00744840269908309\n",
            "Epoch 13, Step 64, Loss: 0.006545206531882286\n",
            "Epoch 13, Step 65, Loss: 0.007280811667442322\n",
            "Epoch 13, Step 66, Loss: 0.007841978222131729\n",
            "Epoch 13, Step 67, Loss: 0.008953530341386795\n",
            "Epoch 13, Step 68, Loss: 0.008220851421356201\n",
            "Epoch 13, Step 69, Loss: 0.008628890849649906\n",
            "Epoch 13, Step 70, Loss: 0.009291299618780613\n",
            "Epoch 13, Step 71, Loss: 0.009636222384870052\n",
            "Epoch 13, Step 72, Loss: 0.00830130372196436\n",
            "Epoch 13, Step 73, Loss: 0.007682144176214933\n",
            "Epoch 13, Step 74, Loss: 0.007476028520613909\n",
            "Epoch 13, Step 75, Loss: 0.008990834467113018\n",
            "Epoch 13, Step 76, Loss: 0.00831501092761755\n",
            "Epoch 13, Step 77, Loss: 0.00908964779227972\n",
            "Epoch 13, Step 78, Loss: 0.006802022457122803\n",
            "Epoch 13, Step 79, Loss: 0.007593332789838314\n",
            "Epoch 13, Step 80, Loss: 0.008119955658912659\n",
            "Epoch 13, Step 81, Loss: 0.010631971061229706\n",
            "Epoch 13, Step 82, Loss: 0.009599716402590275\n",
            "Epoch 13, Step 83, Loss: 0.008245625533163548\n",
            "Epoch 13, Step 84, Loss: 0.010087179951369762\n",
            "Epoch 13, Step 85, Loss: 0.010683652013540268\n",
            "Train Metric MRRs: 0.28951946798945416\n",
            "Train Metric MAPs: 0.3010504776784394\n",
            "Validation Metric MRRs: 0.22428470827229507\n",
            "Validation Metric MAPs: 0.2103845832023855\n",
            "Epoch 14, Step 1, Loss: 0.023620544001460075\n",
            "Epoch 14, Step 2, Loss: 0.022725047543644905\n",
            "Epoch 14, Step 3, Loss: 0.018819240853190422\n",
            "Epoch 14, Step 4, Loss: 0.01485588401556015\n",
            "Epoch 14, Step 5, Loss: 0.010651268064975739\n",
            "Epoch 14, Step 6, Loss: 0.007901116274297237\n",
            "Epoch 14, Step 7, Loss: 0.005785354413092136\n",
            "Epoch 14, Step 8, Loss: 0.005898712668567896\n",
            "Epoch 14, Step 9, Loss: 0.005419779568910599\n",
            "Epoch 14, Step 10, Loss: 0.005256626754999161\n",
            "Epoch 14, Step 11, Loss: 0.0060924650169909\n",
            "Epoch 14, Step 12, Loss: 0.005707350093871355\n",
            "Epoch 14, Step 13, Loss: 0.005184152163565159\n",
            "Epoch 14, Step 14, Loss: 0.004462189506739378\n",
            "Epoch 14, Step 15, Loss: 0.004686362110078335\n",
            "Epoch 14, Step 16, Loss: 0.00515296496450901\n",
            "Epoch 14, Step 17, Loss: 0.0068030329421162605\n",
            "Epoch 14, Step 18, Loss: 0.007912738248705864\n",
            "Epoch 14, Step 19, Loss: 0.009619761258363724\n",
            "Epoch 14, Step 20, Loss: 0.009332379326224327\n",
            "Epoch 14, Step 21, Loss: 0.00981825590133667\n",
            "Epoch 14, Step 22, Loss: 0.009892504662275314\n",
            "Epoch 14, Step 23, Loss: 0.010623704642057419\n",
            "Epoch 14, Step 24, Loss: 0.010903913527727127\n",
            "Epoch 14, Step 25, Loss: 0.012161338701844215\n",
            "Epoch 14, Step 26, Loss: 0.010629606433212757\n",
            "Epoch 14, Step 27, Loss: 0.009092826396226883\n",
            "Epoch 14, Step 28, Loss: 0.01056482270359993\n",
            "Epoch 14, Step 29, Loss: 0.0102340467274189\n",
            "Epoch 14, Step 30, Loss: 0.008208281360566616\n",
            "Epoch 14, Step 31, Loss: 0.01070349384099245\n",
            "Epoch 14, Step 32, Loss: 0.008913649246096611\n",
            "Epoch 14, Step 33, Loss: 0.010051136836409569\n",
            "Epoch 14, Step 34, Loss: 0.009408622980117798\n",
            "Epoch 14, Step 35, Loss: 0.009992592968046665\n",
            "Epoch 14, Step 36, Loss: 0.008742897771298885\n",
            "Epoch 14, Step 37, Loss: 0.009583829902112484\n",
            "Epoch 14, Step 38, Loss: 0.00888905581086874\n",
            "Epoch 14, Step 39, Loss: 0.009018481709063053\n",
            "Epoch 14, Step 40, Loss: 0.009384730830788612\n",
            "Epoch 14, Step 41, Loss: 0.007439550012350082\n",
            "Epoch 14, Step 42, Loss: 0.007443168666213751\n",
            "Epoch 14, Step 43, Loss: 0.006818383000791073\n",
            "Epoch 14, Step 44, Loss: 0.007413260173052549\n",
            "Epoch 14, Step 45, Loss: 0.008561846800148487\n",
            "Epoch 14, Step 46, Loss: 0.007974566891789436\n",
            "Epoch 14, Step 47, Loss: 0.007859197445213795\n",
            "Epoch 14, Step 48, Loss: 0.007149711716920137\n",
            "Epoch 14, Step 49, Loss: 0.007158896420150995\n",
            "Epoch 14, Step 50, Loss: 0.006881347391754389\n",
            "Epoch 14, Step 51, Loss: 0.007065912242978811\n",
            "Epoch 14, Step 52, Loss: 0.006477022543549538\n",
            "Epoch 14, Step 53, Loss: 0.008565063588321209\n",
            "Epoch 14, Step 54, Loss: 0.005849310662597418\n",
            "Epoch 14, Step 55, Loss: 0.0068612308241426945\n",
            "Epoch 14, Step 56, Loss: 0.007334410212934017\n",
            "Epoch 14, Step 57, Loss: 0.006310891360044479\n",
            "Epoch 14, Step 58, Loss: 0.006665944121778011\n",
            "Epoch 14, Step 59, Loss: 0.0065029761753976345\n",
            "Epoch 14, Step 60, Loss: 0.006600080989301205\n",
            "Epoch 14, Step 61, Loss: 0.00900328904390335\n",
            "Epoch 14, Step 62, Loss: 0.006440652534365654\n",
            "Epoch 14, Step 63, Loss: 0.007365080993622541\n",
            "Epoch 14, Step 64, Loss: 0.006386403925716877\n",
            "Epoch 14, Step 65, Loss: 0.007176678162068129\n",
            "Epoch 14, Step 66, Loss: 0.007846037857234478\n",
            "Epoch 14, Step 67, Loss: 0.00887520331889391\n",
            "Epoch 14, Step 68, Loss: 0.008113057352602482\n",
            "Epoch 14, Step 69, Loss: 0.008530844002962112\n",
            "Epoch 14, Step 70, Loss: 0.009321200661361217\n",
            "Epoch 14, Step 71, Loss: 0.009521318599581718\n",
            "Epoch 14, Step 72, Loss: 0.008166194893419743\n",
            "Epoch 14, Step 73, Loss: 0.007570671383291483\n",
            "Epoch 14, Step 74, Loss: 0.0073846131563186646\n",
            "Epoch 14, Step 75, Loss: 0.008832236751914024\n",
            "Epoch 14, Step 76, Loss: 0.008308959193527699\n",
            "Epoch 14, Step 77, Loss: 0.009040032513439655\n",
            "Epoch 14, Step 78, Loss: 0.006811969447880983\n",
            "Epoch 14, Step 79, Loss: 0.007466795854270458\n",
            "Epoch 14, Step 80, Loss: 0.00788246002048254\n",
            "Epoch 14, Step 81, Loss: 0.010572139173746109\n",
            "Epoch 14, Step 82, Loss: 0.009493903256952763\n",
            "Epoch 14, Step 83, Loss: 0.008233784697949886\n",
            "Epoch 14, Step 84, Loss: 0.010108694434165955\n",
            "Epoch 14, Step 85, Loss: 0.010738593526184559\n",
            "Train Metric MRRs: 0.29208592293748836\n",
            "Train Metric MAPs: 0.3001686795548817\n",
            "Validation Metric MRRs: 0.22230602791263251\n",
            "Validation Metric MAPs: 0.20935673190988432\n",
            "Epoch 15, Step 1, Loss: 0.02283855713903904\n",
            "Epoch 15, Step 2, Loss: 0.022517945617437363\n",
            "Epoch 15, Step 3, Loss: 0.018512047827243805\n",
            "Epoch 15, Step 4, Loss: 0.014670105651021004\n",
            "Epoch 15, Step 5, Loss: 0.010573607869446278\n",
            "Epoch 15, Step 6, Loss: 0.007896867580711842\n",
            "Epoch 15, Step 7, Loss: 0.005716467276215553\n",
            "Epoch 15, Step 8, Loss: 0.005841761361807585\n",
            "Epoch 15, Step 9, Loss: 0.005243996623903513\n",
            "Epoch 15, Step 10, Loss: 0.00528678297996521\n",
            "Epoch 15, Step 11, Loss: 0.005945148412138224\n",
            "Epoch 15, Step 12, Loss: 0.00560056883841753\n",
            "Epoch 15, Step 13, Loss: 0.005192490294575691\n",
            "Epoch 15, Step 14, Loss: 0.004391152877360582\n",
            "Epoch 15, Step 15, Loss: 0.004813183099031448\n",
            "Epoch 15, Step 16, Loss: 0.005116104148328304\n",
            "Epoch 15, Step 17, Loss: 0.00661954702809453\n",
            "Epoch 15, Step 18, Loss: 0.0077139087952673435\n",
            "Epoch 15, Step 19, Loss: 0.009494262747466564\n",
            "Epoch 15, Step 20, Loss: 0.009201769717037678\n",
            "Epoch 15, Step 21, Loss: 0.01009310781955719\n",
            "Epoch 15, Step 22, Loss: 0.010053926147520542\n",
            "Epoch 15, Step 23, Loss: 0.01053338311612606\n",
            "Epoch 15, Step 24, Loss: 0.010965217836201191\n",
            "Epoch 15, Step 25, Loss: 0.01209917664527893\n",
            "Epoch 15, Step 26, Loss: 0.010427462868392467\n",
            "Epoch 15, Step 27, Loss: 0.009154482744634151\n",
            "Epoch 15, Step 28, Loss: 0.010470947250723839\n",
            "Epoch 15, Step 29, Loss: 0.01024648267775774\n",
            "Epoch 15, Step 30, Loss: 0.008440081961452961\n",
            "Epoch 15, Step 31, Loss: 0.010783185251057148\n",
            "Epoch 15, Step 32, Loss: 0.008784383535385132\n",
            "Epoch 15, Step 33, Loss: 0.010054550133645535\n",
            "Epoch 15, Step 34, Loss: 0.009254190139472485\n",
            "Epoch 15, Step 35, Loss: 0.009907613508403301\n",
            "Epoch 15, Step 36, Loss: 0.00891312025487423\n",
            "Epoch 15, Step 37, Loss: 0.00970373209565878\n",
            "Epoch 15, Step 38, Loss: 0.009129785001277924\n",
            "Epoch 15, Step 39, Loss: 0.009185411036014557\n",
            "Epoch 15, Step 40, Loss: 0.009501555003225803\n",
            "Epoch 15, Step 41, Loss: 0.007403702940791845\n",
            "Epoch 15, Step 42, Loss: 0.007472554687410593\n",
            "Epoch 15, Step 43, Loss: 0.006835911888629198\n",
            "Epoch 15, Step 44, Loss: 0.007402411196380854\n",
            "Epoch 15, Step 45, Loss: 0.008593754842877388\n",
            "Epoch 15, Step 46, Loss: 0.008011562749743462\n",
            "Epoch 15, Step 47, Loss: 0.008069061674177647\n",
            "Epoch 15, Step 48, Loss: 0.007317948620766401\n",
            "Epoch 15, Step 49, Loss: 0.007321734447032213\n",
            "Epoch 15, Step 50, Loss: 0.007030086126178503\n",
            "Epoch 15, Step 51, Loss: 0.007106604054570198\n",
            "Epoch 15, Step 52, Loss: 0.006480544805526733\n",
            "Epoch 15, Step 53, Loss: 0.008502647280693054\n",
            "Epoch 15, Step 54, Loss: 0.005826106760650873\n",
            "Epoch 15, Step 55, Loss: 0.006899780593812466\n",
            "Epoch 15, Step 56, Loss: 0.007252272218465805\n",
            "Epoch 15, Step 57, Loss: 0.0064376783557236195\n",
            "Epoch 15, Step 58, Loss: 0.006851931102573872\n",
            "Epoch 15, Step 59, Loss: 0.006702575366944075\n",
            "Epoch 15, Step 60, Loss: 0.006843112409114838\n",
            "Epoch 15, Step 61, Loss: 0.008828758262097836\n",
            "Epoch 15, Step 62, Loss: 0.006459543015807867\n",
            "Epoch 15, Step 63, Loss: 0.007327626924961805\n",
            "Epoch 15, Step 64, Loss: 0.006423115264624357\n",
            "Epoch 15, Step 65, Loss: 0.007197290658950806\n",
            "Epoch 15, Step 66, Loss: 0.007826202549040318\n",
            "Epoch 15, Step 67, Loss: 0.008968154899775982\n",
            "Epoch 15, Step 68, Loss: 0.00807765033096075\n",
            "Epoch 15, Step 69, Loss: 0.008750582113862038\n",
            "Epoch 15, Step 70, Loss: 0.00932250451296568\n",
            "Epoch 15, Step 71, Loss: 0.009608965367078781\n",
            "Epoch 15, Step 72, Loss: 0.008292426355183125\n",
            "Epoch 15, Step 73, Loss: 0.007585767190903425\n",
            "Epoch 15, Step 74, Loss: 0.007510693743824959\n",
            "Epoch 15, Step 75, Loss: 0.008974422700703144\n",
            "Epoch 15, Step 76, Loss: 0.008342194370925426\n",
            "Epoch 15, Step 77, Loss: 0.009070444852113724\n",
            "Epoch 15, Step 78, Loss: 0.0069136423990130424\n",
            "Epoch 15, Step 79, Loss: 0.0073949554935097694\n",
            "Epoch 15, Step 80, Loss: 0.007909685373306274\n",
            "Epoch 15, Step 81, Loss: 0.010671885684132576\n",
            "Epoch 15, Step 82, Loss: 0.009398877620697021\n",
            "Epoch 15, Step 83, Loss: 0.008096032775938511\n",
            "Epoch 15, Step 84, Loss: 0.009985609911382198\n",
            "Epoch 15, Step 85, Loss: 0.010637667961418629\n",
            "Train Metric MRRs: 0.29133684400937154\n",
            "Train Metric MAPs: 0.3054279214293189\n",
            "Validation Metric MRRs: 0.2207086098363151\n",
            "Validation Metric MAPs: 0.21086768140196477\n",
            "Epoch 16, Step 1, Loss: 0.023165974766016006\n",
            "Epoch 16, Step 2, Loss: 0.022447124123573303\n",
            "Epoch 16, Step 3, Loss: 0.01832711510360241\n",
            "Epoch 16, Step 4, Loss: 0.014625802636146545\n",
            "Epoch 16, Step 5, Loss: 0.010632903315126896\n",
            "Epoch 16, Step 6, Loss: 0.007850793190300465\n",
            "Epoch 16, Step 7, Loss: 0.005716787185519934\n",
            "Epoch 16, Step 8, Loss: 0.0058202375657856464\n",
            "Epoch 16, Step 9, Loss: 0.005323417950421572\n",
            "Epoch 16, Step 10, Loss: 0.005543949082493782\n",
            "Epoch 16, Step 11, Loss: 0.006506981328129768\n",
            "Epoch 16, Step 12, Loss: 0.005656961817294359\n",
            "Epoch 16, Step 13, Loss: 0.005253357347100973\n",
            "Epoch 16, Step 14, Loss: 0.004576138220727444\n",
            "Epoch 16, Step 15, Loss: 0.004791839513927698\n",
            "Epoch 16, Step 16, Loss: 0.005163113586604595\n",
            "Epoch 16, Step 17, Loss: 0.006547619588673115\n",
            "Epoch 16, Step 18, Loss: 0.007821357809007168\n",
            "Epoch 16, Step 19, Loss: 0.009245381690561771\n",
            "Epoch 16, Step 20, Loss: 0.009167393669486046\n",
            "Epoch 16, Step 21, Loss: 0.010084605775773525\n",
            "Epoch 16, Step 22, Loss: 0.009712382219731808\n",
            "Epoch 16, Step 23, Loss: 0.010562530718743801\n",
            "Epoch 16, Step 24, Loss: 0.010961061343550682\n",
            "Epoch 16, Step 25, Loss: 0.012000982649624348\n",
            "Epoch 16, Step 26, Loss: 0.01021265983581543\n",
            "Epoch 16, Step 27, Loss: 0.008748017251491547\n",
            "Epoch 16, Step 28, Loss: 0.010397298261523247\n",
            "Epoch 16, Step 29, Loss: 0.010227940045297146\n",
            "Epoch 16, Step 30, Loss: 0.008366952650249004\n",
            "Epoch 16, Step 31, Loss: 0.010754418559372425\n",
            "Epoch 16, Step 32, Loss: 0.009036283008754253\n",
            "Epoch 16, Step 33, Loss: 0.010295445099473\n",
            "Epoch 16, Step 34, Loss: 0.009227653034031391\n",
            "Epoch 16, Step 35, Loss: 0.009699839167296886\n",
            "Epoch 16, Step 36, Loss: 0.008819809183478355\n",
            "Epoch 16, Step 37, Loss: 0.009772962890565395\n",
            "Epoch 16, Step 38, Loss: 0.009308424778282642\n",
            "Epoch 16, Step 39, Loss: 0.009426984935998917\n",
            "Epoch 16, Step 40, Loss: 0.009610692039132118\n",
            "Epoch 16, Step 41, Loss: 0.007570804562419653\n",
            "Epoch 16, Step 42, Loss: 0.007478100247681141\n",
            "Epoch 16, Step 43, Loss: 0.006763201206922531\n",
            "Epoch 16, Step 44, Loss: 0.007416119799017906\n",
            "Epoch 16, Step 45, Loss: 0.008475469425320625\n",
            "Epoch 16, Step 46, Loss: 0.007986083626747131\n",
            "Epoch 16, Step 47, Loss: 0.008016661740839481\n",
            "Epoch 16, Step 48, Loss: 0.007426653988659382\n",
            "Epoch 16, Step 49, Loss: 0.007388632278889418\n",
            "Epoch 16, Step 50, Loss: 0.007142568472772837\n",
            "Epoch 16, Step 51, Loss: 0.007080158684402704\n",
            "Epoch 16, Step 52, Loss: 0.006453368347138166\n",
            "Epoch 16, Step 53, Loss: 0.008573192171752453\n",
            "Epoch 16, Step 54, Loss: 0.005831517744809389\n",
            "Epoch 16, Step 55, Loss: 0.006867233198136091\n",
            "Epoch 16, Step 56, Loss: 0.007245822809636593\n",
            "Epoch 16, Step 57, Loss: 0.006346333306282759\n",
            "Epoch 16, Step 58, Loss: 0.006692873779684305\n",
            "Epoch 16, Step 59, Loss: 0.006499412469565868\n",
            "Epoch 16, Step 60, Loss: 0.006731649860739708\n",
            "Epoch 16, Step 61, Loss: 0.008973788470029831\n",
            "Epoch 16, Step 62, Loss: 0.00649535097181797\n",
            "Epoch 16, Step 63, Loss: 0.007329059764742851\n",
            "Epoch 16, Step 64, Loss: 0.006376492790877819\n",
            "Epoch 16, Step 65, Loss: 0.007255417760461569\n",
            "Epoch 16, Step 66, Loss: 0.007842806167900562\n",
            "Epoch 16, Step 67, Loss: 0.00885751098394394\n",
            "Epoch 16, Step 68, Loss: 0.008001663722097874\n",
            "Epoch 16, Step 69, Loss: 0.008732005022466183\n",
            "Epoch 16, Step 70, Loss: 0.00945400632917881\n",
            "Epoch 16, Step 71, Loss: 0.00972876138985157\n",
            "Epoch 16, Step 72, Loss: 0.008107406087219715\n",
            "Epoch 16, Step 73, Loss: 0.00762890325859189\n",
            "Epoch 16, Step 74, Loss: 0.007334768772125244\n",
            "Epoch 16, Step 75, Loss: 0.008975599892437458\n",
            "Epoch 16, Step 76, Loss: 0.00830561388283968\n",
            "Epoch 16, Step 77, Loss: 0.009053805842995644\n",
            "Epoch 16, Step 78, Loss: 0.006828300189226866\n",
            "Epoch 16, Step 79, Loss: 0.007557214703410864\n",
            "Epoch 16, Step 80, Loss: 0.007836529985070229\n",
            "Epoch 16, Step 81, Loss: 0.01043416652828455\n",
            "Epoch 16, Step 82, Loss: 0.00935235247015953\n",
            "Epoch 16, Step 83, Loss: 0.008194142952561378\n",
            "Epoch 16, Step 84, Loss: 0.010043475776910782\n",
            "Epoch 16, Step 85, Loss: 0.010569422505795956\n",
            "Train Metric MRRs: 0.2911079765919858\n",
            "Train Metric MAPs: 0.2997005009595796\n",
            "Validation Metric MRRs: 0.22104825388725946\n",
            "Validation Metric MAPs: 0.20967466276182384\n",
            "Epoch 17, Step 1, Loss: 0.022244907915592194\n",
            "Epoch 17, Step 2, Loss: 0.022157395258545876\n",
            "Epoch 17, Step 3, Loss: 0.018421240150928497\n",
            "Epoch 17, Step 4, Loss: 0.014532232657074928\n",
            "Epoch 17, Step 5, Loss: 0.01060863770544529\n",
            "Epoch 17, Step 6, Loss: 0.007733008824288845\n",
            "Epoch 17, Step 7, Loss: 0.005674377549439669\n",
            "Epoch 17, Step 8, Loss: 0.005770919378846884\n",
            "Epoch 17, Step 9, Loss: 0.005206435453146696\n",
            "Epoch 17, Step 10, Loss: 0.0052765049040317535\n",
            "Epoch 17, Step 11, Loss: 0.006077520549297333\n",
            "Epoch 17, Step 12, Loss: 0.005692456383258104\n",
            "Epoch 17, Step 13, Loss: 0.0052040945738554\n",
            "Epoch 17, Step 14, Loss: 0.004443183075636625\n",
            "Epoch 17, Step 15, Loss: 0.004606651607900858\n",
            "Epoch 17, Step 16, Loss: 0.004856796469539404\n",
            "Epoch 17, Step 17, Loss: 0.0065796272829174995\n",
            "Epoch 17, Step 18, Loss: 0.0075186630710959435\n",
            "Epoch 17, Step 19, Loss: 0.009321983903646469\n",
            "Epoch 17, Step 20, Loss: 0.009006750769913197\n",
            "Epoch 17, Step 21, Loss: 0.009789254516363144\n",
            "Epoch 17, Step 22, Loss: 0.009800063446164131\n",
            "Epoch 17, Step 23, Loss: 0.010510792024433613\n",
            "Epoch 17, Step 24, Loss: 0.01085921935737133\n",
            "Epoch 17, Step 25, Loss: 0.012079212814569473\n",
            "Epoch 17, Step 26, Loss: 0.010195501148700714\n",
            "Epoch 17, Step 27, Loss: 0.008808314800262451\n",
            "Epoch 17, Step 28, Loss: 0.010292752645909786\n",
            "Epoch 17, Step 29, Loss: 0.010079189203679562\n",
            "Epoch 17, Step 30, Loss: 0.008183736354112625\n",
            "Epoch 17, Step 31, Loss: 0.010700229555368423\n",
            "Epoch 17, Step 32, Loss: 0.008881685324013233\n",
            "Epoch 17, Step 33, Loss: 0.010065007954835892\n",
            "Epoch 17, Step 34, Loss: 0.009044858627021313\n",
            "Epoch 17, Step 35, Loss: 0.009641995653510094\n",
            "Epoch 17, Step 36, Loss: 0.008511506021022797\n",
            "Epoch 17, Step 37, Loss: 0.009427940472960472\n",
            "Epoch 17, Step 38, Loss: 0.009045937098562717\n",
            "Epoch 17, Step 39, Loss: 0.009198623709380627\n",
            "Epoch 17, Step 40, Loss: 0.009487797506153584\n",
            "Epoch 17, Step 41, Loss: 0.007621045224368572\n",
            "Epoch 17, Step 42, Loss: 0.007496020291000605\n",
            "Epoch 17, Step 43, Loss: 0.00691083911806345\n",
            "Epoch 17, Step 44, Loss: 0.007367652840912342\n",
            "Epoch 17, Step 45, Loss: 0.00827097985893488\n",
            "Epoch 17, Step 46, Loss: 0.007807671558111906\n",
            "Epoch 17, Step 47, Loss: 0.007906935177743435\n",
            "Epoch 17, Step 48, Loss: 0.007358878385275602\n",
            "Epoch 17, Step 49, Loss: 0.007320235949009657\n",
            "Epoch 17, Step 50, Loss: 0.007093073800206184\n",
            "Epoch 17, Step 51, Loss: 0.007161767687648535\n",
            "Epoch 17, Step 52, Loss: 0.006397698540240526\n",
            "Epoch 17, Step 53, Loss: 0.00863431952893734\n",
            "Epoch 17, Step 54, Loss: 0.005858355201780796\n",
            "Epoch 17, Step 55, Loss: 0.006780947092920542\n",
            "Epoch 17, Step 56, Loss: 0.007139021065086126\n",
            "Epoch 17, Step 57, Loss: 0.006365457084029913\n",
            "Epoch 17, Step 58, Loss: 0.006676492281258106\n",
            "Epoch 17, Step 59, Loss: 0.006505267228931189\n",
            "Epoch 17, Step 60, Loss: 0.006889501586556435\n",
            "Epoch 17, Step 61, Loss: 0.008802250027656555\n",
            "Epoch 17, Step 62, Loss: 0.006512075196951628\n",
            "Epoch 17, Step 63, Loss: 0.007345142774283886\n",
            "Epoch 17, Step 64, Loss: 0.006409623194485903\n",
            "Epoch 17, Step 65, Loss: 0.007247195579111576\n",
            "Epoch 17, Step 66, Loss: 0.00768624059855938\n",
            "Epoch 17, Step 67, Loss: 0.008756628260016441\n",
            "Epoch 17, Step 68, Loss: 0.007946966215968132\n",
            "Epoch 17, Step 69, Loss: 0.008551713079214096\n",
            "Epoch 17, Step 70, Loss: 0.009442302398383617\n",
            "Epoch 17, Step 71, Loss: 0.009659255854785442\n",
            "Epoch 17, Step 72, Loss: 0.007950176484882832\n",
            "Epoch 17, Step 73, Loss: 0.007544019725173712\n",
            "Epoch 17, Step 74, Loss: 0.00721549428999424\n",
            "Epoch 17, Step 75, Loss: 0.008770029060542583\n",
            "Epoch 17, Step 76, Loss: 0.008222638629376888\n",
            "Epoch 17, Step 77, Loss: 0.008973360061645508\n",
            "Epoch 17, Step 78, Loss: 0.006813297048211098\n",
            "Epoch 17, Step 79, Loss: 0.007312604691833258\n",
            "Epoch 17, Step 80, Loss: 0.007855312898755074\n",
            "Epoch 17, Step 81, Loss: 0.010778989642858505\n",
            "Epoch 17, Step 82, Loss: 0.009328331798315048\n",
            "Epoch 17, Step 83, Loss: 0.008206784725189209\n",
            "Epoch 17, Step 84, Loss: 0.009845860302448273\n",
            "Epoch 17, Step 85, Loss: 0.010377928614616394\n",
            "Train Metric MRRs: 0.2942174616164855\n",
            "Train Metric MAPs: 0.3053808155164591\n",
            "Validation Metric MRRs: 0.21987344783838597\n",
            "Validation Metric MAPs: 0.20941557733790478\n",
            "Epoch 18, Step 1, Loss: 0.022014280781149864\n",
            "Epoch 18, Step 2, Loss: 0.022115347906947136\n",
            "Epoch 18, Step 3, Loss: 0.018383890390396118\n",
            "Epoch 18, Step 4, Loss: 0.014802356250584126\n",
            "Epoch 18, Step 5, Loss: 0.010856304317712784\n",
            "Epoch 18, Step 6, Loss: 0.007819737307727337\n",
            "Epoch 18, Step 7, Loss: 0.005634472705423832\n",
            "Epoch 18, Step 8, Loss: 0.005747014191001654\n",
            "Epoch 18, Step 9, Loss: 0.005254960618913174\n",
            "Epoch 18, Step 10, Loss: 0.005274821072816849\n",
            "Epoch 18, Step 11, Loss: 0.005982623435556889\n",
            "Epoch 18, Step 12, Loss: 0.005645516328513622\n",
            "Epoch 18, Step 13, Loss: 0.005195036996155977\n",
            "Epoch 18, Step 14, Loss: 0.004605058114975691\n",
            "Epoch 18, Step 15, Loss: 0.004978503100574017\n",
            "Epoch 18, Step 16, Loss: 0.004952290561050177\n",
            "Epoch 18, Step 17, Loss: 0.0065372660756111145\n",
            "Epoch 18, Step 18, Loss: 0.007673249114304781\n",
            "Epoch 18, Step 19, Loss: 0.009208416566252708\n",
            "Epoch 18, Step 20, Loss: 0.00932349730283022\n",
            "Epoch 18, Step 21, Loss: 0.009805431589484215\n",
            "Epoch 18, Step 22, Loss: 0.009893781505525112\n",
            "Epoch 18, Step 23, Loss: 0.010341659188270569\n",
            "Epoch 18, Step 24, Loss: 0.010752836242318153\n",
            "Epoch 18, Step 25, Loss: 0.01182088628411293\n",
            "Epoch 18, Step 26, Loss: 0.010158071294426918\n",
            "Epoch 18, Step 27, Loss: 0.0087432861328125\n",
            "Epoch 18, Step 28, Loss: 0.010306437499821186\n",
            "Epoch 18, Step 29, Loss: 0.01025056466460228\n",
            "Epoch 18, Step 30, Loss: 0.008279210887849331\n",
            "Epoch 18, Step 31, Loss: 0.010616261512041092\n",
            "Epoch 18, Step 32, Loss: 0.009036136791110039\n",
            "Epoch 18, Step 33, Loss: 0.010176907293498516\n",
            "Epoch 18, Step 34, Loss: 0.008974943310022354\n",
            "Epoch 18, Step 35, Loss: 0.009567459113895893\n",
            "Epoch 18, Step 36, Loss: 0.008435769006609917\n",
            "Epoch 18, Step 37, Loss: 0.009342597797513008\n",
            "Epoch 18, Step 38, Loss: 0.008919144980609417\n",
            "Epoch 18, Step 39, Loss: 0.009035127237439156\n",
            "Epoch 18, Step 40, Loss: 0.009396570734679699\n",
            "Epoch 18, Step 41, Loss: 0.007606745231896639\n",
            "Epoch 18, Step 42, Loss: 0.0075832814909517765\n",
            "Epoch 18, Step 43, Loss: 0.00686264643445611\n",
            "Epoch 18, Step 44, Loss: 0.00739711569622159\n",
            "Epoch 18, Step 45, Loss: 0.00815517082810402\n",
            "Epoch 18, Step 46, Loss: 0.007706459611654282\n",
            "Epoch 18, Step 47, Loss: 0.007668548729270697\n",
            "Epoch 18, Step 48, Loss: 0.007211445365101099\n",
            "Epoch 18, Step 49, Loss: 0.007257496472448111\n",
            "Epoch 18, Step 50, Loss: 0.00702687818557024\n",
            "Epoch 18, Step 51, Loss: 0.007169793825596571\n",
            "Epoch 18, Step 52, Loss: 0.006481118034571409\n",
            "Epoch 18, Step 53, Loss: 0.008769921958446503\n",
            "Epoch 18, Step 54, Loss: 0.005833390634506941\n",
            "Epoch 18, Step 55, Loss: 0.006852538324892521\n",
            "Epoch 18, Step 56, Loss: 0.007108417339622974\n",
            "Epoch 18, Step 57, Loss: 0.006273361388593912\n",
            "Epoch 18, Step 58, Loss: 0.006607261952012777\n",
            "Epoch 18, Step 59, Loss: 0.0063200476579368114\n",
            "Epoch 18, Step 60, Loss: 0.006733110640197992\n",
            "Epoch 18, Step 61, Loss: 0.008780266158282757\n",
            "Epoch 18, Step 62, Loss: 0.0065755899995565414\n",
            "Epoch 18, Step 63, Loss: 0.007631024811416864\n",
            "Epoch 18, Step 64, Loss: 0.0066507430747151375\n",
            "Epoch 18, Step 65, Loss: 0.007204425521194935\n",
            "Epoch 18, Step 66, Loss: 0.007703324314206839\n",
            "Epoch 18, Step 67, Loss: 0.008667766116559505\n",
            "Epoch 18, Step 68, Loss: 0.007896755822002888\n",
            "Epoch 18, Step 69, Loss: 0.008504003286361694\n",
            "Epoch 18, Step 70, Loss: 0.009572436101734638\n",
            "Epoch 18, Step 71, Loss: 0.009744284674525261\n",
            "Epoch 18, Step 72, Loss: 0.008124605752527714\n",
            "Epoch 18, Step 73, Loss: 0.007526003755629063\n",
            "Epoch 18, Step 74, Loss: 0.007379902992397547\n",
            "Epoch 18, Step 75, Loss: 0.008873404003679752\n",
            "Epoch 18, Step 76, Loss: 0.00833121407777071\n",
            "Epoch 18, Step 77, Loss: 0.008933051489293575\n",
            "Epoch 18, Step 78, Loss: 0.006734468042850494\n",
            "Epoch 18, Step 79, Loss: 0.0073991636745631695\n",
            "Epoch 18, Step 80, Loss: 0.007766560651361942\n",
            "Epoch 18, Step 81, Loss: 0.01074216142296791\n",
            "Epoch 18, Step 82, Loss: 0.009418399073183537\n",
            "Epoch 18, Step 83, Loss: 0.008271045982837677\n",
            "Epoch 18, Step 84, Loss: 0.010070951655507088\n",
            "Epoch 18, Step 85, Loss: 0.010415337048470974\n",
            "Train Metric MRRs: 0.2947982781062914\n",
            "Train Metric MAPs: 0.3062322179469262\n",
            "Validation Metric MRRs: 0.2235215460139782\n",
            "Validation Metric MAPs: 0.21074821797428991\n",
            "Epoch 19, Step 1, Loss: 0.02235012874007225\n",
            "Epoch 19, Step 2, Loss: 0.02189387008547783\n",
            "Epoch 19, Step 3, Loss: 0.018316613510251045\n",
            "Epoch 19, Step 4, Loss: 0.014951296150684357\n",
            "Epoch 19, Step 5, Loss: 0.011072010733187199\n",
            "Epoch 19, Step 6, Loss: 0.008024386130273342\n",
            "Epoch 19, Step 7, Loss: 0.0057266950607299805\n",
            "Epoch 19, Step 8, Loss: 0.005852682515978813\n",
            "Epoch 19, Step 9, Loss: 0.005407468881458044\n",
            "Epoch 19, Step 10, Loss: 0.005257836543023586\n",
            "Epoch 19, Step 11, Loss: 0.00593861797824502\n",
            "Epoch 19, Step 12, Loss: 0.005482131149619818\n",
            "Epoch 19, Step 13, Loss: 0.005216961260885\n",
            "Epoch 19, Step 14, Loss: 0.004715990275144577\n",
            "Epoch 19, Step 15, Loss: 0.005209899973124266\n",
            "Epoch 19, Step 16, Loss: 0.005299137439578772\n",
            "Epoch 19, Step 17, Loss: 0.006733962334692478\n",
            "Epoch 19, Step 18, Loss: 0.007845252752304077\n",
            "Epoch 19, Step 19, Loss: 0.009263928979635239\n",
            "Epoch 19, Step 20, Loss: 0.009117141366004944\n",
            "Epoch 19, Step 21, Loss: 0.009521402418613434\n",
            "Epoch 19, Step 22, Loss: 0.009976241737604141\n",
            "Epoch 19, Step 23, Loss: 0.010133551433682442\n",
            "Epoch 19, Step 24, Loss: 0.010738189332187176\n",
            "Epoch 19, Step 25, Loss: 0.011904585175216198\n",
            "Epoch 19, Step 26, Loss: 0.01003726851195097\n",
            "Epoch 19, Step 27, Loss: 0.008669467642903328\n",
            "Epoch 19, Step 28, Loss: 0.010092584416270256\n",
            "Epoch 19, Step 29, Loss: 0.010477251373231411\n",
            "Epoch 19, Step 30, Loss: 0.008195060305297375\n",
            "Epoch 19, Step 31, Loss: 0.0106894476339221\n",
            "Epoch 19, Step 32, Loss: 0.00911619234830141\n",
            "Epoch 19, Step 33, Loss: 0.010370822623372078\n",
            "Epoch 19, Step 34, Loss: 0.00903585460036993\n",
            "Epoch 19, Step 35, Loss: 0.00954822450876236\n",
            "Epoch 19, Step 36, Loss: 0.008447916246950626\n",
            "Epoch 19, Step 37, Loss: 0.009183420799672604\n",
            "Epoch 19, Step 38, Loss: 0.008809089660644531\n",
            "Epoch 19, Step 39, Loss: 0.008956247940659523\n",
            "Epoch 19, Step 40, Loss: 0.009369217790663242\n",
            "Epoch 19, Step 41, Loss: 0.007729879580438137\n",
            "Epoch 19, Step 42, Loss: 0.0076105608604848385\n",
            "Epoch 19, Step 43, Loss: 0.007112589199095964\n",
            "Epoch 19, Step 44, Loss: 0.007569069508463144\n",
            "Epoch 19, Step 45, Loss: 0.008159894496202469\n",
            "Epoch 19, Step 46, Loss: 0.0075585427694022655\n",
            "Epoch 19, Step 47, Loss: 0.007672182284295559\n",
            "Epoch 19, Step 48, Loss: 0.007203154265880585\n",
            "Epoch 19, Step 49, Loss: 0.007125309202820063\n",
            "Epoch 19, Step 50, Loss: 0.007035346701741219\n",
            "Epoch 19, Step 51, Loss: 0.007143670693039894\n",
            "Epoch 19, Step 52, Loss: 0.006594570353627205\n",
            "Epoch 19, Step 53, Loss: 0.00891019031405449\n",
            "Epoch 19, Step 54, Loss: 0.00593156274408102\n",
            "Epoch 19, Step 55, Loss: 0.006882804445922375\n",
            "Epoch 19, Step 56, Loss: 0.007045457139611244\n",
            "Epoch 19, Step 57, Loss: 0.0062494887970387936\n",
            "Epoch 19, Step 58, Loss: 0.006589380092918873\n",
            "Epoch 19, Step 59, Loss: 0.006279204040765762\n",
            "Epoch 19, Step 60, Loss: 0.00661608949303627\n",
            "Epoch 19, Step 61, Loss: 0.008823119103908539\n",
            "Epoch 19, Step 62, Loss: 0.006534100044518709\n",
            "Epoch 19, Step 63, Loss: 0.007581853307783604\n",
            "Epoch 19, Step 64, Loss: 0.0066522033885121346\n",
            "Epoch 19, Step 65, Loss: 0.00734924478456378\n",
            "Epoch 19, Step 66, Loss: 0.007807481102645397\n",
            "Epoch 19, Step 67, Loss: 0.00865460280328989\n",
            "Epoch 19, Step 68, Loss: 0.008075173012912273\n",
            "Epoch 19, Step 69, Loss: 0.00865093618631363\n",
            "Epoch 19, Step 70, Loss: 0.009306738153100014\n",
            "Epoch 19, Step 71, Loss: 0.009689176455140114\n",
            "Epoch 19, Step 72, Loss: 0.008017282001674175\n",
            "Epoch 19, Step 73, Loss: 0.007571711670607328\n",
            "Epoch 19, Step 74, Loss: 0.0073891282081604\n",
            "Epoch 19, Step 75, Loss: 0.00898649264127016\n",
            "Epoch 19, Step 76, Loss: 0.008342670276761055\n",
            "Epoch 19, Step 77, Loss: 0.009109488688409328\n",
            "Epoch 19, Step 78, Loss: 0.006602566689252853\n",
            "Epoch 19, Step 79, Loss: 0.007229573093354702\n",
            "Epoch 19, Step 80, Loss: 0.0076007237657904625\n",
            "Epoch 19, Step 81, Loss: 0.010357023216784\n",
            "Epoch 19, Step 82, Loss: 0.009400583803653717\n",
            "Epoch 19, Step 83, Loss: 0.008270369842648506\n",
            "Epoch 19, Step 84, Loss: 0.010043326765298843\n",
            "Epoch 19, Step 85, Loss: 0.010425357148051262\n",
            "Train Metric MRRs: 0.2949610318026842\n",
            "Train Metric MAPs: 0.3076999571159666\n",
            "Validation Metric MRRs: 0.22484871968244075\n",
            "Validation Metric MAPs: 0.2138164615077356\n",
            "Epoch 20, Step 1, Loss: 0.0241208728402853\n",
            "Epoch 20, Step 2, Loss: 0.0220705084502697\n",
            "Epoch 20, Step 3, Loss: 0.01805308647453785\n",
            "Epoch 20, Step 4, Loss: 0.014927067793905735\n",
            "Epoch 20, Step 5, Loss: 0.011330723762512207\n",
            "Epoch 20, Step 6, Loss: 0.008343297988176346\n",
            "Epoch 20, Step 7, Loss: 0.005901424679905176\n",
            "Epoch 20, Step 8, Loss: 0.006128302309662104\n",
            "Epoch 20, Step 9, Loss: 0.005616891663521528\n",
            "Epoch 20, Step 10, Loss: 0.005460684187710285\n",
            "Epoch 20, Step 11, Loss: 0.0062441136687994\n",
            "Epoch 20, Step 12, Loss: 0.0056619709357619286\n",
            "Epoch 20, Step 13, Loss: 0.005404937546700239\n",
            "Epoch 20, Step 14, Loss: 0.004471479915082455\n",
            "Epoch 20, Step 15, Loss: 0.005149912089109421\n",
            "Epoch 20, Step 16, Loss: 0.0055243270471692085\n",
            "Epoch 20, Step 17, Loss: 0.00706343213096261\n",
            "Epoch 20, Step 18, Loss: 0.007946866564452648\n",
            "Epoch 20, Step 19, Loss: 0.009824930690228939\n",
            "Epoch 20, Step 20, Loss: 0.009467149153351784\n",
            "Epoch 20, Step 21, Loss: 0.00985605176538229\n",
            "Epoch 20, Step 22, Loss: 0.010813799686729908\n",
            "Epoch 20, Step 23, Loss: 0.010368231683969498\n",
            "Epoch 20, Step 24, Loss: 0.011347116902470589\n",
            "Epoch 20, Step 25, Loss: 0.012207087129354477\n",
            "Epoch 20, Step 26, Loss: 0.010481482371687889\n",
            "Epoch 20, Step 27, Loss: 0.008823823183774948\n",
            "Epoch 20, Step 28, Loss: 0.010650650598108768\n",
            "Epoch 20, Step 29, Loss: 0.010989301837980747\n",
            "Epoch 20, Step 30, Loss: 0.00863454770296812\n",
            "Epoch 20, Step 31, Loss: 0.01115314569324255\n",
            "Epoch 20, Step 32, Loss: 0.009121577255427837\n",
            "Epoch 20, Step 33, Loss: 0.010737359523773193\n",
            "Epoch 20, Step 34, Loss: 0.009179195389151573\n",
            "Epoch 20, Step 35, Loss: 0.009630954824388027\n",
            "Epoch 20, Step 36, Loss: 0.008497419767081738\n",
            "Epoch 20, Step 37, Loss: 0.009388134814798832\n",
            "Epoch 20, Step 38, Loss: 0.009163830429315567\n",
            "Epoch 20, Step 39, Loss: 0.008977227844297886\n",
            "Epoch 20, Step 40, Loss: 0.009530805051326752\n",
            "Epoch 20, Step 41, Loss: 0.007913478650152683\n",
            "Epoch 20, Step 42, Loss: 0.007846823893487453\n",
            "Epoch 20, Step 43, Loss: 0.007198067381978035\n",
            "Epoch 20, Step 44, Loss: 0.00783594325184822\n",
            "Epoch 20, Step 45, Loss: 0.008349004201591015\n",
            "Epoch 20, Step 46, Loss: 0.007574969902634621\n",
            "Epoch 20, Step 47, Loss: 0.007704662624746561\n",
            "Epoch 20, Step 48, Loss: 0.007201747503131628\n",
            "Epoch 20, Step 49, Loss: 0.007056328933686018\n",
            "Epoch 20, Step 50, Loss: 0.006813523825258017\n",
            "Epoch 20, Step 51, Loss: 0.0070579457096755505\n",
            "Epoch 20, Step 52, Loss: 0.006438751704990864\n",
            "Epoch 20, Step 53, Loss: 0.009022511541843414\n",
            "Epoch 20, Step 54, Loss: 0.006018674001097679\n",
            "Epoch 20, Step 55, Loss: 0.006955960765480995\n",
            "Epoch 20, Step 56, Loss: 0.007311380002647638\n",
            "Epoch 20, Step 57, Loss: 0.0062647326849401\n",
            "Epoch 20, Step 58, Loss: 0.006644250825047493\n",
            "Epoch 20, Step 59, Loss: 0.006279062479734421\n",
            "Epoch 20, Step 60, Loss: 0.0064749447628855705\n",
            "Epoch 20, Step 61, Loss: 0.00900187250226736\n",
            "Epoch 20, Step 62, Loss: 0.006435707677155733\n",
            "Epoch 20, Step 63, Loss: 0.0074883755296468735\n",
            "Epoch 20, Step 64, Loss: 0.006635243538767099\n",
            "Epoch 20, Step 65, Loss: 0.007298547308892012\n",
            "Epoch 20, Step 66, Loss: 0.007895450107753277\n",
            "Epoch 20, Step 67, Loss: 0.008923268876969814\n",
            "Epoch 20, Step 68, Loss: 0.00831259973347187\n",
            "Epoch 20, Step 69, Loss: 0.00866718776524067\n",
            "Epoch 20, Step 70, Loss: 0.009300273843109608\n",
            "Epoch 20, Step 71, Loss: 0.00963675044476986\n",
            "Epoch 20, Step 72, Loss: 0.007999828085303307\n",
            "Epoch 20, Step 73, Loss: 0.0074189091101288795\n",
            "Epoch 20, Step 74, Loss: 0.007375908549875021\n",
            "Epoch 20, Step 75, Loss: 0.009055174887180328\n",
            "Epoch 20, Step 76, Loss: 0.008527479134500027\n",
            "Epoch 20, Step 77, Loss: 0.00944723840802908\n",
            "Epoch 20, Step 78, Loss: 0.006706496700644493\n",
            "Epoch 20, Step 79, Loss: 0.007644998375326395\n",
            "Epoch 20, Step 80, Loss: 0.007854745723307133\n",
            "Epoch 20, Step 81, Loss: 0.01048545353114605\n",
            "Epoch 20, Step 82, Loss: 0.009308109991252422\n",
            "Epoch 20, Step 83, Loss: 0.008280067704617977\n",
            "Epoch 20, Step 84, Loss: 0.010132498107850552\n",
            "Epoch 20, Step 85, Loss: 0.010524195618927479\n",
            "Train Metric MRRs: 0.29370692504031676\n",
            "Train Metric MAPs: 0.3077414121043469\n",
            "Validation Metric MRRs: 0.22399250687019914\n",
            "Validation Metric MAPs: 0.2163746226595247\n",
            "Epoch 21, Step 1, Loss: 0.023588521406054497\n",
            "Epoch 21, Step 2, Loss: 0.022991778329014778\n",
            "Epoch 21, Step 3, Loss: 0.019239256158471107\n",
            "Epoch 21, Step 4, Loss: 0.01431634183973074\n",
            "Epoch 21, Step 5, Loss: 0.010667284950613976\n",
            "Epoch 21, Step 6, Loss: 0.007824813947081566\n",
            "Epoch 21, Step 7, Loss: 0.005826280917972326\n",
            "Epoch 21, Step 8, Loss: 0.006380811799317598\n",
            "Epoch 21, Step 9, Loss: 0.006011375226080418\n",
            "Epoch 21, Step 10, Loss: 0.005829694215208292\n",
            "Epoch 21, Step 11, Loss: 0.0067938570864498615\n",
            "Epoch 21, Step 12, Loss: 0.00669509032741189\n",
            "Epoch 21, Step 13, Loss: 0.00620128121227026\n",
            "Epoch 21, Step 14, Loss: 0.004993761889636517\n",
            "Epoch 21, Step 15, Loss: 0.005714140832424164\n",
            "Epoch 21, Step 16, Loss: 0.005197258200496435\n",
            "Epoch 21, Step 17, Loss: 0.0068678404204547405\n",
            "Epoch 21, Step 18, Loss: 0.007890134118497372\n",
            "Epoch 21, Step 19, Loss: 0.0095553332939744\n",
            "Epoch 21, Step 20, Loss: 0.00947562512010336\n",
            "Epoch 21, Step 21, Loss: 0.010113249532878399\n",
            "Epoch 21, Step 22, Loss: 0.01069851778447628\n",
            "Epoch 21, Step 23, Loss: 0.01037636585533619\n",
            "Epoch 21, Step 24, Loss: 0.011622470803558826\n",
            "Epoch 21, Step 25, Loss: 0.011592301540076733\n",
            "Epoch 21, Step 26, Loss: 0.010706568136811256\n",
            "Epoch 21, Step 27, Loss: 0.009054860100150108\n",
            "Epoch 21, Step 28, Loss: 0.009979330003261566\n",
            "Epoch 21, Step 29, Loss: 0.010463825426995754\n",
            "Epoch 21, Step 30, Loss: 0.008463261649012566\n",
            "Epoch 21, Step 31, Loss: 0.01139614637941122\n",
            "Epoch 21, Step 32, Loss: 0.009499460458755493\n",
            "Epoch 21, Step 33, Loss: 0.01122958678752184\n",
            "Epoch 21, Step 34, Loss: 0.009550872258841991\n",
            "Epoch 21, Step 35, Loss: 0.010738812386989594\n",
            "Epoch 21, Step 36, Loss: 0.00862925499677658\n",
            "Epoch 21, Step 37, Loss: 0.009817677550017834\n",
            "Epoch 21, Step 38, Loss: 0.008733728900551796\n",
            "Epoch 21, Step 39, Loss: 0.008941487409174442\n",
            "Epoch 21, Step 40, Loss: 0.009534339420497417\n",
            "Epoch 21, Step 41, Loss: 0.0077105797827243805\n",
            "Epoch 21, Step 42, Loss: 0.007981724105775356\n",
            "Epoch 21, Step 43, Loss: 0.007458513602614403\n",
            "Epoch 21, Step 44, Loss: 0.008345842361450195\n",
            "Epoch 21, Step 45, Loss: 0.008924132212996483\n",
            "Epoch 21, Step 46, Loss: 0.008121486753225327\n",
            "Epoch 21, Step 47, Loss: 0.007926883175969124\n",
            "Epoch 21, Step 48, Loss: 0.007269739173352718\n",
            "Epoch 21, Step 49, Loss: 0.007028975524008274\n",
            "Epoch 21, Step 50, Loss: 0.006733006797730923\n",
            "Epoch 21, Step 51, Loss: 0.006961493287235498\n",
            "Epoch 21, Step 52, Loss: 0.0063820588402450085\n",
            "Epoch 21, Step 53, Loss: 0.008960776031017303\n",
            "Epoch 21, Step 54, Loss: 0.006099745165556669\n",
            "Epoch 21, Step 55, Loss: 0.006947517395019531\n",
            "Epoch 21, Step 56, Loss: 0.007414741907268763\n",
            "Epoch 21, Step 57, Loss: 0.0067202989012002945\n",
            "Epoch 21, Step 58, Loss: 0.0069800554774701595\n",
            "Epoch 21, Step 59, Loss: 0.006466100923717022\n",
            "Epoch 21, Step 60, Loss: 0.00671574380248785\n",
            "Epoch 21, Step 61, Loss: 0.009669381193816662\n",
            "Epoch 21, Step 62, Loss: 0.006512311287224293\n",
            "Epoch 21, Step 63, Loss: 0.007432492449879646\n",
            "Epoch 21, Step 64, Loss: 0.006542927585542202\n",
            "Epoch 21, Step 65, Loss: 0.007174357771873474\n",
            "Epoch 21, Step 66, Loss: 0.007838789373636246\n",
            "Epoch 21, Step 67, Loss: 0.009129711426794529\n",
            "Epoch 21, Step 68, Loss: 0.008550633676350117\n",
            "Epoch 21, Step 69, Loss: 0.008871807716786861\n",
            "Epoch 21, Step 70, Loss: 0.009453407488763332\n",
            "Epoch 21, Step 71, Loss: 0.009682695381343365\n",
            "Epoch 21, Step 72, Loss: 0.008181629702448845\n",
            "Epoch 21, Step 73, Loss: 0.007507165893912315\n",
            "Epoch 21, Step 74, Loss: 0.007256743498146534\n",
            "Epoch 21, Step 75, Loss: 0.008931562304496765\n",
            "Epoch 21, Step 76, Loss: 0.008331704884767532\n",
            "Epoch 21, Step 77, Loss: 0.009153138846158981\n",
            "Epoch 21, Step 78, Loss: 0.006675343494862318\n",
            "Epoch 21, Step 79, Loss: 0.007557031698524952\n",
            "Epoch 21, Step 80, Loss: 0.00823548436164856\n",
            "Epoch 21, Step 81, Loss: 0.010684204287827015\n",
            "Epoch 21, Step 82, Loss: 0.009829116053879261\n",
            "Epoch 21, Step 83, Loss: 0.008290445432066917\n",
            "Epoch 21, Step 84, Loss: 0.010275602340698242\n",
            "Epoch 21, Step 85, Loss: 0.010366889648139477\n",
            "Train Metric MRRs: 0.2915268421430086\n",
            "Train Metric MAPs: 0.3048601420749403\n",
            "Validation Metric MRRs: 0.22585918181289247\n",
            "Validation Metric MAPs: 0.21927025855671986\n",
            "Epoch 22, Step 1, Loss: 0.023496467620134354\n",
            "Epoch 22, Step 2, Loss: 0.022050749510526657\n",
            "Epoch 22, Step 3, Loss: 0.0189337320625782\n",
            "Epoch 22, Step 4, Loss: 0.015438176691532135\n",
            "Epoch 22, Step 5, Loss: 0.011853132396936417\n",
            "Epoch 22, Step 6, Loss: 0.008213251829147339\n",
            "Epoch 22, Step 7, Loss: 0.00600307434797287\n",
            "Epoch 22, Step 8, Loss: 0.005857299547642469\n",
            "Epoch 22, Step 9, Loss: 0.005300633143633604\n",
            "Epoch 22, Step 10, Loss: 0.005251782946288586\n",
            "Epoch 22, Step 11, Loss: 0.005878834519535303\n",
            "Epoch 22, Step 12, Loss: 0.005756941623985767\n",
            "Epoch 22, Step 13, Loss: 0.005273547489196062\n",
            "Epoch 22, Step 14, Loss: 0.004253614693880081\n",
            "Epoch 22, Step 15, Loss: 0.005235231947153807\n",
            "Epoch 22, Step 16, Loss: 0.0050229644402861595\n",
            "Epoch 22, Step 17, Loss: 0.006709960754960775\n",
            "Epoch 22, Step 18, Loss: 0.007508187089115381\n",
            "Epoch 22, Step 19, Loss: 0.009557930752635002\n",
            "Epoch 22, Step 20, Loss: 0.0093706538900733\n",
            "Epoch 22, Step 21, Loss: 0.010020134039223194\n",
            "Epoch 22, Step 22, Loss: 0.010033168829977512\n",
            "Epoch 22, Step 23, Loss: 0.010561122559010983\n",
            "Epoch 22, Step 24, Loss: 0.011166076175868511\n",
            "Epoch 22, Step 25, Loss: 0.011615187861025333\n",
            "Epoch 22, Step 26, Loss: 0.010132981464266777\n",
            "Epoch 22, Step 27, Loss: 0.008716356940567493\n",
            "Epoch 22, Step 28, Loss: 0.009989922866225243\n",
            "Epoch 22, Step 29, Loss: 0.010343999601900578\n",
            "Epoch 22, Step 30, Loss: 0.008097511716187\n",
            "Epoch 22, Step 31, Loss: 0.010637442581355572\n",
            "Epoch 22, Step 32, Loss: 0.00888009276241064\n",
            "Epoch 22, Step 33, Loss: 0.010276476852595806\n",
            "Epoch 22, Step 34, Loss: 0.008975069038569927\n",
            "Epoch 22, Step 35, Loss: 0.009982715360820293\n",
            "Epoch 22, Step 36, Loss: 0.008537108078598976\n",
            "Epoch 22, Step 37, Loss: 0.00936985109001398\n",
            "Epoch 22, Step 38, Loss: 0.008893707767128944\n",
            "Epoch 22, Step 39, Loss: 0.008965566754341125\n",
            "Epoch 22, Step 40, Loss: 0.00946393609046936\n",
            "Epoch 22, Step 41, Loss: 0.007461483124643564\n",
            "Epoch 22, Step 42, Loss: 0.007498221006244421\n",
            "Epoch 22, Step 43, Loss: 0.006917441263794899\n",
            "Epoch 22, Step 44, Loss: 0.007764850277453661\n",
            "Epoch 22, Step 45, Loss: 0.008577074855566025\n",
            "Epoch 22, Step 46, Loss: 0.00782855786383152\n",
            "Epoch 22, Step 47, Loss: 0.007866769097745419\n",
            "Epoch 22, Step 48, Loss: 0.007257961668074131\n",
            "Epoch 22, Step 49, Loss: 0.0071195452474057674\n",
            "Epoch 22, Step 50, Loss: 0.006839739624410868\n",
            "Epoch 22, Step 51, Loss: 0.007005850784480572\n",
            "Epoch 22, Step 52, Loss: 0.006290743127465248\n",
            "Epoch 22, Step 53, Loss: 0.008675687946379185\n",
            "Epoch 22, Step 54, Loss: 0.005836545489728451\n",
            "Epoch 22, Step 55, Loss: 0.006795533467084169\n",
            "Epoch 22, Step 56, Loss: 0.007242149673402309\n",
            "Epoch 22, Step 57, Loss: 0.006347327493131161\n",
            "Epoch 22, Step 58, Loss: 0.006578229833394289\n",
            "Epoch 22, Step 59, Loss: 0.00640129903331399\n",
            "Epoch 22, Step 60, Loss: 0.006545497570186853\n",
            "Epoch 22, Step 61, Loss: 0.009091916494071484\n",
            "Epoch 22, Step 62, Loss: 0.006259409245103598\n",
            "Epoch 22, Step 63, Loss: 0.0072625791653990746\n",
            "Epoch 22, Step 64, Loss: 0.006348051596432924\n",
            "Epoch 22, Step 65, Loss: 0.007112450432032347\n",
            "Epoch 22, Step 66, Loss: 0.007771466393023729\n",
            "Epoch 22, Step 67, Loss: 0.00874832458794117\n",
            "Epoch 22, Step 68, Loss: 0.008294779807329178\n",
            "Epoch 22, Step 69, Loss: 0.008830878883600235\n",
            "Epoch 22, Step 70, Loss: 0.00946272723376751\n",
            "Epoch 22, Step 71, Loss: 0.00957691203802824\n",
            "Epoch 22, Step 72, Loss: 0.008029075339436531\n",
            "Epoch 22, Step 73, Loss: 0.007588894572108984\n",
            "Epoch 22, Step 74, Loss: 0.007341084070503712\n",
            "Epoch 22, Step 75, Loss: 0.008854311890900135\n",
            "Epoch 22, Step 76, Loss: 0.008186927065253258\n",
            "Epoch 22, Step 77, Loss: 0.008935393765568733\n",
            "Epoch 22, Step 78, Loss: 0.006501039024442434\n",
            "Epoch 22, Step 79, Loss: 0.007247783709317446\n",
            "Epoch 22, Step 80, Loss: 0.007850926369428635\n",
            "Epoch 22, Step 81, Loss: 0.010517371818423271\n",
            "Epoch 22, Step 82, Loss: 0.009529374539852142\n",
            "Epoch 22, Step 83, Loss: 0.008188078179955482\n",
            "Epoch 22, Step 84, Loss: 0.009942241944372654\n",
            "Epoch 22, Step 85, Loss: 0.010371518321335316\n",
            "Train Metric MRRs: 0.2963487491405285\n",
            "Train Metric MAPs: 0.3118833943444068\n",
            "Validation Metric MRRs: 0.22248952607611377\n",
            "Validation Metric MAPs: 0.21405878992655983\n",
            "Epoch 23, Step 1, Loss: 0.022100407630205154\n",
            "Epoch 23, Step 2, Loss: 0.02145557478070259\n",
            "Epoch 23, Step 3, Loss: 0.01840652897953987\n",
            "Epoch 23, Step 4, Loss: 0.014290919527411461\n",
            "Epoch 23, Step 5, Loss: 0.010782305151224136\n",
            "Epoch 23, Step 6, Loss: 0.0079734455794096\n",
            "Epoch 23, Step 7, Loss: 0.005835431627929211\n",
            "Epoch 23, Step 8, Loss: 0.0058880518190562725\n",
            "Epoch 23, Step 9, Loss: 0.005506498739123344\n",
            "Epoch 23, Step 10, Loss: 0.005499798338860273\n",
            "Epoch 23, Step 11, Loss: 0.005864755250513554\n",
            "Epoch 23, Step 12, Loss: 0.005425639450550079\n",
            "Epoch 23, Step 13, Loss: 0.004849916789680719\n",
            "Epoch 23, Step 14, Loss: 0.004079365637153387\n",
            "Epoch 23, Step 15, Loss: 0.004833359271287918\n",
            "Epoch 23, Step 16, Loss: 0.0047490657307207584\n",
            "Epoch 23, Step 17, Loss: 0.006356493569910526\n",
            "Epoch 23, Step 18, Loss: 0.007290190551429987\n",
            "Epoch 23, Step 19, Loss: 0.009258859790861607\n",
            "Epoch 23, Step 20, Loss: 0.008946621790528297\n",
            "Epoch 23, Step 21, Loss: 0.009728926233947277\n",
            "Epoch 23, Step 22, Loss: 0.009841584600508213\n",
            "Epoch 23, Step 23, Loss: 0.010141870006918907\n",
            "Epoch 23, Step 24, Loss: 0.011132325045764446\n",
            "Epoch 23, Step 25, Loss: 0.011508209630846977\n",
            "Epoch 23, Step 26, Loss: 0.010097223334014416\n",
            "Epoch 23, Step 27, Loss: 0.008765416219830513\n",
            "Epoch 23, Step 28, Loss: 0.009889381006360054\n",
            "Epoch 23, Step 29, Loss: 0.010114660486578941\n",
            "Epoch 23, Step 30, Loss: 0.008121218532323837\n",
            "Epoch 23, Step 31, Loss: 0.010582021437585354\n",
            "Epoch 23, Step 32, Loss: 0.008852547965943813\n",
            "Epoch 23, Step 33, Loss: 0.010130775161087513\n",
            "Epoch 23, Step 34, Loss: 0.009026860818266869\n",
            "Epoch 23, Step 35, Loss: 0.009636614471673965\n",
            "Epoch 23, Step 36, Loss: 0.008238894864916801\n",
            "Epoch 23, Step 37, Loss: 0.009250885806977749\n",
            "Epoch 23, Step 38, Loss: 0.008678738959133625\n",
            "Epoch 23, Step 39, Loss: 0.008787726052105427\n",
            "Epoch 23, Step 40, Loss: 0.009276566095650196\n",
            "Epoch 23, Step 41, Loss: 0.007396712899208069\n",
            "Epoch 23, Step 42, Loss: 0.007536093704402447\n",
            "Epoch 23, Step 43, Loss: 0.006924724671989679\n",
            "Epoch 23, Step 44, Loss: 0.00769312959164381\n",
            "Epoch 23, Step 45, Loss: 0.008381744846701622\n",
            "Epoch 23, Step 46, Loss: 0.007665529847145081\n",
            "Epoch 23, Step 47, Loss: 0.007706995587795973\n",
            "Epoch 23, Step 48, Loss: 0.00716532813385129\n",
            "Epoch 23, Step 49, Loss: 0.006993837188929319\n",
            "Epoch 23, Step 50, Loss: 0.006735728122293949\n",
            "Epoch 23, Step 51, Loss: 0.00692412257194519\n",
            "Epoch 23, Step 52, Loss: 0.006268328055739403\n",
            "Epoch 23, Step 53, Loss: 0.00866322685033083\n",
            "Epoch 23, Step 54, Loss: 0.005820897873491049\n",
            "Epoch 23, Step 55, Loss: 0.006659943610429764\n",
            "Epoch 23, Step 56, Loss: 0.0072618103586137295\n",
            "Epoch 23, Step 57, Loss: 0.006181635893881321\n",
            "Epoch 23, Step 58, Loss: 0.006485592108219862\n",
            "Epoch 23, Step 59, Loss: 0.006303127389401197\n",
            "Epoch 23, Step 60, Loss: 0.006462655961513519\n",
            "Epoch 23, Step 61, Loss: 0.008832531049847603\n",
            "Epoch 23, Step 62, Loss: 0.006325540132820606\n",
            "Epoch 23, Step 63, Loss: 0.007255900651216507\n",
            "Epoch 23, Step 64, Loss: 0.006381295155733824\n",
            "Epoch 23, Step 65, Loss: 0.007046459708362818\n",
            "Epoch 23, Step 66, Loss: 0.007602569181472063\n",
            "Epoch 23, Step 67, Loss: 0.008706177584826946\n",
            "Epoch 23, Step 68, Loss: 0.008133085444569588\n",
            "Epoch 23, Step 69, Loss: 0.008668389171361923\n",
            "Epoch 23, Step 70, Loss: 0.009360069409012794\n",
            "Epoch 23, Step 71, Loss: 0.009468864649534225\n",
            "Epoch 23, Step 72, Loss: 0.00790148600935936\n",
            "Epoch 23, Step 73, Loss: 0.007479241117835045\n",
            "Epoch 23, Step 74, Loss: 0.007266542874276638\n",
            "Epoch 23, Step 75, Loss: 0.008746836334466934\n",
            "Epoch 23, Step 76, Loss: 0.008158455602824688\n",
            "Epoch 23, Step 77, Loss: 0.00879038404673338\n",
            "Epoch 23, Step 78, Loss: 0.0064771175384521484\n",
            "Epoch 23, Step 79, Loss: 0.007204971741884947\n",
            "Epoch 23, Step 80, Loss: 0.007602711208164692\n",
            "Epoch 23, Step 81, Loss: 0.010243412107229233\n",
            "Epoch 23, Step 82, Loss: 0.009261108003556728\n",
            "Epoch 23, Step 83, Loss: 0.007840371690690517\n",
            "Epoch 23, Step 84, Loss: 0.00977668073028326\n",
            "Epoch 23, Step 85, Loss: 0.010082811117172241\n",
            "Train Metric MRRs: 0.29609651882941024\n",
            "Train Metric MAPs: 0.30958159430407456\n",
            "Validation Metric MRRs: 0.22504967868040016\n",
            "Validation Metric MAPs: 0.21428352973133108\n",
            "Epoch 24, Step 1, Loss: 0.02153325080871582\n",
            "Epoch 24, Step 2, Loss: 0.02167801931500435\n",
            "Epoch 24, Step 3, Loss: 0.018043285235762596\n",
            "Epoch 24, Step 4, Loss: 0.014291738159954548\n",
            "Epoch 24, Step 5, Loss: 0.010572678409516811\n",
            "Epoch 24, Step 6, Loss: 0.007639503106474876\n",
            "Epoch 24, Step 7, Loss: 0.005520808044821024\n",
            "Epoch 24, Step 8, Loss: 0.0055633182637393475\n",
            "Epoch 24, Step 9, Loss: 0.005223255604505539\n",
            "Epoch 24, Step 10, Loss: 0.005480087362229824\n",
            "Epoch 24, Step 11, Loss: 0.005897514056414366\n",
            "Epoch 24, Step 12, Loss: 0.005507552996277809\n",
            "Epoch 24, Step 13, Loss: 0.0050278641283512115\n",
            "Epoch 24, Step 14, Loss: 0.004298034589737654\n",
            "Epoch 24, Step 15, Loss: 0.004844064824283123\n",
            "Epoch 24, Step 16, Loss: 0.004758569411933422\n",
            "Epoch 24, Step 17, Loss: 0.00647474080324173\n",
            "Epoch 24, Step 18, Loss: 0.007416434586048126\n",
            "Epoch 24, Step 19, Loss: 0.008843098767101765\n",
            "Epoch 24, Step 20, Loss: 0.008918887935578823\n",
            "Epoch 24, Step 21, Loss: 0.009592599235475063\n",
            "Epoch 24, Step 22, Loss: 0.009749711491167545\n",
            "Epoch 24, Step 23, Loss: 0.009997362270951271\n",
            "Epoch 24, Step 24, Loss: 0.010769521817564964\n",
            "Epoch 24, Step 25, Loss: 0.01159342285245657\n",
            "Epoch 24, Step 26, Loss: 0.010016785934567451\n",
            "Epoch 24, Step 27, Loss: 0.008818029426038265\n",
            "Epoch 24, Step 28, Loss: 0.009881937876343727\n",
            "Epoch 24, Step 29, Loss: 0.010184221900999546\n",
            "Epoch 24, Step 30, Loss: 0.008032347075641155\n",
            "Epoch 24, Step 31, Loss: 0.010533515363931656\n",
            "Epoch 24, Step 32, Loss: 0.008895768783986568\n",
            "Epoch 24, Step 33, Loss: 0.010177968069911003\n",
            "Epoch 24, Step 34, Loss: 0.00881238654255867\n",
            "Epoch 24, Step 35, Loss: 0.009663629345595837\n",
            "Epoch 24, Step 36, Loss: 0.008261722512543201\n",
            "Epoch 24, Step 37, Loss: 0.00908027496188879\n",
            "Epoch 24, Step 38, Loss: 0.008589557372033596\n",
            "Epoch 24, Step 39, Loss: 0.008723306469619274\n",
            "Epoch 24, Step 40, Loss: 0.009080796502530575\n",
            "Epoch 24, Step 41, Loss: 0.00739520275965333\n",
            "Epoch 24, Step 42, Loss: 0.00740802614018321\n",
            "Epoch 24, Step 43, Loss: 0.006922239903360605\n",
            "Epoch 24, Step 44, Loss: 0.007698174566030502\n",
            "Epoch 24, Step 45, Loss: 0.008464457467198372\n",
            "Epoch 24, Step 46, Loss: 0.007622001226991415\n",
            "Epoch 24, Step 47, Loss: 0.007688535843044519\n",
            "Epoch 24, Step 48, Loss: 0.007219422608613968\n",
            "Epoch 24, Step 49, Loss: 0.0069615961983799934\n",
            "Epoch 24, Step 50, Loss: 0.006736231502145529\n",
            "Epoch 24, Step 51, Loss: 0.006878085434436798\n",
            "Epoch 24, Step 52, Loss: 0.0062736100517213345\n",
            "Epoch 24, Step 53, Loss: 0.008552951738238335\n",
            "Epoch 24, Step 54, Loss: 0.005757954437285662\n",
            "Epoch 24, Step 55, Loss: 0.006626818794757128\n",
            "Epoch 24, Step 56, Loss: 0.0071259899996221066\n",
            "Epoch 24, Step 57, Loss: 0.006121983285993338\n",
            "Epoch 24, Step 58, Loss: 0.0064720031805336475\n",
            "Epoch 24, Step 59, Loss: 0.006262184586375952\n",
            "Epoch 24, Step 60, Loss: 0.006398347206413746\n",
            "Epoch 24, Step 61, Loss: 0.00888651330024004\n",
            "Epoch 24, Step 62, Loss: 0.006159208714962006\n",
            "Epoch 24, Step 63, Loss: 0.007190202362835407\n",
            "Epoch 24, Step 64, Loss: 0.006263752933591604\n",
            "Epoch 24, Step 65, Loss: 0.007005483377724886\n",
            "Epoch 24, Step 66, Loss: 0.007473238743841648\n",
            "Epoch 24, Step 67, Loss: 0.008526653982698917\n",
            "Epoch 24, Step 68, Loss: 0.008074071258306503\n",
            "Epoch 24, Step 69, Loss: 0.008537650108337402\n",
            "Epoch 24, Step 70, Loss: 0.009302284568548203\n",
            "Epoch 24, Step 71, Loss: 0.00945284590125084\n",
            "Epoch 24, Step 72, Loss: 0.007891803979873657\n",
            "Epoch 24, Step 73, Loss: 0.0075241560116410255\n",
            "Epoch 24, Step 74, Loss: 0.007196750957518816\n",
            "Epoch 24, Step 75, Loss: 0.008727170526981354\n",
            "Epoch 24, Step 76, Loss: 0.008084418252110481\n",
            "Epoch 24, Step 77, Loss: 0.008761411532759666\n",
            "Epoch 24, Step 78, Loss: 0.006388254463672638\n",
            "Epoch 24, Step 79, Loss: 0.0071724713779985905\n",
            "Epoch 24, Step 80, Loss: 0.00760540971532464\n",
            "Epoch 24, Step 81, Loss: 0.010082684457302094\n",
            "Epoch 24, Step 82, Loss: 0.009050945751369\n",
            "Epoch 24, Step 83, Loss: 0.007829153910279274\n",
            "Epoch 24, Step 84, Loss: 0.0098463399335742\n",
            "Epoch 24, Step 85, Loss: 0.00999272521585226\n",
            "Train Metric MRRs: 0.2990013796070063\n",
            "Train Metric MAPs: 0.315826332038741\n",
            "Validation Metric MRRs: 0.2225191188343552\n",
            "Validation Metric MAPs: 0.2147522506278856\n",
            "Epoch 25, Step 1, Loss: 0.023822195827960968\n",
            "Epoch 25, Step 2, Loss: 0.021854398772120476\n",
            "Epoch 25, Step 3, Loss: 0.01801232248544693\n",
            "Epoch 25, Step 4, Loss: 0.014021780341863632\n",
            "Epoch 25, Step 5, Loss: 0.010520296171307564\n",
            "Epoch 25, Step 6, Loss: 0.007768233772367239\n",
            "Epoch 25, Step 7, Loss: 0.005616211332380772\n",
            "Epoch 25, Step 8, Loss: 0.00572434114292264\n",
            "Epoch 25, Step 9, Loss: 0.0052914097905159\n",
            "Epoch 25, Step 10, Loss: 0.005358806811273098\n",
            "Epoch 25, Step 11, Loss: 0.006118663586676121\n",
            "Epoch 25, Step 12, Loss: 0.005945757497102022\n",
            "Epoch 25, Step 13, Loss: 0.005212975665926933\n",
            "Epoch 25, Step 14, Loss: 0.004320540931075811\n",
            "Epoch 25, Step 15, Loss: 0.004829057492315769\n",
            "Epoch 25, Step 16, Loss: 0.004799930844455957\n",
            "Epoch 25, Step 17, Loss: 0.006811242550611496\n",
            "Epoch 25, Step 18, Loss: 0.007538041099905968\n",
            "Epoch 25, Step 19, Loss: 0.009284925647079945\n",
            "Epoch 25, Step 20, Loss: 0.0091108288615942\n",
            "Epoch 25, Step 21, Loss: 0.009650783613324165\n",
            "Epoch 25, Step 22, Loss: 0.009912853129208088\n",
            "Epoch 25, Step 23, Loss: 0.01003719586879015\n",
            "Epoch 25, Step 24, Loss: 0.010661047883331776\n",
            "Epoch 25, Step 25, Loss: 0.011626952327787876\n",
            "Epoch 25, Step 26, Loss: 0.00994012039154768\n",
            "Epoch 25, Step 27, Loss: 0.00856679119169712\n",
            "Epoch 25, Step 28, Loss: 0.009913595393300056\n",
            "Epoch 25, Step 29, Loss: 0.010357514955103397\n",
            "Epoch 25, Step 30, Loss: 0.008163335733115673\n",
            "Epoch 25, Step 31, Loss: 0.01067113596946001\n",
            "Epoch 25, Step 32, Loss: 0.009124076925218105\n",
            "Epoch 25, Step 33, Loss: 0.010159711353480816\n",
            "Epoch 25, Step 34, Loss: 0.009035707451403141\n",
            "Epoch 25, Step 35, Loss: 0.009705840609967709\n",
            "Epoch 25, Step 36, Loss: 0.008293885737657547\n",
            "Epoch 25, Step 37, Loss: 0.009246261790394783\n",
            "Epoch 25, Step 38, Loss: 0.008596290834248066\n",
            "Epoch 25, Step 39, Loss: 0.008826869539916515\n",
            "Epoch 25, Step 40, Loss: 0.009266603738069534\n",
            "Epoch 25, Step 41, Loss: 0.007443629205226898\n",
            "Epoch 25, Step 42, Loss: 0.007478307466953993\n",
            "Epoch 25, Step 43, Loss: 0.0069145094603300095\n",
            "Epoch 25, Step 44, Loss: 0.007562555372714996\n",
            "Epoch 25, Step 45, Loss: 0.00837724469602108\n",
            "Epoch 25, Step 46, Loss: 0.007628042250871658\n",
            "Epoch 25, Step 47, Loss: 0.007687189616262913\n",
            "Epoch 25, Step 48, Loss: 0.007195755373686552\n",
            "Epoch 25, Step 49, Loss: 0.006977782119065523\n",
            "Epoch 25, Step 50, Loss: 0.0067397658713161945\n",
            "Epoch 25, Step 51, Loss: 0.0069011664018034935\n",
            "Epoch 25, Step 52, Loss: 0.006278329528868198\n",
            "Epoch 25, Step 53, Loss: 0.008565911091864109\n",
            "Epoch 25, Step 54, Loss: 0.0057984525337815285\n",
            "Epoch 25, Step 55, Loss: 0.0066925231367349625\n",
            "Epoch 25, Step 56, Loss: 0.007131178863346577\n",
            "Epoch 25, Step 57, Loss: 0.006157267838716507\n",
            "Epoch 25, Step 58, Loss: 0.006455264985561371\n",
            "Epoch 25, Step 59, Loss: 0.006211392115801573\n",
            "Epoch 25, Step 60, Loss: 0.006408948916941881\n",
            "Epoch 25, Step 61, Loss: 0.008841041475534439\n",
            "Epoch 25, Step 62, Loss: 0.006343975197523832\n",
            "Epoch 25, Step 63, Loss: 0.0072099328972399235\n",
            "Epoch 25, Step 64, Loss: 0.0062842462211847305\n",
            "Epoch 25, Step 65, Loss: 0.007121297065168619\n",
            "Epoch 25, Step 66, Loss: 0.007430886849761009\n",
            "Epoch 25, Step 67, Loss: 0.008572476916015148\n",
            "Epoch 25, Step 68, Loss: 0.008037817664444447\n",
            "Epoch 25, Step 69, Loss: 0.00858695711940527\n",
            "Epoch 25, Step 70, Loss: 0.009523020125925541\n",
            "Epoch 25, Step 71, Loss: 0.00944538600742817\n",
            "Epoch 25, Step 72, Loss: 0.007852406240999699\n",
            "Epoch 25, Step 73, Loss: 0.007573152892291546\n",
            "Epoch 25, Step 74, Loss: 0.007237832993268967\n",
            "Epoch 25, Step 75, Loss: 0.00868032407015562\n",
            "Epoch 25, Step 76, Loss: 0.008077620528638363\n",
            "Epoch 25, Step 77, Loss: 0.00887901522219181\n",
            "Epoch 25, Step 78, Loss: 0.006429704371839762\n",
            "Epoch 25, Step 79, Loss: 0.007196595426648855\n",
            "Epoch 25, Step 80, Loss: 0.007573743816465139\n",
            "Epoch 25, Step 81, Loss: 0.010067257098853588\n",
            "Epoch 25, Step 82, Loss: 0.009244588203728199\n",
            "Epoch 25, Step 83, Loss: 0.00785782653838396\n",
            "Epoch 25, Step 84, Loss: 0.009760698303580284\n",
            "Epoch 25, Step 85, Loss: 0.01012157741934061\n",
            "Train Metric MRRs: 0.29703685384562356\n",
            "Train Metric MAPs: 0.30782566530862404\n",
            "Validation Metric MRRs: 0.22857094543382325\n",
            "Validation Metric MAPs: 0.21645889098401644\n",
            "Epoch 26, Step 1, Loss: 0.022327283397316933\n",
            "Epoch 26, Step 2, Loss: 0.02177605964243412\n",
            "Epoch 26, Step 3, Loss: 0.01770874485373497\n",
            "Epoch 26, Step 4, Loss: 0.01404681708663702\n",
            "Epoch 26, Step 5, Loss: 0.01041456125676632\n",
            "Epoch 26, Step 6, Loss: 0.007664772216230631\n",
            "Epoch 26, Step 7, Loss: 0.005592585541307926\n",
            "Epoch 26, Step 8, Loss: 0.005635843612253666\n",
            "Epoch 26, Step 9, Loss: 0.005262845661491156\n",
            "Epoch 26, Step 10, Loss: 0.0051977140828967094\n",
            "Epoch 26, Step 11, Loss: 0.0057251644320786\n",
            "Epoch 26, Step 12, Loss: 0.0053838808089494705\n",
            "Epoch 26, Step 13, Loss: 0.00485937250778079\n",
            "Epoch 26, Step 14, Loss: 0.00410767225548625\n",
            "Epoch 26, Step 15, Loss: 0.004873784724622965\n",
            "Epoch 26, Step 16, Loss: 0.004625049419701099\n",
            "Epoch 26, Step 17, Loss: 0.006328737363219261\n",
            "Epoch 26, Step 18, Loss: 0.007273514289408922\n",
            "Epoch 26, Step 19, Loss: 0.009229231625795364\n",
            "Epoch 26, Step 20, Loss: 0.009154635481536388\n",
            "Epoch 26, Step 21, Loss: 0.009696451015770435\n",
            "Epoch 26, Step 22, Loss: 0.009583528153598309\n",
            "Epoch 26, Step 23, Loss: 0.010186439380049706\n",
            "Epoch 26, Step 24, Loss: 0.010799109004437923\n",
            "Epoch 26, Step 25, Loss: 0.011434303596615791\n",
            "Epoch 26, Step 26, Loss: 0.01001240499317646\n",
            "Epoch 26, Step 27, Loss: 0.00855666771531105\n",
            "Epoch 26, Step 28, Loss: 0.009705053642392159\n",
            "Epoch 26, Step 29, Loss: 0.010094698518514633\n",
            "Epoch 26, Step 30, Loss: 0.007963445037603378\n",
            "Epoch 26, Step 31, Loss: 0.010483236983418465\n",
            "Epoch 26, Step 32, Loss: 0.009024430066347122\n",
            "Epoch 26, Step 33, Loss: 0.010044013150036335\n",
            "Epoch 26, Step 34, Loss: 0.008834040723741055\n",
            "Epoch 26, Step 35, Loss: 0.00956591498106718\n",
            "Epoch 26, Step 36, Loss: 0.008145042695105076\n",
            "Epoch 26, Step 37, Loss: 0.0092393197119236\n",
            "Epoch 26, Step 38, Loss: 0.008573798462748528\n",
            "Epoch 26, Step 39, Loss: 0.008718502707779408\n",
            "Epoch 26, Step 40, Loss: 0.009068090468645096\n",
            "Epoch 26, Step 41, Loss: 0.0072556957602500916\n",
            "Epoch 26, Step 42, Loss: 0.007268334273248911\n",
            "Epoch 26, Step 43, Loss: 0.006874618586152792\n",
            "Epoch 26, Step 44, Loss: 0.0073228939436376095\n",
            "Epoch 26, Step 45, Loss: 0.00827115774154663\n",
            "Epoch 26, Step 46, Loss: 0.007560119032859802\n",
            "Epoch 26, Step 47, Loss: 0.007786204572767019\n",
            "Epoch 26, Step 48, Loss: 0.007128956727683544\n",
            "Epoch 26, Step 49, Loss: 0.006983831524848938\n",
            "Epoch 26, Step 50, Loss: 0.006767112296074629\n",
            "Epoch 26, Step 51, Loss: 0.006919909734278917\n",
            "Epoch 26, Step 52, Loss: 0.0063128238543868065\n",
            "Epoch 26, Step 53, Loss: 0.008402790874242783\n",
            "Epoch 26, Step 54, Loss: 0.005824304651468992\n",
            "Epoch 26, Step 55, Loss: 0.0066090417094528675\n",
            "Epoch 26, Step 56, Loss: 0.007005443796515465\n",
            "Epoch 26, Step 57, Loss: 0.0061544072814285755\n",
            "Epoch 26, Step 58, Loss: 0.006363072898238897\n",
            "Epoch 26, Step 59, Loss: 0.006184866186231375\n",
            "Epoch 26, Step 60, Loss: 0.0063709975220263\n",
            "Epoch 26, Step 61, Loss: 0.008858316577970982\n",
            "Epoch 26, Step 62, Loss: 0.006331618409603834\n",
            "Epoch 26, Step 63, Loss: 0.007132538594305515\n",
            "Epoch 26, Step 64, Loss: 0.006256236229091883\n",
            "Epoch 26, Step 65, Loss: 0.007066777441650629\n",
            "Epoch 26, Step 66, Loss: 0.0074335564859211445\n",
            "Epoch 26, Step 67, Loss: 0.00856208149343729\n",
            "Epoch 26, Step 68, Loss: 0.008096007630228996\n",
            "Epoch 26, Step 69, Loss: 0.008597740903496742\n",
            "Epoch 26, Step 70, Loss: 0.009384488686919212\n",
            "Epoch 26, Step 71, Loss: 0.009420463815331459\n",
            "Epoch 26, Step 72, Loss: 0.007806450594216585\n",
            "Epoch 26, Step 73, Loss: 0.007436293642967939\n",
            "Epoch 26, Step 74, Loss: 0.00714963860809803\n",
            "Epoch 26, Step 75, Loss: 0.008719594217836857\n",
            "Epoch 26, Step 76, Loss: 0.008140817284584045\n",
            "Epoch 26, Step 77, Loss: 0.008796624839305878\n",
            "Epoch 26, Step 78, Loss: 0.00641958974301815\n",
            "Epoch 26, Step 79, Loss: 0.00706053851172328\n",
            "Epoch 26, Step 80, Loss: 0.007553974632173777\n",
            "Epoch 26, Step 81, Loss: 0.010073965415358543\n",
            "Epoch 26, Step 82, Loss: 0.009048396721482277\n",
            "Epoch 26, Step 83, Loss: 0.0077768960036337376\n",
            "Epoch 26, Step 84, Loss: 0.009795872494578362\n",
            "Epoch 26, Step 85, Loss: 0.010000674054026604\n",
            "Train Metric MRRs: 0.3009949270339145\n",
            "Train Metric MAPs: 0.31105901316535484\n",
            "Validation Metric MRRs: 0.2248957648551279\n",
            "Validation Metric MAPs: 0.21281514126816023\n",
            "Epoch 27, Step 1, Loss: 0.02091636322438717\n",
            "Epoch 27, Step 2, Loss: 0.02122330665588379\n",
            "Epoch 27, Step 3, Loss: 0.017578281462192535\n",
            "Epoch 27, Step 4, Loss: 0.014410147443413734\n",
            "Epoch 27, Step 5, Loss: 0.010488956235349178\n",
            "Epoch 27, Step 6, Loss: 0.007673431187868118\n",
            "Epoch 27, Step 7, Loss: 0.005383159499615431\n",
            "Epoch 27, Step 8, Loss: 0.005501147825270891\n",
            "Epoch 27, Step 9, Loss: 0.005079993978142738\n",
            "Epoch 27, Step 10, Loss: 0.00520495418459177\n",
            "Epoch 27, Step 11, Loss: 0.005793364718556404\n",
            "Epoch 27, Step 12, Loss: 0.0054122828878462315\n",
            "Epoch 27, Step 13, Loss: 0.005113398190587759\n",
            "Epoch 27, Step 14, Loss: 0.0042524454183876514\n",
            "Epoch 27, Step 15, Loss: 0.004876357037574053\n",
            "Epoch 27, Step 16, Loss: 0.00483075762167573\n",
            "Epoch 27, Step 17, Loss: 0.0066058700904250145\n",
            "Epoch 27, Step 18, Loss: 0.0073729571886360645\n",
            "Epoch 27, Step 19, Loss: 0.009003198705613613\n",
            "Epoch 27, Step 20, Loss: 0.008875221945345402\n",
            "Epoch 27, Step 21, Loss: 0.009306068532168865\n",
            "Epoch 27, Step 22, Loss: 0.009768761694431305\n",
            "Epoch 27, Step 23, Loss: 0.009865385480225086\n",
            "Epoch 27, Step 24, Loss: 0.010713914409279823\n",
            "Epoch 27, Step 25, Loss: 0.01147159282118082\n",
            "Epoch 27, Step 26, Loss: 0.009844448417425156\n",
            "Epoch 27, Step 27, Loss: 0.00856555625796318\n",
            "Epoch 27, Step 28, Loss: 0.009891851805150509\n",
            "Epoch 27, Step 29, Loss: 0.010351884178817272\n",
            "Epoch 27, Step 30, Loss: 0.008199057541787624\n",
            "Epoch 27, Step 31, Loss: 0.010739456862211227\n",
            "Epoch 27, Step 32, Loss: 0.009064681828022003\n",
            "Epoch 27, Step 33, Loss: 0.010138887912034988\n",
            "Epoch 27, Step 34, Loss: 0.008908924646675587\n",
            "Epoch 27, Step 35, Loss: 0.009494944475591183\n",
            "Epoch 27, Step 36, Loss: 0.008101406507194042\n",
            "Epoch 27, Step 37, Loss: 0.009083759039640427\n",
            "Epoch 27, Step 38, Loss: 0.00879773311316967\n",
            "Epoch 27, Step 39, Loss: 0.008712737821042538\n",
            "Epoch 27, Step 40, Loss: 0.008981822058558464\n",
            "Epoch 27, Step 41, Loss: 0.007327299565076828\n",
            "Epoch 27, Step 42, Loss: 0.007300030905753374\n",
            "Epoch 27, Step 43, Loss: 0.006756491027772427\n",
            "Epoch 27, Step 44, Loss: 0.00728781521320343\n",
            "Epoch 27, Step 45, Loss: 0.008230529725551605\n",
            "Epoch 27, Step 46, Loss: 0.007418660447001457\n",
            "Epoch 27, Step 47, Loss: 0.007690284866839647\n",
            "Epoch 27, Step 48, Loss: 0.007109415251761675\n",
            "Epoch 27, Step 49, Loss: 0.006903312634676695\n",
            "Epoch 27, Step 50, Loss: 0.006640221457928419\n",
            "Epoch 27, Step 51, Loss: 0.0068627893924713135\n",
            "Epoch 27, Step 52, Loss: 0.006291924975812435\n",
            "Epoch 27, Step 53, Loss: 0.008479360491037369\n",
            "Epoch 27, Step 54, Loss: 0.00584998307749629\n",
            "Epoch 27, Step 55, Loss: 0.006546165328472853\n",
            "Epoch 27, Step 56, Loss: 0.006994503550231457\n",
            "Epoch 27, Step 57, Loss: 0.006134503986686468\n",
            "Epoch 27, Step 58, Loss: 0.006351911928504705\n",
            "Epoch 27, Step 59, Loss: 0.006143743637949228\n",
            "Epoch 27, Step 60, Loss: 0.006330552976578474\n",
            "Epoch 27, Step 61, Loss: 0.008624588139355183\n",
            "Epoch 27, Step 62, Loss: 0.006200418807566166\n",
            "Epoch 27, Step 63, Loss: 0.007072201929986477\n",
            "Epoch 27, Step 64, Loss: 0.006240150425583124\n",
            "Epoch 27, Step 65, Loss: 0.007035332731902599\n",
            "Epoch 27, Step 66, Loss: 0.007522473111748695\n",
            "Epoch 27, Step 67, Loss: 0.0085098622366786\n",
            "Epoch 27, Step 68, Loss: 0.008072367869317532\n",
            "Epoch 27, Step 69, Loss: 0.008436661213636398\n",
            "Epoch 27, Step 70, Loss: 0.009360257536172867\n",
            "Epoch 27, Step 71, Loss: 0.009409075602889061\n",
            "Epoch 27, Step 72, Loss: 0.007726418785750866\n",
            "Epoch 27, Step 73, Loss: 0.007558133453130722\n",
            "Epoch 27, Step 74, Loss: 0.007238319143652916\n",
            "Epoch 27, Step 75, Loss: 0.00866188108921051\n",
            "Epoch 27, Step 76, Loss: 0.00808569137006998\n",
            "Epoch 27, Step 77, Loss: 0.008707189001142979\n",
            "Epoch 27, Step 78, Loss: 0.006436124909669161\n",
            "Epoch 27, Step 79, Loss: 0.006955102551728487\n",
            "Epoch 27, Step 80, Loss: 0.0076143150217831135\n",
            "Epoch 27, Step 81, Loss: 0.010002928785979748\n",
            "Epoch 27, Step 82, Loss: 0.00903722271323204\n",
            "Epoch 27, Step 83, Loss: 0.007702566217631102\n",
            "Epoch 27, Step 84, Loss: 0.010166680440306664\n",
            "Epoch 27, Step 85, Loss: 0.010129313915967941\n",
            "Train Metric MRRs: 0.30090538437028425\n",
            "Train Metric MAPs: 0.31539664247203697\n",
            "Validation Metric MRRs: 0.22959189911119135\n",
            "Validation Metric MAPs: 0.21452126039365985\n",
            "Epoch 28, Step 1, Loss: 0.020885523408651352\n",
            "Epoch 28, Step 2, Loss: 0.021029630675911903\n",
            "Epoch 28, Step 3, Loss: 0.017501404508948326\n",
            "Epoch 28, Step 4, Loss: 0.013973701745271683\n",
            "Epoch 28, Step 5, Loss: 0.010320245288312435\n",
            "Epoch 28, Step 6, Loss: 0.007709627505391836\n",
            "Epoch 28, Step 7, Loss: 0.005477083381265402\n",
            "Epoch 28, Step 8, Loss: 0.005541099701076746\n",
            "Epoch 28, Step 9, Loss: 0.005210741888731718\n",
            "Epoch 28, Step 10, Loss: 0.005190043244510889\n",
            "Epoch 28, Step 11, Loss: 0.005671661347150803\n",
            "Epoch 28, Step 12, Loss: 0.005405992269515991\n",
            "Epoch 28, Step 13, Loss: 0.00473350053653121\n",
            "Epoch 28, Step 14, Loss: 0.003969685640186071\n",
            "Epoch 28, Step 15, Loss: 0.004801695700734854\n",
            "Epoch 28, Step 16, Loss: 0.00454406812787056\n",
            "Epoch 28, Step 17, Loss: 0.006253512110561132\n",
            "Epoch 28, Step 18, Loss: 0.007160558365285397\n",
            "Epoch 28, Step 19, Loss: 0.008988711051642895\n",
            "Epoch 28, Step 20, Loss: 0.008886507712304592\n",
            "Epoch 28, Step 21, Loss: 0.009378413669764996\n",
            "Epoch 28, Step 22, Loss: 0.00939955748617649\n",
            "Epoch 28, Step 23, Loss: 0.010108896531164646\n",
            "Epoch 28, Step 24, Loss: 0.010707524605095387\n",
            "Epoch 28, Step 25, Loss: 0.01148160733282566\n",
            "Epoch 28, Step 26, Loss: 0.00989794172346592\n",
            "Epoch 28, Step 27, Loss: 0.00874208752065897\n",
            "Epoch 28, Step 28, Loss: 0.009765327908098698\n",
            "Epoch 28, Step 29, Loss: 0.010040211491286755\n",
            "Epoch 28, Step 30, Loss: 0.008037232793867588\n",
            "Epoch 28, Step 31, Loss: 0.010534233413636684\n",
            "Epoch 28, Step 32, Loss: 0.008949479088187218\n",
            "Epoch 28, Step 33, Loss: 0.010074936784803867\n",
            "Epoch 28, Step 34, Loss: 0.008723312988877296\n",
            "Epoch 28, Step 35, Loss: 0.009612562134861946\n",
            "Epoch 28, Step 36, Loss: 0.008098063990473747\n",
            "Epoch 28, Step 37, Loss: 0.00920370314270258\n",
            "Epoch 28, Step 38, Loss: 0.008501560427248478\n",
            "Epoch 28, Step 39, Loss: 0.008735707961022854\n",
            "Epoch 28, Step 40, Loss: 0.008873865939676762\n",
            "Epoch 28, Step 41, Loss: 0.007311267778277397\n",
            "Epoch 28, Step 42, Loss: 0.007322380319237709\n",
            "Epoch 28, Step 43, Loss: 0.006835812237113714\n",
            "Epoch 28, Step 44, Loss: 0.007440151646733284\n",
            "Epoch 28, Step 45, Loss: 0.00823628343641758\n",
            "Epoch 28, Step 46, Loss: 0.007528988644480705\n",
            "Epoch 28, Step 47, Loss: 0.007658818736672401\n",
            "Epoch 28, Step 48, Loss: 0.007015245035290718\n",
            "Epoch 28, Step 49, Loss: 0.006823895499110222\n",
            "Epoch 28, Step 50, Loss: 0.006597001105546951\n",
            "Epoch 28, Step 51, Loss: 0.006877222564071417\n",
            "Epoch 28, Step 52, Loss: 0.006287721451371908\n",
            "Epoch 28, Step 53, Loss: 0.008429811336100101\n",
            "Epoch 28, Step 54, Loss: 0.005789425224065781\n",
            "Epoch 28, Step 55, Loss: 0.006528455764055252\n",
            "Epoch 28, Step 56, Loss: 0.0069968500174582005\n",
            "Epoch 28, Step 57, Loss: 0.006122331600636244\n",
            "Epoch 28, Step 58, Loss: 0.006326844450086355\n",
            "Epoch 28, Step 59, Loss: 0.006137690506875515\n",
            "Epoch 28, Step 60, Loss: 0.006316767539829016\n",
            "Epoch 28, Step 61, Loss: 0.008708039298653603\n",
            "Epoch 28, Step 62, Loss: 0.0061608292162418365\n",
            "Epoch 28, Step 63, Loss: 0.00703187333419919\n",
            "Epoch 28, Step 64, Loss: 0.006174389738589525\n",
            "Epoch 28, Step 65, Loss: 0.0069886259734630585\n",
            "Epoch 28, Step 66, Loss: 0.0074108559638261795\n",
            "Epoch 28, Step 67, Loss: 0.008429808542132378\n",
            "Epoch 28, Step 68, Loss: 0.008000636473298073\n",
            "Epoch 28, Step 69, Loss: 0.008398226462304592\n",
            "Epoch 28, Step 70, Loss: 0.009199904277920723\n",
            "Epoch 28, Step 71, Loss: 0.009359000250697136\n",
            "Epoch 28, Step 72, Loss: 0.007702605798840523\n",
            "Epoch 28, Step 73, Loss: 0.007400624919682741\n",
            "Epoch 28, Step 74, Loss: 0.007154382765293121\n",
            "Epoch 28, Step 75, Loss: 0.008630960248410702\n",
            "Epoch 28, Step 76, Loss: 0.008013357408344746\n",
            "Epoch 28, Step 77, Loss: 0.00866013579070568\n",
            "Epoch 28, Step 78, Loss: 0.006346309091895819\n",
            "Epoch 28, Step 79, Loss: 0.0068518780171871185\n",
            "Epoch 28, Step 80, Loss: 0.007526242174208164\n",
            "Epoch 28, Step 81, Loss: 0.009779590182006359\n",
            "Epoch 28, Step 82, Loss: 0.008827099576592445\n",
            "Epoch 28, Step 83, Loss: 0.007815614342689514\n",
            "Epoch 28, Step 84, Loss: 0.009654075838625431\n",
            "Epoch 28, Step 85, Loss: 0.010070374235510826\n",
            "Train Metric MRRs: 0.3035666906468544\n",
            "Train Metric MAPs: 0.312811079885385\n",
            "Validation Metric MRRs: 0.22783079120497832\n",
            "Validation Metric MAPs: 0.21264103326028871\n",
            "Epoch 29, Step 1, Loss: 0.02153456024825573\n",
            "Epoch 29, Step 2, Loss: 0.020665176212787628\n",
            "Epoch 29, Step 3, Loss: 0.017693182453513145\n",
            "Epoch 29, Step 4, Loss: 0.013953650370240211\n",
            "Epoch 29, Step 5, Loss: 0.010187181644141674\n",
            "Epoch 29, Step 6, Loss: 0.007614297792315483\n",
            "Epoch 29, Step 7, Loss: 0.005473441444337368\n",
            "Epoch 29, Step 8, Loss: 0.005563613958656788\n",
            "Epoch 29, Step 9, Loss: 0.005160413216799498\n",
            "Epoch 29, Step 10, Loss: 0.005267522297799587\n",
            "Epoch 29, Step 11, Loss: 0.005621582735329866\n",
            "Epoch 29, Step 12, Loss: 0.005260912701487541\n",
            "Epoch 29, Step 13, Loss: 0.004746660124510527\n",
            "Epoch 29, Step 14, Loss: 0.004027672111988068\n",
            "Epoch 29, Step 15, Loss: 0.004759840667247772\n",
            "Epoch 29, Step 16, Loss: 0.00466109486296773\n",
            "Epoch 29, Step 17, Loss: 0.00628177635371685\n",
            "Epoch 29, Step 18, Loss: 0.007202697452157736\n",
            "Epoch 29, Step 19, Loss: 0.00877455435693264\n",
            "Epoch 29, Step 20, Loss: 0.008849874138832092\n",
            "Epoch 29, Step 21, Loss: 0.00950048677623272\n",
            "Epoch 29, Step 22, Loss: 0.009425776079297066\n",
            "Epoch 29, Step 23, Loss: 0.010199062526226044\n",
            "Epoch 29, Step 24, Loss: 0.011090585961937904\n",
            "Epoch 29, Step 25, Loss: 0.011282764375209808\n",
            "Epoch 29, Step 26, Loss: 0.009809419512748718\n",
            "Epoch 29, Step 27, Loss: 0.008638353087008\n",
            "Epoch 29, Step 28, Loss: 0.009733086451888084\n",
            "Epoch 29, Step 29, Loss: 0.009835030883550644\n",
            "Epoch 29, Step 30, Loss: 0.007950760424137115\n",
            "Epoch 29, Step 31, Loss: 0.010275773704051971\n",
            "Epoch 29, Step 32, Loss: 0.008705731481313705\n",
            "Epoch 29, Step 33, Loss: 0.009795685298740864\n",
            "Epoch 29, Step 34, Loss: 0.008735175244510174\n",
            "Epoch 29, Step 35, Loss: 0.009352379478514194\n",
            "Epoch 29, Step 36, Loss: 0.00806277897208929\n",
            "Epoch 29, Step 37, Loss: 0.009168494492769241\n",
            "Epoch 29, Step 38, Loss: 0.008457327261567116\n",
            "Epoch 29, Step 39, Loss: 0.008610867895185947\n",
            "Epoch 29, Step 40, Loss: 0.00876164436340332\n",
            "Epoch 29, Step 41, Loss: 0.007154298946261406\n",
            "Epoch 29, Step 42, Loss: 0.007286014035344124\n",
            "Epoch 29, Step 43, Loss: 0.006666459608823061\n",
            "Epoch 29, Step 44, Loss: 0.0071838777512311935\n",
            "Epoch 29, Step 45, Loss: 0.008118164725601673\n",
            "Epoch 29, Step 46, Loss: 0.007430500816553831\n",
            "Epoch 29, Step 47, Loss: 0.007550640497356653\n",
            "Epoch 29, Step 48, Loss: 0.0070252432487905025\n",
            "Epoch 29, Step 49, Loss: 0.006891296710819006\n",
            "Epoch 29, Step 50, Loss: 0.006635975558310747\n",
            "Epoch 29, Step 51, Loss: 0.006829374469816685\n",
            "Epoch 29, Step 52, Loss: 0.006312042940407991\n",
            "Epoch 29, Step 53, Loss: 0.00839113537222147\n",
            "Epoch 29, Step 54, Loss: 0.005801631603389978\n",
            "Epoch 29, Step 55, Loss: 0.006544259376823902\n",
            "Epoch 29, Step 56, Loss: 0.0069176205433905125\n",
            "Epoch 29, Step 57, Loss: 0.006081422790884972\n",
            "Epoch 29, Step 58, Loss: 0.0063832844607532024\n",
            "Epoch 29, Step 59, Loss: 0.006114009767770767\n",
            "Epoch 29, Step 60, Loss: 0.006364620756357908\n",
            "Epoch 29, Step 61, Loss: 0.008568408899009228\n",
            "Epoch 29, Step 62, Loss: 0.00605383375659585\n",
            "Epoch 29, Step 63, Loss: 0.0070553249679505825\n",
            "Epoch 29, Step 64, Loss: 0.006174568552523851\n",
            "Epoch 29, Step 65, Loss: 0.006960692815482616\n",
            "Epoch 29, Step 66, Loss: 0.007494286634027958\n",
            "Epoch 29, Step 67, Loss: 0.008434958755970001\n",
            "Epoch 29, Step 68, Loss: 0.007968314923346043\n",
            "Epoch 29, Step 69, Loss: 0.008432273752987385\n",
            "Epoch 29, Step 70, Loss: 0.009242840111255646\n",
            "Epoch 29, Step 71, Loss: 0.009340941905975342\n",
            "Epoch 29, Step 72, Loss: 0.007678970228880644\n",
            "Epoch 29, Step 73, Loss: 0.007476438768208027\n",
            "Epoch 29, Step 74, Loss: 0.007144817616790533\n",
            "Epoch 29, Step 75, Loss: 0.008661636151373386\n",
            "Epoch 29, Step 76, Loss: 0.00800473615527153\n",
            "Epoch 29, Step 77, Loss: 0.008600195869803429\n",
            "Epoch 29, Step 78, Loss: 0.006353201810270548\n",
            "Epoch 29, Step 79, Loss: 0.006966634653508663\n",
            "Epoch 29, Step 80, Loss: 0.007397887296974659\n",
            "Epoch 29, Step 81, Loss: 0.009658261202275753\n",
            "Epoch 29, Step 82, Loss: 0.008816016837954521\n",
            "Epoch 29, Step 83, Loss: 0.007720105815678835\n",
            "Epoch 29, Step 84, Loss: 0.00954977236688137\n",
            "Epoch 29, Step 85, Loss: 0.009794860146939754\n",
            "Train Metric MRRs: 0.3021885616343254\n",
            "Train Metric MAPs: 0.31346327381694744\n",
            "Validation Metric MRRs: 0.22451008226613825\n",
            "Validation Metric MAPs: 0.21140915630643525\n",
            "Epoch 30, Step 1, Loss: 0.021558916196227074\n",
            "Epoch 30, Step 2, Loss: 0.020714053884148598\n",
            "Epoch 30, Step 3, Loss: 0.01777232438325882\n",
            "Epoch 30, Step 4, Loss: 0.014883950352668762\n",
            "Epoch 30, Step 5, Loss: 0.01079188659787178\n",
            "Epoch 30, Step 6, Loss: 0.0077757155522704124\n",
            "Epoch 30, Step 7, Loss: 0.00551181985065341\n",
            "Epoch 30, Step 8, Loss: 0.005441035609692335\n",
            "Epoch 30, Step 9, Loss: 0.005120983812958002\n",
            "Epoch 30, Step 10, Loss: 0.005271339789032936\n",
            "Epoch 30, Step 11, Loss: 0.0056610400788486\n",
            "Epoch 30, Step 12, Loss: 0.005459742620587349\n",
            "Epoch 30, Step 13, Loss: 0.005145522765815258\n",
            "Epoch 30, Step 14, Loss: 0.004375195596367121\n",
            "Epoch 30, Step 15, Loss: 0.004978572949767113\n",
            "Epoch 30, Step 16, Loss: 0.00486588291823864\n",
            "Epoch 30, Step 17, Loss: 0.0063839806243777275\n",
            "Epoch 30, Step 18, Loss: 0.007691184524446726\n",
            "Epoch 30, Step 19, Loss: 0.008801770396530628\n",
            "Epoch 30, Step 20, Loss: 0.00909783598035574\n",
            "Epoch 30, Step 21, Loss: 0.009408006444573402\n",
            "Epoch 30, Step 22, Loss: 0.009717395529150963\n",
            "Epoch 30, Step 23, Loss: 0.0099887540563941\n",
            "Epoch 30, Step 24, Loss: 0.010718230158090591\n",
            "Epoch 30, Step 25, Loss: 0.01145736500620842\n",
            "Epoch 30, Step 26, Loss: 0.010164760984480381\n",
            "Epoch 30, Step 27, Loss: 0.008822343312203884\n",
            "Epoch 30, Step 28, Loss: 0.009841619990766048\n",
            "Epoch 30, Step 29, Loss: 0.010223238728940487\n",
            "Epoch 30, Step 30, Loss: 0.008105137385427952\n",
            "Epoch 30, Step 31, Loss: 0.010412435978651047\n",
            "Epoch 30, Step 32, Loss: 0.008969798684120178\n",
            "Epoch 30, Step 33, Loss: 0.010013876482844353\n",
            "Epoch 30, Step 34, Loss: 0.008749710395932198\n",
            "Epoch 30, Step 35, Loss: 0.009524216875433922\n",
            "Epoch 30, Step 36, Loss: 0.008175550028681755\n",
            "Epoch 30, Step 37, Loss: 0.00915850605815649\n",
            "Epoch 30, Step 38, Loss: 0.008560043759644032\n",
            "Epoch 30, Step 39, Loss: 0.008726581931114197\n",
            "Epoch 30, Step 40, Loss: 0.008719210512936115\n",
            "Epoch 30, Step 41, Loss: 0.007291772868484259\n",
            "Epoch 30, Step 42, Loss: 0.007300201803445816\n",
            "Epoch 30, Step 43, Loss: 0.006958573125302792\n",
            "Epoch 30, Step 44, Loss: 0.00720893032848835\n",
            "Epoch 30, Step 45, Loss: 0.00821793545037508\n",
            "Epoch 30, Step 46, Loss: 0.0073938495479524136\n",
            "Epoch 30, Step 47, Loss: 0.007668761536478996\n",
            "Epoch 30, Step 48, Loss: 0.00707350205630064\n",
            "Epoch 30, Step 49, Loss: 0.006828088313341141\n",
            "Epoch 30, Step 50, Loss: 0.006624519359320402\n",
            "Epoch 30, Step 51, Loss: 0.006882143206894398\n",
            "Epoch 30, Step 52, Loss: 0.0063088638707995415\n",
            "Epoch 30, Step 53, Loss: 0.008408909663558006\n",
            "Epoch 30, Step 54, Loss: 0.005822011735290289\n",
            "Epoch 30, Step 55, Loss: 0.006612713448703289\n",
            "Epoch 30, Step 56, Loss: 0.006896673701703548\n",
            "Epoch 30, Step 57, Loss: 0.005988509394228458\n",
            "Epoch 30, Step 58, Loss: 0.006304701790213585\n",
            "Epoch 30, Step 59, Loss: 0.006129630375653505\n",
            "Epoch 30, Step 60, Loss: 0.006333435885608196\n",
            "Epoch 30, Step 61, Loss: 0.008642475120723248\n",
            "Epoch 30, Step 62, Loss: 0.00625082291662693\n",
            "Epoch 30, Step 63, Loss: 0.007084082346409559\n",
            "Epoch 30, Step 64, Loss: 0.006126724649220705\n",
            "Epoch 30, Step 65, Loss: 0.006958032492548227\n",
            "Epoch 30, Step 66, Loss: 0.007458315696567297\n",
            "Epoch 30, Step 67, Loss: 0.008501604199409485\n",
            "Epoch 30, Step 68, Loss: 0.008022289723157883\n",
            "Epoch 30, Step 69, Loss: 0.008350709453225136\n",
            "Epoch 30, Step 70, Loss: 0.009178304113447666\n",
            "Epoch 30, Step 71, Loss: 0.009413829073309898\n",
            "Epoch 30, Step 72, Loss: 0.007817208766937256\n",
            "Epoch 30, Step 73, Loss: 0.007389006670564413\n",
            "Epoch 30, Step 74, Loss: 0.007231858093291521\n",
            "Epoch 30, Step 75, Loss: 0.008772749453783035\n",
            "Epoch 30, Step 76, Loss: 0.00789575930684805\n",
            "Epoch 30, Step 77, Loss: 0.008590510115027428\n",
            "Epoch 30, Step 78, Loss: 0.006400131154805422\n",
            "Epoch 30, Step 79, Loss: 0.0069889044389128685\n",
            "Epoch 30, Step 80, Loss: 0.007542040199041367\n",
            "Epoch 30, Step 81, Loss: 0.00956960953772068\n",
            "Epoch 30, Step 82, Loss: 0.008838174864649773\n",
            "Epoch 30, Step 83, Loss: 0.007737787440419197\n",
            "Epoch 30, Step 84, Loss: 0.009426736272871494\n",
            "Epoch 30, Step 85, Loss: 0.009932172484695911\n",
            "Train Metric MRRs: 0.30150403163909345\n",
            "Train Metric MAPs: 0.3158530689576503\n",
            "Validation Metric MRRs: 0.22585507320675322\n",
            "Validation Metric MAPs: 0.2146557127810855\n",
            "Epoch 31, Step 1, Loss: 0.02132910117506981\n",
            "Epoch 31, Step 2, Loss: 0.020754678174853325\n",
            "Epoch 31, Step 3, Loss: 0.01837027259171009\n",
            "Epoch 31, Step 4, Loss: 0.014005939476191998\n",
            "Epoch 31, Step 5, Loss: 0.010567670688033104\n",
            "Epoch 31, Step 6, Loss: 0.007920247502624989\n",
            "Epoch 31, Step 7, Loss: 0.005615394562482834\n",
            "Epoch 31, Step 8, Loss: 0.005835127085447311\n",
            "Epoch 31, Step 9, Loss: 0.005412327125668526\n",
            "Epoch 31, Step 10, Loss: 0.005221642088145018\n",
            "Epoch 31, Step 11, Loss: 0.0059178732335567474\n",
            "Epoch 31, Step 12, Loss: 0.005448466632515192\n",
            "Epoch 31, Step 13, Loss: 0.004929344169795513\n",
            "Epoch 31, Step 14, Loss: 0.004325529560446739\n",
            "Epoch 31, Step 15, Loss: 0.004870044067502022\n",
            "Epoch 31, Step 16, Loss: 0.004906777758151293\n",
            "Epoch 31, Step 17, Loss: 0.00654807360842824\n",
            "Epoch 31, Step 18, Loss: 0.007681740913540125\n",
            "Epoch 31, Step 19, Loss: 0.009169105440378189\n",
            "Epoch 31, Step 20, Loss: 0.008954123593866825\n",
            "Epoch 31, Step 21, Loss: 0.009407458826899529\n",
            "Epoch 31, Step 22, Loss: 0.009533108212053776\n",
            "Epoch 31, Step 23, Loss: 0.009839385747909546\n",
            "Epoch 31, Step 24, Loss: 0.010626465082168579\n",
            "Epoch 31, Step 25, Loss: 0.011512432247400284\n",
            "Epoch 31, Step 26, Loss: 0.010045782662928104\n",
            "Epoch 31, Step 27, Loss: 0.0085329944267869\n",
            "Epoch 31, Step 28, Loss: 0.009707236662507057\n",
            "Epoch 31, Step 29, Loss: 0.01015825942158699\n",
            "Epoch 31, Step 30, Loss: 0.008092145435512066\n",
            "Epoch 31, Step 31, Loss: 0.010462354868650436\n",
            "Epoch 31, Step 32, Loss: 0.009054751135408878\n",
            "Epoch 31, Step 33, Loss: 0.01003186870366335\n",
            "Epoch 31, Step 34, Loss: 0.008780773729085922\n",
            "Epoch 31, Step 35, Loss: 0.009718815796077251\n",
            "Epoch 31, Step 36, Loss: 0.008141784928739071\n",
            "Epoch 31, Step 37, Loss: 0.009067762643098831\n",
            "Epoch 31, Step 38, Loss: 0.008512761443853378\n",
            "Epoch 31, Step 39, Loss: 0.008625044487416744\n",
            "Epoch 31, Step 40, Loss: 0.008774453774094582\n",
            "Epoch 31, Step 41, Loss: 0.007385464385151863\n",
            "Epoch 31, Step 42, Loss: 0.0073533193208277225\n",
            "Epoch 31, Step 43, Loss: 0.006841313559561968\n",
            "Epoch 31, Step 44, Loss: 0.0073888846673071384\n",
            "Epoch 31, Step 45, Loss: 0.008205450139939785\n",
            "Epoch 31, Step 46, Loss: 0.007401022594422102\n",
            "Epoch 31, Step 47, Loss: 0.007549321744590998\n",
            "Epoch 31, Step 48, Loss: 0.0070338742807507515\n",
            "Epoch 31, Step 49, Loss: 0.0068588522262871265\n",
            "Epoch 31, Step 50, Loss: 0.006597621366381645\n",
            "Epoch 31, Step 51, Loss: 0.00687861954793334\n",
            "Epoch 31, Step 52, Loss: 0.006294223479926586\n",
            "Epoch 31, Step 53, Loss: 0.008410386741161346\n",
            "Epoch 31, Step 54, Loss: 0.0057982648722827435\n",
            "Epoch 31, Step 55, Loss: 0.006586520932614803\n",
            "Epoch 31, Step 56, Loss: 0.007026022765785456\n",
            "Epoch 31, Step 57, Loss: 0.006094565149396658\n",
            "Epoch 31, Step 58, Loss: 0.006268051918596029\n",
            "Epoch 31, Step 59, Loss: 0.00604112958535552\n",
            "Epoch 31, Step 60, Loss: 0.006310703698545694\n",
            "Epoch 31, Step 61, Loss: 0.008543683215975761\n",
            "Epoch 31, Step 62, Loss: 0.006134033668786287\n",
            "Epoch 31, Step 63, Loss: 0.007018638774752617\n",
            "Epoch 31, Step 64, Loss: 0.006158207543194294\n",
            "Epoch 31, Step 65, Loss: 0.00692698173224926\n",
            "Epoch 31, Step 66, Loss: 0.007311162538826466\n",
            "Epoch 31, Step 67, Loss: 0.008485982194542885\n",
            "Epoch 31, Step 68, Loss: 0.007904402911663055\n",
            "Epoch 31, Step 69, Loss: 0.008221419528126717\n",
            "Epoch 31, Step 70, Loss: 0.009199917316436768\n",
            "Epoch 31, Step 71, Loss: 0.009359624236822128\n",
            "Epoch 31, Step 72, Loss: 0.007635075133293867\n",
            "Epoch 31, Step 73, Loss: 0.007309819106012583\n",
            "Epoch 31, Step 74, Loss: 0.0072404127568006516\n",
            "Epoch 31, Step 75, Loss: 0.0087236063554883\n",
            "Epoch 31, Step 76, Loss: 0.007966974750161171\n",
            "Epoch 31, Step 77, Loss: 0.008537450805306435\n",
            "Epoch 31, Step 78, Loss: 0.006351510062813759\n",
            "Epoch 31, Step 79, Loss: 0.0068910494446754456\n",
            "Epoch 31, Step 80, Loss: 0.007498817518353462\n",
            "Epoch 31, Step 81, Loss: 0.009533577598631382\n",
            "Epoch 31, Step 82, Loss: 0.008862452581524849\n",
            "Epoch 31, Step 83, Loss: 0.007676098495721817\n",
            "Epoch 31, Step 84, Loss: 0.00977703183889389\n",
            "Epoch 31, Step 85, Loss: 0.010071530006825924\n",
            "Train Metric MRRs: 0.301009864217536\n",
            "Train Metric MAPs: 0.3122547017617781\n",
            "Validation Metric MRRs: 0.2257846076396686\n",
            "Validation Metric MAPs: 0.2123985509645474\n",
            "Epoch 32, Step 1, Loss: 0.02023911103606224\n",
            "Epoch 32, Step 2, Loss: 0.020650489255785942\n",
            "Epoch 32, Step 3, Loss: 0.01738993264734745\n",
            "Epoch 32, Step 4, Loss: 0.013985599391162395\n",
            "Epoch 32, Step 5, Loss: 0.010216196067631245\n",
            "Epoch 32, Step 6, Loss: 0.007630796171724796\n",
            "Epoch 32, Step 7, Loss: 0.005496771074831486\n",
            "Epoch 32, Step 8, Loss: 0.005453923717141151\n",
            "Epoch 32, Step 9, Loss: 0.005191875621676445\n",
            "Epoch 32, Step 10, Loss: 0.0051286714151501656\n",
            "Epoch 32, Step 11, Loss: 0.005670477636158466\n",
            "Epoch 32, Step 12, Loss: 0.005349450279027224\n",
            "Epoch 32, Step 13, Loss: 0.004859595093876123\n",
            "Epoch 32, Step 14, Loss: 0.00396482041105628\n",
            "Epoch 32, Step 15, Loss: 0.004791581071913242\n",
            "Epoch 32, Step 16, Loss: 0.0047058165073394775\n",
            "Epoch 32, Step 17, Loss: 0.0065079499036073685\n",
            "Epoch 32, Step 18, Loss: 0.007455998100340366\n",
            "Epoch 32, Step 19, Loss: 0.008483308367431164\n",
            "Epoch 32, Step 20, Loss: 0.008889682590961456\n",
            "Epoch 32, Step 21, Loss: 0.009464992210268974\n",
            "Epoch 32, Step 22, Loss: 0.009543958120048046\n",
            "Epoch 32, Step 23, Loss: 0.009894244372844696\n",
            "Epoch 32, Step 24, Loss: 0.010782619006931782\n",
            "Epoch 32, Step 25, Loss: 0.011069783940911293\n",
            "Epoch 32, Step 26, Loss: 0.009762100875377655\n",
            "Epoch 32, Step 27, Loss: 0.008522187359631062\n",
            "Epoch 32, Step 28, Loss: 0.00988119188696146\n",
            "Epoch 32, Step 29, Loss: 0.010052426718175411\n",
            "Epoch 32, Step 30, Loss: 0.008065886795520782\n",
            "Epoch 32, Step 31, Loss: 0.0103157302364707\n",
            "Epoch 32, Step 32, Loss: 0.008917635306715965\n",
            "Epoch 32, Step 33, Loss: 0.009786009788513184\n",
            "Epoch 32, Step 34, Loss: 0.008769823238253593\n",
            "Epoch 32, Step 35, Loss: 0.009570238180458546\n",
            "Epoch 32, Step 36, Loss: 0.00806348118931055\n",
            "Epoch 32, Step 37, Loss: 0.009262564592063427\n",
            "Epoch 32, Step 38, Loss: 0.008463245816528797\n",
            "Epoch 32, Step 39, Loss: 0.008612905628979206\n",
            "Epoch 32, Step 40, Loss: 0.00866665132343769\n",
            "Epoch 32, Step 41, Loss: 0.0072279139421880245\n",
            "Epoch 32, Step 42, Loss: 0.007238558027893305\n",
            "Epoch 32, Step 43, Loss: 0.006632096599787474\n",
            "Epoch 32, Step 44, Loss: 0.0072086225263774395\n",
            "Epoch 32, Step 45, Loss: 0.008159019984304905\n",
            "Epoch 32, Step 46, Loss: 0.007423048838973045\n",
            "Epoch 32, Step 47, Loss: 0.007496042177081108\n",
            "Epoch 32, Step 48, Loss: 0.006997768301516771\n",
            "Epoch 32, Step 49, Loss: 0.0068829660303890705\n",
            "Epoch 32, Step 50, Loss: 0.0066087027080357075\n",
            "Epoch 32, Step 51, Loss: 0.006864434573799372\n",
            "Epoch 32, Step 52, Loss: 0.006242216564714909\n",
            "Epoch 32, Step 53, Loss: 0.00835392251610756\n",
            "Epoch 32, Step 54, Loss: 0.0058095576241612434\n",
            "Epoch 32, Step 55, Loss: 0.006603386253118515\n",
            "Epoch 32, Step 56, Loss: 0.006869640666991472\n",
            "Epoch 32, Step 57, Loss: 0.0060372245498001575\n",
            "Epoch 32, Step 58, Loss: 0.006372625473886728\n",
            "Epoch 32, Step 59, Loss: 0.0060504041612148285\n",
            "Epoch 32, Step 60, Loss: 0.0063147288747131824\n",
            "Epoch 32, Step 61, Loss: 0.00835940521210432\n",
            "Epoch 32, Step 62, Loss: 0.005941187497228384\n",
            "Epoch 32, Step 63, Loss: 0.006955292075872421\n",
            "Epoch 32, Step 64, Loss: 0.00612174766138196\n",
            "Epoch 32, Step 65, Loss: 0.006901565473526716\n",
            "Epoch 32, Step 66, Loss: 0.0073110200464725494\n",
            "Epoch 32, Step 67, Loss: 0.008309624157845974\n",
            "Epoch 32, Step 68, Loss: 0.007988736033439636\n",
            "Epoch 32, Step 69, Loss: 0.008215343579649925\n",
            "Epoch 32, Step 70, Loss: 0.009267875924706459\n",
            "Epoch 32, Step 71, Loss: 0.009334038011729717\n",
            "Epoch 32, Step 72, Loss: 0.0075654624961316586\n",
            "Epoch 32, Step 73, Loss: 0.007380068302154541\n",
            "Epoch 32, Step 74, Loss: 0.007176055107265711\n",
            "Epoch 32, Step 75, Loss: 0.008554480038583279\n",
            "Epoch 32, Step 76, Loss: 0.008024397306144238\n",
            "Epoch 32, Step 77, Loss: 0.008740122430026531\n",
            "Epoch 32, Step 78, Loss: 0.006301160901784897\n",
            "Epoch 32, Step 79, Loss: 0.0067621320486068726\n",
            "Epoch 32, Step 80, Loss: 0.007490665651857853\n",
            "Epoch 32, Step 81, Loss: 0.009609933011233807\n",
            "Epoch 32, Step 82, Loss: 0.008765227161347866\n",
            "Epoch 32, Step 83, Loss: 0.0075618610717356205\n",
            "Epoch 32, Step 84, Loss: 0.009553025476634502\n",
            "Epoch 32, Step 85, Loss: 0.009659134782850742\n",
            "Train Metric MRRs: 0.3031184262047709\n",
            "Train Metric MAPs: 0.31387381823505595\n",
            "Validation Metric MRRs: 0.22471122285640485\n",
            "Validation Metric MAPs: 0.21064270692053197\n",
            "Epoch 33, Step 1, Loss: 0.02050497941672802\n",
            "Epoch 33, Step 2, Loss: 0.020680271089076996\n",
            "Epoch 33, Step 3, Loss: 0.017127392813563347\n",
            "Epoch 33, Step 4, Loss: 0.014201976358890533\n",
            "Epoch 33, Step 5, Loss: 0.01036064513027668\n",
            "Epoch 33, Step 6, Loss: 0.007696840446442366\n",
            "Epoch 33, Step 7, Loss: 0.00541716767475009\n",
            "Epoch 33, Step 8, Loss: 0.0054365224204957485\n",
            "Epoch 33, Step 9, Loss: 0.005044323857873678\n",
            "Epoch 33, Step 10, Loss: 0.0051201884634792805\n",
            "Epoch 33, Step 11, Loss: 0.005677228327840567\n",
            "Epoch 33, Step 12, Loss: 0.0051735141314566135\n",
            "Epoch 33, Step 13, Loss: 0.004697404336184263\n",
            "Epoch 33, Step 14, Loss: 0.0039343759417533875\n",
            "Epoch 33, Step 15, Loss: 0.004700334742665291\n",
            "Epoch 33, Step 16, Loss: 0.004518443252891302\n",
            "Epoch 33, Step 17, Loss: 0.006376844365149736\n",
            "Epoch 33, Step 18, Loss: 0.007178603205829859\n",
            "Epoch 33, Step 19, Loss: 0.008416280150413513\n",
            "Epoch 33, Step 20, Loss: 0.008988729678094387\n",
            "Epoch 33, Step 21, Loss: 0.009629111737012863\n",
            "Epoch 33, Step 22, Loss: 0.009373991750180721\n",
            "Epoch 33, Step 23, Loss: 0.009879359975457191\n",
            "Epoch 33, Step 24, Loss: 0.010634123347699642\n",
            "Epoch 33, Step 25, Loss: 0.011154655367136002\n",
            "Epoch 33, Step 26, Loss: 0.009615388698875904\n",
            "Epoch 33, Step 27, Loss: 0.008444718085229397\n",
            "Epoch 33, Step 28, Loss: 0.009528163820505142\n",
            "Epoch 33, Step 29, Loss: 0.009791751392185688\n",
            "Epoch 33, Step 30, Loss: 0.007834376767277718\n",
            "Epoch 33, Step 31, Loss: 0.010381273925304413\n",
            "Epoch 33, Step 32, Loss: 0.008749431930482388\n",
            "Epoch 33, Step 33, Loss: 0.009700743481516838\n",
            "Epoch 33, Step 34, Loss: 0.00864114984869957\n",
            "Epoch 33, Step 35, Loss: 0.009384752251207829\n",
            "Epoch 33, Step 36, Loss: 0.007961684837937355\n",
            "Epoch 33, Step 37, Loss: 0.009111215360462666\n",
            "Epoch 33, Step 38, Loss: 0.008419015444815159\n",
            "Epoch 33, Step 39, Loss: 0.008625056594610214\n",
            "Epoch 33, Step 40, Loss: 0.008683057501912117\n",
            "Epoch 33, Step 41, Loss: 0.007166063878685236\n",
            "Epoch 33, Step 42, Loss: 0.00728058023378253\n",
            "Epoch 33, Step 43, Loss: 0.006613799370825291\n",
            "Epoch 33, Step 44, Loss: 0.007244936656206846\n",
            "Epoch 33, Step 45, Loss: 0.008048389106988907\n",
            "Epoch 33, Step 46, Loss: 0.007330569438636303\n",
            "Epoch 33, Step 47, Loss: 0.007548539899289608\n",
            "Epoch 33, Step 48, Loss: 0.006880002561956644\n",
            "Epoch 33, Step 49, Loss: 0.006804716773331165\n",
            "Epoch 33, Step 50, Loss: 0.006546740420162678\n",
            "Epoch 33, Step 51, Loss: 0.006817901507019997\n",
            "Epoch 33, Step 52, Loss: 0.006247472483664751\n",
            "Epoch 33, Step 53, Loss: 0.008429192006587982\n",
            "Epoch 33, Step 54, Loss: 0.005771060939878225\n",
            "Epoch 33, Step 55, Loss: 0.006510400213301182\n",
            "Epoch 33, Step 56, Loss: 0.006893021985888481\n",
            "Epoch 33, Step 57, Loss: 0.005906003061681986\n",
            "Epoch 33, Step 58, Loss: 0.006298138294368982\n",
            "Epoch 33, Step 59, Loss: 0.006038984749466181\n",
            "Epoch 33, Step 60, Loss: 0.006210688501596451\n",
            "Epoch 33, Step 61, Loss: 0.008354964666068554\n",
            "Epoch 33, Step 62, Loss: 0.006100993137806654\n",
            "Epoch 33, Step 63, Loss: 0.006903127301484346\n",
            "Epoch 33, Step 64, Loss: 0.006136114243417978\n",
            "Epoch 33, Step 65, Loss: 0.006893759127706289\n",
            "Epoch 33, Step 66, Loss: 0.007327205967158079\n",
            "Epoch 33, Step 67, Loss: 0.008271408267319202\n",
            "Epoch 33, Step 68, Loss: 0.007819299586117268\n",
            "Epoch 33, Step 69, Loss: 0.00819944217801094\n",
            "Epoch 33, Step 70, Loss: 0.009257847443223\n",
            "Epoch 33, Step 71, Loss: 0.009290260262787342\n",
            "Epoch 33, Step 72, Loss: 0.007497597951442003\n",
            "Epoch 33, Step 73, Loss: 0.00735414307564497\n",
            "Epoch 33, Step 74, Loss: 0.007207170594483614\n",
            "Epoch 33, Step 75, Loss: 0.008647849783301353\n",
            "Epoch 33, Step 76, Loss: 0.007956487126648426\n",
            "Epoch 33, Step 77, Loss: 0.00846010260283947\n",
            "Epoch 33, Step 78, Loss: 0.006232688669115305\n",
            "Epoch 33, Step 79, Loss: 0.006588406395167112\n",
            "Epoch 33, Step 80, Loss: 0.007434800732880831\n",
            "Epoch 33, Step 81, Loss: 0.009430540725588799\n",
            "Epoch 33, Step 82, Loss: 0.008762159384787083\n",
            "Epoch 33, Step 83, Loss: 0.007530819159001112\n",
            "Epoch 33, Step 84, Loss: 0.009485501796007156\n",
            "Epoch 33, Step 85, Loss: 0.009673654101788998\n",
            "Train Metric MRRs: 0.3032169947929856\n",
            "Train Metric MAPs: 0.3140475738506804\n",
            "Validation Metric MRRs: 0.22485898662841458\n",
            "Validation Metric MAPs: 0.21161063451980391\n",
            "Epoch 34, Step 1, Loss: 0.02067592926323414\n",
            "Epoch 34, Step 2, Loss: 0.020452633500099182\n",
            "Epoch 34, Step 3, Loss: 0.017335519194602966\n",
            "Epoch 34, Step 4, Loss: 0.014228319749236107\n",
            "Epoch 34, Step 5, Loss: 0.010177415795624256\n",
            "Epoch 34, Step 6, Loss: 0.0076170251704752445\n",
            "Epoch 34, Step 7, Loss: 0.0053887926042079926\n",
            "Epoch 34, Step 8, Loss: 0.005373967811465263\n",
            "Epoch 34, Step 9, Loss: 0.005017765332013369\n",
            "Epoch 34, Step 10, Loss: 0.005198069382458925\n",
            "Epoch 34, Step 11, Loss: 0.005656115710735321\n",
            "Epoch 34, Step 12, Loss: 0.00533824460580945\n",
            "Epoch 34, Step 13, Loss: 0.0050388784147799015\n",
            "Epoch 34, Step 14, Loss: 0.004107318818569183\n",
            "Epoch 34, Step 15, Loss: 0.004895136225968599\n",
            "Epoch 34, Step 16, Loss: 0.004851076286286116\n",
            "Epoch 34, Step 17, Loss: 0.006460982374846935\n",
            "Epoch 34, Step 18, Loss: 0.007434411905705929\n",
            "Epoch 34, Step 19, Loss: 0.008868525736033916\n",
            "Epoch 34, Step 20, Loss: 0.009068118408322334\n",
            "Epoch 34, Step 21, Loss: 0.009341158904135227\n",
            "Epoch 34, Step 22, Loss: 0.009795865043997765\n",
            "Epoch 34, Step 23, Loss: 0.010205349884927273\n",
            "Epoch 34, Step 24, Loss: 0.010775518603622913\n",
            "Epoch 34, Step 25, Loss: 0.011142966337502003\n",
            "Epoch 34, Step 26, Loss: 0.010015481151640415\n",
            "Epoch 34, Step 27, Loss: 0.008761482313275337\n",
            "Epoch 34, Step 28, Loss: 0.00975773110985756\n",
            "Epoch 34, Step 29, Loss: 0.010151596739888191\n",
            "Epoch 34, Step 30, Loss: 0.008141331374645233\n",
            "Epoch 34, Step 31, Loss: 0.010519060306251049\n",
            "Epoch 34, Step 32, Loss: 0.008891085162758827\n",
            "Epoch 34, Step 33, Loss: 0.009803271852433681\n",
            "Epoch 34, Step 34, Loss: 0.00866687297821045\n",
            "Epoch 34, Step 35, Loss: 0.009959552437067032\n",
            "Epoch 34, Step 36, Loss: 0.008133159950375557\n",
            "Epoch 34, Step 37, Loss: 0.009072320535779\n",
            "Epoch 34, Step 38, Loss: 0.008537467569112778\n",
            "Epoch 34, Step 39, Loss: 0.0086497338488698\n",
            "Epoch 34, Step 40, Loss: 0.008676274679601192\n",
            "Epoch 34, Step 41, Loss: 0.0073130447417497635\n",
            "Epoch 34, Step 42, Loss: 0.0073726121336221695\n",
            "Epoch 34, Step 43, Loss: 0.006656669545918703\n",
            "Epoch 34, Step 44, Loss: 0.007272057700902224\n",
            "Epoch 34, Step 45, Loss: 0.008137289434671402\n",
            "Epoch 34, Step 46, Loss: 0.007408109959214926\n",
            "Epoch 34, Step 47, Loss: 0.007561341393738985\n",
            "Epoch 34, Step 48, Loss: 0.007030600216239691\n",
            "Epoch 34, Step 49, Loss: 0.006872710306197405\n",
            "Epoch 34, Step 50, Loss: 0.006600893568247557\n",
            "Epoch 34, Step 51, Loss: 0.006846551783382893\n",
            "Epoch 34, Step 52, Loss: 0.0061803883872926235\n",
            "Epoch 34, Step 53, Loss: 0.008363138884305954\n",
            "Epoch 34, Step 54, Loss: 0.005823981482535601\n",
            "Epoch 34, Step 55, Loss: 0.006551602389663458\n",
            "Epoch 34, Step 56, Loss: 0.006850919220596552\n",
            "Epoch 34, Step 57, Loss: 0.006003267131745815\n",
            "Epoch 34, Step 58, Loss: 0.0063356878235936165\n",
            "Epoch 34, Step 59, Loss: 0.006083797197788954\n",
            "Epoch 34, Step 60, Loss: 0.006269504781812429\n",
            "Epoch 34, Step 61, Loss: 0.008349730633199215\n",
            "Epoch 34, Step 62, Loss: 0.0061157820746302605\n",
            "Epoch 34, Step 63, Loss: 0.006997722666710615\n",
            "Epoch 34, Step 64, Loss: 0.006247686222195625\n",
            "Epoch 34, Step 65, Loss: 0.006964767351746559\n",
            "Epoch 34, Step 66, Loss: 0.0073052034713327885\n",
            "Epoch 34, Step 67, Loss: 0.008355086669325829\n",
            "Epoch 34, Step 68, Loss: 0.007974764332175255\n",
            "Epoch 34, Step 69, Loss: 0.0082793477922678\n",
            "Epoch 34, Step 70, Loss: 0.009262153878808022\n",
            "Epoch 34, Step 71, Loss: 0.009377142414450645\n",
            "Epoch 34, Step 72, Loss: 0.0076111480593681335\n",
            "Epoch 34, Step 73, Loss: 0.007336512207984924\n",
            "Epoch 34, Step 74, Loss: 0.007167350966483355\n",
            "Epoch 34, Step 75, Loss: 0.00864048395305872\n",
            "Epoch 34, Step 76, Loss: 0.007931319996714592\n",
            "Epoch 34, Step 77, Loss: 0.008581310510635376\n",
            "Epoch 34, Step 78, Loss: 0.00634097121655941\n",
            "Epoch 34, Step 79, Loss: 0.006708091124892235\n",
            "Epoch 34, Step 80, Loss: 0.007487126160413027\n",
            "Epoch 34, Step 81, Loss: 0.009694037958979607\n",
            "Epoch 34, Step 82, Loss: 0.008827944286167622\n",
            "Epoch 34, Step 83, Loss: 0.007568109314888716\n",
            "Epoch 34, Step 84, Loss: 0.01003406010568142\n",
            "Epoch 34, Step 85, Loss: 0.009677283465862274\n",
            "Train Metric MRRs: 0.30570975780067483\n",
            "Train Metric MAPs: 0.3130655993538512\n",
            "Validation Metric MRRs: 0.22443400607231975\n",
            "Validation Metric MAPs: 0.21031549968598287\n",
            "Epoch 35, Step 1, Loss: 0.021604187786579132\n",
            "Epoch 35, Step 2, Loss: 0.020616784691810608\n",
            "Epoch 35, Step 3, Loss: 0.01740698702633381\n",
            "Epoch 35, Step 4, Loss: 0.014163966290652752\n",
            "Epoch 35, Step 5, Loss: 0.01049311924725771\n",
            "Epoch 35, Step 6, Loss: 0.008031591773033142\n",
            "Epoch 35, Step 7, Loss: 0.00556324515491724\n",
            "Epoch 35, Step 8, Loss: 0.005738840438425541\n",
            "Epoch 35, Step 9, Loss: 0.005299092270433903\n",
            "Epoch 35, Step 10, Loss: 0.005266987718641758\n",
            "Epoch 35, Step 11, Loss: 0.005752218887209892\n",
            "Epoch 35, Step 12, Loss: 0.005336748901754618\n",
            "Epoch 35, Step 13, Loss: 0.004738095682114363\n",
            "Epoch 35, Step 14, Loss: 0.004374504555016756\n",
            "Epoch 35, Step 15, Loss: 0.004805063363164663\n",
            "Epoch 35, Step 16, Loss: 0.004557715728878975\n",
            "Epoch 35, Step 17, Loss: 0.006534312851727009\n",
            "Epoch 35, Step 18, Loss: 0.007235855329781771\n",
            "Epoch 35, Step 19, Loss: 0.009167684242129326\n",
            "Epoch 35, Step 20, Loss: 0.00921453908085823\n",
            "Epoch 35, Step 21, Loss: 0.009425921365618706\n",
            "Epoch 35, Step 22, Loss: 0.009432992897927761\n",
            "Epoch 35, Step 23, Loss: 0.010128645226359367\n",
            "Epoch 35, Step 24, Loss: 0.010782507248222828\n",
            "Epoch 35, Step 25, Loss: 0.011268123053014278\n",
            "Epoch 35, Step 26, Loss: 0.009806458838284016\n",
            "Epoch 35, Step 27, Loss: 0.008605489507317543\n",
            "Epoch 35, Step 28, Loss: 0.009562056511640549\n",
            "Epoch 35, Step 29, Loss: 0.010126255452632904\n",
            "Epoch 35, Step 30, Loss: 0.008050452917814255\n",
            "Epoch 35, Step 31, Loss: 0.010262500494718552\n",
            "Epoch 35, Step 32, Loss: 0.009025732055306435\n",
            "Epoch 35, Step 33, Loss: 0.009923789650201797\n",
            "Epoch 35, Step 34, Loss: 0.008838828653097153\n",
            "Epoch 35, Step 35, Loss: 0.009696541354060173\n",
            "Epoch 35, Step 36, Loss: 0.008087269961833954\n",
            "Epoch 35, Step 37, Loss: 0.009116067551076412\n",
            "Epoch 35, Step 38, Loss: 0.008494461886584759\n",
            "Epoch 35, Step 39, Loss: 0.008678502403199673\n",
            "Epoch 35, Step 40, Loss: 0.008723284117877483\n",
            "Epoch 35, Step 41, Loss: 0.007395835593342781\n",
            "Epoch 35, Step 42, Loss: 0.007471886929124594\n",
            "Epoch 35, Step 43, Loss: 0.006955637596547604\n",
            "Epoch 35, Step 44, Loss: 0.007490525487810373\n",
            "Epoch 35, Step 45, Loss: 0.008184039033949375\n",
            "Epoch 35, Step 46, Loss: 0.007364519871771336\n",
            "Epoch 35, Step 47, Loss: 0.007546861656010151\n",
            "Epoch 35, Step 48, Loss: 0.006973584648221731\n",
            "Epoch 35, Step 49, Loss: 0.006896503269672394\n",
            "Epoch 35, Step 50, Loss: 0.006610853131860495\n",
            "Epoch 35, Step 51, Loss: 0.006860796362161636\n",
            "Epoch 35, Step 52, Loss: 0.006328694988042116\n",
            "Epoch 35, Step 53, Loss: 0.0087732570245862\n",
            "Epoch 35, Step 54, Loss: 0.005823122337460518\n",
            "Epoch 35, Step 55, Loss: 0.006577315274626017\n",
            "Epoch 35, Step 56, Loss: 0.006979890633374453\n",
            "Epoch 35, Step 57, Loss: 0.006023139227181673\n",
            "Epoch 35, Step 58, Loss: 0.0063299317844212055\n",
            "Epoch 35, Step 59, Loss: 0.00602826289832592\n",
            "Epoch 35, Step 60, Loss: 0.006256704218685627\n",
            "Epoch 35, Step 61, Loss: 0.008368819020688534\n",
            "Epoch 35, Step 62, Loss: 0.006087344139814377\n",
            "Epoch 35, Step 63, Loss: 0.0069180638529360294\n",
            "Epoch 35, Step 64, Loss: 0.006221825256943703\n",
            "Epoch 35, Step 65, Loss: 0.007006767205893993\n",
            "Epoch 35, Step 66, Loss: 0.007263164035975933\n",
            "Epoch 35, Step 67, Loss: 0.008392691612243652\n",
            "Epoch 35, Step 68, Loss: 0.007842990569770336\n",
            "Epoch 35, Step 69, Loss: 0.00810422282665968\n",
            "Epoch 35, Step 70, Loss: 0.009037301875650883\n",
            "Epoch 35, Step 71, Loss: 0.009400071576237679\n",
            "Epoch 35, Step 72, Loss: 0.007569176610559225\n",
            "Epoch 35, Step 73, Loss: 0.007364488672465086\n",
            "Epoch 35, Step 74, Loss: 0.0071448371745646\n",
            "Epoch 35, Step 75, Loss: 0.008610068820416927\n",
            "Epoch 35, Step 76, Loss: 0.007948575541377068\n",
            "Epoch 35, Step 77, Loss: 0.008381585590541363\n",
            "Epoch 35, Step 78, Loss: 0.0064421407878398895\n",
            "Epoch 35, Step 79, Loss: 0.006842130795121193\n",
            "Epoch 35, Step 80, Loss: 0.0073827775195240974\n",
            "Epoch 35, Step 81, Loss: 0.009604444727301598\n",
            "Epoch 35, Step 82, Loss: 0.008761698380112648\n",
            "Epoch 35, Step 83, Loss: 0.007600544951856136\n",
            "Epoch 35, Step 84, Loss: 0.009686209261417389\n",
            "Epoch 35, Step 85, Loss: 0.009830961935222149\n",
            "Train Metric MRRs: 0.3027311649129844\n",
            "Train Metric MAPs: 0.30890399547743297\n",
            "Validation Metric MRRs: 0.22918466435753487\n",
            "Validation Metric MAPs: 0.2136601233733699\n",
            "Epoch 36, Step 1, Loss: 0.021147631108760834\n",
            "Epoch 36, Step 2, Loss: 0.02186676301062107\n",
            "Epoch 36, Step 3, Loss: 0.017414066940546036\n",
            "Epoch 36, Step 4, Loss: 0.014273016713559628\n",
            "Epoch 36, Step 5, Loss: 0.01041168812662363\n",
            "Epoch 36, Step 6, Loss: 0.00772883091121912\n",
            "Epoch 36, Step 7, Loss: 0.0055434503592550755\n",
            "Epoch 36, Step 8, Loss: 0.005435706581920385\n",
            "Epoch 36, Step 9, Loss: 0.00518818199634552\n",
            "Epoch 36, Step 10, Loss: 0.005180136766284704\n",
            "Epoch 36, Step 11, Loss: 0.005558941047638655\n",
            "Epoch 36, Step 12, Loss: 0.005416208412498236\n",
            "Epoch 36, Step 13, Loss: 0.004708518739789724\n",
            "Epoch 36, Step 14, Loss: 0.003955308347940445\n",
            "Epoch 36, Step 15, Loss: 0.004790456499904394\n",
            "Epoch 36, Step 16, Loss: 0.00468397093936801\n",
            "Epoch 36, Step 17, Loss: 0.006204731296747923\n",
            "Epoch 36, Step 18, Loss: 0.007481257896870375\n",
            "Epoch 36, Step 19, Loss: 0.008750212378799915\n",
            "Epoch 36, Step 20, Loss: 0.009223813191056252\n",
            "Epoch 36, Step 21, Loss: 0.009667628444731236\n",
            "Epoch 36, Step 22, Loss: 0.009654753841459751\n",
            "Epoch 36, Step 23, Loss: 0.010276428423821926\n",
            "Epoch 36, Step 24, Loss: 0.010952367447316647\n",
            "Epoch 36, Step 25, Loss: 0.011502102017402649\n",
            "Epoch 36, Step 26, Loss: 0.010110230185091496\n",
            "Epoch 36, Step 27, Loss: 0.008471541106700897\n",
            "Epoch 36, Step 28, Loss: 0.009596816264092922\n",
            "Epoch 36, Step 29, Loss: 0.00967746414244175\n",
            "Epoch 36, Step 30, Loss: 0.008006025105714798\n",
            "Epoch 36, Step 31, Loss: 0.010254853405058384\n",
            "Epoch 36, Step 32, Loss: 0.008884587325155735\n",
            "Epoch 36, Step 33, Loss: 0.009791569784283638\n",
            "Epoch 36, Step 34, Loss: 0.00869546364992857\n",
            "Epoch 36, Step 35, Loss: 0.009473586454987526\n",
            "Epoch 36, Step 36, Loss: 0.008001066744327545\n",
            "Epoch 36, Step 37, Loss: 0.00926756951957941\n",
            "Epoch 36, Step 38, Loss: 0.00850999727845192\n",
            "Epoch 36, Step 39, Loss: 0.008575113490223885\n",
            "Epoch 36, Step 40, Loss: 0.008803306147456169\n",
            "Epoch 36, Step 41, Loss: 0.007108798250555992\n",
            "Epoch 36, Step 42, Loss: 0.0073498995043337345\n",
            "Epoch 36, Step 43, Loss: 0.006642327643930912\n",
            "Epoch 36, Step 44, Loss: 0.007272125221788883\n",
            "Epoch 36, Step 45, Loss: 0.008089086040854454\n",
            "Epoch 36, Step 46, Loss: 0.007346506230533123\n",
            "Epoch 36, Step 47, Loss: 0.007472455035895109\n",
            "Epoch 36, Step 48, Loss: 0.006924842018634081\n",
            "Epoch 36, Step 49, Loss: 0.006860526278614998\n",
            "Epoch 36, Step 50, Loss: 0.006578602362424135\n",
            "Epoch 36, Step 51, Loss: 0.006873912177979946\n",
            "Epoch 36, Step 52, Loss: 0.006108911242336035\n",
            "Epoch 36, Step 53, Loss: 0.008346054702997208\n",
            "Epoch 36, Step 54, Loss: 0.005859398748725653\n",
            "Epoch 36, Step 55, Loss: 0.006660176906734705\n",
            "Epoch 36, Step 56, Loss: 0.00693951640278101\n",
            "Epoch 36, Step 57, Loss: 0.006001187022775412\n",
            "Epoch 36, Step 58, Loss: 0.006307506468147039\n",
            "Epoch 36, Step 59, Loss: 0.006073391530662775\n",
            "Epoch 36, Step 60, Loss: 0.006301074288785458\n",
            "Epoch 36, Step 61, Loss: 0.008356144651770592\n",
            "Epoch 36, Step 62, Loss: 0.006013181991875172\n",
            "Epoch 36, Step 63, Loss: 0.006954863667488098\n",
            "Epoch 36, Step 64, Loss: 0.0062362938188016415\n",
            "Epoch 36, Step 65, Loss: 0.006830496713519096\n",
            "Epoch 36, Step 66, Loss: 0.007228540722280741\n",
            "Epoch 36, Step 67, Loss: 0.008258244954049587\n",
            "Epoch 36, Step 68, Loss: 0.007893411442637444\n",
            "Epoch 36, Step 69, Loss: 0.008252592757344246\n",
            "Epoch 36, Step 70, Loss: 0.00911223515868187\n",
            "Epoch 36, Step 71, Loss: 0.00929898489266634\n",
            "Epoch 36, Step 72, Loss: 0.0075431205332279205\n",
            "Epoch 36, Step 73, Loss: 0.007271768059581518\n",
            "Epoch 36, Step 74, Loss: 0.007077799644321203\n",
            "Epoch 36, Step 75, Loss: 0.008571386337280273\n",
            "Epoch 36, Step 76, Loss: 0.00796434935182333\n",
            "Epoch 36, Step 77, Loss: 0.008588431403040886\n",
            "Epoch 36, Step 78, Loss: 0.006292680278420448\n",
            "Epoch 36, Step 79, Loss: 0.006743522360920906\n",
            "Epoch 36, Step 80, Loss: 0.00741360941901803\n",
            "Epoch 36, Step 81, Loss: 0.009666994214057922\n",
            "Epoch 36, Step 82, Loss: 0.008925070986151695\n",
            "Epoch 36, Step 83, Loss: 0.00753043731674552\n",
            "Epoch 36, Step 84, Loss: 0.00952533632516861\n",
            "Epoch 36, Step 85, Loss: 0.009690184146165848\n",
            "Train Metric MRRs: 0.30175948905903777\n",
            "Train Metric MAPs: 0.30810946482917795\n",
            "Validation Metric MRRs: 0.22586672636092028\n",
            "Validation Metric MAPs: 0.21223599487499265\n",
            "Epoch 37, Step 1, Loss: 0.022533530369400978\n",
            "Epoch 37, Step 2, Loss: 0.021307125687599182\n",
            "Epoch 37, Step 3, Loss: 0.017917761579155922\n",
            "Epoch 37, Step 4, Loss: 0.015548455528914928\n",
            "Epoch 37, Step 5, Loss: 0.010741670615971088\n",
            "Epoch 37, Step 6, Loss: 0.007860594429075718\n",
            "Epoch 37, Step 7, Loss: 0.005446615628898144\n",
            "Epoch 37, Step 8, Loss: 0.005391882266849279\n",
            "Epoch 37, Step 9, Loss: 0.005167842842638493\n",
            "Epoch 37, Step 10, Loss: 0.005370957311242819\n",
            "Epoch 37, Step 11, Loss: 0.005722826812416315\n",
            "Epoch 37, Step 12, Loss: 0.005434401333332062\n",
            "Epoch 37, Step 13, Loss: 0.004992435220628977\n",
            "Epoch 37, Step 14, Loss: 0.004212958738207817\n",
            "Epoch 37, Step 15, Loss: 0.00485161691904068\n",
            "Epoch 37, Step 16, Loss: 0.004631481599062681\n",
            "Epoch 37, Step 17, Loss: 0.006567366886883974\n",
            "Epoch 37, Step 18, Loss: 0.007270483765751123\n",
            "Epoch 37, Step 19, Loss: 0.008552883751690388\n",
            "Epoch 37, Step 20, Loss: 0.009048311971127987\n",
            "Epoch 37, Step 21, Loss: 0.009486978873610497\n",
            "Epoch 37, Step 22, Loss: 0.009689395315945148\n",
            "Epoch 37, Step 23, Loss: 0.010228595696389675\n",
            "Epoch 37, Step 24, Loss: 0.011069337837398052\n",
            "Epoch 37, Step 25, Loss: 0.011475061066448689\n",
            "Epoch 37, Step 26, Loss: 0.010072635486721992\n",
            "Epoch 37, Step 27, Loss: 0.00868057832121849\n",
            "Epoch 37, Step 28, Loss: 0.010148695670068264\n",
            "Epoch 37, Step 29, Loss: 0.010457302443683147\n",
            "Epoch 37, Step 30, Loss: 0.008073268458247185\n",
            "Epoch 37, Step 31, Loss: 0.010721043683588505\n",
            "Epoch 37, Step 32, Loss: 0.009153243154287338\n",
            "Epoch 37, Step 33, Loss: 0.009839767590165138\n",
            "Epoch 37, Step 34, Loss: 0.008746475912630558\n",
            "Epoch 37, Step 35, Loss: 0.009354681707918644\n",
            "Epoch 37, Step 36, Loss: 0.008080009371042252\n",
            "Epoch 37, Step 37, Loss: 0.00909106619656086\n",
            "Epoch 37, Step 38, Loss: 0.008581699803471565\n",
            "Epoch 37, Step 39, Loss: 0.008824574761092663\n",
            "Epoch 37, Step 40, Loss: 0.008841111324727535\n",
            "Epoch 37, Step 41, Loss: 0.0073301405645906925\n",
            "Epoch 37, Step 42, Loss: 0.007306896150112152\n",
            "Epoch 37, Step 43, Loss: 0.0067125773057341576\n",
            "Epoch 37, Step 44, Loss: 0.0072365920059382915\n",
            "Epoch 37, Step 45, Loss: 0.008147036656737328\n",
            "Epoch 37, Step 46, Loss: 0.007348719984292984\n",
            "Epoch 37, Step 47, Loss: 0.00744212232530117\n",
            "Epoch 37, Step 48, Loss: 0.00692023616284132\n",
            "Epoch 37, Step 49, Loss: 0.006827985402196646\n",
            "Epoch 37, Step 50, Loss: 0.0066034928895533085\n",
            "Epoch 37, Step 51, Loss: 0.006738136522471905\n",
            "Epoch 37, Step 52, Loss: 0.00624679122120142\n",
            "Epoch 37, Step 53, Loss: 0.00850987620651722\n",
            "Epoch 37, Step 54, Loss: 0.0058560618199408054\n",
            "Epoch 37, Step 55, Loss: 0.006533127278089523\n",
            "Epoch 37, Step 56, Loss: 0.006971264723688364\n",
            "Epoch 37, Step 57, Loss: 0.006014278624206781\n",
            "Epoch 37, Step 58, Loss: 0.006320995278656483\n",
            "Epoch 37, Step 59, Loss: 0.006051060277968645\n",
            "Epoch 37, Step 60, Loss: 0.006342596840113401\n",
            "Epoch 37, Step 61, Loss: 0.008416412398219109\n",
            "Epoch 37, Step 62, Loss: 0.005936567671597004\n",
            "Epoch 37, Step 63, Loss: 0.006932360120117664\n",
            "Epoch 37, Step 64, Loss: 0.006200938019901514\n",
            "Epoch 37, Step 65, Loss: 0.00686270697042346\n",
            "Epoch 37, Step 66, Loss: 0.007223146501928568\n",
            "Epoch 37, Step 67, Loss: 0.008331570774316788\n",
            "Epoch 37, Step 68, Loss: 0.007927353493869305\n",
            "Epoch 37, Step 69, Loss: 0.008227935992181301\n",
            "Epoch 37, Step 70, Loss: 0.009080596268177032\n",
            "Epoch 37, Step 71, Loss: 0.00933296512812376\n",
            "Epoch 37, Step 72, Loss: 0.007541182916611433\n",
            "Epoch 37, Step 73, Loss: 0.00737438490614295\n",
            "Epoch 37, Step 74, Loss: 0.007032733876258135\n",
            "Epoch 37, Step 75, Loss: 0.008524931967258453\n",
            "Epoch 37, Step 76, Loss: 0.007870553992688656\n",
            "Epoch 37, Step 77, Loss: 0.008426705375313759\n",
            "Epoch 37, Step 78, Loss: 0.006307679228484631\n",
            "Epoch 37, Step 79, Loss: 0.0066742077469825745\n",
            "Epoch 37, Step 80, Loss: 0.007574234623461962\n",
            "Epoch 37, Step 81, Loss: 0.009476111270487309\n",
            "Epoch 37, Step 82, Loss: 0.008811180479824543\n",
            "Epoch 37, Step 83, Loss: 0.007513544522225857\n",
            "Epoch 37, Step 84, Loss: 0.009353473782539368\n",
            "Epoch 37, Step 85, Loss: 0.009586209431290627\n",
            "Train Metric MRRs: 0.3022268946017973\n",
            "Train Metric MAPs: 0.31009325665435433\n",
            "Validation Metric MRRs: 0.22744220451999095\n",
            "Validation Metric MAPs: 0.2134991576596394\n",
            "Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "trainer.train(config['num_epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHIu_eBzX_eC",
        "outputId": "305dfd49-f54c-4d3f-c367-004736324cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metric MRRs: 0.22959189911119135\n",
            "Validation Metric MAPs: 0.2145212607284248\n",
            "Test Metric MRRs: 0.3352759294584985\n",
            "Test Metric MAPs: 0.3252200633497918\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3352759294584985, 0.3252200633497918)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainer.restore_best_checkpoint()\n",
        "trainer.validate('Validation')\n",
        "trainer.validate('Test')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}