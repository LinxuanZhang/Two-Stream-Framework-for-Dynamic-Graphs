{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFmnbM5n8fFk",
        "outputId": "df1b4305-b86d-4c30-cc3d-a735f262ddcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/mlds\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/mlds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9rULJX1_8jW4"
      },
      "outputs": [],
      "source": [
        "import data_UCI as uci\n",
        "import tasker_link_prediction as t_lp\n",
        "from splitter import splitter\n",
        "from models import TwoStream_GCN\n",
        "from trainer import Trainer\n",
        "import yaml\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvGXFPFi825w",
        "outputId": "a766312a-e681-45f9-d142-5e3c8d595891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_config': {'adam_beta_1': 0.9,\n",
              "  'adam_beta_2': 0.999,\n",
              "  'adam_epsilon': 1e-07,\n",
              "  'adam_learning_rate': 0.005},\n",
              " 'model_path': 'models/UCI_TwoStream/',\n",
              " 'classifier_hidden_size': 24,\n",
              " 'ffn_fusion_size': 12,\n",
              " 'ffn_hidden_size': 12,\n",
              " 'gcn_fusion_size': 24,\n",
              " 'spatial_hidden_size': 24,\n",
              " 'spatial_input_dim': 64,\n",
              " 'temporal_hidden_size': 24,\n",
              " 'temporal_input_dim': 60,\n",
              " 'num_epochs': 1000,\n",
              " 'patience': 10,\n",
              " 'major_threshold': None,\n",
              " 'train_proportion': 0.71,\n",
              " 'dev_proportion': 0.1,\n",
              " 'data_path': 'data/UCI/',\n",
              " 'prep_data_path': 'prep_data/UCI_neg/'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "prep = False\n",
        "\n",
        "with open('config/config_UCI.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "model_path = config['model_path']\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "    os.mkdir(model_path + \"best_checkpoints/\")\n",
        "    os.mkdir(model_path + \"latest_checkpoints/\")\n",
        "\n",
        "with open(model_path + 'config.yaml', 'w') as file:\n",
        "    yaml.dump(config, file)\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n2tmk8H89Sw",
        "outputId": "629e1a21-45f8-4f8d-b817-7e8c237e14c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits sizes:  train 53 dev 9 test 17\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "data = uci.UC_Irvine_Dataset(config['data_path'])\n",
        "tasker = t_lp.Link_Pred_Tasker(data, path=config['prep_data_path'], prep=prep,\n",
        "                               embs_dim=config['spatial_input_dim'], temp_dim=int(config['temporal_input_dim']/10),\n",
        "                               major_threshold=config['major_threshold'], smart_neg_sampling=True)\n",
        "\n",
        "splitter_as = splitter(tasker, train_proportion = config['train_proportion'], dev_proportion = config['dev_proportion'])\n",
        "\n",
        "model= TwoStream_GCN(spatial_input_dim=config['spatial_input_dim'],\n",
        "                 temporal_input_dim=config['temporal_input_dim'],\n",
        "                 spatial_hidden_size=config['spatial_hidden_size'],\n",
        "                 temporal_hidden_size=config['temporal_hidden_size'],\n",
        "                 classifier_hidden_size=config['classifier_hidden_size'],\n",
        "                 gcn_fusion_size=config['gcn_fusion_size'],\n",
        "                 ffn_fusion_size=config['ffn_fusion_size'],\n",
        "                 ffn_hiden_size=config['ffn_hidden_size'])\n",
        "\n",
        "trainer = Trainer(model=model, splitter=splitter_as, model_path=model_path, adam_config=config['adam_config'], patience=config['patience'])\n",
        "print(trainer.patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeDJaNaz9BxO",
        "outputId": "52d275f3-d276-4642-df18-825e970ca407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x78547357fbe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x78547357fbe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 1, Loss: 0.2282620072364807\n",
            "Epoch 1, Step 2, Loss: 0.12501214444637299\n",
            "Epoch 1, Step 3, Loss: 0.08930474519729614\n",
            "Epoch 1, Step 4, Loss: 0.07176508754491806\n",
            "Epoch 1, Step 5, Loss: 0.06538151949644089\n",
            "Epoch 1, Step 6, Loss: 0.05936218053102493\n",
            "Epoch 1, Step 7, Loss: 0.05360637232661247\n",
            "Epoch 1, Step 8, Loss: 0.04846390709280968\n",
            "Epoch 1, Step 9, Loss: 0.05504963919520378\n",
            "Epoch 1, Step 10, Loss: 0.03689223527908325\n",
            "Epoch 1, Step 11, Loss: 0.025829272344708443\n",
            "Epoch 1, Step 12, Loss: 0.025422798469662666\n",
            "Epoch 1, Step 13, Loss: 0.0266325194388628\n",
            "Epoch 1, Step 14, Loss: 0.021093660965561867\n",
            "Epoch 1, Step 15, Loss: 0.02905338630080223\n",
            "Epoch 1, Step 16, Loss: 0.04730558767914772\n",
            "Epoch 1, Step 17, Loss: 0.02537008933722973\n",
            "Epoch 1, Step 18, Loss: 0.0306964460760355\n",
            "Epoch 1, Step 19, Loss: 0.010875536128878593\n",
            "Epoch 1, Step 20, Loss: 0.01240849681198597\n",
            "Epoch 1, Step 21, Loss: 0.012613222934305668\n",
            "Epoch 1, Step 22, Loss: 0.012458082288503647\n",
            "Epoch 1, Step 23, Loss: 0.011827181093394756\n",
            "Epoch 1, Step 24, Loss: 0.03359167277812958\n",
            "Epoch 1, Step 25, Loss: 0.029278449714183807\n",
            "Epoch 1, Step 26, Loss: 0.03512677177786827\n",
            "Epoch 1, Step 27, Loss: 0.032461877912282944\n",
            "Epoch 1, Step 28, Loss: 0.04003271460533142\n",
            "Epoch 1, Step 29, Loss: 0.03340490534901619\n",
            "Epoch 1, Step 30, Loss: 0.027526939287781715\n",
            "Epoch 1, Step 31, Loss: 0.026143981143832207\n",
            "Epoch 1, Step 32, Loss: 0.022376487031579018\n",
            "Epoch 1, Step 33, Loss: 0.01696173846721649\n",
            "Epoch 1, Step 34, Loss: 0.027205821126699448\n",
            "Epoch 1, Step 35, Loss: 0.027137773111462593\n",
            "Epoch 1, Step 36, Loss: 0.023246392607688904\n",
            "Epoch 1, Step 37, Loss: 0.032276034355163574\n",
            "Epoch 1, Step 38, Loss: 0.028877658769488335\n",
            "Epoch 1, Step 39, Loss: 0.02900541014969349\n",
            "Epoch 1, Step 40, Loss: 0.027689218521118164\n",
            "Epoch 1, Step 41, Loss: 0.03249610215425491\n",
            "Epoch 1, Step 42, Loss: 0.02643071860074997\n",
            "Epoch 1, Step 43, Loss: 0.023979568853974342\n",
            "Epoch 1, Step 44, Loss: 0.03181425482034683\n",
            "Epoch 1, Step 45, Loss: 0.027199650183320045\n",
            "Epoch 1, Step 46, Loss: 0.026295803487300873\n",
            "Epoch 1, Step 47, Loss: 0.03291257470846176\n",
            "Epoch 1, Step 48, Loss: 0.034317806363105774\n",
            "Epoch 1, Step 49, Loss: 0.038453906774520874\n",
            "Epoch 1, Step 50, Loss: 0.03201745077967644\n",
            "Epoch 1, Step 51, Loss: 0.0366932712495327\n",
            "Epoch 1, Step 52, Loss: 0.03225157782435417\n",
            "Epoch 1, Step 53, Loss: 0.034138020128011703\n",
            "Train Metric MRRs: 0.008750629093525163\n",
            "Train Metric MAPs: 0.009484265851144865\n",
            "Validation Metric MRRs: 0.03861236342159157\n",
            "Validation Metric MAPs: 0.029083098106138874\n",
            "Epoch 2, Step 1, Loss: 0.02912226691842079\n",
            "Epoch 2, Step 2, Loss: 0.035364292562007904\n",
            "Epoch 2, Step 3, Loss: 0.02793646790087223\n",
            "Epoch 2, Step 4, Loss: 0.022930040955543518\n",
            "Epoch 2, Step 5, Loss: 0.02920534648001194\n",
            "Epoch 2, Step 6, Loss: 0.03217879310250282\n",
            "Epoch 2, Step 7, Loss: 0.031131234019994736\n",
            "Epoch 2, Step 8, Loss: 0.025829367339611053\n",
            "Epoch 2, Step 9, Loss: 0.04342477768659592\n",
            "Epoch 2, Step 10, Loss: 0.02084275335073471\n",
            "Epoch 2, Step 11, Loss: 0.017034435644745827\n",
            "Epoch 2, Step 12, Loss: 0.01777346059679985\n",
            "Epoch 2, Step 13, Loss: 0.02065012976527214\n",
            "Epoch 2, Step 14, Loss: 0.016528481617569923\n",
            "Epoch 2, Step 15, Loss: 0.01987922191619873\n",
            "Epoch 2, Step 16, Loss: 0.023560721427202225\n",
            "Epoch 2, Step 17, Loss: 0.014984508976340294\n",
            "Epoch 2, Step 18, Loss: 0.01679542101919651\n",
            "Epoch 2, Step 19, Loss: 0.00782555527985096\n",
            "Epoch 2, Step 20, Loss: 0.007355577778071165\n",
            "Epoch 2, Step 21, Loss: 0.006120741833001375\n",
            "Epoch 2, Step 22, Loss: 0.007353062275797129\n",
            "Epoch 2, Step 23, Loss: 0.007103272248059511\n",
            "Epoch 2, Step 24, Loss: 0.026595572009682655\n",
            "Epoch 2, Step 25, Loss: 0.018811695277690887\n",
            "Epoch 2, Step 26, Loss: 0.02133120410144329\n",
            "Epoch 2, Step 27, Loss: 0.0193580761551857\n",
            "Epoch 2, Step 28, Loss: 0.024979952722787857\n",
            "Epoch 2, Step 29, Loss: 0.0259862057864666\n",
            "Epoch 2, Step 30, Loss: 0.023037873208522797\n",
            "Epoch 2, Step 31, Loss: 0.022940026596188545\n",
            "Epoch 2, Step 32, Loss: 0.018360668793320656\n",
            "Epoch 2, Step 33, Loss: 0.012960702180862427\n",
            "Epoch 2, Step 34, Loss: 0.022023078054189682\n",
            "Epoch 2, Step 35, Loss: 0.020318463444709778\n",
            "Epoch 2, Step 36, Loss: 0.018492477014660835\n",
            "Epoch 2, Step 37, Loss: 0.027926206588745117\n",
            "Epoch 2, Step 38, Loss: 0.024400804191827774\n",
            "Epoch 2, Step 39, Loss: 0.025986487045884132\n",
            "Epoch 2, Step 40, Loss: 0.023159030824899673\n",
            "Epoch 2, Step 41, Loss: 0.0279555544257164\n",
            "Epoch 2, Step 42, Loss: 0.02338147722184658\n",
            "Epoch 2, Step 43, Loss: 0.021057594567537308\n",
            "Epoch 2, Step 44, Loss: 0.026157908141613007\n",
            "Epoch 2, Step 45, Loss: 0.02514972724020481\n",
            "Epoch 2, Step 46, Loss: 0.02490922436118126\n",
            "Epoch 2, Step 47, Loss: 0.02947436459362507\n",
            "Epoch 2, Step 48, Loss: 0.03412653133273125\n",
            "Epoch 2, Step 49, Loss: 0.03254454955458641\n",
            "Epoch 2, Step 50, Loss: 0.029678696766495705\n",
            "Epoch 2, Step 51, Loss: 0.032123077660799026\n",
            "Epoch 2, Step 52, Loss: 0.026884347200393677\n",
            "Epoch 2, Step 53, Loss: 0.029441485181450844\n",
            "Train Metric MRRs: 0.020834737654656595\n",
            "Train Metric MAPs: 0.02074459426368965\n",
            "Validation Metric MRRs: 0.05162511275632297\n",
            "Validation Metric MAPs: 0.03827675115621913\n",
            "Epoch 3, Step 1, Loss: 0.02652030624449253\n",
            "Epoch 3, Step 2, Loss: 0.03185970336198807\n",
            "Epoch 3, Step 3, Loss: 0.026852738112211227\n",
            "Epoch 3, Step 4, Loss: 0.022145520895719528\n",
            "Epoch 3, Step 5, Loss: 0.02707364223897457\n",
            "Epoch 3, Step 6, Loss: 0.029248781502246857\n",
            "Epoch 3, Step 7, Loss: 0.028926974162459373\n",
            "Epoch 3, Step 8, Loss: 0.02432861365377903\n",
            "Epoch 3, Step 9, Loss: 0.04200287163257599\n",
            "Epoch 3, Step 10, Loss: 0.019584830850362778\n",
            "Epoch 3, Step 11, Loss: 0.015709230676293373\n",
            "Epoch 3, Step 12, Loss: 0.016935894265770912\n",
            "Epoch 3, Step 13, Loss: 0.019670071080327034\n",
            "Epoch 3, Step 14, Loss: 0.015182058326900005\n",
            "Epoch 3, Step 15, Loss: 0.01902487315237522\n",
            "Epoch 3, Step 16, Loss: 0.022807935252785683\n",
            "Epoch 3, Step 17, Loss: 0.014698868617415428\n",
            "Epoch 3, Step 18, Loss: 0.016067175194621086\n",
            "Epoch 3, Step 19, Loss: 0.008072161115705967\n",
            "Epoch 3, Step 20, Loss: 0.007426730822771788\n",
            "Epoch 3, Step 21, Loss: 0.006528997328132391\n",
            "Epoch 3, Step 22, Loss: 0.007439760956913233\n",
            "Epoch 3, Step 23, Loss: 0.007444859016686678\n",
            "Epoch 3, Step 24, Loss: 0.023706698790192604\n",
            "Epoch 3, Step 25, Loss: 0.017554637044668198\n",
            "Epoch 3, Step 26, Loss: 0.018217187374830246\n",
            "Epoch 3, Step 27, Loss: 0.017931140959262848\n",
            "Epoch 3, Step 28, Loss: 0.02239415980875492\n",
            "Epoch 3, Step 29, Loss: 0.024395734071731567\n",
            "Epoch 3, Step 30, Loss: 0.023893889039754868\n",
            "Epoch 3, Step 31, Loss: 0.02146916091442108\n",
            "Epoch 3, Step 32, Loss: 0.016678161919116974\n",
            "Epoch 3, Step 33, Loss: 0.011914687231183052\n",
            "Epoch 3, Step 34, Loss: 0.02093302644789219\n",
            "Epoch 3, Step 35, Loss: 0.018524831160902977\n",
            "Epoch 3, Step 36, Loss: 0.01705946773290634\n",
            "Epoch 3, Step 37, Loss: 0.025943487882614136\n",
            "Epoch 3, Step 38, Loss: 0.023633472621440887\n",
            "Epoch 3, Step 39, Loss: 0.025069262832403183\n",
            "Epoch 3, Step 40, Loss: 0.02170271798968315\n",
            "Epoch 3, Step 41, Loss: 0.02671661227941513\n",
            "Epoch 3, Step 42, Loss: 0.021134503185749054\n",
            "Epoch 3, Step 43, Loss: 0.020776044577360153\n",
            "Epoch 3, Step 44, Loss: 0.02406012825667858\n",
            "Epoch 3, Step 45, Loss: 0.021927010267972946\n",
            "Epoch 3, Step 46, Loss: 0.022700946778059006\n",
            "Epoch 3, Step 47, Loss: 0.02635522373020649\n",
            "Epoch 3, Step 48, Loss: 0.02847113646566868\n",
            "Epoch 3, Step 49, Loss: 0.030091457068920135\n",
            "Epoch 3, Step 50, Loss: 0.0272661242634058\n",
            "Epoch 3, Step 51, Loss: 0.0275642778724432\n",
            "Epoch 3, Step 52, Loss: 0.023368392139673233\n",
            "Epoch 3, Step 53, Loss: 0.025182483717799187\n",
            "Train Metric MRRs: 0.03587862054483612\n",
            "Train Metric MAPs: 0.040179040967270624\n",
            "Validation Metric MRRs: 0.07091529309859228\n",
            "Validation Metric MAPs: 0.14512610058566205\n",
            "Epoch 4, Step 1, Loss: 0.024648023769259453\n",
            "Epoch 4, Step 2, Loss: 0.03064551018178463\n",
            "Epoch 4, Step 3, Loss: 0.026410182937979698\n",
            "Epoch 4, Step 4, Loss: 0.02081291750073433\n",
            "Epoch 4, Step 5, Loss: 0.02614998258650303\n",
            "Epoch 4, Step 6, Loss: 0.02805926278233528\n",
            "Epoch 4, Step 7, Loss: 0.02781680040061474\n",
            "Epoch 4, Step 8, Loss: 0.023815911263227463\n",
            "Epoch 4, Step 9, Loss: 0.03827344998717308\n",
            "Epoch 4, Step 10, Loss: 0.01969175972044468\n",
            "Epoch 4, Step 11, Loss: 0.015428461134433746\n",
            "Epoch 4, Step 12, Loss: 0.016435356810688972\n",
            "Epoch 4, Step 13, Loss: 0.01916739158332348\n",
            "Epoch 4, Step 14, Loss: 0.014066064730286598\n",
            "Epoch 4, Step 15, Loss: 0.018155844882130623\n",
            "Epoch 4, Step 16, Loss: 0.022146986797451973\n",
            "Epoch 4, Step 17, Loss: 0.014283237978816032\n",
            "Epoch 4, Step 18, Loss: 0.015208245255053043\n",
            "Epoch 4, Step 19, Loss: 0.007486128713935614\n",
            "Epoch 4, Step 20, Loss: 0.007281783502548933\n",
            "Epoch 4, Step 21, Loss: 0.00633513368666172\n",
            "Epoch 4, Step 22, Loss: 0.007362447213381529\n",
            "Epoch 4, Step 23, Loss: 0.007503274362534285\n",
            "Epoch 4, Step 24, Loss: 0.023188414052128792\n",
            "Epoch 4, Step 25, Loss: 0.016804685816168785\n",
            "Epoch 4, Step 26, Loss: 0.016622664406895638\n",
            "Epoch 4, Step 27, Loss: 0.015667539089918137\n",
            "Epoch 4, Step 28, Loss: 0.019818108528852463\n",
            "Epoch 4, Step 29, Loss: 0.022363776341080666\n",
            "Epoch 4, Step 30, Loss: 0.022543366998434067\n",
            "Epoch 4, Step 31, Loss: 0.020037546753883362\n",
            "Epoch 4, Step 32, Loss: 0.01609422266483307\n",
            "Epoch 4, Step 33, Loss: 0.0111735500395298\n",
            "Epoch 4, Step 34, Loss: 0.01923474483191967\n",
            "Epoch 4, Step 35, Loss: 0.017212212085723877\n",
            "Epoch 4, Step 36, Loss: 0.01595023274421692\n",
            "Epoch 4, Step 37, Loss: 0.024460038170218468\n",
            "Epoch 4, Step 38, Loss: 0.022973619401454926\n",
            "Epoch 4, Step 39, Loss: 0.02471546083688736\n",
            "Epoch 4, Step 40, Loss: 0.02113431505858898\n",
            "Epoch 4, Step 41, Loss: 0.02427254617214203\n",
            "Epoch 4, Step 42, Loss: 0.01984548568725586\n",
            "Epoch 4, Step 43, Loss: 0.019546877592802048\n",
            "Epoch 4, Step 44, Loss: 0.02271031029522419\n",
            "Epoch 4, Step 45, Loss: 0.02049766480922699\n",
            "Epoch 4, Step 46, Loss: 0.021466167643666267\n",
            "Epoch 4, Step 47, Loss: 0.024541106075048447\n",
            "Epoch 4, Step 48, Loss: 0.026534676551818848\n",
            "Epoch 4, Step 49, Loss: 0.027118507772684097\n",
            "Epoch 4, Step 50, Loss: 0.025050748139619827\n",
            "Epoch 4, Step 51, Loss: 0.02484709955751896\n",
            "Epoch 4, Step 52, Loss: 0.021299151703715324\n",
            "Epoch 4, Step 53, Loss: 0.023883916437625885\n",
            "Train Metric MRRs: 0.04689353394050153\n",
            "Train Metric MAPs: 0.06269987941015918\n",
            "Validation Metric MRRs: 0.08087963925796823\n",
            "Validation Metric MAPs: 0.16428915593304808\n",
            "Epoch 5, Step 1, Loss: 0.023910988122224808\n",
            "Epoch 5, Step 2, Loss: 0.029902426525950432\n",
            "Epoch 5, Step 3, Loss: 0.025981325656175613\n",
            "Epoch 5, Step 4, Loss: 0.020131835713982582\n",
            "Epoch 5, Step 5, Loss: 0.02565457671880722\n",
            "Epoch 5, Step 6, Loss: 0.02778795175254345\n",
            "Epoch 5, Step 7, Loss: 0.02735673449933529\n",
            "Epoch 5, Step 8, Loss: 0.023263532668352127\n",
            "Epoch 5, Step 9, Loss: 0.03715241700410843\n",
            "Epoch 5, Step 10, Loss: 0.01974780485033989\n",
            "Epoch 5, Step 11, Loss: 0.01506447046995163\n",
            "Epoch 5, Step 12, Loss: 0.015958217903971672\n",
            "Epoch 5, Step 13, Loss: 0.018977299332618713\n",
            "Epoch 5, Step 14, Loss: 0.013694756664335728\n",
            "Epoch 5, Step 15, Loss: 0.01760130375623703\n",
            "Epoch 5, Step 16, Loss: 0.021634656935930252\n",
            "Epoch 5, Step 17, Loss: 0.01399496290832758\n",
            "Epoch 5, Step 18, Loss: 0.015011328272521496\n",
            "Epoch 5, Step 19, Loss: 0.007029595784842968\n",
            "Epoch 5, Step 20, Loss: 0.007277813274413347\n",
            "Epoch 5, Step 21, Loss: 0.006077562924474478\n",
            "Epoch 5, Step 22, Loss: 0.007518375758081675\n",
            "Epoch 5, Step 23, Loss: 0.007170679979026318\n",
            "Epoch 5, Step 24, Loss: 0.022697512060403824\n",
            "Epoch 5, Step 25, Loss: 0.016337228938937187\n",
            "Epoch 5, Step 26, Loss: 0.01573890633881092\n",
            "Epoch 5, Step 27, Loss: 0.014670469798147678\n",
            "Epoch 5, Step 28, Loss: 0.019056493416428566\n",
            "Epoch 5, Step 29, Loss: 0.02155429683625698\n",
            "Epoch 5, Step 30, Loss: 0.020963549613952637\n",
            "Epoch 5, Step 31, Loss: 0.01913394406437874\n",
            "Epoch 5, Step 32, Loss: 0.01466845441609621\n",
            "Epoch 5, Step 33, Loss: 0.010901902802288532\n",
            "Epoch 5, Step 34, Loss: 0.01775553449988365\n",
            "Epoch 5, Step 35, Loss: 0.016821829602122307\n",
            "Epoch 5, Step 36, Loss: 0.014945964328944683\n",
            "Epoch 5, Step 37, Loss: 0.023429445922374725\n",
            "Epoch 5, Step 38, Loss: 0.022672142833471298\n",
            "Epoch 5, Step 39, Loss: 0.022863781079649925\n",
            "Epoch 5, Step 40, Loss: 0.021220359951257706\n",
            "Epoch 5, Step 41, Loss: 0.02525591291487217\n",
            "Epoch 5, Step 42, Loss: 0.01977030746638775\n",
            "Epoch 5, Step 43, Loss: 0.019873986020684242\n",
            "Epoch 5, Step 44, Loss: 0.021923650056123734\n",
            "Epoch 5, Step 45, Loss: 0.01875372789800167\n",
            "Epoch 5, Step 46, Loss: 0.02158381976187229\n",
            "Epoch 5, Step 47, Loss: 0.025822751224040985\n",
            "Epoch 5, Step 48, Loss: 0.026725543662905693\n",
            "Epoch 5, Step 49, Loss: 0.032292094081640244\n",
            "Epoch 5, Step 50, Loss: 0.025530921295285225\n",
            "Epoch 5, Step 51, Loss: 0.025438863784074783\n",
            "Epoch 5, Step 52, Loss: 0.02165193483233452\n",
            "Epoch 5, Step 53, Loss: 0.023928320035338402\n",
            "Train Metric MRRs: 0.053231600266240145\n",
            "Train Metric MAPs: 0.06996944158721793\n",
            "Validation Metric MRRs: 0.08217848247791536\n",
            "Validation Metric MAPs: 0.1811076268061047\n",
            "Epoch 6, Step 1, Loss: 0.02448539063334465\n",
            "Epoch 6, Step 2, Loss: 0.030424894765019417\n",
            "Epoch 6, Step 3, Loss: 0.025961266830563545\n",
            "Epoch 6, Step 4, Loss: 0.02075059525668621\n",
            "Epoch 6, Step 5, Loss: 0.025263389572501183\n",
            "Epoch 6, Step 6, Loss: 0.02747333236038685\n",
            "Epoch 6, Step 7, Loss: 0.02739480510354042\n",
            "Epoch 6, Step 8, Loss: 0.02332307957112789\n",
            "Epoch 6, Step 9, Loss: 0.03736808896064758\n",
            "Epoch 6, Step 10, Loss: 0.019173068925738335\n",
            "Epoch 6, Step 11, Loss: 0.014662312343716621\n",
            "Epoch 6, Step 12, Loss: 0.01594620943069458\n",
            "Epoch 6, Step 13, Loss: 0.018999967724084854\n",
            "Epoch 6, Step 14, Loss: 0.0139039671048522\n",
            "Epoch 6, Step 15, Loss: 0.017477553337812424\n",
            "Epoch 6, Step 16, Loss: 0.022047149017453194\n",
            "Epoch 6, Step 17, Loss: 0.014027604833245277\n",
            "Epoch 6, Step 18, Loss: 0.014366241171956062\n",
            "Epoch 6, Step 19, Loss: 0.008188295178115368\n",
            "Epoch 6, Step 20, Loss: 0.006993436720222235\n",
            "Epoch 6, Step 21, Loss: 0.006055982317775488\n",
            "Epoch 6, Step 22, Loss: 0.007359434850513935\n",
            "Epoch 6, Step 23, Loss: 0.0074727898463606834\n",
            "Epoch 6, Step 24, Loss: 0.02340170368552208\n",
            "Epoch 6, Step 25, Loss: 0.016611604019999504\n",
            "Epoch 6, Step 26, Loss: 0.015466858632862568\n",
            "Epoch 6, Step 27, Loss: 0.015204356051981449\n",
            "Epoch 6, Step 28, Loss: 0.019685428589582443\n",
            "Epoch 6, Step 29, Loss: 0.021404536440968513\n",
            "Epoch 6, Step 30, Loss: 0.02098517306149006\n",
            "Epoch 6, Step 31, Loss: 0.019519707188010216\n",
            "Epoch 6, Step 32, Loss: 0.014653720892965794\n",
            "Epoch 6, Step 33, Loss: 0.011090833693742752\n",
            "Epoch 6, Step 34, Loss: 0.018099335953593254\n",
            "Epoch 6, Step 35, Loss: 0.01640133373439312\n",
            "Epoch 6, Step 36, Loss: 0.015517231076955795\n",
            "Epoch 6, Step 37, Loss: 0.023098060861229897\n",
            "Epoch 6, Step 38, Loss: 0.021274933591485023\n",
            "Epoch 6, Step 39, Loss: 0.022959867492318153\n",
            "Epoch 6, Step 40, Loss: 0.020345617085695267\n",
            "Epoch 6, Step 41, Loss: 0.024450046941637993\n",
            "Epoch 6, Step 42, Loss: 0.01843089982867241\n",
            "Epoch 6, Step 43, Loss: 0.02048707753419876\n",
            "Epoch 6, Step 44, Loss: 0.02245447039604187\n",
            "Epoch 6, Step 45, Loss: 0.019387822598218918\n",
            "Epoch 6, Step 46, Loss: 0.022608445957303047\n",
            "Epoch 6, Step 47, Loss: 0.02321799099445343\n",
            "Epoch 6, Step 48, Loss: 0.025401772931218147\n",
            "Epoch 6, Step 49, Loss: 0.02656867355108261\n",
            "Epoch 6, Step 50, Loss: 0.02867392636835575\n",
            "Epoch 6, Step 51, Loss: 0.03113766573369503\n",
            "Epoch 6, Step 52, Loss: 0.02557878941297531\n",
            "Epoch 6, Step 53, Loss: 0.025301992893218994\n",
            "Train Metric MRRs: 0.056093407552912276\n",
            "Train Metric MAPs: 0.07318979731484583\n",
            "Validation Metric MRRs: 0.09183386281690656\n",
            "Validation Metric MAPs: 0.14979846466588545\n",
            "Epoch 7, Step 1, Loss: 0.025171568617224693\n",
            "Epoch 7, Step 2, Loss: 0.030919790267944336\n",
            "Epoch 7, Step 3, Loss: 0.02581583894789219\n",
            "Epoch 7, Step 4, Loss: 0.021056529134511948\n",
            "Epoch 7, Step 5, Loss: 0.02645525150001049\n",
            "Epoch 7, Step 6, Loss: 0.02936459705233574\n",
            "Epoch 7, Step 7, Loss: 0.029061108827590942\n",
            "Epoch 7, Step 8, Loss: 0.02565654180943966\n",
            "Epoch 7, Step 9, Loss: 0.0358564667403698\n",
            "Epoch 7, Step 10, Loss: 0.020863743498921394\n",
            "Epoch 7, Step 11, Loss: 0.015558095648884773\n",
            "Epoch 7, Step 12, Loss: 0.016036182641983032\n",
            "Epoch 7, Step 13, Loss: 0.018475044518709183\n",
            "Epoch 7, Step 14, Loss: 0.013450942002236843\n",
            "Epoch 7, Step 15, Loss: 0.017496194690465927\n",
            "Epoch 7, Step 16, Loss: 0.021334916353225708\n",
            "Epoch 7, Step 17, Loss: 0.014010246843099594\n",
            "Epoch 7, Step 18, Loss: 0.014067383483052254\n",
            "Epoch 7, Step 19, Loss: 0.006884165108203888\n",
            "Epoch 7, Step 20, Loss: 0.0065372600220143795\n",
            "Epoch 7, Step 21, Loss: 0.005508134141564369\n",
            "Epoch 7, Step 22, Loss: 0.0074534183368086815\n",
            "Epoch 7, Step 23, Loss: 0.007835065014660358\n",
            "Epoch 7, Step 24, Loss: 0.023807747289538383\n",
            "Epoch 7, Step 25, Loss: 0.01630411297082901\n",
            "Epoch 7, Step 26, Loss: 0.01599002629518509\n",
            "Epoch 7, Step 27, Loss: 0.014823651872575283\n",
            "Epoch 7, Step 28, Loss: 0.019664160907268524\n",
            "Epoch 7, Step 29, Loss: 0.021303284913301468\n",
            "Epoch 7, Step 30, Loss: 0.021181151270866394\n",
            "Epoch 7, Step 31, Loss: 0.01896037720143795\n",
            "Epoch 7, Step 32, Loss: 0.014694533310830593\n",
            "Epoch 7, Step 33, Loss: 0.011500216089189053\n",
            "Epoch 7, Step 34, Loss: 0.018890809267759323\n",
            "Epoch 7, Step 35, Loss: 0.016339845955371857\n",
            "Epoch 7, Step 36, Loss: 0.015627453103661537\n",
            "Epoch 7, Step 37, Loss: 0.022576652467250824\n",
            "Epoch 7, Step 38, Loss: 0.021025752648711205\n",
            "Epoch 7, Step 39, Loss: 0.022759228944778442\n",
            "Epoch 7, Step 40, Loss: 0.02131071127951145\n",
            "Epoch 7, Step 41, Loss: 0.02515519969165325\n",
            "Epoch 7, Step 42, Loss: 0.01975160837173462\n",
            "Epoch 7, Step 43, Loss: 0.02154410257935524\n",
            "Epoch 7, Step 44, Loss: 0.02178942784667015\n",
            "Epoch 7, Step 45, Loss: 0.018494868651032448\n",
            "Epoch 7, Step 46, Loss: 0.02046661265194416\n",
            "Epoch 7, Step 47, Loss: 0.023457923904061317\n",
            "Epoch 7, Step 48, Loss: 0.02594621293246746\n",
            "Epoch 7, Step 49, Loss: 0.027014857158064842\n",
            "Epoch 7, Step 50, Loss: 0.02750304527580738\n",
            "Epoch 7, Step 51, Loss: 0.025519760325551033\n",
            "Epoch 7, Step 52, Loss: 0.020966805517673492\n",
            "Epoch 7, Step 53, Loss: 0.024734975770115852\n",
            "Train Metric MRRs: 0.05501318770030991\n",
            "Train Metric MAPs: 0.0667300206091029\n",
            "Validation Metric MRRs: 0.09459482554142114\n",
            "Validation Metric MAPs: 0.16368539424259562\n",
            "Epoch 8, Step 1, Loss: 0.03139637038111687\n",
            "Epoch 8, Step 2, Loss: 0.03862351179122925\n",
            "Epoch 8, Step 3, Loss: 0.030926169827580452\n",
            "Epoch 8, Step 4, Loss: 0.02144000679254532\n",
            "Epoch 8, Step 5, Loss: 0.025957860052585602\n",
            "Epoch 8, Step 6, Loss: 0.027918903157114983\n",
            "Epoch 8, Step 7, Loss: 0.028000483289361\n",
            "Epoch 8, Step 8, Loss: 0.025644145905971527\n",
            "Epoch 8, Step 9, Loss: 0.03660041093826294\n",
            "Epoch 8, Step 10, Loss: 0.023969033733010292\n",
            "Epoch 8, Step 11, Loss: 0.02013474889099598\n",
            "Epoch 8, Step 12, Loss: 0.019856272265315056\n",
            "Epoch 8, Step 13, Loss: 0.02086072601377964\n",
            "Epoch 8, Step 14, Loss: 0.01685502380132675\n",
            "Epoch 8, Step 15, Loss: 0.018250426277518272\n",
            "Epoch 8, Step 16, Loss: 0.021751733496785164\n",
            "Epoch 8, Step 17, Loss: 0.013780488632619381\n",
            "Epoch 8, Step 18, Loss: 0.013760739006102085\n",
            "Epoch 8, Step 19, Loss: 0.006507745943963528\n",
            "Epoch 8, Step 20, Loss: 0.006653592921793461\n",
            "Epoch 8, Step 21, Loss: 0.005548648536205292\n",
            "Epoch 8, Step 22, Loss: 0.007097503170371056\n",
            "Epoch 8, Step 23, Loss: 0.007422857917845249\n",
            "Epoch 8, Step 24, Loss: 0.02470983751118183\n",
            "Epoch 8, Step 25, Loss: 0.016833214089274406\n",
            "Epoch 8, Step 26, Loss: 0.016326256096363068\n",
            "Epoch 8, Step 27, Loss: 0.015080819837749004\n",
            "Epoch 8, Step 28, Loss: 0.019529253244400024\n",
            "Epoch 8, Step 29, Loss: 0.021588042378425598\n",
            "Epoch 8, Step 30, Loss: 0.021256359294056892\n",
            "Epoch 8, Step 31, Loss: 0.01998068392276764\n",
            "Epoch 8, Step 32, Loss: 0.013816677033901215\n",
            "Epoch 8, Step 33, Loss: 0.010260200127959251\n",
            "Epoch 8, Step 34, Loss: 0.017569050192832947\n",
            "Epoch 8, Step 35, Loss: 0.015922248363494873\n",
            "Epoch 8, Step 36, Loss: 0.014359932392835617\n",
            "Epoch 8, Step 37, Loss: 0.022169191390275955\n",
            "Epoch 8, Step 38, Loss: 0.021019602194428444\n",
            "Epoch 8, Step 39, Loss: 0.021905407309532166\n",
            "Epoch 8, Step 40, Loss: 0.0200364850461483\n",
            "Epoch 8, Step 41, Loss: 0.024007409811019897\n",
            "Epoch 8, Step 42, Loss: 0.018068671226501465\n",
            "Epoch 8, Step 43, Loss: 0.019113419577479362\n",
            "Epoch 8, Step 44, Loss: 0.021318631246685982\n",
            "Epoch 8, Step 45, Loss: 0.019682615995407104\n",
            "Epoch 8, Step 46, Loss: 0.020677590742707253\n",
            "Epoch 8, Step 47, Loss: 0.02406175062060356\n",
            "Epoch 8, Step 48, Loss: 0.02530536986887455\n",
            "Epoch 8, Step 49, Loss: 0.026168067008256912\n",
            "Epoch 8, Step 50, Loss: 0.024401774629950523\n",
            "Epoch 8, Step 51, Loss: 0.022754402831196785\n",
            "Epoch 8, Step 52, Loss: 0.01766047067940235\n",
            "Epoch 8, Step 53, Loss: 0.025401746854186058\n",
            "Train Metric MRRs: 0.06126040828488203\n",
            "Train Metric MAPs: 0.07336689870847783\n",
            "Validation Metric MRRs: 0.10012641002707039\n",
            "Validation Metric MAPs: 0.17454336342266438\n",
            "Epoch 9, Step 1, Loss: 0.029186151921749115\n",
            "Epoch 9, Step 2, Loss: 0.0395672507584095\n",
            "Epoch 9, Step 3, Loss: 0.032383907586336136\n",
            "Epoch 9, Step 4, Loss: 0.023993924260139465\n",
            "Epoch 9, Step 5, Loss: 0.02890683524310589\n",
            "Epoch 9, Step 6, Loss: 0.029392056167125702\n",
            "Epoch 9, Step 7, Loss: 0.027941234409809113\n",
            "Epoch 9, Step 8, Loss: 0.02424701489508152\n",
            "Epoch 9, Step 9, Loss: 0.03600693121552467\n",
            "Epoch 9, Step 10, Loss: 0.021749580278992653\n",
            "Epoch 9, Step 11, Loss: 0.01860337145626545\n",
            "Epoch 9, Step 12, Loss: 0.020259695127606392\n",
            "Epoch 9, Step 13, Loss: 0.022276820614933968\n",
            "Epoch 9, Step 14, Loss: 0.01899326965212822\n",
            "Epoch 9, Step 15, Loss: 0.021098552271723747\n",
            "Epoch 9, Step 16, Loss: 0.023566007614135742\n",
            "Epoch 9, Step 17, Loss: 0.016368640586733818\n",
            "Epoch 9, Step 18, Loss: 0.015338766388595104\n",
            "Epoch 9, Step 19, Loss: 0.008277351967990398\n",
            "Epoch 9, Step 20, Loss: 0.007630333304405212\n",
            "Epoch 9, Step 21, Loss: 0.006171657238155603\n",
            "Epoch 9, Step 22, Loss: 0.007175399921834469\n",
            "Epoch 9, Step 23, Loss: 0.007067038211971521\n",
            "Epoch 9, Step 24, Loss: 0.021821796894073486\n",
            "Epoch 9, Step 25, Loss: 0.016468096524477005\n",
            "Epoch 9, Step 26, Loss: 0.015643075108528137\n",
            "Epoch 9, Step 27, Loss: 0.01504475250840187\n",
            "Epoch 9, Step 28, Loss: 0.019023632630705833\n",
            "Epoch 9, Step 29, Loss: 0.020989948883652687\n",
            "Epoch 9, Step 30, Loss: 0.020133070647716522\n",
            "Epoch 9, Step 31, Loss: 0.02006201259791851\n",
            "Epoch 9, Step 32, Loss: 0.013392255641520023\n",
            "Epoch 9, Step 33, Loss: 0.010122179053723812\n",
            "Epoch 9, Step 34, Loss: 0.016703039407730103\n",
            "Epoch 9, Step 35, Loss: 0.015917042270302773\n",
            "Epoch 9, Step 36, Loss: 0.01384009700268507\n",
            "Epoch 9, Step 37, Loss: 0.022527620196342468\n",
            "Epoch 9, Step 38, Loss: 0.021195869892835617\n",
            "Epoch 9, Step 39, Loss: 0.02195962704718113\n",
            "Epoch 9, Step 40, Loss: 0.0192808136343956\n",
            "Epoch 9, Step 41, Loss: 0.024713192135095596\n",
            "Epoch 9, Step 42, Loss: 0.01935001090168953\n",
            "Epoch 9, Step 43, Loss: 0.018976354971528053\n",
            "Epoch 9, Step 44, Loss: 0.020072007551789284\n",
            "Epoch 9, Step 45, Loss: 0.01615739054977894\n",
            "Epoch 9, Step 46, Loss: 0.01927184872329235\n",
            "Epoch 9, Step 47, Loss: 0.02171177603304386\n",
            "Epoch 9, Step 48, Loss: 0.023113280534744263\n",
            "Epoch 9, Step 49, Loss: 0.024464990943670273\n",
            "Epoch 9, Step 50, Loss: 0.0231105238199234\n",
            "Epoch 9, Step 51, Loss: 0.021427078172564507\n",
            "Epoch 9, Step 52, Loss: 0.01693195290863514\n",
            "Epoch 9, Step 53, Loss: 0.01952367089688778\n",
            "Train Metric MRRs: 0.05931050008249725\n",
            "Train Metric MAPs: 0.07742685770778857\n",
            "Validation Metric MRRs: 0.10359096643476234\n",
            "Validation Metric MAPs: 0.19579432810089079\n",
            "Epoch 10, Step 1, Loss: 0.023731734603643417\n",
            "Epoch 10, Step 2, Loss: 0.03234415501356125\n",
            "Epoch 10, Step 3, Loss: 0.027730615809559822\n",
            "Epoch 10, Step 4, Loss: 0.021871058270335197\n",
            "Epoch 10, Step 5, Loss: 0.02816307172179222\n",
            "Epoch 10, Step 6, Loss: 0.028329597786068916\n",
            "Epoch 10, Step 7, Loss: 0.02840849570930004\n",
            "Epoch 10, Step 8, Loss: 0.023279370740056038\n",
            "Epoch 10, Step 9, Loss: 0.0359213761985302\n",
            "Epoch 10, Step 10, Loss: 0.020431840792298317\n",
            "Epoch 10, Step 11, Loss: 0.0168889332562685\n",
            "Epoch 10, Step 12, Loss: 0.01768253557384014\n",
            "Epoch 10, Step 13, Loss: 0.020131539553403854\n",
            "Epoch 10, Step 14, Loss: 0.015416151843965054\n",
            "Epoch 10, Step 15, Loss: 0.018066950142383575\n",
            "Epoch 10, Step 16, Loss: 0.021256770938634872\n",
            "Epoch 10, Step 17, Loss: 0.014829947613179684\n",
            "Epoch 10, Step 18, Loss: 0.014338389970362186\n",
            "Epoch 10, Step 19, Loss: 0.00764612527564168\n",
            "Epoch 10, Step 20, Loss: 0.007697367575019598\n",
            "Epoch 10, Step 21, Loss: 0.007437869440764189\n",
            "Epoch 10, Step 22, Loss: 0.007674579508602619\n",
            "Epoch 10, Step 23, Loss: 0.00734389154240489\n",
            "Epoch 10, Step 24, Loss: 0.02016918919980526\n",
            "Epoch 10, Step 25, Loss: 0.01599976234138012\n",
            "Epoch 10, Step 26, Loss: 0.014604698866605759\n",
            "Epoch 10, Step 27, Loss: 0.014204833656549454\n",
            "Epoch 10, Step 28, Loss: 0.01885220780968666\n",
            "Epoch 10, Step 29, Loss: 0.01984982006251812\n",
            "Epoch 10, Step 30, Loss: 0.01946133002638817\n",
            "Epoch 10, Step 31, Loss: 0.018380828201770782\n",
            "Epoch 10, Step 32, Loss: 0.012986386194825172\n",
            "Epoch 10, Step 33, Loss: 0.009486055932939053\n",
            "Epoch 10, Step 34, Loss: 0.01676155813038349\n",
            "Epoch 10, Step 35, Loss: 0.016701076179742813\n",
            "Epoch 10, Step 36, Loss: 0.013047249056398869\n",
            "Epoch 10, Step 37, Loss: 0.02210746519267559\n",
            "Epoch 10, Step 38, Loss: 0.020774373784661293\n",
            "Epoch 10, Step 39, Loss: 0.022714024409651756\n",
            "Epoch 10, Step 40, Loss: 0.019276199862360954\n",
            "Epoch 10, Step 41, Loss: 0.026756344363093376\n",
            "Epoch 10, Step 42, Loss: 0.018274381756782532\n",
            "Epoch 10, Step 43, Loss: 0.02407681569457054\n",
            "Epoch 10, Step 44, Loss: 0.022533133625984192\n",
            "Epoch 10, Step 45, Loss: 0.017618244513869286\n",
            "Epoch 10, Step 46, Loss: 0.01871427521109581\n",
            "Epoch 10, Step 47, Loss: 0.02178102731704712\n",
            "Epoch 10, Step 48, Loss: 0.024037551134824753\n",
            "Epoch 10, Step 49, Loss: 0.02344261109828949\n",
            "Epoch 10, Step 50, Loss: 0.023908579722046852\n",
            "Epoch 10, Step 51, Loss: 0.02540835365653038\n",
            "Epoch 10, Step 52, Loss: 0.018511498346924782\n",
            "Epoch 10, Step 53, Loss: 0.018493521958589554\n",
            "Train Metric MRRs: 0.06398633528827041\n",
            "Train Metric MAPs: 0.09572557031369361\n",
            "Validation Metric MRRs: 0.09692317182407234\n",
            "Validation Metric MAPs: 0.15342840183474368\n",
            "Epoch 11, Step 1, Loss: 0.023061025887727737\n",
            "Epoch 11, Step 2, Loss: 0.0295609962195158\n",
            "Epoch 11, Step 3, Loss: 0.02510671131312847\n",
            "Epoch 11, Step 4, Loss: 0.01934824325144291\n",
            "Epoch 11, Step 5, Loss: 0.024892650544643402\n",
            "Epoch 11, Step 6, Loss: 0.026439780369400978\n",
            "Epoch 11, Step 7, Loss: 0.026459649205207825\n",
            "Epoch 11, Step 8, Loss: 0.022344663739204407\n",
            "Epoch 11, Step 9, Loss: 0.03508956357836723\n",
            "Epoch 11, Step 10, Loss: 0.019234389066696167\n",
            "Epoch 11, Step 11, Loss: 0.014971118420362473\n",
            "Epoch 11, Step 12, Loss: 0.015747904777526855\n",
            "Epoch 11, Step 13, Loss: 0.018853269517421722\n",
            "Epoch 11, Step 14, Loss: 0.014901423826813698\n",
            "Epoch 11, Step 15, Loss: 0.017889726907014847\n",
            "Epoch 11, Step 16, Loss: 0.0213514044880867\n",
            "Epoch 11, Step 17, Loss: 0.015040017664432526\n",
            "Epoch 11, Step 18, Loss: 0.014666199684143066\n",
            "Epoch 11, Step 19, Loss: 0.008054179139435291\n",
            "Epoch 11, Step 20, Loss: 0.00751436548307538\n",
            "Epoch 11, Step 21, Loss: 0.00677907932549715\n",
            "Epoch 11, Step 22, Loss: 0.00799125712364912\n",
            "Epoch 11, Step 23, Loss: 0.007720484398305416\n",
            "Epoch 11, Step 24, Loss: 0.019948812201619148\n",
            "Epoch 11, Step 25, Loss: 0.01578659936785698\n",
            "Epoch 11, Step 26, Loss: 0.014668685384094715\n",
            "Epoch 11, Step 27, Loss: 0.013720743358135223\n",
            "Epoch 11, Step 28, Loss: 0.018166298046708107\n",
            "Epoch 11, Step 29, Loss: 0.01945086382329464\n",
            "Epoch 11, Step 30, Loss: 0.01865699142217636\n",
            "Epoch 11, Step 31, Loss: 0.0184632521122694\n",
            "Epoch 11, Step 32, Loss: 0.013349668122828007\n",
            "Epoch 11, Step 33, Loss: 0.010041626170277596\n",
            "Epoch 11, Step 34, Loss: 0.017045119777321815\n",
            "Epoch 11, Step 35, Loss: 0.016651246696710587\n",
            "Epoch 11, Step 36, Loss: 0.01303131878376007\n",
            "Epoch 11, Step 37, Loss: 0.021482713520526886\n",
            "Epoch 11, Step 38, Loss: 0.02037723921239376\n",
            "Epoch 11, Step 39, Loss: 0.020158734172582626\n",
            "Epoch 11, Step 40, Loss: 0.018359003588557243\n",
            "Epoch 11, Step 41, Loss: 0.02481728233397007\n",
            "Epoch 11, Step 42, Loss: 0.017744675278663635\n",
            "Epoch 11, Step 43, Loss: 0.01936333440244198\n",
            "Epoch 11, Step 44, Loss: 0.0196144487708807\n",
            "Epoch 11, Step 45, Loss: 0.018311882391572\n",
            "Epoch 11, Step 46, Loss: 0.02264411188662052\n",
            "Epoch 11, Step 47, Loss: 0.031513966619968414\n",
            "Epoch 11, Step 48, Loss: 0.03757540136575699\n",
            "Epoch 11, Step 49, Loss: 0.028581421822309494\n",
            "Epoch 11, Step 50, Loss: 0.022716406732797623\n",
            "Epoch 11, Step 51, Loss: 0.021543964743614197\n",
            "Epoch 11, Step 52, Loss: 0.01918644644320011\n",
            "Epoch 11, Step 53, Loss: 0.026376333087682724\n",
            "Train Metric MRRs: 0.06342645477591677\n",
            "Train Metric MAPs: 0.08187681896137178\n",
            "Validation Metric MRRs: 0.10607726493364535\n",
            "Validation Metric MAPs: 0.09076866808489928\n",
            "Epoch 12, Step 1, Loss: 0.027672046795487404\n",
            "Epoch 12, Step 2, Loss: 0.03823588788509369\n",
            "Epoch 12, Step 3, Loss: 0.031121892854571342\n",
            "Epoch 12, Step 4, Loss: 0.023232627660036087\n",
            "Epoch 12, Step 5, Loss: 0.030094638466835022\n",
            "Epoch 12, Step 6, Loss: 0.030829105526208878\n",
            "Epoch 12, Step 7, Loss: 0.02895265817642212\n",
            "Epoch 12, Step 8, Loss: 0.024004178121685982\n",
            "Epoch 12, Step 9, Loss: 0.03675273805856705\n",
            "Epoch 12, Step 10, Loss: 0.020309124141931534\n",
            "Epoch 12, Step 11, Loss: 0.016527986153960228\n",
            "Epoch 12, Step 12, Loss: 0.01789694093167782\n",
            "Epoch 12, Step 13, Loss: 0.020645098760724068\n",
            "Epoch 12, Step 14, Loss: 0.01777772419154644\n",
            "Epoch 12, Step 15, Loss: 0.020369617268443108\n",
            "Epoch 12, Step 16, Loss: 0.02392544224858284\n",
            "Epoch 12, Step 17, Loss: 0.016372257843613625\n",
            "Epoch 12, Step 18, Loss: 0.016438057646155357\n",
            "Epoch 12, Step 19, Loss: 0.009341767057776451\n",
            "Epoch 12, Step 20, Loss: 0.009353271685540676\n",
            "Epoch 12, Step 21, Loss: 0.008082316257059574\n",
            "Epoch 12, Step 22, Loss: 0.008374153636395931\n",
            "Epoch 12, Step 23, Loss: 0.007417048793286085\n",
            "Epoch 12, Step 24, Loss: 0.02053309604525566\n",
            "Epoch 12, Step 25, Loss: 0.01644628308713436\n",
            "Epoch 12, Step 26, Loss: 0.016592958942055702\n",
            "Epoch 12, Step 27, Loss: 0.015399505384266376\n",
            "Epoch 12, Step 28, Loss: 0.019511889666318893\n",
            "Epoch 12, Step 29, Loss: 0.02099655196070671\n",
            "Epoch 12, Step 30, Loss: 0.01948276348412037\n",
            "Epoch 12, Step 31, Loss: 0.019040314480662346\n",
            "Epoch 12, Step 32, Loss: 0.01369569357484579\n",
            "Epoch 12, Step 33, Loss: 0.00997014157474041\n",
            "Epoch 12, Step 34, Loss: 0.018004748970270157\n",
            "Epoch 12, Step 35, Loss: 0.017481671646237373\n",
            "Epoch 12, Step 36, Loss: 0.014924966730177402\n",
            "Epoch 12, Step 37, Loss: 0.02720911055803299\n",
            "Epoch 12, Step 38, Loss: 0.023146266117691994\n",
            "Epoch 12, Step 39, Loss: 0.024124465882778168\n",
            "Epoch 12, Step 40, Loss: 0.021688442677259445\n",
            "Epoch 12, Step 41, Loss: 0.02273138053715229\n",
            "Epoch 12, Step 42, Loss: 0.019038384780287743\n",
            "Epoch 12, Step 43, Loss: 0.018874425441026688\n",
            "Epoch 12, Step 44, Loss: 0.020486734807491302\n",
            "Epoch 12, Step 45, Loss: 0.0172424279153347\n",
            "Epoch 12, Step 46, Loss: 0.019515741616487503\n",
            "Epoch 12, Step 47, Loss: 0.026119926944375038\n",
            "Epoch 12, Step 48, Loss: 0.02875325456261635\n",
            "Epoch 12, Step 49, Loss: 0.03065863624215126\n",
            "Epoch 12, Step 50, Loss: 0.027543960139155388\n",
            "Epoch 12, Step 51, Loss: 0.029794825240969658\n",
            "Epoch 12, Step 52, Loss: 0.02315782941877842\n",
            "Epoch 12, Step 53, Loss: 0.027349036186933517\n",
            "Train Metric MRRs: 0.060857493840454656\n",
            "Train Metric MAPs: 0.026425025235981434\n",
            "Validation Metric MRRs: 0.10559220216681396\n",
            "Validation Metric MAPs: 0.04088128254886645\n",
            "Epoch 13, Step 1, Loss: 0.023359782993793488\n",
            "Epoch 13, Step 2, Loss: 0.02824615128338337\n",
            "Epoch 13, Step 3, Loss: 0.02537577413022518\n",
            "Epoch 13, Step 4, Loss: 0.020413298159837723\n",
            "Epoch 13, Step 5, Loss: 0.028826933354139328\n",
            "Epoch 13, Step 6, Loss: 0.03170780465006828\n",
            "Epoch 13, Step 7, Loss: 0.031693246215581894\n",
            "Epoch 13, Step 8, Loss: 0.02673833630979061\n",
            "Epoch 13, Step 9, Loss: 0.04329165816307068\n",
            "Epoch 13, Step 10, Loss: 0.01986793987452984\n",
            "Epoch 13, Step 11, Loss: 0.0143886161968112\n",
            "Epoch 13, Step 12, Loss: 0.015392255038022995\n",
            "Epoch 13, Step 13, Loss: 0.018832040950655937\n",
            "Epoch 13, Step 14, Loss: 0.014474179595708847\n",
            "Epoch 13, Step 15, Loss: 0.018337983638048172\n",
            "Epoch 13, Step 16, Loss: 0.022246239706873894\n",
            "Epoch 13, Step 17, Loss: 0.016330139711499214\n",
            "Epoch 13, Step 18, Loss: 0.01664150319993496\n",
            "Epoch 13, Step 19, Loss: 0.010567874647676945\n",
            "Epoch 13, Step 20, Loss: 0.011197811923921108\n",
            "Epoch 13, Step 21, Loss: 0.009917096234858036\n",
            "Epoch 13, Step 22, Loss: 0.010845266282558441\n",
            "Epoch 13, Step 23, Loss: 0.009337736293673515\n",
            "Epoch 13, Step 24, Loss: 0.020100073888897896\n",
            "Epoch 13, Step 25, Loss: 0.016611561179161072\n",
            "Epoch 13, Step 26, Loss: 0.016118377447128296\n",
            "Epoch 13, Step 27, Loss: 0.014749657362699509\n",
            "Epoch 13, Step 28, Loss: 0.0184214785695076\n",
            "Epoch 13, Step 29, Loss: 0.020237263292074203\n",
            "Epoch 13, Step 30, Loss: 0.01813739724457264\n",
            "Epoch 13, Step 31, Loss: 0.018111640587449074\n",
            "Epoch 13, Step 32, Loss: 0.013203264214098454\n",
            "Epoch 13, Step 33, Loss: 0.00969619583338499\n",
            "Epoch 13, Step 34, Loss: 0.01685468479990959\n",
            "Epoch 13, Step 35, Loss: 0.0169871486723423\n",
            "Epoch 13, Step 36, Loss: 0.014452689327299595\n",
            "Epoch 13, Step 37, Loss: 0.024298010393977165\n",
            "Epoch 13, Step 38, Loss: 0.020259954035282135\n",
            "Epoch 13, Step 39, Loss: 0.021909864619374275\n",
            "Epoch 13, Step 40, Loss: 0.021251263096928596\n",
            "Epoch 13, Step 41, Loss: 0.02308802492916584\n",
            "Epoch 13, Step 42, Loss: 0.017834562808275223\n",
            "Epoch 13, Step 43, Loss: 0.019414305686950684\n",
            "Epoch 13, Step 44, Loss: 0.019387679174542427\n",
            "Epoch 13, Step 45, Loss: 0.015941236168146133\n",
            "Epoch 13, Step 46, Loss: 0.019146284088492393\n",
            "Epoch 13, Step 47, Loss: 0.02172135002911091\n",
            "Epoch 13, Step 48, Loss: 0.023970086127519608\n",
            "Epoch 13, Step 49, Loss: 0.026145443320274353\n",
            "Epoch 13, Step 50, Loss: 0.024643106386065483\n",
            "Epoch 13, Step 51, Loss: 0.02487407624721527\n",
            "Epoch 13, Step 52, Loss: 0.02066490426659584\n",
            "Epoch 13, Step 53, Loss: 0.023455487564206123\n",
            "Train Metric MRRs: 0.05941464563581379\n",
            "Train Metric MAPs: 0.03183561556920231\n",
            "Validation Metric MRRs: 0.10012863056363742\n",
            "Validation Metric MAPs: 0.022037380004408035\n",
            "Epoch 14, Step 1, Loss: 0.02489638514816761\n",
            "Epoch 14, Step 2, Loss: 0.028210818767547607\n",
            "Epoch 14, Step 3, Loss: 0.02377038262784481\n",
            "Epoch 14, Step 4, Loss: 0.018812017515301704\n",
            "Epoch 14, Step 5, Loss: 0.024330629035830498\n",
            "Epoch 14, Step 6, Loss: 0.027286536991596222\n",
            "Epoch 14, Step 7, Loss: 0.027603451162576675\n",
            "Epoch 14, Step 8, Loss: 0.024881703779101372\n",
            "Epoch 14, Step 9, Loss: 0.040190983563661575\n",
            "Epoch 14, Step 10, Loss: 0.020278938114643097\n",
            "Epoch 14, Step 11, Loss: 0.014649497345089912\n",
            "Epoch 14, Step 12, Loss: 0.015871362760663033\n",
            "Epoch 14, Step 13, Loss: 0.01922827772796154\n",
            "Epoch 14, Step 14, Loss: 0.013287949375808239\n",
            "Epoch 14, Step 15, Loss: 0.017211347818374634\n",
            "Epoch 14, Step 16, Loss: 0.020433038473129272\n",
            "Epoch 14, Step 17, Loss: 0.014394793659448624\n",
            "Epoch 14, Step 18, Loss: 0.015011384151875973\n",
            "Epoch 14, Step 19, Loss: 0.00889403373003006\n",
            "Epoch 14, Step 20, Loss: 0.009494936093688011\n",
            "Epoch 14, Step 21, Loss: 0.00887184776365757\n",
            "Epoch 14, Step 22, Loss: 0.010602298192679882\n",
            "Epoch 14, Step 23, Loss: 0.009424610063433647\n",
            "Epoch 14, Step 24, Loss: 0.019892841577529907\n",
            "Epoch 14, Step 25, Loss: 0.01787726767361164\n",
            "Epoch 14, Step 26, Loss: 0.016567420214414597\n",
            "Epoch 14, Step 27, Loss: 0.014998584054410458\n",
            "Epoch 14, Step 28, Loss: 0.01847677305340767\n",
            "Epoch 14, Step 29, Loss: 0.018915457651019096\n",
            "Epoch 14, Step 30, Loss: 0.01701287552714348\n",
            "Epoch 14, Step 31, Loss: 0.01745014637708664\n",
            "Epoch 14, Step 32, Loss: 0.012230594642460346\n",
            "Epoch 14, Step 33, Loss: 0.009036866948008537\n",
            "Epoch 14, Step 34, Loss: 0.016125192865729332\n",
            "Epoch 14, Step 35, Loss: 0.016077395528554916\n",
            "Epoch 14, Step 36, Loss: 0.013150055892765522\n",
            "Epoch 14, Step 37, Loss: 0.02303341031074524\n",
            "Epoch 14, Step 38, Loss: 0.02058461122214794\n",
            "Epoch 14, Step 39, Loss: 0.021437138319015503\n",
            "Epoch 14, Step 40, Loss: 0.020732931792736053\n",
            "Epoch 14, Step 41, Loss: 0.0225185789167881\n",
            "Epoch 14, Step 42, Loss: 0.016780734062194824\n",
            "Epoch 14, Step 43, Loss: 0.01771995611488819\n",
            "Epoch 14, Step 44, Loss: 0.018223581835627556\n",
            "Epoch 14, Step 45, Loss: 0.014858715236186981\n",
            "Epoch 14, Step 46, Loss: 0.01762876845896244\n",
            "Epoch 14, Step 47, Loss: 0.02089359052479267\n",
            "Epoch 14, Step 48, Loss: 0.02247183956205845\n",
            "Epoch 14, Step 49, Loss: 0.025091011077165604\n",
            "Epoch 14, Step 50, Loss: 0.022231202572584152\n",
            "Epoch 14, Step 51, Loss: 0.02215728349983692\n",
            "Epoch 14, Step 52, Loss: 0.0181577131152153\n",
            "Epoch 14, Step 53, Loss: 0.018616963177919388\n",
            "Train Metric MRRs: 0.06830705081475481\n",
            "Train Metric MAPs: 0.027608365867881155\n",
            "Validation Metric MRRs: 0.10843820152013497\n",
            "Validation Metric MAPs: 0.02805850152780702\n",
            "Epoch 15, Step 1, Loss: 0.02393658459186554\n",
            "Epoch 15, Step 2, Loss: 0.02753208950161934\n",
            "Epoch 15, Step 3, Loss: 0.023357972502708435\n",
            "Epoch 15, Step 4, Loss: 0.018672358244657516\n",
            "Epoch 15, Step 5, Loss: 0.02339956909418106\n",
            "Epoch 15, Step 6, Loss: 0.02644742839038372\n",
            "Epoch 15, Step 7, Loss: 0.025992803275585175\n",
            "Epoch 15, Step 8, Loss: 0.023106886073946953\n",
            "Epoch 15, Step 9, Loss: 0.0372784323990345\n",
            "Epoch 15, Step 10, Loss: 0.019875776022672653\n",
            "Epoch 15, Step 11, Loss: 0.014296980574727058\n",
            "Epoch 15, Step 12, Loss: 0.01576601341366768\n",
            "Epoch 15, Step 13, Loss: 0.019194036722183228\n",
            "Epoch 15, Step 14, Loss: 0.01296498253941536\n",
            "Epoch 15, Step 15, Loss: 0.016784820705652237\n",
            "Epoch 15, Step 16, Loss: 0.019786890596151352\n",
            "Epoch 15, Step 17, Loss: 0.01409048680216074\n",
            "Epoch 15, Step 18, Loss: 0.01450738962739706\n",
            "Epoch 15, Step 19, Loss: 0.00842927023768425\n",
            "Epoch 15, Step 20, Loss: 0.008258126676082611\n",
            "Epoch 15, Step 21, Loss: 0.007654315326362848\n",
            "Epoch 15, Step 22, Loss: 0.009602285921573639\n",
            "Epoch 15, Step 23, Loss: 0.008794873021543026\n",
            "Epoch 15, Step 24, Loss: 0.019652236253023148\n",
            "Epoch 15, Step 25, Loss: 0.016755355522036552\n",
            "Epoch 15, Step 26, Loss: 0.015776248648762703\n",
            "Epoch 15, Step 27, Loss: 0.014362212270498276\n",
            "Epoch 15, Step 28, Loss: 0.01835441403090954\n",
            "Epoch 15, Step 29, Loss: 0.01851763017475605\n",
            "Epoch 15, Step 30, Loss: 0.016531629487872124\n",
            "Epoch 15, Step 31, Loss: 0.016512684524059296\n",
            "Epoch 15, Step 32, Loss: 0.011665038764476776\n",
            "Epoch 15, Step 33, Loss: 0.008835938759148121\n",
            "Epoch 15, Step 34, Loss: 0.015349917113780975\n",
            "Epoch 15, Step 35, Loss: 0.014772086404263973\n",
            "Epoch 15, Step 36, Loss: 0.01194840669631958\n",
            "Epoch 15, Step 37, Loss: 0.021077880635857582\n",
            "Epoch 15, Step 38, Loss: 0.018734797835350037\n",
            "Epoch 15, Step 39, Loss: 0.01969648152589798\n",
            "Epoch 15, Step 40, Loss: 0.018918290734291077\n",
            "Epoch 15, Step 41, Loss: 0.022568412125110626\n",
            "Epoch 15, Step 42, Loss: 0.016054216772317886\n",
            "Epoch 15, Step 43, Loss: 0.017875438556075096\n",
            "Epoch 15, Step 44, Loss: 0.01718185842037201\n",
            "Epoch 15, Step 45, Loss: 0.014394287019968033\n",
            "Epoch 15, Step 46, Loss: 0.017510060220956802\n",
            "Epoch 15, Step 47, Loss: 0.0199467483907938\n",
            "Epoch 15, Step 48, Loss: 0.021702997386455536\n",
            "Epoch 15, Step 49, Loss: 0.02345130406320095\n",
            "Epoch 15, Step 50, Loss: 0.021037790924310684\n",
            "Epoch 15, Step 51, Loss: 0.020201219245791435\n",
            "Epoch 15, Step 52, Loss: 0.018381578847765923\n",
            "Epoch 15, Step 53, Loss: 0.01931537687778473\n",
            "Train Metric MRRs: 0.07117491344055657\n",
            "Train Metric MAPs: 0.025114388562728462\n",
            "Validation Metric MRRs: 0.11376957083116422\n",
            "Validation Metric MAPs: 0.026924475356797203\n",
            "Epoch 16, Step 1, Loss: 0.025800300762057304\n",
            "Epoch 16, Step 2, Loss: 0.028257574886083603\n",
            "Epoch 16, Step 3, Loss: 0.02321936935186386\n",
            "Epoch 16, Step 4, Loss: 0.018930545076727867\n",
            "Epoch 16, Step 5, Loss: 0.023111622780561447\n",
            "Epoch 16, Step 6, Loss: 0.026069724932312965\n",
            "Epoch 16, Step 7, Loss: 0.025527212768793106\n",
            "Epoch 16, Step 8, Loss: 0.02275647409260273\n",
            "Epoch 16, Step 9, Loss: 0.036726806312799454\n",
            "Epoch 16, Step 10, Loss: 0.020266452804207802\n",
            "Epoch 16, Step 11, Loss: 0.014521862380206585\n",
            "Epoch 16, Step 12, Loss: 0.015667041763663292\n",
            "Epoch 16, Step 13, Loss: 0.019060084596276283\n",
            "Epoch 16, Step 14, Loss: 0.012993898242712021\n",
            "Epoch 16, Step 15, Loss: 0.016558842733502388\n",
            "Epoch 16, Step 16, Loss: 0.019483782351017\n",
            "Epoch 16, Step 17, Loss: 0.013974045403301716\n",
            "Epoch 16, Step 18, Loss: 0.01434634905308485\n",
            "Epoch 16, Step 19, Loss: 0.007926574908196926\n",
            "Epoch 16, Step 20, Loss: 0.007916665636003017\n",
            "Epoch 16, Step 21, Loss: 0.007362738251686096\n",
            "Epoch 16, Step 22, Loss: 0.008965585380792618\n",
            "Epoch 16, Step 23, Loss: 0.008481842465698719\n",
            "Epoch 16, Step 24, Loss: 0.019322674721479416\n",
            "Epoch 16, Step 25, Loss: 0.016204437240958214\n",
            "Epoch 16, Step 26, Loss: 0.015825504437088966\n",
            "Epoch 16, Step 27, Loss: 0.014073096215724945\n",
            "Epoch 16, Step 28, Loss: 0.017768479883670807\n",
            "Epoch 16, Step 29, Loss: 0.018675200641155243\n",
            "Epoch 16, Step 30, Loss: 0.01623421534895897\n",
            "Epoch 16, Step 31, Loss: 0.017112208530306816\n",
            "Epoch 16, Step 32, Loss: 0.01176734734326601\n",
            "Epoch 16, Step 33, Loss: 0.00951412320137024\n",
            "Epoch 16, Step 34, Loss: 0.01493957918137312\n",
            "Epoch 16, Step 35, Loss: 0.014190463349223137\n",
            "Epoch 16, Step 36, Loss: 0.01166447438299656\n",
            "Epoch 16, Step 37, Loss: 0.020779278129339218\n",
            "Epoch 16, Step 38, Loss: 0.01855555921792984\n",
            "Epoch 16, Step 39, Loss: 0.01827102154493332\n",
            "Epoch 16, Step 40, Loss: 0.017577175050973892\n",
            "Epoch 16, Step 41, Loss: 0.02154184877872467\n",
            "Epoch 16, Step 42, Loss: 0.01630503125488758\n",
            "Epoch 16, Step 43, Loss: 0.017688708379864693\n",
            "Epoch 16, Step 44, Loss: 0.01633353903889656\n",
            "Epoch 16, Step 45, Loss: 0.014823573641479015\n",
            "Epoch 16, Step 46, Loss: 0.016377652063965797\n",
            "Epoch 16, Step 47, Loss: 0.018953178077936172\n",
            "Epoch 16, Step 48, Loss: 0.020213568583130836\n",
            "Epoch 16, Step 49, Loss: 0.021971629932522774\n",
            "Epoch 16, Step 50, Loss: 0.018644703552126884\n",
            "Epoch 16, Step 51, Loss: 0.01831643097102642\n",
            "Epoch 16, Step 52, Loss: 0.014912452548742294\n",
            "Epoch 16, Step 53, Loss: 0.01600590907037258\n",
            "Train Metric MRRs: 0.07374672368140318\n",
            "Train Metric MAPs: 0.027928432363858616\n",
            "Validation Metric MRRs: 0.12811518098441751\n",
            "Validation Metric MAPs: 0.060343250211496724\n",
            "Epoch 17, Step 1, Loss: 0.02327428013086319\n",
            "Epoch 17, Step 2, Loss: 0.027797803282737732\n",
            "Epoch 17, Step 3, Loss: 0.023226015269756317\n",
            "Epoch 17, Step 4, Loss: 0.019527429714798927\n",
            "Epoch 17, Step 5, Loss: 0.02319883555173874\n",
            "Epoch 17, Step 6, Loss: 0.025872591882944107\n",
            "Epoch 17, Step 7, Loss: 0.025203736498951912\n",
            "Epoch 17, Step 8, Loss: 0.021851912140846252\n",
            "Epoch 17, Step 9, Loss: 0.03352268412709236\n",
            "Epoch 17, Step 10, Loss: 0.01961393468081951\n",
            "Epoch 17, Step 11, Loss: 0.01430167444050312\n",
            "Epoch 17, Step 12, Loss: 0.015807192772626877\n",
            "Epoch 17, Step 13, Loss: 0.019106628373265266\n",
            "Epoch 17, Step 14, Loss: 0.012841043062508106\n",
            "Epoch 17, Step 15, Loss: 0.016176512464880943\n",
            "Epoch 17, Step 16, Loss: 0.018813757225871086\n",
            "Epoch 17, Step 17, Loss: 0.013770324178040028\n",
            "Epoch 17, Step 18, Loss: 0.013706522062420845\n",
            "Epoch 17, Step 19, Loss: 0.007485799491405487\n",
            "Epoch 17, Step 20, Loss: 0.007270737551152706\n",
            "Epoch 17, Step 21, Loss: 0.006740246899425983\n",
            "Epoch 17, Step 22, Loss: 0.00839135330170393\n",
            "Epoch 17, Step 23, Loss: 0.007803113665431738\n",
            "Epoch 17, Step 24, Loss: 0.01894267275929451\n",
            "Epoch 17, Step 25, Loss: 0.015437990427017212\n",
            "Epoch 17, Step 26, Loss: 0.014624533243477345\n",
            "Epoch 17, Step 27, Loss: 0.013501008041203022\n",
            "Epoch 17, Step 28, Loss: 0.01768242008984089\n",
            "Epoch 17, Step 29, Loss: 0.017504746094346046\n",
            "Epoch 17, Step 30, Loss: 0.015351520851254463\n",
            "Epoch 17, Step 31, Loss: 0.015758292749524117\n",
            "Epoch 17, Step 32, Loss: 0.01116187684237957\n",
            "Epoch 17, Step 33, Loss: 0.008318879641592503\n",
            "Epoch 17, Step 34, Loss: 0.014553466811776161\n",
            "Epoch 17, Step 35, Loss: 0.013414855115115643\n",
            "Epoch 17, Step 36, Loss: 0.011188927106559277\n",
            "Epoch 17, Step 37, Loss: 0.01829569600522518\n",
            "Epoch 17, Step 38, Loss: 0.017788255587220192\n",
            "Epoch 17, Step 39, Loss: 0.017165614292025566\n",
            "Epoch 17, Step 40, Loss: 0.01640705205500126\n",
            "Epoch 17, Step 41, Loss: 0.019603345543146133\n",
            "Epoch 17, Step 42, Loss: 0.01581578701734543\n",
            "Epoch 17, Step 43, Loss: 0.016014177352190018\n",
            "Epoch 17, Step 44, Loss: 0.015238575637340546\n",
            "Epoch 17, Step 45, Loss: 0.01413377933204174\n",
            "Epoch 17, Step 46, Loss: 0.01573328673839569\n",
            "Epoch 17, Step 47, Loss: 0.01876956783235073\n",
            "Epoch 17, Step 48, Loss: 0.019652167335152626\n",
            "Epoch 17, Step 49, Loss: 0.021567631512880325\n",
            "Epoch 17, Step 50, Loss: 0.018193142488598824\n",
            "Epoch 17, Step 51, Loss: 0.01712030917406082\n",
            "Epoch 17, Step 52, Loss: 0.014103731140494347\n",
            "Epoch 17, Step 53, Loss: 0.014873216859996319\n",
            "Train Metric MRRs: 0.07098052446719118\n",
            "Train Metric MAPs: 0.03348937781311361\n",
            "Validation Metric MRRs: 0.1583411426787582\n",
            "Validation Metric MAPs: 0.06759849710647718\n",
            "Epoch 18, Step 1, Loss: 0.02259918488562107\n",
            "Epoch 18, Step 2, Loss: 0.02677319385111332\n",
            "Epoch 18, Step 3, Loss: 0.022482026368379593\n",
            "Epoch 18, Step 4, Loss: 0.01872011087834835\n",
            "Epoch 18, Step 5, Loss: 0.02287065051496029\n",
            "Epoch 18, Step 6, Loss: 0.025532254949212074\n",
            "Epoch 18, Step 7, Loss: 0.024885231629014015\n",
            "Epoch 18, Step 8, Loss: 0.021462678909301758\n",
            "Epoch 18, Step 9, Loss: 0.03236166760325432\n",
            "Epoch 18, Step 10, Loss: 0.01929774135351181\n",
            "Epoch 18, Step 11, Loss: 0.014217926189303398\n",
            "Epoch 18, Step 12, Loss: 0.015260487794876099\n",
            "Epoch 18, Step 13, Loss: 0.018146784976124763\n",
            "Epoch 18, Step 14, Loss: 0.01254277303814888\n",
            "Epoch 18, Step 15, Loss: 0.01604033261537552\n",
            "Epoch 18, Step 16, Loss: 0.01855403557419777\n",
            "Epoch 18, Step 17, Loss: 0.013464107178151608\n",
            "Epoch 18, Step 18, Loss: 0.0134266447275877\n",
            "Epoch 18, Step 19, Loss: 0.007222367916256189\n",
            "Epoch 18, Step 20, Loss: 0.006978931371122599\n",
            "Epoch 18, Step 21, Loss: 0.006244251038879156\n",
            "Epoch 18, Step 22, Loss: 0.007659560069441795\n",
            "Epoch 18, Step 23, Loss: 0.007661245297640562\n",
            "Epoch 18, Step 24, Loss: 0.019165800884366035\n",
            "Epoch 18, Step 25, Loss: 0.015424343757331371\n",
            "Epoch 18, Step 26, Loss: 0.014437639154493809\n",
            "Epoch 18, Step 27, Loss: 0.013089527375996113\n",
            "Epoch 18, Step 28, Loss: 0.016806194558739662\n",
            "Epoch 18, Step 29, Loss: 0.016944652423262596\n",
            "Epoch 18, Step 30, Loss: 0.015133249573409557\n",
            "Epoch 18, Step 31, Loss: 0.015562309883534908\n",
            "Epoch 18, Step 32, Loss: 0.01110747642815113\n",
            "Epoch 18, Step 33, Loss: 0.008256262168288231\n",
            "Epoch 18, Step 34, Loss: 0.01379658654332161\n",
            "Epoch 18, Step 35, Loss: 0.013355565257370472\n",
            "Epoch 18, Step 36, Loss: 0.011017516255378723\n",
            "Epoch 18, Step 37, Loss: 0.017647093161940575\n",
            "Epoch 18, Step 38, Loss: 0.01677311584353447\n",
            "Epoch 18, Step 39, Loss: 0.016521230340003967\n",
            "Epoch 18, Step 40, Loss: 0.015486137010157108\n",
            "Epoch 18, Step 41, Loss: 0.017561770975589752\n",
            "Epoch 18, Step 42, Loss: 0.013841490261256695\n",
            "Epoch 18, Step 43, Loss: 0.014491637237370014\n",
            "Epoch 18, Step 44, Loss: 0.01367144100368023\n",
            "Epoch 18, Step 45, Loss: 0.01300957053899765\n",
            "Epoch 18, Step 46, Loss: 0.01304586697369814\n",
            "Epoch 18, Step 47, Loss: 0.017635565251111984\n",
            "Epoch 18, Step 48, Loss: 0.0195078756660223\n",
            "Epoch 18, Step 49, Loss: 0.018989499658346176\n",
            "Epoch 18, Step 50, Loss: 0.01736624352633953\n",
            "Epoch 18, Step 51, Loss: 0.01728002540767193\n",
            "Epoch 18, Step 52, Loss: 0.012692654505372047\n",
            "Epoch 18, Step 53, Loss: 0.012784413062036037\n",
            "Train Metric MRRs: 0.07818289604930598\n",
            "Train Metric MAPs: 0.03210538264657267\n",
            "Validation Metric MRRs: 0.18285820276922116\n",
            "Validation Metric MAPs: 0.10802878103022308\n",
            "Epoch 19, Step 1, Loss: 0.025844382122159004\n",
            "Epoch 19, Step 2, Loss: 0.031103625893592834\n",
            "Epoch 19, Step 3, Loss: 0.024192724376916885\n",
            "Epoch 19, Step 4, Loss: 0.020819375291466713\n",
            "Epoch 19, Step 5, Loss: 0.022724881768226624\n",
            "Epoch 19, Step 6, Loss: 0.025243056938052177\n",
            "Epoch 19, Step 7, Loss: 0.024099744856357574\n",
            "Epoch 19, Step 8, Loss: 0.021508648991584778\n",
            "Epoch 19, Step 9, Loss: 0.03173395246267319\n",
            "Epoch 19, Step 10, Loss: 0.01923958770930767\n",
            "Epoch 19, Step 11, Loss: 0.014177788980305195\n",
            "Epoch 19, Step 12, Loss: 0.015344942919909954\n",
            "Epoch 19, Step 13, Loss: 0.01867997646331787\n",
            "Epoch 19, Step 14, Loss: 0.012414839118719101\n",
            "Epoch 19, Step 15, Loss: 0.01611103117465973\n",
            "Epoch 19, Step 16, Loss: 0.018484672531485558\n",
            "Epoch 19, Step 17, Loss: 0.013369934633374214\n",
            "Epoch 19, Step 18, Loss: 0.013262853026390076\n",
            "Epoch 19, Step 19, Loss: 0.007166406139731407\n",
            "Epoch 19, Step 20, Loss: 0.006753898225724697\n",
            "Epoch 19, Step 21, Loss: 0.0060650743544101715\n",
            "Epoch 19, Step 22, Loss: 0.007446072995662689\n",
            "Epoch 19, Step 23, Loss: 0.0073824250139296055\n",
            "Epoch 19, Step 24, Loss: 0.019408153370022774\n",
            "Epoch 19, Step 25, Loss: 0.015092521905899048\n",
            "Epoch 19, Step 26, Loss: 0.01403352152556181\n",
            "Epoch 19, Step 27, Loss: 0.013227739371359348\n",
            "Epoch 19, Step 28, Loss: 0.01699875295162201\n",
            "Epoch 19, Step 29, Loss: 0.01692042127251625\n",
            "Epoch 19, Step 30, Loss: 0.015352773480117321\n",
            "Epoch 19, Step 31, Loss: 0.015899136662483215\n",
            "Epoch 19, Step 32, Loss: 0.011028093285858631\n",
            "Epoch 19, Step 33, Loss: 0.00805571023374796\n",
            "Epoch 19, Step 34, Loss: 0.014501248486340046\n",
            "Epoch 19, Step 35, Loss: 0.013238998129963875\n",
            "Epoch 19, Step 36, Loss: 0.011303100734949112\n",
            "Epoch 19, Step 37, Loss: 0.018535584211349487\n",
            "Epoch 19, Step 38, Loss: 0.017472324892878532\n",
            "Epoch 19, Step 39, Loss: 0.016897214576601982\n",
            "Epoch 19, Step 40, Loss: 0.016154661774635315\n",
            "Epoch 19, Step 41, Loss: 0.018726397305727005\n",
            "Epoch 19, Step 42, Loss: 0.014962645247578621\n",
            "Epoch 19, Step 43, Loss: 0.014777024276554585\n",
            "Epoch 19, Step 44, Loss: 0.016001248732209206\n",
            "Epoch 19, Step 45, Loss: 0.014162980020046234\n",
            "Epoch 19, Step 46, Loss: 0.015155074186623096\n",
            "Epoch 19, Step 47, Loss: 0.018198125064373016\n",
            "Epoch 19, Step 48, Loss: 0.01960158720612526\n",
            "Epoch 19, Step 49, Loss: 0.019314086064696312\n",
            "Epoch 19, Step 50, Loss: 0.017876392230391502\n",
            "Epoch 19, Step 51, Loss: 0.018329620361328125\n",
            "Epoch 19, Step 52, Loss: 0.013748380355536938\n",
            "Epoch 19, Step 53, Loss: 0.014130087569355965\n",
            "Train Metric MRRs: 0.07516331479519388\n",
            "Train Metric MAPs: 0.03414499934553238\n",
            "Validation Metric MRRs: 0.17093556286931105\n",
            "Validation Metric MAPs: 0.027708825630447152\n",
            "Epoch 20, Step 1, Loss: 0.02114682085812092\n",
            "Epoch 20, Step 2, Loss: 0.025699589401483536\n",
            "Epoch 20, Step 3, Loss: 0.022188423201441765\n",
            "Epoch 20, Step 4, Loss: 0.01853485032916069\n",
            "Epoch 20, Step 5, Loss: 0.02237457036972046\n",
            "Epoch 20, Step 6, Loss: 0.025523437187075615\n",
            "Epoch 20, Step 7, Loss: 0.024278469383716583\n",
            "Epoch 20, Step 8, Loss: 0.021308770403265953\n",
            "Epoch 20, Step 9, Loss: 0.029750533401966095\n",
            "Epoch 20, Step 10, Loss: 0.018718857318162918\n",
            "Epoch 20, Step 11, Loss: 0.0142001211643219\n",
            "Epoch 20, Step 12, Loss: 0.014801425859332085\n",
            "Epoch 20, Step 13, Loss: 0.017962470650672913\n",
            "Epoch 20, Step 14, Loss: 0.012688757851719856\n",
            "Epoch 20, Step 15, Loss: 0.015835056081414223\n",
            "Epoch 20, Step 16, Loss: 0.01866859756410122\n",
            "Epoch 20, Step 17, Loss: 0.013364044949412346\n",
            "Epoch 20, Step 18, Loss: 0.013133675791323185\n",
            "Epoch 20, Step 19, Loss: 0.006854015868157148\n",
            "Epoch 20, Step 20, Loss: 0.006427365820854902\n",
            "Epoch 20, Step 21, Loss: 0.005884346552193165\n",
            "Epoch 20, Step 22, Loss: 0.007122248876839876\n",
            "Epoch 20, Step 23, Loss: 0.006761341355741024\n",
            "Epoch 20, Step 24, Loss: 0.017678864300251007\n",
            "Epoch 20, Step 25, Loss: 0.014564178884029388\n",
            "Epoch 20, Step 26, Loss: 0.013373277150094509\n",
            "Epoch 20, Step 27, Loss: 0.012783866375684738\n",
            "Epoch 20, Step 28, Loss: 0.016667110845446587\n",
            "Epoch 20, Step 29, Loss: 0.015884941443800926\n",
            "Epoch 20, Step 30, Loss: 0.014140995219349861\n",
            "Epoch 20, Step 31, Loss: 0.015066205523908138\n",
            "Epoch 20, Step 32, Loss: 0.010259929113090038\n",
            "Epoch 20, Step 33, Loss: 0.007629260886460543\n",
            "Epoch 20, Step 34, Loss: 0.013511384837329388\n",
            "Epoch 20, Step 35, Loss: 0.012626937590539455\n",
            "Epoch 20, Step 36, Loss: 0.010409736074507236\n",
            "Epoch 20, Step 37, Loss: 0.016782518476247787\n",
            "Epoch 20, Step 38, Loss: 0.01669413223862648\n",
            "Epoch 20, Step 39, Loss: 0.016002316027879715\n",
            "Epoch 20, Step 40, Loss: 0.01512435544282198\n",
            "Epoch 20, Step 41, Loss: 0.017674986273050308\n",
            "Epoch 20, Step 42, Loss: 0.012887414544820786\n",
            "Epoch 20, Step 43, Loss: 0.01325920969247818\n",
            "Epoch 20, Step 44, Loss: 0.013907415792346\n",
            "Epoch 20, Step 45, Loss: 0.011947938241064548\n",
            "Epoch 20, Step 46, Loss: 0.012389607727527618\n",
            "Epoch 20, Step 47, Loss: 0.01723213493824005\n",
            "Epoch 20, Step 48, Loss: 0.017063219100236893\n",
            "Epoch 20, Step 49, Loss: 0.018795551732182503\n",
            "Epoch 20, Step 50, Loss: 0.016797956079244614\n",
            "Epoch 20, Step 51, Loss: 0.016394762322306633\n",
            "Epoch 20, Step 52, Loss: 0.011692299507558346\n",
            "Epoch 20, Step 53, Loss: 0.011868877336382866\n",
            "Train Metric MRRs: 0.08048461546706048\n",
            "Train Metric MAPs: 0.027986778231287167\n",
            "Validation Metric MRRs: 0.2029342297203605\n",
            "Validation Metric MAPs: 0.045547072816951334\n",
            "Epoch 21, Step 1, Loss: 0.020713891834020615\n",
            "Epoch 21, Step 2, Loss: 0.024734701961278915\n",
            "Epoch 21, Step 3, Loss: 0.022035755217075348\n",
            "Epoch 21, Step 4, Loss: 0.018566308543086052\n",
            "Epoch 21, Step 5, Loss: 0.02217869646847248\n",
            "Epoch 21, Step 6, Loss: 0.02503488026559353\n",
            "Epoch 21, Step 7, Loss: 0.023877518251538277\n",
            "Epoch 21, Step 8, Loss: 0.02095646969974041\n",
            "Epoch 21, Step 9, Loss: 0.028980672359466553\n",
            "Epoch 21, Step 10, Loss: 0.018649062141776085\n",
            "Epoch 21, Step 11, Loss: 0.013928762637078762\n",
            "Epoch 21, Step 12, Loss: 0.014594306237995625\n",
            "Epoch 21, Step 13, Loss: 0.01783960685133934\n",
            "Epoch 21, Step 14, Loss: 0.01241032499819994\n",
            "Epoch 21, Step 15, Loss: 0.015381320379674435\n",
            "Epoch 21, Step 16, Loss: 0.01801324635744095\n",
            "Epoch 21, Step 17, Loss: 0.01299392431974411\n",
            "Epoch 21, Step 18, Loss: 0.012753083370625973\n",
            "Epoch 21, Step 19, Loss: 0.006685112603008747\n",
            "Epoch 21, Step 20, Loss: 0.006352532655000687\n",
            "Epoch 21, Step 21, Loss: 0.005421855486929417\n",
            "Epoch 21, Step 22, Loss: 0.006810907740145922\n",
            "Epoch 21, Step 23, Loss: 0.006744155660271645\n",
            "Epoch 21, Step 24, Loss: 0.018253030255436897\n",
            "Epoch 21, Step 25, Loss: 0.014541076496243477\n",
            "Epoch 21, Step 26, Loss: 0.013330396264791489\n",
            "Epoch 21, Step 27, Loss: 0.012651756405830383\n",
            "Epoch 21, Step 28, Loss: 0.016260197386145592\n",
            "Epoch 21, Step 29, Loss: 0.01627325266599655\n",
            "Epoch 21, Step 30, Loss: 0.013876968994736671\n",
            "Epoch 21, Step 31, Loss: 0.014849488623440266\n",
            "Epoch 21, Step 32, Loss: 0.010272311046719551\n",
            "Epoch 21, Step 33, Loss: 0.007809116505086422\n",
            "Epoch 21, Step 34, Loss: 0.013061217032372952\n",
            "Epoch 21, Step 35, Loss: 0.012816198170185089\n",
            "Epoch 21, Step 36, Loss: 0.010221445001661777\n",
            "Epoch 21, Step 37, Loss: 0.016719110310077667\n",
            "Epoch 21, Step 38, Loss: 0.01632624678313732\n",
            "Epoch 21, Step 39, Loss: 0.015795253217220306\n",
            "Epoch 21, Step 40, Loss: 0.014732013456523418\n",
            "Epoch 21, Step 41, Loss: 0.018617697060108185\n",
            "Epoch 21, Step 42, Loss: 0.011661579832434654\n",
            "Epoch 21, Step 43, Loss: 0.013200455345213413\n",
            "Epoch 21, Step 44, Loss: 0.012342117726802826\n",
            "Epoch 21, Step 45, Loss: 0.011195835657417774\n",
            "Epoch 21, Step 46, Loss: 0.012975258752703667\n",
            "Epoch 21, Step 47, Loss: 0.016174569725990295\n",
            "Epoch 21, Step 48, Loss: 0.01647755689918995\n",
            "Epoch 21, Step 49, Loss: 0.01636844128370285\n",
            "Epoch 21, Step 50, Loss: 0.01457772683352232\n",
            "Epoch 21, Step 51, Loss: 0.012956757098436356\n",
            "Epoch 21, Step 52, Loss: 0.011233916506171227\n",
            "Epoch 21, Step 53, Loss: 0.010761532932519913\n",
            "Train Metric MRRs: 0.09061500659944015\n",
            "Train Metric MAPs: 0.032125432142599754\n",
            "Validation Metric MRRs: 0.2552903915729199\n",
            "Validation Metric MAPs: 0.05861882272233583\n",
            "Epoch 22, Step 1, Loss: 0.020989522337913513\n",
            "Epoch 22, Step 2, Loss: 0.025800121948122978\n",
            "Epoch 22, Step 3, Loss: 0.022320609539747238\n",
            "Epoch 22, Step 4, Loss: 0.018360745161771774\n",
            "Epoch 22, Step 5, Loss: 0.0219257865101099\n",
            "Epoch 22, Step 6, Loss: 0.023891115561127663\n",
            "Epoch 22, Step 7, Loss: 0.02245895378291607\n",
            "Epoch 22, Step 8, Loss: 0.020016824826598167\n",
            "Epoch 22, Step 9, Loss: 0.028869135305285454\n",
            "Epoch 22, Step 10, Loss: 0.01829388737678528\n",
            "Epoch 22, Step 11, Loss: 0.013720722869038582\n",
            "Epoch 22, Step 12, Loss: 0.014673218131065369\n",
            "Epoch 22, Step 13, Loss: 0.017200671136379242\n",
            "Epoch 22, Step 14, Loss: 0.012438519857823849\n",
            "Epoch 22, Step 15, Loss: 0.015459461137652397\n",
            "Epoch 22, Step 16, Loss: 0.01782943308353424\n",
            "Epoch 22, Step 17, Loss: 0.012892765924334526\n",
            "Epoch 22, Step 18, Loss: 0.012731745839118958\n",
            "Epoch 22, Step 19, Loss: 0.0065485103987157345\n",
            "Epoch 22, Step 20, Loss: 0.006247309967875481\n",
            "Epoch 22, Step 21, Loss: 0.005276327952742577\n",
            "Epoch 22, Step 22, Loss: 0.00696136150509119\n",
            "Epoch 22, Step 23, Loss: 0.006659279111772776\n",
            "Epoch 22, Step 24, Loss: 0.018194833770394325\n",
            "Epoch 22, Step 25, Loss: 0.014750304631888866\n",
            "Epoch 22, Step 26, Loss: 0.013719053938984871\n",
            "Epoch 22, Step 27, Loss: 0.012973815202713013\n",
            "Epoch 22, Step 28, Loss: 0.015551595948636532\n",
            "Epoch 22, Step 29, Loss: 0.015775619074702263\n",
            "Epoch 22, Step 30, Loss: 0.01345059834420681\n",
            "Epoch 22, Step 31, Loss: 0.015012161806225777\n",
            "Epoch 22, Step 32, Loss: 0.01041786465793848\n",
            "Epoch 22, Step 33, Loss: 0.007378986570984125\n",
            "Epoch 22, Step 34, Loss: 0.013536208309233189\n",
            "Epoch 22, Step 35, Loss: 0.012546376325190067\n",
            "Epoch 22, Step 36, Loss: 0.010199364274740219\n",
            "Epoch 22, Step 37, Loss: 0.015359601937234402\n",
            "Epoch 22, Step 38, Loss: 0.015831295400857925\n",
            "Epoch 22, Step 39, Loss: 0.014984039589762688\n",
            "Epoch 22, Step 40, Loss: 0.0146228838711977\n",
            "Epoch 22, Step 41, Loss: 0.01741771213710308\n",
            "Epoch 22, Step 42, Loss: 0.011775264516472816\n",
            "Epoch 22, Step 43, Loss: 0.013037126511335373\n",
            "Epoch 22, Step 44, Loss: 0.011741368100047112\n",
            "Epoch 22, Step 45, Loss: 0.011134727858006954\n",
            "Epoch 22, Step 46, Loss: 0.0116609837859869\n",
            "Epoch 22, Step 47, Loss: 0.016670221462845802\n",
            "Epoch 22, Step 48, Loss: 0.01581897959113121\n",
            "Epoch 22, Step 49, Loss: 0.015923991799354553\n",
            "Epoch 22, Step 50, Loss: 0.014200819656252861\n",
            "Epoch 22, Step 51, Loss: 0.013047855347394943\n",
            "Epoch 22, Step 52, Loss: 0.012613998726010323\n",
            "Epoch 22, Step 53, Loss: 0.012001791968941689\n",
            "Train Metric MRRs: 0.09900599146942687\n",
            "Train Metric MAPs: 0.02943508145081519\n",
            "Validation Metric MRRs: 0.25241760230951094\n",
            "Validation Metric MAPs: 0.08006750652364329\n",
            "Epoch 23, Step 1, Loss: 0.019679494202136993\n",
            "Epoch 23, Step 2, Loss: 0.02400277741253376\n",
            "Epoch 23, Step 3, Loss: 0.021605288609862328\n",
            "Epoch 23, Step 4, Loss: 0.017438318580389023\n",
            "Epoch 23, Step 5, Loss: 0.02213299088180065\n",
            "Epoch 23, Step 6, Loss: 0.02346070110797882\n",
            "Epoch 23, Step 7, Loss: 0.021937483921647072\n",
            "Epoch 23, Step 8, Loss: 0.019532781094312668\n",
            "Epoch 23, Step 9, Loss: 0.027785010635852814\n",
            "Epoch 23, Step 10, Loss: 0.018333178013563156\n",
            "Epoch 23, Step 11, Loss: 0.01337564829736948\n",
            "Epoch 23, Step 12, Loss: 0.014441138133406639\n",
            "Epoch 23, Step 13, Loss: 0.017261533066630363\n",
            "Epoch 23, Step 14, Loss: 0.012428984977304935\n",
            "Epoch 23, Step 15, Loss: 0.015339578501880169\n",
            "Epoch 23, Step 16, Loss: 0.017686469480395317\n",
            "Epoch 23, Step 17, Loss: 0.013053788803517818\n",
            "Epoch 23, Step 18, Loss: 0.012915716506540775\n",
            "Epoch 23, Step 19, Loss: 0.00635500717908144\n",
            "Epoch 23, Step 20, Loss: 0.006105642765760422\n",
            "Epoch 23, Step 21, Loss: 0.0054238708689808846\n",
            "Epoch 23, Step 22, Loss: 0.006867000833153725\n",
            "Epoch 23, Step 23, Loss: 0.006577762309461832\n",
            "Epoch 23, Step 24, Loss: 0.017874786630272865\n",
            "Epoch 23, Step 25, Loss: 0.0142154386267066\n",
            "Epoch 23, Step 26, Loss: 0.012889621779322624\n",
            "Epoch 23, Step 27, Loss: 0.012439471669495106\n",
            "Epoch 23, Step 28, Loss: 0.015100219286978245\n",
            "Epoch 23, Step 29, Loss: 0.014720863662660122\n",
            "Epoch 23, Step 30, Loss: 0.013243086636066437\n",
            "Epoch 23, Step 31, Loss: 0.013975096866488457\n",
            "Epoch 23, Step 32, Loss: 0.01012879703193903\n",
            "Epoch 23, Step 33, Loss: 0.007403434254229069\n",
            "Epoch 23, Step 34, Loss: 0.013077708892524242\n",
            "Epoch 23, Step 35, Loss: 0.0119277099147439\n",
            "Epoch 23, Step 36, Loss: 0.009958554059267044\n",
            "Epoch 23, Step 37, Loss: 0.015323330648243427\n",
            "Epoch 23, Step 38, Loss: 0.015592720359563828\n",
            "Epoch 23, Step 39, Loss: 0.014535807073116302\n",
            "Epoch 23, Step 40, Loss: 0.013477730564773083\n",
            "Epoch 23, Step 41, Loss: 0.017478808760643005\n",
            "Epoch 23, Step 42, Loss: 0.011713660322129726\n",
            "Epoch 23, Step 43, Loss: 0.012122237123548985\n",
            "Epoch 23, Step 44, Loss: 0.010890718549489975\n",
            "Epoch 23, Step 45, Loss: 0.010403460822999477\n",
            "Epoch 23, Step 46, Loss: 0.011171013116836548\n",
            "Epoch 23, Step 47, Loss: 0.016249163076281548\n",
            "Epoch 23, Step 48, Loss: 0.016165493056178093\n",
            "Epoch 23, Step 49, Loss: 0.01690010353922844\n",
            "Epoch 23, Step 50, Loss: 0.015174800530076027\n",
            "Epoch 23, Step 51, Loss: 0.012532886117696762\n",
            "Epoch 23, Step 52, Loss: 0.010770910419523716\n",
            "Epoch 23, Step 53, Loss: 0.010078009217977524\n",
            "Train Metric MRRs: 0.1139097245353643\n",
            "Train Metric MAPs: 0.03904493759564626\n",
            "Validation Metric MRRs: 0.24247934291041176\n",
            "Validation Metric MAPs: 0.13282182455706493\n",
            "Epoch 24, Step 1, Loss: 0.01992473378777504\n",
            "Epoch 24, Step 2, Loss: 0.024394992738962173\n",
            "Epoch 24, Step 3, Loss: 0.020647089928388596\n",
            "Epoch 24, Step 4, Loss: 0.01756049320101738\n",
            "Epoch 24, Step 5, Loss: 0.020840810611844063\n",
            "Epoch 24, Step 6, Loss: 0.022908486425876617\n",
            "Epoch 24, Step 7, Loss: 0.021290581673383713\n",
            "Epoch 24, Step 8, Loss: 0.01924850419163704\n",
            "Epoch 24, Step 9, Loss: 0.027452746406197548\n",
            "Epoch 24, Step 10, Loss: 0.017677389085292816\n",
            "Epoch 24, Step 11, Loss: 0.013367518782615662\n",
            "Epoch 24, Step 12, Loss: 0.014266835525631905\n",
            "Epoch 24, Step 13, Loss: 0.01685616746544838\n",
            "Epoch 24, Step 14, Loss: 0.012144695967435837\n",
            "Epoch 24, Step 15, Loss: 0.015181830152869225\n",
            "Epoch 24, Step 16, Loss: 0.017452089115977287\n",
            "Epoch 24, Step 17, Loss: 0.012995262630283833\n",
            "Epoch 24, Step 18, Loss: 0.012691878713667393\n",
            "Epoch 24, Step 19, Loss: 0.006569379474967718\n",
            "Epoch 24, Step 20, Loss: 0.006221788469702005\n",
            "Epoch 24, Step 21, Loss: 0.005142648704349995\n",
            "Epoch 24, Step 22, Loss: 0.006490590516477823\n",
            "Epoch 24, Step 23, Loss: 0.006538541056215763\n",
            "Epoch 24, Step 24, Loss: 0.017831718549132347\n",
            "Epoch 24, Step 25, Loss: 0.01372577715665102\n",
            "Epoch 24, Step 26, Loss: 0.012400583364069462\n",
            "Epoch 24, Step 27, Loss: 0.011605322360992432\n",
            "Epoch 24, Step 28, Loss: 0.014430500566959381\n",
            "Epoch 24, Step 29, Loss: 0.013372513465583324\n",
            "Epoch 24, Step 30, Loss: 0.012626228854060173\n",
            "Epoch 24, Step 31, Loss: 0.013070858083665371\n",
            "Epoch 24, Step 32, Loss: 0.00944589450955391\n",
            "Epoch 24, Step 33, Loss: 0.007101402617990971\n",
            "Epoch 24, Step 34, Loss: 0.011885794810950756\n",
            "Epoch 24, Step 35, Loss: 0.011874496005475521\n",
            "Epoch 24, Step 36, Loss: 0.00949510745704174\n",
            "Epoch 24, Step 37, Loss: 0.014385858550667763\n",
            "Epoch 24, Step 38, Loss: 0.015180064365267754\n",
            "Epoch 24, Step 39, Loss: 0.013761247508227825\n",
            "Epoch 24, Step 40, Loss: 0.013559316284954548\n",
            "Epoch 24, Step 41, Loss: 0.015399573370814323\n",
            "Epoch 24, Step 42, Loss: 0.010640476830303669\n",
            "Epoch 24, Step 43, Loss: 0.011412525549530983\n",
            "Epoch 24, Step 44, Loss: 0.010551190003752708\n",
            "Epoch 24, Step 45, Loss: 0.00964218657463789\n",
            "Epoch 24, Step 46, Loss: 0.012141906656324863\n",
            "Epoch 24, Step 47, Loss: 0.015817588195204735\n",
            "Epoch 24, Step 48, Loss: 0.014294109307229519\n",
            "Epoch 24, Step 49, Loss: 0.0157328974455595\n",
            "Epoch 24, Step 50, Loss: 0.014466927386820316\n",
            "Epoch 24, Step 51, Loss: 0.012470521032810211\n",
            "Epoch 24, Step 52, Loss: 0.012362035922706127\n",
            "Epoch 24, Step 53, Loss: 0.010725585743784904\n",
            "Train Metric MRRs: 0.11763012905592515\n",
            "Train Metric MAPs: 0.05447928929542585\n",
            "Validation Metric MRRs: 0.25118008544998593\n",
            "Validation Metric MAPs: 0.1484307927601206\n",
            "Epoch 25, Step 1, Loss: 0.020596984773874283\n",
            "Epoch 25, Step 2, Loss: 0.02470732107758522\n",
            "Epoch 25, Step 3, Loss: 0.0210396908223629\n",
            "Epoch 25, Step 4, Loss: 0.017528144642710686\n",
            "Epoch 25, Step 5, Loss: 0.020858021453022957\n",
            "Epoch 25, Step 6, Loss: 0.02329074777662754\n",
            "Epoch 25, Step 7, Loss: 0.022064805030822754\n",
            "Epoch 25, Step 8, Loss: 0.01902732439339161\n",
            "Epoch 25, Step 9, Loss: 0.027079114690423012\n",
            "Epoch 25, Step 10, Loss: 0.017812490463256836\n",
            "Epoch 25, Step 11, Loss: 0.013346362859010696\n",
            "Epoch 25, Step 12, Loss: 0.014110359363257885\n",
            "Epoch 25, Step 13, Loss: 0.016892068088054657\n",
            "Epoch 25, Step 14, Loss: 0.012048007920384407\n",
            "Epoch 25, Step 15, Loss: 0.015163835138082504\n",
            "Epoch 25, Step 16, Loss: 0.01758856512606144\n",
            "Epoch 25, Step 17, Loss: 0.01291530579328537\n",
            "Epoch 25, Step 18, Loss: 0.012227988801896572\n",
            "Epoch 25, Step 19, Loss: 0.006466034799814224\n",
            "Epoch 25, Step 20, Loss: 0.0061155338771641254\n",
            "Epoch 25, Step 21, Loss: 0.005139434710144997\n",
            "Epoch 25, Step 22, Loss: 0.006933983415365219\n",
            "Epoch 25, Step 23, Loss: 0.006629457231611013\n",
            "Epoch 25, Step 24, Loss: 0.0170698631554842\n",
            "Epoch 25, Step 25, Loss: 0.014082485809922218\n",
            "Epoch 25, Step 26, Loss: 0.012634902261197567\n",
            "Epoch 25, Step 27, Loss: 0.012327232398092747\n",
            "Epoch 25, Step 28, Loss: 0.015354077331721783\n",
            "Epoch 25, Step 29, Loss: 0.014044295996427536\n",
            "Epoch 25, Step 30, Loss: 0.013003619387745857\n",
            "Epoch 25, Step 31, Loss: 0.013687551952898502\n",
            "Epoch 25, Step 32, Loss: 0.008907239884138107\n",
            "Epoch 25, Step 33, Loss: 0.006817036308348179\n",
            "Epoch 25, Step 34, Loss: 0.011730295605957508\n",
            "Epoch 25, Step 35, Loss: 0.011524008587002754\n",
            "Epoch 25, Step 36, Loss: 0.009535618126392365\n",
            "Epoch 25, Step 37, Loss: 0.014293964020907879\n",
            "Epoch 25, Step 38, Loss: 0.01588723063468933\n",
            "Epoch 25, Step 39, Loss: 0.013652092777192593\n",
            "Epoch 25, Step 40, Loss: 0.01284234132617712\n",
            "Epoch 25, Step 41, Loss: 0.014851745218038559\n",
            "Epoch 25, Step 42, Loss: 0.01026537362486124\n",
            "Epoch 25, Step 43, Loss: 0.011301900260150433\n",
            "Epoch 25, Step 44, Loss: 0.010166583582758904\n",
            "Epoch 25, Step 45, Loss: 0.009687417186796665\n",
            "Epoch 25, Step 46, Loss: 0.011458412744104862\n",
            "Epoch 25, Step 47, Loss: 0.015258521772921085\n",
            "Epoch 25, Step 48, Loss: 0.014794733375310898\n",
            "Epoch 25, Step 49, Loss: 0.015390090644359589\n",
            "Epoch 25, Step 50, Loss: 0.014001826755702496\n",
            "Epoch 25, Step 51, Loss: 0.01210145466029644\n",
            "Epoch 25, Step 52, Loss: 0.01083778589963913\n",
            "Epoch 25, Step 53, Loss: 0.011260566301643848\n",
            "Train Metric MRRs: 0.11467701355102966\n",
            "Train Metric MAPs: 0.05817481171806974\n",
            "Validation Metric MRRs: 0.25722566740392255\n",
            "Validation Metric MAPs: 0.1520653453570754\n",
            "Epoch 26, Step 1, Loss: 0.01956036314368248\n",
            "Epoch 26, Step 2, Loss: 0.023883255198597908\n",
            "Epoch 26, Step 3, Loss: 0.021640930324792862\n",
            "Epoch 26, Step 4, Loss: 0.01739819161593914\n",
            "Epoch 26, Step 5, Loss: 0.021759554743766785\n",
            "Epoch 26, Step 6, Loss: 0.023549649864435196\n",
            "Epoch 26, Step 7, Loss: 0.021382363513112068\n",
            "Epoch 26, Step 8, Loss: 0.01858959160745144\n",
            "Epoch 26, Step 9, Loss: 0.026359882205724716\n",
            "Epoch 26, Step 10, Loss: 0.017660807818174362\n",
            "Epoch 26, Step 11, Loss: 0.01311210636049509\n",
            "Epoch 26, Step 12, Loss: 0.014274363406002522\n",
            "Epoch 26, Step 13, Loss: 0.016731565818190575\n",
            "Epoch 26, Step 14, Loss: 0.012348107993602753\n",
            "Epoch 26, Step 15, Loss: 0.015468218363821507\n",
            "Epoch 26, Step 16, Loss: 0.017695564776659012\n",
            "Epoch 26, Step 17, Loss: 0.012848902493715286\n",
            "Epoch 26, Step 18, Loss: 0.012442227452993393\n",
            "Epoch 26, Step 19, Loss: 0.006350425537675619\n",
            "Epoch 26, Step 20, Loss: 0.006181919015944004\n",
            "Epoch 26, Step 21, Loss: 0.005177384242415428\n",
            "Epoch 26, Step 22, Loss: 0.007092182524502277\n",
            "Epoch 26, Step 23, Loss: 0.006467809434980154\n",
            "Epoch 26, Step 24, Loss: 0.017455732449889183\n",
            "Epoch 26, Step 25, Loss: 0.014114008285105228\n",
            "Epoch 26, Step 26, Loss: 0.012765913270413876\n",
            "Epoch 26, Step 27, Loss: 0.012571596540510654\n",
            "Epoch 26, Step 28, Loss: 0.015313029289245605\n",
            "Epoch 26, Step 29, Loss: 0.015203733928501606\n",
            "Epoch 26, Step 30, Loss: 0.013183400966227055\n",
            "Epoch 26, Step 31, Loss: 0.014211183413863182\n",
            "Epoch 26, Step 32, Loss: 0.009147477336227894\n",
            "Epoch 26, Step 33, Loss: 0.0070415036752820015\n",
            "Epoch 26, Step 34, Loss: 0.012028047814965248\n",
            "Epoch 26, Step 35, Loss: 0.012107388116419315\n",
            "Epoch 26, Step 36, Loss: 0.009316044859588146\n",
            "Epoch 26, Step 37, Loss: 0.015152587555348873\n",
            "Epoch 26, Step 38, Loss: 0.016710128635168076\n",
            "Epoch 26, Step 39, Loss: 0.013907043263316154\n",
            "Epoch 26, Step 40, Loss: 0.01332146767526865\n",
            "Epoch 26, Step 41, Loss: 0.015044021420180798\n",
            "Epoch 26, Step 42, Loss: 0.010794070549309254\n",
            "Epoch 26, Step 43, Loss: 0.011795553378760815\n",
            "Epoch 26, Step 44, Loss: 0.01135390903800726\n",
            "Epoch 26, Step 45, Loss: 0.009848869405686855\n",
            "Epoch 26, Step 46, Loss: 0.0103676225990057\n",
            "Epoch 26, Step 47, Loss: 0.0145267890766263\n",
            "Epoch 26, Step 48, Loss: 0.014298439025878906\n",
            "Epoch 26, Step 49, Loss: 0.015187007375061512\n",
            "Epoch 26, Step 50, Loss: 0.013790054246783257\n",
            "Epoch 26, Step 51, Loss: 0.012056868523359299\n",
            "Epoch 26, Step 52, Loss: 0.011472496204078197\n",
            "Epoch 26, Step 53, Loss: 0.011051361449062824\n",
            "Train Metric MRRs: 0.12110182244191363\n",
            "Train Metric MAPs: 0.05581922279453743\n",
            "Validation Metric MRRs: 0.26083366137161335\n",
            "Validation Metric MAPs: 0.13657327673896202\n",
            "Epoch 27, Step 1, Loss: 0.01996380090713501\n",
            "Epoch 27, Step 2, Loss: 0.023569991812109947\n",
            "Epoch 27, Step 3, Loss: 0.021007858216762543\n",
            "Epoch 27, Step 4, Loss: 0.01672692410647869\n",
            "Epoch 27, Step 5, Loss: 0.020652983337640762\n",
            "Epoch 27, Step 6, Loss: 0.022964749485254288\n",
            "Epoch 27, Step 7, Loss: 0.022476820275187492\n",
            "Epoch 27, Step 8, Loss: 0.01903541572391987\n",
            "Epoch 27, Step 9, Loss: 0.02663397789001465\n",
            "Epoch 27, Step 10, Loss: 0.01767515204846859\n",
            "Epoch 27, Step 11, Loss: 0.013123095966875553\n",
            "Epoch 27, Step 12, Loss: 0.013950932770967484\n",
            "Epoch 27, Step 13, Loss: 0.016536680981516838\n",
            "Epoch 27, Step 14, Loss: 0.011859644204378128\n",
            "Epoch 27, Step 15, Loss: 0.015092981047928333\n",
            "Epoch 27, Step 16, Loss: 0.017338545992970467\n",
            "Epoch 27, Step 17, Loss: 0.012818570248782635\n",
            "Epoch 27, Step 18, Loss: 0.012170926667749882\n",
            "Epoch 27, Step 19, Loss: 0.006556674372404814\n",
            "Epoch 27, Step 20, Loss: 0.006376562174409628\n",
            "Epoch 27, Step 21, Loss: 0.005341389216482639\n",
            "Epoch 27, Step 22, Loss: 0.006866049021482468\n",
            "Epoch 27, Step 23, Loss: 0.006376373581588268\n",
            "Epoch 27, Step 24, Loss: 0.01692538894712925\n",
            "Epoch 27, Step 25, Loss: 0.014068137854337692\n",
            "Epoch 27, Step 26, Loss: 0.012582210823893547\n",
            "Epoch 27, Step 27, Loss: 0.012228420935571194\n",
            "Epoch 27, Step 28, Loss: 0.01477198675274849\n",
            "Epoch 27, Step 29, Loss: 0.013615203090012074\n",
            "Epoch 27, Step 30, Loss: 0.012113629840314388\n",
            "Epoch 27, Step 31, Loss: 0.012720403261482716\n",
            "Epoch 27, Step 32, Loss: 0.008987468667328358\n",
            "Epoch 27, Step 33, Loss: 0.007081357296556234\n",
            "Epoch 27, Step 34, Loss: 0.010949753224849701\n",
            "Epoch 27, Step 35, Loss: 0.011485655792057514\n",
            "Epoch 27, Step 36, Loss: 0.008932818658649921\n",
            "Epoch 27, Step 37, Loss: 0.014442934654653072\n",
            "Epoch 27, Step 38, Loss: 0.015174823813140392\n",
            "Epoch 27, Step 39, Loss: 0.013361849822103977\n",
            "Epoch 27, Step 40, Loss: 0.012198500335216522\n",
            "Epoch 27, Step 41, Loss: 0.015045439824461937\n",
            "Epoch 27, Step 42, Loss: 0.010375576093792915\n",
            "Epoch 27, Step 43, Loss: 0.010828250087797642\n",
            "Epoch 27, Step 44, Loss: 0.01034652441740036\n",
            "Epoch 27, Step 45, Loss: 0.010133672505617142\n",
            "Epoch 27, Step 46, Loss: 0.010756207630038261\n",
            "Epoch 27, Step 47, Loss: 0.014546412974596024\n",
            "Epoch 27, Step 48, Loss: 0.014443491585552692\n",
            "Epoch 27, Step 49, Loss: 0.014236566610634327\n",
            "Epoch 27, Step 50, Loss: 0.015062207356095314\n",
            "Epoch 27, Step 51, Loss: 0.010893839411437511\n",
            "Epoch 27, Step 52, Loss: 0.011326390318572521\n",
            "Epoch 27, Step 53, Loss: 0.009849089197814465\n",
            "Train Metric MRRs: 0.12293778464917983\n",
            "Train Metric MAPs: 0.06285535997193745\n",
            "Validation Metric MRRs: 0.2698904619829582\n",
            "Validation Metric MAPs: 0.1199328615966682\n",
            "Epoch 28, Step 1, Loss: 0.019126439467072487\n",
            "Epoch 28, Step 2, Loss: 0.023901544511318207\n",
            "Epoch 28, Step 3, Loss: 0.022238600999116898\n",
            "Epoch 28, Step 4, Loss: 0.017175009474158287\n",
            "Epoch 28, Step 5, Loss: 0.022591767832636833\n",
            "Epoch 28, Step 6, Loss: 0.022834768518805504\n",
            "Epoch 28, Step 7, Loss: 0.021208949387073517\n",
            "Epoch 28, Step 8, Loss: 0.018925191834568977\n",
            "Epoch 28, Step 9, Loss: 0.026852039620280266\n",
            "Epoch 28, Step 10, Loss: 0.01829812489449978\n",
            "Epoch 28, Step 11, Loss: 0.013068950735032558\n",
            "Epoch 28, Step 12, Loss: 0.014016544446349144\n",
            "Epoch 28, Step 13, Loss: 0.016183409839868546\n",
            "Epoch 28, Step 14, Loss: 0.012404395267367363\n",
            "Epoch 28, Step 15, Loss: 0.015332075767219067\n",
            "Epoch 28, Step 16, Loss: 0.01764746569097042\n",
            "Epoch 28, Step 17, Loss: 0.013066781684756279\n",
            "Epoch 28, Step 18, Loss: 0.012371745891869068\n",
            "Epoch 28, Step 19, Loss: 0.006417690776288509\n",
            "Epoch 28, Step 20, Loss: 0.006087164394557476\n",
            "Epoch 28, Step 21, Loss: 0.0053819031454622746\n",
            "Epoch 28, Step 22, Loss: 0.006869331933557987\n",
            "Epoch 28, Step 23, Loss: 0.006500718649476767\n",
            "Epoch 28, Step 24, Loss: 0.01760019361972809\n",
            "Epoch 28, Step 25, Loss: 0.013762539252638817\n",
            "Epoch 28, Step 26, Loss: 0.013049142435193062\n",
            "Epoch 28, Step 27, Loss: 0.012356949038803577\n",
            "Epoch 28, Step 28, Loss: 0.015312658622860909\n",
            "Epoch 28, Step 29, Loss: 0.01389163825660944\n",
            "Epoch 28, Step 30, Loss: 0.013171599246561527\n",
            "Epoch 28, Step 31, Loss: 0.013108697719871998\n",
            "Epoch 28, Step 32, Loss: 0.009013439528644085\n",
            "Epoch 28, Step 33, Loss: 0.006831384729593992\n",
            "Epoch 28, Step 34, Loss: 0.01118636503815651\n",
            "Epoch 28, Step 35, Loss: 0.011711129918694496\n",
            "Epoch 28, Step 36, Loss: 0.009031297639012337\n",
            "Epoch 28, Step 37, Loss: 0.014200610108673573\n",
            "Epoch 28, Step 38, Loss: 0.014921232126653194\n",
            "Epoch 28, Step 39, Loss: 0.013994746841490269\n",
            "Epoch 28, Step 40, Loss: 0.013087425380945206\n",
            "Epoch 28, Step 41, Loss: 0.014890875667333603\n",
            "Epoch 28, Step 42, Loss: 0.010495346039533615\n",
            "Epoch 28, Step 43, Loss: 0.01067044772207737\n",
            "Epoch 28, Step 44, Loss: 0.010108290240168571\n",
            "Epoch 28, Step 45, Loss: 0.009796511381864548\n",
            "Epoch 28, Step 46, Loss: 0.010744198225438595\n",
            "Epoch 28, Step 47, Loss: 0.015205246396362782\n",
            "Epoch 28, Step 48, Loss: 0.014144636690616608\n",
            "Epoch 28, Step 49, Loss: 0.013700961135327816\n",
            "Epoch 28, Step 50, Loss: 0.012821679934859276\n",
            "Epoch 28, Step 51, Loss: 0.010710553266108036\n",
            "Epoch 28, Step 52, Loss: 0.012536182068288326\n",
            "Epoch 28, Step 53, Loss: 0.009694402106106281\n",
            "Train Metric MRRs: 0.12512076484070997\n",
            "Train Metric MAPs: 0.05703783336964915\n",
            "Validation Metric MRRs: 0.2648110871166469\n",
            "Validation Metric MAPs: 0.11730270035957074\n",
            "Epoch 29, Step 1, Loss: 0.018528303131461143\n",
            "Epoch 29, Step 2, Loss: 0.022753190249204636\n",
            "Epoch 29, Step 3, Loss: 0.021146712824702263\n",
            "Epoch 29, Step 4, Loss: 0.016784608364105225\n",
            "Epoch 29, Step 5, Loss: 0.021408800035715103\n",
            "Epoch 29, Step 6, Loss: 0.022397903725504875\n",
            "Epoch 29, Step 7, Loss: 0.02067776955664158\n",
            "Epoch 29, Step 8, Loss: 0.018724782392382622\n",
            "Epoch 29, Step 9, Loss: 0.026757288724184036\n",
            "Epoch 29, Step 10, Loss: 0.017826369032263756\n",
            "Epoch 29, Step 11, Loss: 0.013215896673500538\n",
            "Epoch 29, Step 12, Loss: 0.013867822475731373\n",
            "Epoch 29, Step 13, Loss: 0.015534801408648491\n",
            "Epoch 29, Step 14, Loss: 0.011828945949673653\n",
            "Epoch 29, Step 15, Loss: 0.014712057076394558\n",
            "Epoch 29, Step 16, Loss: 0.017347197979688644\n",
            "Epoch 29, Step 17, Loss: 0.012883991934359074\n",
            "Epoch 29, Step 18, Loss: 0.012275774963200092\n",
            "Epoch 29, Step 19, Loss: 0.006520372815430164\n",
            "Epoch 29, Step 20, Loss: 0.005962208844721317\n",
            "Epoch 29, Step 21, Loss: 0.005060087889432907\n",
            "Epoch 29, Step 22, Loss: 0.006907200440764427\n",
            "Epoch 29, Step 23, Loss: 0.00658573629334569\n",
            "Epoch 29, Step 24, Loss: 0.016322461888194084\n",
            "Epoch 29, Step 25, Loss: 0.0141321225091815\n",
            "Epoch 29, Step 26, Loss: 0.012460187077522278\n",
            "Epoch 29, Step 27, Loss: 0.011811019852757454\n",
            "Epoch 29, Step 28, Loss: 0.014494209550321102\n",
            "Epoch 29, Step 29, Loss: 0.013275298289954662\n",
            "Epoch 29, Step 30, Loss: 0.012306665070354939\n",
            "Epoch 29, Step 31, Loss: 0.012923150323331356\n",
            "Epoch 29, Step 32, Loss: 0.008511334657669067\n",
            "Epoch 29, Step 33, Loss: 0.006570346653461456\n",
            "Epoch 29, Step 34, Loss: 0.011218336410820484\n",
            "Epoch 29, Step 35, Loss: 0.011350099928677082\n",
            "Epoch 29, Step 36, Loss: 0.009099528193473816\n",
            "Epoch 29, Step 37, Loss: 0.01405902486294508\n",
            "Epoch 29, Step 38, Loss: 0.014548643492162228\n",
            "Epoch 29, Step 39, Loss: 0.013110321946442127\n",
            "Epoch 29, Step 40, Loss: 0.011966563761234283\n",
            "Epoch 29, Step 41, Loss: 0.015171019360423088\n",
            "Epoch 29, Step 42, Loss: 0.010817787609994411\n",
            "Epoch 29, Step 43, Loss: 0.010289768688380718\n",
            "Epoch 29, Step 44, Loss: 0.009676728397607803\n",
            "Epoch 29, Step 45, Loss: 0.009684362448751926\n",
            "Epoch 29, Step 46, Loss: 0.010580236092209816\n",
            "Epoch 29, Step 47, Loss: 0.0149315120652318\n",
            "Epoch 29, Step 48, Loss: 0.013375825248658657\n",
            "Epoch 29, Step 49, Loss: 0.013875337317585945\n",
            "Epoch 29, Step 50, Loss: 0.01290819700807333\n",
            "Epoch 29, Step 51, Loss: 0.010996876284480095\n",
            "Epoch 29, Step 52, Loss: 0.009846051223576069\n",
            "Epoch 29, Step 53, Loss: 0.009965064935386181\n",
            "Train Metric MRRs: 0.13729182991446612\n",
            "Train Metric MAPs: 0.05591827573185464\n",
            "Validation Metric MRRs: 0.27410945872413717\n",
            "Validation Metric MAPs: 0.11851336382032805\n",
            "Epoch 30, Step 1, Loss: 0.017951155081391335\n",
            "Epoch 30, Step 2, Loss: 0.023055218160152435\n",
            "Epoch 30, Step 3, Loss: 0.02127925492823124\n",
            "Epoch 30, Step 4, Loss: 0.01702963560819626\n",
            "Epoch 30, Step 5, Loss: 0.022436831146478653\n",
            "Epoch 30, Step 6, Loss: 0.022887159138917923\n",
            "Epoch 30, Step 7, Loss: 0.020491983741521835\n",
            "Epoch 30, Step 8, Loss: 0.018379492685198784\n",
            "Epoch 30, Step 9, Loss: 0.026496868580579758\n",
            "Epoch 30, Step 10, Loss: 0.017807869240641594\n",
            "Epoch 30, Step 11, Loss: 0.013741709291934967\n",
            "Epoch 30, Step 12, Loss: 0.014077061787247658\n",
            "Epoch 30, Step 13, Loss: 0.015825308859348297\n",
            "Epoch 30, Step 14, Loss: 0.012001145631074905\n",
            "Epoch 30, Step 15, Loss: 0.01465643011033535\n",
            "Epoch 30, Step 16, Loss: 0.017431193962693214\n",
            "Epoch 30, Step 17, Loss: 0.012729216367006302\n",
            "Epoch 30, Step 18, Loss: 0.012384800240397453\n",
            "Epoch 30, Step 19, Loss: 0.006485268007963896\n",
            "Epoch 30, Step 20, Loss: 0.006187476683408022\n",
            "Epoch 30, Step 21, Loss: 0.005049468018114567\n",
            "Epoch 30, Step 22, Loss: 0.0069071343168616295\n",
            "Epoch 30, Step 23, Loss: 0.006417770870029926\n",
            "Epoch 30, Step 24, Loss: 0.017647406086325645\n",
            "Epoch 30, Step 25, Loss: 0.014333602972328663\n",
            "Epoch 30, Step 26, Loss: 0.012509502470493317\n",
            "Epoch 30, Step 27, Loss: 0.01233460009098053\n",
            "Epoch 30, Step 28, Loss: 0.015234652906656265\n",
            "Epoch 30, Step 29, Loss: 0.014272945001721382\n",
            "Epoch 30, Step 30, Loss: 0.013419266790151596\n",
            "Epoch 30, Step 31, Loss: 0.013415679335594177\n",
            "Epoch 30, Step 32, Loss: 0.008867710828781128\n",
            "Epoch 30, Step 33, Loss: 0.006638547871261835\n",
            "Epoch 30, Step 34, Loss: 0.011320531368255615\n",
            "Epoch 30, Step 35, Loss: 0.011807356029748917\n",
            "Epoch 30, Step 36, Loss: 0.009153313003480434\n",
            "Epoch 30, Step 37, Loss: 0.014184948988258839\n",
            "Epoch 30, Step 38, Loss: 0.014720299281179905\n",
            "Epoch 30, Step 39, Loss: 0.013346533291041851\n",
            "Epoch 30, Step 40, Loss: 0.012195796705782413\n",
            "Epoch 30, Step 41, Loss: 0.016091488301753998\n",
            "Epoch 30, Step 42, Loss: 0.010188999585807323\n",
            "Epoch 30, Step 43, Loss: 0.010385419242084026\n",
            "Epoch 30, Step 44, Loss: 0.009587818756699562\n",
            "Epoch 30, Step 45, Loss: 0.00964258424937725\n",
            "Epoch 30, Step 46, Loss: 0.010423501953482628\n",
            "Epoch 30, Step 47, Loss: 0.015342471189796925\n",
            "Epoch 30, Step 48, Loss: 0.01344938762485981\n",
            "Epoch 30, Step 49, Loss: 0.01462410669773817\n",
            "Epoch 30, Step 50, Loss: 0.013027123175561428\n",
            "Epoch 30, Step 51, Loss: 0.010239328257739544\n",
            "Epoch 30, Step 52, Loss: 0.009423919953405857\n",
            "Epoch 30, Step 53, Loss: 0.010179389268159866\n",
            "Train Metric MRRs: 0.14333689156082483\n",
            "Train Metric MAPs: 0.05127413847217823\n",
            "Validation Metric MRRs: 0.2555104327921403\n",
            "Validation Metric MAPs: 0.13478369518641276\n",
            "Epoch 31, Step 1, Loss: 0.018297770991921425\n",
            "Epoch 31, Step 2, Loss: 0.022934580221772194\n",
            "Epoch 31, Step 3, Loss: 0.019901489838957787\n",
            "Epoch 31, Step 4, Loss: 0.01602143980562687\n",
            "Epoch 31, Step 5, Loss: 0.02069171704351902\n",
            "Epoch 31, Step 6, Loss: 0.022285563871264458\n",
            "Epoch 31, Step 7, Loss: 0.020844342187047005\n",
            "Epoch 31, Step 8, Loss: 0.01911633089184761\n",
            "Epoch 31, Step 9, Loss: 0.0272221677005291\n",
            "Epoch 31, Step 10, Loss: 0.017583411186933517\n",
            "Epoch 31, Step 11, Loss: 0.012810957618057728\n",
            "Epoch 31, Step 12, Loss: 0.013671674765646458\n",
            "Epoch 31, Step 13, Loss: 0.015526105649769306\n",
            "Epoch 31, Step 14, Loss: 0.012568698264658451\n",
            "Epoch 31, Step 15, Loss: 0.014353837817907333\n",
            "Epoch 31, Step 16, Loss: 0.017190543934702873\n",
            "Epoch 31, Step 17, Loss: 0.013196845538914204\n",
            "Epoch 31, Step 18, Loss: 0.012320543639361858\n",
            "Epoch 31, Step 19, Loss: 0.006677982397377491\n",
            "Epoch 31, Step 20, Loss: 0.006159067153930664\n",
            "Epoch 31, Step 21, Loss: 0.005028444807976484\n",
            "Epoch 31, Step 22, Loss: 0.006901850923895836\n",
            "Epoch 31, Step 23, Loss: 0.006522248033434153\n",
            "Epoch 31, Step 24, Loss: 0.015870708972215652\n",
            "Epoch 31, Step 25, Loss: 0.013876236975193024\n",
            "Epoch 31, Step 26, Loss: 0.011948244646191597\n",
            "Epoch 31, Step 27, Loss: 0.01136633288115263\n",
            "Epoch 31, Step 28, Loss: 0.013874969445168972\n",
            "Epoch 31, Step 29, Loss: 0.012960609048604965\n",
            "Epoch 31, Step 30, Loss: 0.012277993373572826\n",
            "Epoch 31, Step 31, Loss: 0.012529551051557064\n",
            "Epoch 31, Step 32, Loss: 0.008498121984302998\n",
            "Epoch 31, Step 33, Loss: 0.0063178217969834805\n",
            "Epoch 31, Step 34, Loss: 0.01137105654925108\n",
            "Epoch 31, Step 35, Loss: 0.01169787161052227\n",
            "Epoch 31, Step 36, Loss: 0.008206227794289589\n",
            "Epoch 31, Step 37, Loss: 0.014414669014513493\n",
            "Epoch 31, Step 38, Loss: 0.014246420003473759\n",
            "Epoch 31, Step 39, Loss: 0.013373413123190403\n",
            "Epoch 31, Step 40, Loss: 0.012831113301217556\n",
            "Epoch 31, Step 41, Loss: 0.014574241824448109\n",
            "Epoch 31, Step 42, Loss: 0.009892620146274567\n",
            "Epoch 31, Step 43, Loss: 0.01049548014998436\n",
            "Epoch 31, Step 44, Loss: 0.010088480077683926\n",
            "Epoch 31, Step 45, Loss: 0.009770401753485203\n",
            "Epoch 31, Step 46, Loss: 0.010170893743634224\n",
            "Epoch 31, Step 47, Loss: 0.01462537981569767\n",
            "Epoch 31, Step 48, Loss: 0.013712936080992222\n",
            "Epoch 31, Step 49, Loss: 0.015408115461468697\n",
            "Epoch 31, Step 50, Loss: 0.013689338229596615\n",
            "Epoch 31, Step 51, Loss: 0.011866828426718712\n",
            "Epoch 31, Step 52, Loss: 0.009700743481516838\n",
            "Epoch 31, Step 53, Loss: 0.01051628589630127\n",
            "Train Metric MRRs: 0.14900408368801252\n",
            "Train Metric MAPs: 0.06319672790331844\n",
            "Validation Metric MRRs: 0.2723976854432964\n",
            "Validation Metric MAPs: 0.12550679277563734\n",
            "Epoch 32, Step 1, Loss: 0.017780547961592674\n",
            "Epoch 32, Step 2, Loss: 0.021548325195908546\n",
            "Epoch 32, Step 3, Loss: 0.019926367327570915\n",
            "Epoch 32, Step 4, Loss: 0.015651511028409004\n",
            "Epoch 32, Step 5, Loss: 0.020077217370271683\n",
            "Epoch 32, Step 6, Loss: 0.02183113619685173\n",
            "Epoch 32, Step 7, Loss: 0.01989884115755558\n",
            "Epoch 32, Step 8, Loss: 0.01825997605919838\n",
            "Epoch 32, Step 9, Loss: 0.025738826021552086\n",
            "Epoch 32, Step 10, Loss: 0.01717781275510788\n",
            "Epoch 32, Step 11, Loss: 0.012745884247124195\n",
            "Epoch 32, Step 12, Loss: 0.013701023533940315\n",
            "Epoch 32, Step 13, Loss: 0.015599672682583332\n",
            "Epoch 32, Step 14, Loss: 0.011947868391871452\n",
            "Epoch 32, Step 15, Loss: 0.013915007933974266\n",
            "Epoch 32, Step 16, Loss: 0.015806354582309723\n",
            "Epoch 32, Step 17, Loss: 0.012698546051979065\n",
            "Epoch 32, Step 18, Loss: 0.01185750775039196\n",
            "Epoch 32, Step 19, Loss: 0.00657770037651062\n",
            "Epoch 32, Step 20, Loss: 0.006231519393622875\n",
            "Epoch 32, Step 21, Loss: 0.00515920203179121\n",
            "Epoch 32, Step 22, Loss: 0.0066963061690330505\n",
            "Epoch 32, Step 23, Loss: 0.006486924830824137\n",
            "Epoch 32, Step 24, Loss: 0.015197651460766792\n",
            "Epoch 32, Step 25, Loss: 0.013306993991136551\n",
            "Epoch 32, Step 26, Loss: 0.011881002224981785\n",
            "Epoch 32, Step 27, Loss: 0.010997993871569633\n",
            "Epoch 32, Step 28, Loss: 0.013694980181753635\n",
            "Epoch 32, Step 29, Loss: 0.012300749309360981\n",
            "Epoch 32, Step 30, Loss: 0.01265646331012249\n",
            "Epoch 32, Step 31, Loss: 0.011904099956154823\n",
            "Epoch 32, Step 32, Loss: 0.0085471011698246\n",
            "Epoch 32, Step 33, Loss: 0.006486217956990004\n",
            "Epoch 32, Step 34, Loss: 0.012396159581840038\n",
            "Epoch 32, Step 35, Loss: 0.011510301381349564\n",
            "Epoch 32, Step 36, Loss: 0.00829978659749031\n",
            "Epoch 32, Step 37, Loss: 0.013768235221505165\n",
            "Epoch 32, Step 38, Loss: 0.014247486367821693\n",
            "Epoch 32, Step 39, Loss: 0.012959910556674004\n",
            "Epoch 32, Step 40, Loss: 0.011893757618963718\n",
            "Epoch 32, Step 41, Loss: 0.014084900729358196\n",
            "Epoch 32, Step 42, Loss: 0.00931267999112606\n",
            "Epoch 32, Step 43, Loss: 0.010127418674528599\n",
            "Epoch 32, Step 44, Loss: 0.009702371433377266\n",
            "Epoch 32, Step 45, Loss: 0.010005192831158638\n",
            "Epoch 32, Step 46, Loss: 0.010968386195600033\n",
            "Epoch 32, Step 47, Loss: 0.015758724883198738\n",
            "Epoch 32, Step 48, Loss: 0.014837522059679031\n",
            "Epoch 32, Step 49, Loss: 0.014301094226539135\n",
            "Epoch 32, Step 50, Loss: 0.013341621495783329\n",
            "Epoch 32, Step 51, Loss: 0.012853117659687996\n",
            "Epoch 32, Step 52, Loss: 0.009705337695777416\n",
            "Epoch 32, Step 53, Loss: 0.010135226882994175\n",
            "Train Metric MRRs: 0.1550820170174384\n",
            "Train Metric MAPs: 0.06278895922872405\n",
            "Validation Metric MRRs: 0.2642921975216014\n",
            "Validation Metric MAPs: 0.13932441025475256\n",
            "Epoch 33, Step 1, Loss: 0.017646241933107376\n",
            "Epoch 33, Step 2, Loss: 0.021770985797047615\n",
            "Epoch 33, Step 3, Loss: 0.02004851959645748\n",
            "Epoch 33, Step 4, Loss: 0.015942387282848358\n",
            "Epoch 33, Step 5, Loss: 0.021478930488228798\n",
            "Epoch 33, Step 6, Loss: 0.021940359845757484\n",
            "Epoch 33, Step 7, Loss: 0.01963910646736622\n",
            "Epoch 33, Step 8, Loss: 0.017719166353344917\n",
            "Epoch 33, Step 9, Loss: 0.026144523173570633\n",
            "Epoch 33, Step 10, Loss: 0.016737261787056923\n",
            "Epoch 33, Step 11, Loss: 0.012256261892616749\n",
            "Epoch 33, Step 12, Loss: 0.01334855891764164\n",
            "Epoch 33, Step 13, Loss: 0.014581716619431973\n",
            "Epoch 33, Step 14, Loss: 0.011551788076758385\n",
            "Epoch 33, Step 15, Loss: 0.014014608226716518\n",
            "Epoch 33, Step 16, Loss: 0.015318343415856361\n",
            "Epoch 33, Step 17, Loss: 0.012653199024498463\n",
            "Epoch 33, Step 18, Loss: 0.012196538038551807\n",
            "Epoch 33, Step 19, Loss: 0.006116061937063932\n",
            "Epoch 33, Step 20, Loss: 0.005698077380657196\n",
            "Epoch 33, Step 21, Loss: 0.004712666850537062\n",
            "Epoch 33, Step 22, Loss: 0.00622770469635725\n",
            "Epoch 33, Step 23, Loss: 0.00613377382978797\n",
            "Epoch 33, Step 24, Loss: 0.015996739268302917\n",
            "Epoch 33, Step 25, Loss: 0.013220108114182949\n",
            "Epoch 33, Step 26, Loss: 0.011696365661919117\n",
            "Epoch 33, Step 27, Loss: 0.011076289229094982\n",
            "Epoch 33, Step 28, Loss: 0.014049447141587734\n",
            "Epoch 33, Step 29, Loss: 0.012592154555022717\n",
            "Epoch 33, Step 30, Loss: 0.013186682015657425\n",
            "Epoch 33, Step 31, Loss: 0.01192195899784565\n",
            "Epoch 33, Step 32, Loss: 0.00843631662428379\n",
            "Epoch 33, Step 33, Loss: 0.006009230390191078\n",
            "Epoch 33, Step 34, Loss: 0.010427595116198063\n",
            "Epoch 33, Step 35, Loss: 0.011427514255046844\n",
            "Epoch 33, Step 36, Loss: 0.008436060510575771\n",
            "Epoch 33, Step 37, Loss: 0.013928666710853577\n",
            "Epoch 33, Step 38, Loss: 0.013838685117661953\n",
            "Epoch 33, Step 39, Loss: 0.01279315073043108\n",
            "Epoch 33, Step 40, Loss: 0.013276053592562675\n",
            "Epoch 33, Step 41, Loss: 0.013768188655376434\n",
            "Epoch 33, Step 42, Loss: 0.008957724086940289\n",
            "Epoch 33, Step 43, Loss: 0.009903771802783012\n",
            "Epoch 33, Step 44, Loss: 0.009912352077662945\n",
            "Epoch 33, Step 45, Loss: 0.009994679130613804\n",
            "Epoch 33, Step 46, Loss: 0.010689401999115944\n",
            "Epoch 33, Step 47, Loss: 0.014817604795098305\n",
            "Epoch 33, Step 48, Loss: 0.013547143898904324\n",
            "Epoch 33, Step 49, Loss: 0.013217012397944927\n",
            "Epoch 33, Step 50, Loss: 0.015380915254354477\n",
            "Epoch 33, Step 51, Loss: 0.014669720083475113\n",
            "Epoch 33, Step 52, Loss: 0.010070865042507648\n",
            "Epoch 33, Step 53, Loss: 0.009438452310860157\n",
            "Train Metric MRRs: 0.16229249354935749\n",
            "Train Metric MAPs: 0.059356275299053976\n",
            "Validation Metric MRRs: 0.2814632741881798\n",
            "Validation Metric MAPs: 0.13522281395129804\n",
            "Epoch 34, Step 1, Loss: 0.01777307502925396\n",
            "Epoch 34, Step 2, Loss: 0.02120436355471611\n",
            "Epoch 34, Step 3, Loss: 0.019548146054148674\n",
            "Epoch 34, Step 4, Loss: 0.015567895956337452\n",
            "Epoch 34, Step 5, Loss: 0.020373160019516945\n",
            "Epoch 34, Step 6, Loss: 0.021787693724036217\n",
            "Epoch 34, Step 7, Loss: 0.019692974165081978\n",
            "Epoch 34, Step 8, Loss: 0.018709806725382805\n",
            "Epoch 34, Step 9, Loss: 0.025869542732834816\n",
            "Epoch 34, Step 10, Loss: 0.017002057284116745\n",
            "Epoch 34, Step 11, Loss: 0.012485242448747158\n",
            "Epoch 34, Step 12, Loss: 0.013336903415620327\n",
            "Epoch 34, Step 13, Loss: 0.015105098485946655\n",
            "Epoch 34, Step 14, Loss: 0.012107220478355885\n",
            "Epoch 34, Step 15, Loss: 0.013855927623808384\n",
            "Epoch 34, Step 16, Loss: 0.0152910640463233\n",
            "Epoch 34, Step 17, Loss: 0.012346168980002403\n",
            "Epoch 34, Step 18, Loss: 0.0116256820037961\n",
            "Epoch 34, Step 19, Loss: 0.006592432968318462\n",
            "Epoch 34, Step 20, Loss: 0.005914672743529081\n",
            "Epoch 34, Step 21, Loss: 0.004686742089688778\n",
            "Epoch 34, Step 22, Loss: 0.00636661984026432\n",
            "Epoch 34, Step 23, Loss: 0.006391159724444151\n",
            "Epoch 34, Step 24, Loss: 0.014676962047815323\n",
            "Epoch 34, Step 25, Loss: 0.013017748482525349\n",
            "Epoch 34, Step 26, Loss: 0.01159126590937376\n",
            "Epoch 34, Step 27, Loss: 0.011369146406650543\n",
            "Epoch 34, Step 28, Loss: 0.014028348959982395\n",
            "Epoch 34, Step 29, Loss: 0.01237877830862999\n",
            "Epoch 34, Step 30, Loss: 0.012002603150904179\n",
            "Epoch 34, Step 31, Loss: 0.011957547627389431\n",
            "Epoch 34, Step 32, Loss: 0.008485977537930012\n",
            "Epoch 34, Step 33, Loss: 0.006047714501619339\n",
            "Epoch 34, Step 34, Loss: 0.011158211156725883\n",
            "Epoch 34, Step 35, Loss: 0.01143684983253479\n",
            "Epoch 34, Step 36, Loss: 0.008037314750254154\n",
            "Epoch 34, Step 37, Loss: 0.014049222692847252\n",
            "Epoch 34, Step 38, Loss: 0.013998789712786674\n",
            "Epoch 34, Step 39, Loss: 0.01286222878843546\n",
            "Epoch 34, Step 40, Loss: 0.012591865845024586\n",
            "Epoch 34, Step 41, Loss: 0.013283414766192436\n",
            "Epoch 34, Step 42, Loss: 0.009449332021176815\n",
            "Epoch 34, Step 43, Loss: 0.010156845673918724\n",
            "Epoch 34, Step 44, Loss: 0.010684359818696976\n",
            "Epoch 34, Step 45, Loss: 0.010267901234328747\n",
            "Epoch 34, Step 46, Loss: 0.009431980550289154\n",
            "Epoch 34, Step 47, Loss: 0.014738026075065136\n",
            "Epoch 34, Step 48, Loss: 0.014190084300935268\n",
            "Epoch 34, Step 49, Loss: 0.014231034554541111\n",
            "Epoch 34, Step 50, Loss: 0.013328339904546738\n",
            "Epoch 34, Step 51, Loss: 0.010099281556904316\n",
            "Epoch 34, Step 52, Loss: 0.009139341302216053\n",
            "Epoch 34, Step 53, Loss: 0.009870464913547039\n",
            "Train Metric MRRs: 0.15780620279360064\n",
            "Train Metric MAPs: 0.054110756308845105\n",
            "Validation Metric MRRs: 0.2799435154216506\n",
            "Validation Metric MAPs: 0.1127250304881048\n",
            "Epoch 35, Step 1, Loss: 0.018600590527057648\n",
            "Epoch 35, Step 2, Loss: 0.02180442586541176\n",
            "Epoch 35, Step 3, Loss: 0.020857125520706177\n",
            "Epoch 35, Step 4, Loss: 0.016022834926843643\n",
            "Epoch 35, Step 5, Loss: 0.021283362060785294\n",
            "Epoch 35, Step 6, Loss: 0.021532461047172546\n",
            "Epoch 35, Step 7, Loss: 0.01943735033273697\n",
            "Epoch 35, Step 8, Loss: 0.01790652610361576\n",
            "Epoch 35, Step 9, Loss: 0.025811662897467613\n",
            "Epoch 35, Step 10, Loss: 0.016939720138907433\n",
            "Epoch 35, Step 11, Loss: 0.0121273472905159\n",
            "Epoch 35, Step 12, Loss: 0.012949530966579914\n",
            "Epoch 35, Step 13, Loss: 0.014080964028835297\n",
            "Epoch 35, Step 14, Loss: 0.010905949398875237\n",
            "Epoch 35, Step 15, Loss: 0.013316701166331768\n",
            "Epoch 35, Step 16, Loss: 0.015492565929889679\n",
            "Epoch 35, Step 17, Loss: 0.012692310847342014\n",
            "Epoch 35, Step 18, Loss: 0.011725188232958317\n",
            "Epoch 35, Step 19, Loss: 0.006696360185742378\n",
            "Epoch 35, Step 20, Loss: 0.0059354123659431934\n",
            "Epoch 35, Step 21, Loss: 0.004471107851713896\n",
            "Epoch 35, Step 22, Loss: 0.006132243666797876\n",
            "Epoch 35, Step 23, Loss: 0.0057878438383340836\n",
            "Epoch 35, Step 24, Loss: 0.014702611602842808\n",
            "Epoch 35, Step 25, Loss: 0.01299376506358385\n",
            "Epoch 35, Step 26, Loss: 0.011734540574252605\n",
            "Epoch 35, Step 27, Loss: 0.010696927085518837\n",
            "Epoch 35, Step 28, Loss: 0.013447302393615246\n",
            "Epoch 35, Step 29, Loss: 0.011907093226909637\n",
            "Epoch 35, Step 30, Loss: 0.011928417719900608\n",
            "Epoch 35, Step 31, Loss: 0.011658531613647938\n",
            "Epoch 35, Step 32, Loss: 0.008561672642827034\n",
            "Epoch 35, Step 33, Loss: 0.005716640502214432\n",
            "Epoch 35, Step 34, Loss: 0.010376046411693096\n",
            "Epoch 35, Step 35, Loss: 0.011114596389234066\n",
            "Epoch 35, Step 36, Loss: 0.008040446788072586\n",
            "Epoch 35, Step 37, Loss: 0.013884559273719788\n",
            "Epoch 35, Step 38, Loss: 0.014476753771305084\n",
            "Epoch 35, Step 39, Loss: 0.01222927588969469\n",
            "Epoch 35, Step 40, Loss: 0.011732368730008602\n",
            "Epoch 35, Step 41, Loss: 0.013272330164909363\n",
            "Epoch 35, Step 42, Loss: 0.009201429784297943\n",
            "Epoch 35, Step 43, Loss: 0.010116668418049812\n",
            "Epoch 35, Step 44, Loss: 0.009104822762310505\n",
            "Epoch 35, Step 45, Loss: 0.009543251246213913\n",
            "Epoch 35, Step 46, Loss: 0.009069348685443401\n",
            "Epoch 35, Step 47, Loss: 0.013911372981965542\n",
            "Epoch 35, Step 48, Loss: 0.012742849066853523\n",
            "Epoch 35, Step 49, Loss: 0.013547196052968502\n",
            "Epoch 35, Step 50, Loss: 0.011908409185707569\n",
            "Epoch 35, Step 51, Loss: 0.009528083726763725\n",
            "Epoch 35, Step 52, Loss: 0.008755006827414036\n",
            "Epoch 35, Step 53, Loss: 0.010119915008544922\n",
            "Train Metric MRRs: 0.16359561879338258\n",
            "Train Metric MAPs: 0.059301394850693655\n",
            "Validation Metric MRRs: 0.27656458853919236\n",
            "Validation Metric MAPs: 0.1272649987240757\n",
            "Epoch 36, Step 1, Loss: 0.01759033277630806\n",
            "Epoch 36, Step 2, Loss: 0.021112622693181038\n",
            "Epoch 36, Step 3, Loss: 0.02012317255139351\n",
            "Epoch 36, Step 4, Loss: 0.016046497970819473\n",
            "Epoch 36, Step 5, Loss: 0.02118082158267498\n",
            "Epoch 36, Step 6, Loss: 0.021815165877342224\n",
            "Epoch 36, Step 7, Loss: 0.018999120220541954\n",
            "Epoch 36, Step 8, Loss: 0.01751829870045185\n",
            "Epoch 36, Step 9, Loss: 0.02554715797305107\n",
            "Epoch 36, Step 10, Loss: 0.016378827393054962\n",
            "Epoch 36, Step 11, Loss: 0.012049149721860886\n",
            "Epoch 36, Step 12, Loss: 0.013262909837067127\n",
            "Epoch 36, Step 13, Loss: 0.01450980082154274\n",
            "Epoch 36, Step 14, Loss: 0.011147469282150269\n",
            "Epoch 36, Step 15, Loss: 0.013386203907430172\n",
            "Epoch 36, Step 16, Loss: 0.015095675364136696\n",
            "Epoch 36, Step 17, Loss: 0.012106144800782204\n",
            "Epoch 36, Step 18, Loss: 0.01173339132219553\n",
            "Epoch 36, Step 19, Loss: 0.005782823543995619\n",
            "Epoch 36, Step 20, Loss: 0.0057693663984537125\n",
            "Epoch 36, Step 21, Loss: 0.004532563500106335\n",
            "Epoch 36, Step 22, Loss: 0.006041593383997679\n",
            "Epoch 36, Step 23, Loss: 0.005729109980165958\n",
            "Epoch 36, Step 24, Loss: 0.015600026585161686\n",
            "Epoch 36, Step 25, Loss: 0.01274040900170803\n",
            "Epoch 36, Step 26, Loss: 0.011654368601739407\n",
            "Epoch 36, Step 27, Loss: 0.010578218847513199\n",
            "Epoch 36, Step 28, Loss: 0.013731628656387329\n",
            "Epoch 36, Step 29, Loss: 0.011851062066853046\n",
            "Epoch 36, Step 30, Loss: 0.012353334575891495\n",
            "Epoch 36, Step 31, Loss: 0.011848975904285908\n",
            "Epoch 36, Step 32, Loss: 0.008245106786489487\n",
            "Epoch 36, Step 33, Loss: 0.00632608775049448\n",
            "Epoch 36, Step 34, Loss: 0.01017021294683218\n",
            "Epoch 36, Step 35, Loss: 0.011194058693945408\n",
            "Epoch 36, Step 36, Loss: 0.007986815646290779\n",
            "Epoch 36, Step 37, Loss: 0.013293716125190258\n",
            "Epoch 36, Step 38, Loss: 0.013776127249002457\n",
            "Epoch 36, Step 39, Loss: 0.012491638772189617\n",
            "Epoch 36, Step 40, Loss: 0.011370386928319931\n",
            "Epoch 36, Step 41, Loss: 0.012837687507271767\n",
            "Epoch 36, Step 42, Loss: 0.00926271267235279\n",
            "Epoch 36, Step 43, Loss: 0.009130874648690224\n",
            "Epoch 36, Step 44, Loss: 0.008916113525629044\n",
            "Epoch 36, Step 45, Loss: 0.009071056731045246\n",
            "Epoch 36, Step 46, Loss: 0.009321365505456924\n",
            "Epoch 36, Step 47, Loss: 0.014075455255806446\n",
            "Epoch 36, Step 48, Loss: 0.013369203545153141\n",
            "Epoch 36, Step 49, Loss: 0.013722151517868042\n",
            "Epoch 36, Step 50, Loss: 0.011868546716868877\n",
            "Epoch 36, Step 51, Loss: 0.009656217880547047\n",
            "Epoch 36, Step 52, Loss: 0.011618132703006268\n",
            "Epoch 36, Step 53, Loss: 0.009842605330049992\n",
            "Train Metric MRRs: 0.17302306261639844\n",
            "Train Metric MAPs: 0.05616990520586362\n",
            "Validation Metric MRRs: 0.28493468666771843\n",
            "Validation Metric MAPs: 0.13544324181937106\n",
            "Epoch 37, Step 1, Loss: 0.018307743594050407\n",
            "Epoch 37, Step 2, Loss: 0.021582704037427902\n",
            "Epoch 37, Step 3, Loss: 0.02008284069597721\n",
            "Epoch 37, Step 4, Loss: 0.015281379222869873\n",
            "Epoch 37, Step 5, Loss: 0.019717363640666008\n",
            "Epoch 37, Step 6, Loss: 0.021184120327234268\n",
            "Epoch 37, Step 7, Loss: 0.01941519044339657\n",
            "Epoch 37, Step 8, Loss: 0.0176957119256258\n",
            "Epoch 37, Step 9, Loss: 0.025287240743637085\n",
            "Epoch 37, Step 10, Loss: 0.01668681763112545\n",
            "Epoch 37, Step 11, Loss: 0.012584504671394825\n",
            "Epoch 37, Step 12, Loss: 0.013020469807088375\n",
            "Epoch 37, Step 13, Loss: 0.014164101332426071\n",
            "Epoch 37, Step 14, Loss: 0.010988859459757805\n",
            "Epoch 37, Step 15, Loss: 0.013522793538868427\n",
            "Epoch 37, Step 16, Loss: 0.015190932899713516\n",
            "Epoch 37, Step 17, Loss: 0.01249134261161089\n",
            "Epoch 37, Step 18, Loss: 0.011847835034132004\n",
            "Epoch 37, Step 19, Loss: 0.006876715458929539\n",
            "Epoch 37, Step 20, Loss: 0.005497348960489035\n",
            "Epoch 37, Step 21, Loss: 0.004194018431007862\n",
            "Epoch 37, Step 22, Loss: 0.006135552655905485\n",
            "Epoch 37, Step 23, Loss: 0.005517145618796349\n",
            "Epoch 37, Step 24, Loss: 0.015058041550219059\n",
            "Epoch 37, Step 25, Loss: 0.013124515302479267\n",
            "Epoch 37, Step 26, Loss: 0.0113536287099123\n",
            "Epoch 37, Step 27, Loss: 0.010500327683985233\n",
            "Epoch 37, Step 28, Loss: 0.012976552359759808\n",
            "Epoch 37, Step 29, Loss: 0.01150175929069519\n",
            "Epoch 37, Step 30, Loss: 0.012026740238070488\n",
            "Epoch 37, Step 31, Loss: 0.011407059617340565\n",
            "Epoch 37, Step 32, Loss: 0.007594945840537548\n",
            "Epoch 37, Step 33, Loss: 0.006174289621412754\n",
            "Epoch 37, Step 34, Loss: 0.010406333953142166\n",
            "Epoch 37, Step 35, Loss: 0.010984422639012337\n",
            "Epoch 37, Step 36, Loss: 0.008188902400434017\n",
            "Epoch 37, Step 37, Loss: 0.01342922542244196\n",
            "Epoch 37, Step 38, Loss: 0.01384192705154419\n",
            "Epoch 37, Step 39, Loss: 0.01243441179394722\n",
            "Epoch 37, Step 40, Loss: 0.01108267530798912\n",
            "Epoch 37, Step 41, Loss: 0.013169595040380955\n",
            "Epoch 37, Step 42, Loss: 0.00901841651648283\n",
            "Epoch 37, Step 43, Loss: 0.01029593963176012\n",
            "Epoch 37, Step 44, Loss: 0.009484285488724709\n",
            "Epoch 37, Step 45, Loss: 0.009365453384816647\n",
            "Epoch 37, Step 46, Loss: 0.010010670870542526\n",
            "Epoch 37, Step 47, Loss: 0.014445534907281399\n",
            "Epoch 37, Step 48, Loss: 0.013486525043845177\n",
            "Epoch 37, Step 49, Loss: 0.013903116807341576\n",
            "Epoch 37, Step 50, Loss: 0.014164415188133717\n",
            "Epoch 37, Step 51, Loss: 0.012983202002942562\n",
            "Epoch 37, Step 52, Loss: 0.010337235406041145\n",
            "Epoch 37, Step 53, Loss: 0.010020861402153969\n",
            "Train Metric MRRs: 0.16604474887067852\n",
            "Train Metric MAPs: 0.06448764872428692\n",
            "Validation Metric MRRs: 0.2759153236338259\n",
            "Validation Metric MAPs: 0.13651938610192502\n",
            "Epoch 38, Step 1, Loss: 0.017741143703460693\n",
            "Epoch 38, Step 2, Loss: 0.022111456841230392\n",
            "Epoch 38, Step 3, Loss: 0.021700121462345123\n",
            "Epoch 38, Step 4, Loss: 0.017233392223715782\n",
            "Epoch 38, Step 5, Loss: 0.023166274651885033\n",
            "Epoch 38, Step 6, Loss: 0.0224833395332098\n",
            "Epoch 38, Step 7, Loss: 0.019748199731111526\n",
            "Epoch 38, Step 8, Loss: 0.017786623910069466\n",
            "Epoch 38, Step 9, Loss: 0.02688835933804512\n",
            "Epoch 38, Step 10, Loss: 0.017470331862568855\n",
            "Epoch 38, Step 11, Loss: 0.01254965364933014\n",
            "Epoch 38, Step 12, Loss: 0.013696890324354172\n",
            "Epoch 38, Step 13, Loss: 0.014997966587543488\n",
            "Epoch 38, Step 14, Loss: 0.011486642993986607\n",
            "Epoch 38, Step 15, Loss: 0.014084801077842712\n",
            "Epoch 38, Step 16, Loss: 0.015621330589056015\n",
            "Epoch 38, Step 17, Loss: 0.012304643169045448\n",
            "Epoch 38, Step 18, Loss: 0.012054978869855404\n",
            "Epoch 38, Step 19, Loss: 0.005820451769977808\n",
            "Epoch 38, Step 20, Loss: 0.006044301670044661\n",
            "Epoch 38, Step 21, Loss: 0.004658185876905918\n",
            "Epoch 38, Step 22, Loss: 0.005918302107602358\n",
            "Epoch 38, Step 23, Loss: 0.005633182357996702\n",
            "Epoch 38, Step 24, Loss: 0.018708810210227966\n",
            "Epoch 38, Step 25, Loss: 0.01301938109099865\n",
            "Epoch 38, Step 26, Loss: 0.011947530321776867\n",
            "Epoch 38, Step 27, Loss: 0.010906804352998734\n",
            "Epoch 38, Step 28, Loss: 0.014112996868789196\n",
            "Epoch 38, Step 29, Loss: 0.012370436452329159\n",
            "Epoch 38, Step 30, Loss: 0.013191035948693752\n",
            "Epoch 38, Step 31, Loss: 0.01219858042895794\n",
            "Epoch 38, Step 32, Loss: 0.008385516703128815\n",
            "Epoch 38, Step 33, Loss: 0.006888862699270248\n",
            "Epoch 38, Step 34, Loss: 0.011874324642121792\n",
            "Epoch 38, Step 35, Loss: 0.011023908853530884\n",
            "Epoch 38, Step 36, Loss: 0.00906364805996418\n",
            "Epoch 38, Step 37, Loss: 0.013450918719172478\n",
            "Epoch 38, Step 38, Loss: 0.01430665235966444\n",
            "Epoch 38, Step 39, Loss: 0.013367428444325924\n",
            "Epoch 38, Step 40, Loss: 0.013546233996748924\n",
            "Epoch 38, Step 41, Loss: 0.013811972923576832\n",
            "Epoch 38, Step 42, Loss: 0.009319613687694073\n",
            "Epoch 38, Step 43, Loss: 0.011344077996909618\n",
            "Epoch 38, Step 44, Loss: 0.01081425603479147\n",
            "Epoch 38, Step 45, Loss: 0.009679173119366169\n",
            "Epoch 38, Step 46, Loss: 0.010812783613801003\n",
            "Epoch 38, Step 47, Loss: 0.015562507323920727\n",
            "Epoch 38, Step 48, Loss: 0.013188229873776436\n",
            "Epoch 38, Step 49, Loss: 0.015431211329996586\n",
            "Epoch 38, Step 50, Loss: 0.01464823167771101\n",
            "Epoch 38, Step 51, Loss: 0.012699859216809273\n",
            "Epoch 38, Step 52, Loss: 0.010995399206876755\n",
            "Epoch 38, Step 53, Loss: 0.011440647765994072\n",
            "Train Metric MRRs: 0.15882078047468762\n",
            "Train Metric MAPs: 0.039226772226612236\n",
            "Validation Metric MRRs: 0.2637909315941189\n",
            "Validation Metric MAPs: 0.18507785573559446\n",
            "Epoch 39, Step 1, Loss: 0.019376197829842567\n",
            "Epoch 39, Step 2, Loss: 0.022624967619776726\n",
            "Epoch 39, Step 3, Loss: 0.019689636304974556\n",
            "Epoch 39, Step 4, Loss: 0.01590239442884922\n",
            "Epoch 39, Step 5, Loss: 0.020204612985253334\n",
            "Epoch 39, Step 6, Loss: 0.02186637371778488\n",
            "Epoch 39, Step 7, Loss: 0.02080647461116314\n",
            "Epoch 39, Step 8, Loss: 0.01868276111781597\n",
            "Epoch 39, Step 9, Loss: 0.02737593837082386\n",
            "Epoch 39, Step 10, Loss: 0.017295893281698227\n",
            "Epoch 39, Step 11, Loss: 0.012430352158844471\n",
            "Epoch 39, Step 12, Loss: 0.013205566443502903\n",
            "Epoch 39, Step 13, Loss: 0.014974475838243961\n",
            "Epoch 39, Step 14, Loss: 0.0113865090534091\n",
            "Epoch 39, Step 15, Loss: 0.013829891569912434\n",
            "Epoch 39, Step 16, Loss: 0.017483454197645187\n",
            "Epoch 39, Step 17, Loss: 0.013170847669243813\n",
            "Epoch 39, Step 18, Loss: 0.0121586499735713\n",
            "Epoch 39, Step 19, Loss: 0.00638999231159687\n",
            "Epoch 39, Step 20, Loss: 0.0056506735272705555\n",
            "Epoch 39, Step 21, Loss: 0.004466156475245953\n",
            "Epoch 39, Step 22, Loss: 0.005874392110854387\n",
            "Epoch 39, Step 23, Loss: 0.005501296371221542\n",
            "Epoch 39, Step 24, Loss: 0.01654261164367199\n",
            "Epoch 39, Step 25, Loss: 0.01322606299072504\n",
            "Epoch 39, Step 26, Loss: 0.0118093341588974\n",
            "Epoch 39, Step 27, Loss: 0.01048860140144825\n",
            "Epoch 39, Step 28, Loss: 0.013319079764187336\n",
            "Epoch 39, Step 29, Loss: 0.012405474670231342\n",
            "Epoch 39, Step 30, Loss: 0.012612320482730865\n",
            "Epoch 39, Step 31, Loss: 0.01173934992402792\n",
            "Epoch 39, Step 32, Loss: 0.007677570451050997\n",
            "Epoch 39, Step 33, Loss: 0.006207439117133617\n",
            "Epoch 39, Step 34, Loss: 0.010977176018059254\n",
            "Epoch 39, Step 35, Loss: 0.011088667437434196\n",
            "Epoch 39, Step 36, Loss: 0.009023160673677921\n",
            "Epoch 39, Step 37, Loss: 0.013465437106788158\n",
            "Epoch 39, Step 38, Loss: 0.014102538116276264\n",
            "Epoch 39, Step 39, Loss: 0.012729156762361526\n",
            "Epoch 39, Step 40, Loss: 0.011677425354719162\n",
            "Epoch 39, Step 41, Loss: 0.014139180071651936\n",
            "Epoch 39, Step 42, Loss: 0.009511623531579971\n",
            "Epoch 39, Step 43, Loss: 0.009478484280407429\n",
            "Epoch 39, Step 44, Loss: 0.010489312931895256\n",
            "Epoch 39, Step 45, Loss: 0.01168904546648264\n",
            "Epoch 39, Step 46, Loss: 0.00987989455461502\n",
            "Epoch 39, Step 47, Loss: 0.01520742941647768\n",
            "Epoch 39, Step 48, Loss: 0.012945732101798058\n",
            "Epoch 39, Step 49, Loss: 0.013088573701679707\n",
            "Epoch 39, Step 50, Loss: 0.013002592138946056\n",
            "Epoch 39, Step 51, Loss: 0.011948393657803535\n",
            "Epoch 39, Step 52, Loss: 0.010442640632390976\n",
            "Epoch 39, Step 53, Loss: 0.009214963763952255\n",
            "Train Metric MRRs: 0.1574791963183497\n",
            "Train Metric MAPs: 0.07567605930997544\n",
            "Validation Metric MRRs: 0.2786779632878265\n",
            "Validation Metric MAPs: 0.1419717354154758\n",
            "Epoch 40, Step 1, Loss: 0.018581276759505272\n",
            "Epoch 40, Step 2, Loss: 0.022235697135329247\n",
            "Epoch 40, Step 3, Loss: 0.01975305750966072\n",
            "Epoch 40, Step 4, Loss: 0.015952439978718758\n",
            "Epoch 40, Step 5, Loss: 0.020546218380331993\n",
            "Epoch 40, Step 6, Loss: 0.021617894992232323\n",
            "Epoch 40, Step 7, Loss: 0.020074548199772835\n",
            "Epoch 40, Step 8, Loss: 0.01784350350499153\n",
            "Epoch 40, Step 9, Loss: 0.026142537593841553\n",
            "Epoch 40, Step 10, Loss: 0.01696733571588993\n",
            "Epoch 40, Step 11, Loss: 0.012350300326943398\n",
            "Epoch 40, Step 12, Loss: 0.012945408001542091\n",
            "Epoch 40, Step 13, Loss: 0.014425876550376415\n",
            "Epoch 40, Step 14, Loss: 0.01113891415297985\n",
            "Epoch 40, Step 15, Loss: 0.013565126806497574\n",
            "Epoch 40, Step 16, Loss: 0.015612841583788395\n",
            "Epoch 40, Step 17, Loss: 0.012548107653856277\n",
            "Epoch 40, Step 18, Loss: 0.011887161061167717\n",
            "Epoch 40, Step 19, Loss: 0.006451452616602182\n",
            "Epoch 40, Step 20, Loss: 0.005963888019323349\n",
            "Epoch 40, Step 21, Loss: 0.004740525968372822\n",
            "Epoch 40, Step 22, Loss: 0.006204801611602306\n",
            "Epoch 40, Step 23, Loss: 0.00592373451218009\n",
            "Epoch 40, Step 24, Loss: 0.014914929866790771\n",
            "Epoch 40, Step 25, Loss: 0.014921433292329311\n",
            "Epoch 40, Step 26, Loss: 0.012082320638000965\n",
            "Epoch 40, Step 27, Loss: 0.010569615289568901\n",
            "Epoch 40, Step 28, Loss: 0.013345327228307724\n",
            "Epoch 40, Step 29, Loss: 0.011908411979675293\n",
            "Epoch 40, Step 30, Loss: 0.011759823188185692\n",
            "Epoch 40, Step 31, Loss: 0.011611090041697025\n",
            "Epoch 40, Step 32, Loss: 0.007945222780108452\n",
            "Epoch 40, Step 33, Loss: 0.00636175274848938\n",
            "Epoch 40, Step 34, Loss: 0.010972784832119942\n",
            "Epoch 40, Step 35, Loss: 0.011775551363825798\n",
            "Epoch 40, Step 36, Loss: 0.008574909530580044\n",
            "Epoch 40, Step 37, Loss: 0.013151498511433601\n",
            "Epoch 40, Step 38, Loss: 0.014035790227353573\n",
            "Epoch 40, Step 39, Loss: 0.012490840628743172\n",
            "Epoch 40, Step 40, Loss: 0.011959443800151348\n",
            "Epoch 40, Step 41, Loss: 0.015544665046036243\n",
            "Epoch 40, Step 42, Loss: 0.012665479443967342\n",
            "Epoch 40, Step 43, Loss: 0.009870880283415318\n",
            "Epoch 40, Step 44, Loss: 0.010866519995033741\n",
            "Epoch 40, Step 45, Loss: 0.010325654409825802\n",
            "Epoch 40, Step 46, Loss: 0.010166621766984463\n",
            "Epoch 40, Step 47, Loss: 0.01539323665201664\n",
            "Epoch 40, Step 48, Loss: 0.01952260732650757\n",
            "Epoch 40, Step 49, Loss: 0.01617487519979477\n",
            "Epoch 40, Step 50, Loss: 0.015394812449812889\n",
            "Epoch 40, Step 51, Loss: 0.009832651354372501\n",
            "Epoch 40, Step 52, Loss: 0.008765708655118942\n",
            "Epoch 40, Step 53, Loss: 0.010627803392708302\n",
            "Train Metric MRRs: 0.16432850192457377\n",
            "Train Metric MAPs: 0.06123521573057241\n",
            "Validation Metric MRRs: 0.2506089342144806\n",
            "Validation Metric MAPs: 0.13512482876671641\n",
            "Epoch 41, Step 1, Loss: 0.018830904737114906\n",
            "Epoch 41, Step 2, Loss: 0.023198403418064117\n",
            "Epoch 41, Step 3, Loss: 0.019486282020807266\n",
            "Epoch 41, Step 4, Loss: 0.015662256628274918\n",
            "Epoch 41, Step 5, Loss: 0.01981811784207821\n",
            "Epoch 41, Step 6, Loss: 0.02133750170469284\n",
            "Epoch 41, Step 7, Loss: 0.020194150507450104\n",
            "Epoch 41, Step 8, Loss: 0.01874016411602497\n",
            "Epoch 41, Step 9, Loss: 0.027607474476099014\n",
            "Epoch 41, Step 10, Loss: 0.017407827079296112\n",
            "Epoch 41, Step 11, Loss: 0.012528046034276485\n",
            "Epoch 41, Step 12, Loss: 0.01305776834487915\n",
            "Epoch 41, Step 13, Loss: 0.015096045099198818\n",
            "Epoch 41, Step 14, Loss: 0.011098907329142094\n",
            "Epoch 41, Step 15, Loss: 0.013900999911129475\n",
            "Epoch 41, Step 16, Loss: 0.0156084094196558\n",
            "Epoch 41, Step 17, Loss: 0.012586601078510284\n",
            "Epoch 41, Step 18, Loss: 0.012274207547307014\n",
            "Epoch 41, Step 19, Loss: 0.0071418690495193005\n",
            "Epoch 41, Step 20, Loss: 0.0064028059132397175\n",
            "Epoch 41, Step 21, Loss: 0.005240870174020529\n",
            "Epoch 41, Step 22, Loss: 0.006624323315918446\n",
            "Epoch 41, Step 23, Loss: 0.006232751067727804\n",
            "Epoch 41, Step 24, Loss: 0.014476622454822063\n",
            "Epoch 41, Step 25, Loss: 0.013919171877205372\n",
            "Epoch 41, Step 26, Loss: 0.01190064288675785\n",
            "Epoch 41, Step 27, Loss: 0.010892268270254135\n",
            "Epoch 41, Step 28, Loss: 0.014459938742220402\n",
            "Epoch 41, Step 29, Loss: 0.012213447131216526\n",
            "Epoch 41, Step 30, Loss: 0.012051708996295929\n",
            "Epoch 41, Step 31, Loss: 0.011502481997013092\n",
            "Epoch 41, Step 32, Loss: 0.0076217339374125\n",
            "Epoch 41, Step 33, Loss: 0.005784538574516773\n",
            "Epoch 41, Step 34, Loss: 0.012047060765326023\n",
            "Epoch 41, Step 35, Loss: 0.012032573111355305\n",
            "Epoch 41, Step 36, Loss: 0.00875582080334425\n",
            "Epoch 41, Step 37, Loss: 0.014264057390391827\n",
            "Epoch 41, Step 38, Loss: 0.013705057092010975\n",
            "Epoch 41, Step 39, Loss: 0.013658775016665459\n",
            "Epoch 41, Step 40, Loss: 0.011631040833890438\n",
            "Epoch 41, Step 41, Loss: 0.016271745786070824\n",
            "Epoch 41, Step 42, Loss: 0.010489027015864849\n",
            "Epoch 41, Step 43, Loss: 0.010820705443620682\n",
            "Epoch 41, Step 44, Loss: 0.011272253468632698\n",
            "Epoch 41, Step 45, Loss: 0.010424927808344364\n",
            "Epoch 41, Step 46, Loss: 0.009519986808300018\n",
            "Epoch 41, Step 47, Loss: 0.016231929883360863\n",
            "Epoch 41, Step 48, Loss: 0.016421876847743988\n",
            "Epoch 41, Step 49, Loss: 0.015718530863523483\n",
            "Epoch 41, Step 50, Loss: 0.013672418892383575\n",
            "Epoch 41, Step 51, Loss: 0.012062669731676579\n",
            "Epoch 41, Step 52, Loss: 0.013359714299440384\n",
            "Epoch 41, Step 53, Loss: 0.013219797052443027\n",
            "Train Metric MRRs: 0.1618174200736389\n",
            "Train Metric MAPs: 0.043431555706499064\n",
            "Validation Metric MRRs: 0.2795524450628531\n",
            "Validation Metric MAPs: 0.042544949395720406\n",
            "Epoch 42, Step 1, Loss: 0.018091699108481407\n",
            "Epoch 42, Step 2, Loss: 0.02268129587173462\n",
            "Epoch 42, Step 3, Loss: 0.019187822937965393\n",
            "Epoch 42, Step 4, Loss: 0.015094015747308731\n",
            "Epoch 42, Step 5, Loss: 0.019833138212561607\n",
            "Epoch 42, Step 6, Loss: 0.02135016955435276\n",
            "Epoch 42, Step 7, Loss: 0.019983962178230286\n",
            "Epoch 42, Step 8, Loss: 0.01803971640765667\n",
            "Epoch 42, Step 9, Loss: 0.025284701958298683\n",
            "Epoch 42, Step 10, Loss: 0.016766687855124474\n",
            "Epoch 42, Step 11, Loss: 0.012101996690034866\n",
            "Epoch 42, Step 12, Loss: 0.013237886130809784\n",
            "Epoch 42, Step 13, Loss: 0.01462616492062807\n",
            "Epoch 42, Step 14, Loss: 0.01108582317829132\n",
            "Epoch 42, Step 15, Loss: 0.013490613549947739\n",
            "Epoch 42, Step 16, Loss: 0.01574275828897953\n",
            "Epoch 42, Step 17, Loss: 0.01185285858809948\n",
            "Epoch 42, Step 18, Loss: 0.011390537954866886\n",
            "Epoch 42, Step 19, Loss: 0.0062970928847789764\n",
            "Epoch 42, Step 20, Loss: 0.005790787283331156\n",
            "Epoch 42, Step 21, Loss: 0.005040122661739588\n",
            "Epoch 42, Step 22, Loss: 0.006587241776287556\n",
            "Epoch 42, Step 23, Loss: 0.006565187592059374\n",
            "Epoch 42, Step 24, Loss: 0.015039002522826195\n",
            "Epoch 42, Step 25, Loss: 0.0131393913179636\n",
            "Epoch 42, Step 26, Loss: 0.01171969622373581\n",
            "Epoch 42, Step 27, Loss: 0.010971040464937687\n",
            "Epoch 42, Step 28, Loss: 0.014188658446073532\n",
            "Epoch 42, Step 29, Loss: 0.011795327998697758\n",
            "Epoch 42, Step 30, Loss: 0.011571887880563736\n",
            "Epoch 42, Step 31, Loss: 0.01126584317535162\n",
            "Epoch 42, Step 32, Loss: 0.007651017978787422\n",
            "Epoch 42, Step 33, Loss: 0.006103199906647205\n",
            "Epoch 42, Step 34, Loss: 0.01200405228883028\n",
            "Epoch 42, Step 35, Loss: 0.012109983712434769\n",
            "Epoch 42, Step 36, Loss: 0.008388829417526722\n",
            "Epoch 42, Step 37, Loss: 0.013649355620145798\n",
            "Epoch 42, Step 38, Loss: 0.013928349129855633\n",
            "Epoch 42, Step 39, Loss: 0.012946526519954205\n",
            "Epoch 42, Step 40, Loss: 0.011258385144174099\n",
            "Epoch 42, Step 41, Loss: 0.014084259048104286\n",
            "Epoch 42, Step 42, Loss: 0.008852876722812653\n",
            "Epoch 42, Step 43, Loss: 0.009011957794427872\n",
            "Epoch 42, Step 44, Loss: 0.009429596364498138\n",
            "Epoch 42, Step 45, Loss: 0.009795242920517921\n",
            "Epoch 42, Step 46, Loss: 0.010582775808870792\n",
            "Epoch 42, Step 47, Loss: 0.014770543202757835\n",
            "Epoch 42, Step 48, Loss: 0.014813534915447235\n",
            "Epoch 42, Step 49, Loss: 0.015073234215378761\n",
            "Epoch 42, Step 50, Loss: 0.012301775626838207\n",
            "Epoch 42, Step 51, Loss: 0.009547770023345947\n",
            "Epoch 42, Step 52, Loss: 0.00875862780958414\n",
            "Epoch 42, Step 53, Loss: 0.010646451264619827\n",
            "Train Metric MRRs: 0.1675210716240056\n",
            "Train Metric MAPs: 0.024554877378618365\n",
            "Validation Metric MRRs: 0.2728237519896636\n",
            "Validation Metric MAPs: 0.06232347144834044\n",
            "Epoch 43, Step 1, Loss: 0.019613279029726982\n",
            "Epoch 43, Step 2, Loss: 0.02424999698996544\n",
            "Epoch 43, Step 3, Loss: 0.021851664409041405\n",
            "Epoch 43, Step 4, Loss: 0.01621817611157894\n",
            "Epoch 43, Step 5, Loss: 0.021447306498885155\n",
            "Epoch 43, Step 6, Loss: 0.021085605025291443\n",
            "Epoch 43, Step 7, Loss: 0.01895751990377903\n",
            "Epoch 43, Step 8, Loss: 0.017492301762104034\n",
            "Epoch 43, Step 9, Loss: 0.025621630251407623\n",
            "Epoch 43, Step 10, Loss: 0.016921713948249817\n",
            "Epoch 43, Step 11, Loss: 0.01236144918948412\n",
            "Epoch 43, Step 12, Loss: 0.013080794364213943\n",
            "Epoch 43, Step 13, Loss: 0.01396794244647026\n",
            "Epoch 43, Step 14, Loss: 0.010854238644242287\n",
            "Epoch 43, Step 15, Loss: 0.013012709096074104\n",
            "Epoch 43, Step 16, Loss: 0.014963900670409203\n",
            "Epoch 43, Step 17, Loss: 0.011622768826782703\n",
            "Epoch 43, Step 18, Loss: 0.011102993041276932\n",
            "Epoch 43, Step 19, Loss: 0.005803736858069897\n",
            "Epoch 43, Step 20, Loss: 0.005101339425891638\n",
            "Epoch 43, Step 21, Loss: 0.004198029171675444\n",
            "Epoch 43, Step 22, Loss: 0.005737170577049255\n",
            "Epoch 43, Step 23, Loss: 0.005664977245032787\n",
            "Epoch 43, Step 24, Loss: 0.01514749601483345\n",
            "Epoch 43, Step 25, Loss: 0.012518833391368389\n",
            "Epoch 43, Step 26, Loss: 0.011310731992125511\n",
            "Epoch 43, Step 27, Loss: 0.010696085169911385\n",
            "Epoch 43, Step 28, Loss: 0.01359822042286396\n",
            "Epoch 43, Step 29, Loss: 0.011846699751913548\n",
            "Epoch 43, Step 30, Loss: 0.01188117265701294\n",
            "Epoch 43, Step 31, Loss: 0.011310862377285957\n",
            "Epoch 43, Step 32, Loss: 0.007525239139795303\n",
            "Epoch 43, Step 33, Loss: 0.005946853198111057\n",
            "Epoch 43, Step 34, Loss: 0.01074802502989769\n",
            "Epoch 43, Step 35, Loss: 0.011224198155105114\n",
            "Epoch 43, Step 36, Loss: 0.007489260286092758\n",
            "Epoch 43, Step 37, Loss: 0.013594272546470165\n",
            "Epoch 43, Step 38, Loss: 0.013763616792857647\n",
            "Epoch 43, Step 39, Loss: 0.01192257460206747\n",
            "Epoch 43, Step 40, Loss: 0.011621864512562752\n",
            "Epoch 43, Step 41, Loss: 0.01305461023002863\n",
            "Epoch 43, Step 42, Loss: 0.008491349406540394\n",
            "Epoch 43, Step 43, Loss: 0.008790331892669201\n",
            "Epoch 43, Step 44, Loss: 0.008764313533902168\n",
            "Epoch 43, Step 45, Loss: 0.008783265948295593\n",
            "Epoch 43, Step 46, Loss: 0.00891634076833725\n",
            "Epoch 43, Step 47, Loss: 0.014947027899324894\n",
            "Epoch 43, Step 48, Loss: 0.012927431613206863\n",
            "Epoch 43, Step 49, Loss: 0.01287451758980751\n",
            "Epoch 43, Step 50, Loss: 0.011128316633403301\n",
            "Epoch 43, Step 51, Loss: 0.008959364145994186\n",
            "Epoch 43, Step 52, Loss: 0.008022373542189598\n",
            "Epoch 43, Step 53, Loss: 0.009634080342948437\n",
            "Train Metric MRRs: 0.1749923754596518\n",
            "Train Metric MAPs: 0.03315649873792756\n",
            "Validation Metric MRRs: 0.26958661687291036\n",
            "Validation Metric MAPs: 0.11639918782789437\n",
            "Epoch 44, Step 1, Loss: 0.01824076473712921\n",
            "Epoch 44, Step 2, Loss: 0.022393058985471725\n",
            "Epoch 44, Step 3, Loss: 0.021751513704657555\n",
            "Epoch 44, Step 4, Loss: 0.01609467715024948\n",
            "Epoch 44, Step 5, Loss: 0.021547114476561546\n",
            "Epoch 44, Step 6, Loss: 0.022161394357681274\n",
            "Epoch 44, Step 7, Loss: 0.019254455342888832\n",
            "Epoch 44, Step 8, Loss: 0.017484305426478386\n",
            "Epoch 44, Step 9, Loss: 0.025149712339043617\n",
            "Epoch 44, Step 10, Loss: 0.016173310577869415\n",
            "Epoch 44, Step 11, Loss: 0.012583292089402676\n",
            "Epoch 44, Step 12, Loss: 0.013236536644399166\n",
            "Epoch 44, Step 13, Loss: 0.014645321294665337\n",
            "Epoch 44, Step 14, Loss: 0.011438279412686825\n",
            "Epoch 44, Step 15, Loss: 0.013274463824927807\n",
            "Epoch 44, Step 16, Loss: 0.015530826523900032\n",
            "Epoch 44, Step 17, Loss: 0.011860225349664688\n",
            "Epoch 44, Step 18, Loss: 0.011314928531646729\n",
            "Epoch 44, Step 19, Loss: 0.005901620257645845\n",
            "Epoch 44, Step 20, Loss: 0.004916751757264137\n",
            "Epoch 44, Step 21, Loss: 0.004048164933919907\n",
            "Epoch 44, Step 22, Loss: 0.0058140140026807785\n",
            "Epoch 44, Step 23, Loss: 0.00536602595821023\n",
            "Epoch 44, Step 24, Loss: 0.015189730562269688\n",
            "Epoch 44, Step 25, Loss: 0.012366188690066338\n",
            "Epoch 44, Step 26, Loss: 0.011178755201399326\n",
            "Epoch 44, Step 27, Loss: 0.01030595414340496\n",
            "Epoch 44, Step 28, Loss: 0.013238438405096531\n",
            "Epoch 44, Step 29, Loss: 0.011304808780550957\n",
            "Epoch 44, Step 30, Loss: 0.011135434731841087\n",
            "Epoch 44, Step 31, Loss: 0.010774794965982437\n",
            "Epoch 44, Step 32, Loss: 0.007158339023590088\n",
            "Epoch 44, Step 33, Loss: 0.005827485118061304\n",
            "Epoch 44, Step 34, Loss: 0.009870810434222221\n",
            "Epoch 44, Step 35, Loss: 0.010678034275770187\n",
            "Epoch 44, Step 36, Loss: 0.007484928239136934\n",
            "Epoch 44, Step 37, Loss: 0.012693021446466446\n",
            "Epoch 44, Step 38, Loss: 0.01341413613408804\n",
            "Epoch 44, Step 39, Loss: 0.01088486984372139\n",
            "Epoch 44, Step 40, Loss: 0.010145203210413456\n",
            "Epoch 44, Step 41, Loss: 0.012060207314789295\n",
            "Epoch 44, Step 42, Loss: 0.00824045855551958\n",
            "Epoch 44, Step 43, Loss: 0.008895797654986382\n",
            "Epoch 44, Step 44, Loss: 0.007990126498043537\n",
            "Epoch 44, Step 45, Loss: 0.008844845928251743\n",
            "Epoch 44, Step 46, Loss: 0.008990658447146416\n",
            "Epoch 44, Step 47, Loss: 0.014261565171182156\n",
            "Epoch 44, Step 48, Loss: 0.011775610037147999\n",
            "Epoch 44, Step 49, Loss: 0.012313044629991055\n",
            "Epoch 44, Step 50, Loss: 0.012707258574664593\n",
            "Epoch 44, Step 51, Loss: 0.010289755649864674\n",
            "Epoch 44, Step 52, Loss: 0.008881643414497375\n",
            "Epoch 44, Step 53, Loss: 0.009084213525056839\n",
            "Train Metric MRRs: 0.18025424214851044\n",
            "Train Metric MAPs: 0.03476072977200191\n",
            "Validation Metric MRRs: 0.283296517963766\n",
            "Validation Metric MAPs: 0.1394916592525671\n",
            "Epoch 45, Step 1, Loss: 0.017794428393244743\n",
            "Epoch 45, Step 2, Loss: 0.021725377067923546\n",
            "Epoch 45, Step 3, Loss: 0.020746130496263504\n",
            "Epoch 45, Step 4, Loss: 0.01678914576768875\n",
            "Epoch 45, Step 5, Loss: 0.02262043207883835\n",
            "Epoch 45, Step 6, Loss: 0.02323891967535019\n",
            "Epoch 45, Step 7, Loss: 0.02091108448803425\n",
            "Epoch 45, Step 8, Loss: 0.018155982717871666\n",
            "Epoch 45, Step 9, Loss: 0.02633458562195301\n",
            "Epoch 45, Step 10, Loss: 0.01610674522817135\n",
            "Epoch 45, Step 11, Loss: 0.011896434240043163\n",
            "Epoch 45, Step 12, Loss: 0.012973974458873272\n",
            "Epoch 45, Step 13, Loss: 0.01469606626778841\n",
            "Epoch 45, Step 14, Loss: 0.012067439034581184\n",
            "Epoch 45, Step 15, Loss: 0.014578173868358135\n",
            "Epoch 45, Step 16, Loss: 0.016535576432943344\n",
            "Epoch 45, Step 17, Loss: 0.01320747472345829\n",
            "Epoch 45, Step 18, Loss: 0.012036873959004879\n",
            "Epoch 45, Step 19, Loss: 0.006210759282112122\n",
            "Epoch 45, Step 20, Loss: 0.005350352264940739\n",
            "Epoch 45, Step 21, Loss: 0.00444674352183938\n",
            "Epoch 45, Step 22, Loss: 0.00580047070980072\n",
            "Epoch 45, Step 23, Loss: 0.005371051840484142\n",
            "Epoch 45, Step 24, Loss: 0.01649540849030018\n",
            "Epoch 45, Step 25, Loss: 0.012629717588424683\n",
            "Epoch 45, Step 26, Loss: 0.011429829522967339\n",
            "Epoch 45, Step 27, Loss: 0.010387382470071316\n",
            "Epoch 45, Step 28, Loss: 0.012754574418067932\n",
            "Epoch 45, Step 29, Loss: 0.01139309536665678\n",
            "Epoch 45, Step 30, Loss: 0.011725936084985733\n",
            "Epoch 45, Step 31, Loss: 0.010543330572545528\n",
            "Epoch 45, Step 32, Loss: 0.007181005086749792\n",
            "Epoch 45, Step 33, Loss: 0.005971748381853104\n",
            "Epoch 45, Step 34, Loss: 0.010193618945777416\n",
            "Epoch 45, Step 35, Loss: 0.010784199461340904\n",
            "Epoch 45, Step 36, Loss: 0.007582772057503462\n",
            "Epoch 45, Step 37, Loss: 0.012039696797728539\n",
            "Epoch 45, Step 38, Loss: 0.014057568274438381\n",
            "Epoch 45, Step 39, Loss: 0.010743905790150166\n",
            "Epoch 45, Step 40, Loss: 0.010295635089278221\n",
            "Epoch 45, Step 41, Loss: 0.012027783319354057\n",
            "Epoch 45, Step 42, Loss: 0.00803119596093893\n",
            "Epoch 45, Step 43, Loss: 0.008638156577944756\n",
            "Epoch 45, Step 44, Loss: 0.008263125084340572\n",
            "Epoch 45, Step 45, Loss: 0.009197411127388477\n",
            "Epoch 45, Step 46, Loss: 0.009436382912099361\n",
            "Epoch 45, Step 47, Loss: 0.013867666013538837\n",
            "Epoch 45, Step 48, Loss: 0.011923487298190594\n",
            "Epoch 45, Step 49, Loss: 0.012331238947808743\n",
            "Epoch 45, Step 50, Loss: 0.011893472634255886\n",
            "Epoch 45, Step 51, Loss: 0.009361938573420048\n",
            "Epoch 45, Step 52, Loss: 0.008933463133871555\n",
            "Epoch 45, Step 53, Loss: 0.011496728286147118\n",
            "Train Metric MRRs: 0.17689203929087788\n",
            "Train Metric MAPs: 0.034504509409330614\n",
            "Validation Metric MRRs: 0.2680565435822596\n",
            "Validation Metric MAPs: 0.17454299639927479\n",
            "Epoch 46, Step 1, Loss: 0.01965407282114029\n",
            "Epoch 46, Step 2, Loss: 0.022785866633057594\n",
            "Epoch 46, Step 3, Loss: 0.019359959289431572\n",
            "Epoch 46, Step 4, Loss: 0.01545177772641182\n",
            "Epoch 46, Step 5, Loss: 0.020469650626182556\n",
            "Epoch 46, Step 6, Loss: 0.0223455261439085\n",
            "Epoch 46, Step 7, Loss: 0.021387025713920593\n",
            "Epoch 46, Step 8, Loss: 0.019542573019862175\n",
            "Epoch 46, Step 9, Loss: 0.028795769438147545\n",
            "Epoch 46, Step 10, Loss: 0.016652081161737442\n",
            "Epoch 46, Step 11, Loss: 0.012127440422773361\n",
            "Epoch 46, Step 12, Loss: 0.012871792539954185\n",
            "Epoch 46, Step 13, Loss: 0.014296559616923332\n",
            "Epoch 46, Step 14, Loss: 0.011415403336286545\n",
            "Epoch 46, Step 15, Loss: 0.014073634520173073\n",
            "Epoch 46, Step 16, Loss: 0.016605131328105927\n",
            "Epoch 46, Step 17, Loss: 0.013383656740188599\n",
            "Epoch 46, Step 18, Loss: 0.012611225247383118\n",
            "Epoch 46, Step 19, Loss: 0.007282454986125231\n",
            "Epoch 46, Step 20, Loss: 0.006279637571424246\n",
            "Epoch 46, Step 21, Loss: 0.006189970299601555\n",
            "Epoch 46, Step 22, Loss: 0.006294879596680403\n",
            "Epoch 46, Step 23, Loss: 0.006218027789145708\n",
            "Epoch 46, Step 24, Loss: 0.015198183245956898\n",
            "Epoch 46, Step 25, Loss: 0.013748771511018276\n",
            "Epoch 46, Step 26, Loss: 0.01130161713808775\n",
            "Epoch 46, Step 27, Loss: 0.010697176679968834\n",
            "Epoch 46, Step 28, Loss: 0.013050084002315998\n",
            "Epoch 46, Step 29, Loss: 0.01204716507345438\n",
            "Epoch 46, Step 30, Loss: 0.011737828142940998\n",
            "Epoch 46, Step 31, Loss: 0.010970132425427437\n",
            "Epoch 46, Step 32, Loss: 0.00775357848033309\n",
            "Epoch 46, Step 33, Loss: 0.005779024213552475\n",
            "Epoch 46, Step 34, Loss: 0.01037435233592987\n",
            "Epoch 46, Step 35, Loss: 0.011407952755689621\n",
            "Epoch 46, Step 36, Loss: 0.00797711405903101\n",
            "Epoch 46, Step 37, Loss: 0.011890357360243797\n",
            "Epoch 46, Step 38, Loss: 0.013628638349473476\n",
            "Epoch 46, Step 39, Loss: 0.011187577620148659\n",
            "Epoch 46, Step 40, Loss: 0.012100388295948505\n",
            "Epoch 46, Step 41, Loss: 0.01241256296634674\n",
            "Epoch 46, Step 42, Loss: 0.009068447165191174\n",
            "Epoch 46, Step 43, Loss: 0.008976304903626442\n",
            "Epoch 46, Step 44, Loss: 0.008885611779987812\n",
            "Epoch 46, Step 45, Loss: 0.009097279980778694\n",
            "Epoch 46, Step 46, Loss: 0.009847831912338734\n",
            "Epoch 46, Step 47, Loss: 0.015773678198456764\n",
            "Epoch 46, Step 48, Loss: 0.01342967338860035\n",
            "Epoch 46, Step 49, Loss: 0.012801564298570156\n",
            "Epoch 46, Step 50, Loss: 0.011468729935586452\n",
            "Epoch 46, Step 51, Loss: 0.009402972646057606\n",
            "Epoch 46, Step 52, Loss: 0.008753342553973198\n",
            "Epoch 46, Step 53, Loss: 0.009227000176906586\n",
            "Train Metric MRRs: 0.17685436366440524\n",
            "Train Metric MAPs: 0.03303351632229854\n",
            "Validation Metric MRRs: 0.27220399474298246\n",
            "Validation Metric MAPs: 0.17128915969717204\n",
            "Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "trainer.train(config['num_epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHIu_eBzX_eC",
        "outputId": "a6751d4e-75ba-475a-f17e-57397118be66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metric MRRs: 0.28493468666771843\n",
            "Validation Metric MAPs: 0.13544323071101488\n",
            "Test Metric MRRs: 0.3749966502061407\n",
            "Test Metric MAPs: 0.2158253059900545\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3749966502061407, 0.2158253059900545)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainer.restore_best_checkpoint()\n",
        "trainer.validate('Validation')\n",
        "trainer.validate('Test')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}