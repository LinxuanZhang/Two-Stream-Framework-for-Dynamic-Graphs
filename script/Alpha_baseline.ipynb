{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/mlds"
      ],
      "metadata": {
        "id": "cSUthI3K8zSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79cff9a-efb6-4a81-b0cd-d91420f56e58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/mlds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DYryhtF68gXd"
      },
      "outputs": [],
      "source": [
        "import data_bitcoin as btc\n",
        "import tasker_link_prediction as t_lp\n",
        "from splitter import splitter\n",
        "from models import Baseline_node2vec\n",
        "from trainer import Trainer\n",
        "import yaml\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep = False\n",
        "\n",
        "with open('config/config_BTC_Alpha_baseline.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "model_path = config['model_path']\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "    os.mkdir(model_path + \"best_checkpoints/\")\n",
        "    os.mkdir(model_path + \"latest_checkpoints/\")\n",
        "\n",
        "with open(model_path + 'config.yaml', 'w') as file:\n",
        "    yaml.dump(config, file)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUr9nWe-9AVJ",
        "outputId": "6f796946-2441-4abf-cc87-82e7dfc81ef6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_config': {'adam_beta_1': 0.9,\n",
              "  'adam_beta_2': 0.999,\n",
              "  'adam_epsilon': 1e-07,\n",
              "  'adam_learning_rate': 0.005},\n",
              " 'model_path': 'models/BTC_ALPHA_N2V_baseline/',\n",
              " 'classifier_hidden_size': 16,\n",
              " 'ffn_fusion_size': 8,\n",
              " 'ffn_hidden_size': 8,\n",
              " 'gcn_fusion_size': 16,\n",
              " 'spatial_hidden_size': 16,\n",
              " 'spatial_input_dim': 128,\n",
              " 'temporal_hidden_size': 16,\n",
              " 'temporal_input_dim': 100,\n",
              " 'num_epochs': 1000,\n",
              " 'patience': 10,\n",
              " 'major_threshold': None,\n",
              " 'train_proportion': 0.7,\n",
              " 'dev_proportion': 0.1,\n",
              " 'data_path': 'data/BTC-ALPHA/',\n",
              " 'prep_data_path': 'prep_data/BTC_Alpha_neg/'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = btc.Bitcoin_Dataset(config['data_path'])\n",
        "tasker = t_lp.Link_Pred_Tasker(data, path=config['prep_data_path'], prep=prep,\n",
        "                               embs_dim=config['spatial_input_dim'], temp_dim=int(config['temporal_input_dim']/10),\n",
        "                               major_threshold=config['major_threshold'], smart_neg_sampling=True)\n",
        "\n",
        "splitter_as = splitter(tasker, train_proportion = config['train_proportion'], dev_proportion = config['dev_proportion'])\n",
        "\n",
        "model= Baseline_node2vec(config['spatial_input_dim'])\n",
        "\n",
        "trainer = Trainer(model=model, splitter=splitter_as, model_path=model_path, adam_config=config['adam_config'], patience=config['patience'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjgoIKsR86nJ",
        "outputId": "30a06f83-5553-407f-cfa6-813eb51c9ff0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits sizes:  train 85 dev 14 test 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(config['num_epochs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoduoKQ__Eww",
        "outputId": "77cb89bd-1221-448b-cc86-0951f26166c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 1, Loss: 0.08404892683029175\n",
            "Epoch 1, Step 2, Loss: 0.0722685232758522\n",
            "Epoch 1, Step 3, Loss: 0.061451930552721024\n",
            "Epoch 1, Step 4, Loss: 0.043301522731781006\n",
            "Epoch 1, Step 5, Loss: 0.03838137164711952\n",
            "Epoch 1, Step 6, Loss: 0.030119020491838455\n",
            "Epoch 1, Step 7, Loss: 0.023640932515263557\n",
            "Epoch 1, Step 8, Loss: 0.03127807378768921\n",
            "Epoch 1, Step 9, Loss: 0.0333527997136116\n",
            "Epoch 1, Step 10, Loss: 0.0329669751226902\n",
            "Epoch 1, Step 11, Loss: 0.028964119032025337\n",
            "Epoch 1, Step 12, Loss: 0.02888542227447033\n",
            "Epoch 1, Step 13, Loss: 0.02659381553530693\n",
            "Epoch 1, Step 14, Loss: 0.027989663183689117\n",
            "Epoch 1, Step 15, Loss: 0.025209294632077217\n",
            "Epoch 1, Step 16, Loss: 0.027382254600524902\n",
            "Epoch 1, Step 17, Loss: 0.03062332607805729\n",
            "Epoch 1, Step 18, Loss: 0.03478565439581871\n",
            "Epoch 1, Step 19, Loss: 0.032713133841753006\n",
            "Epoch 1, Step 20, Loss: 0.034327369183301926\n",
            "Epoch 1, Step 21, Loss: 0.027364380657672882\n",
            "Epoch 1, Step 22, Loss: 0.023812005296349525\n",
            "Epoch 1, Step 23, Loss: 0.02696155197918415\n",
            "Epoch 1, Step 24, Loss: 0.02613644115626812\n",
            "Epoch 1, Step 25, Loss: 0.02395920641720295\n",
            "Epoch 1, Step 26, Loss: 0.02865230292081833\n",
            "Epoch 1, Step 27, Loss: 0.020166944712400436\n",
            "Epoch 1, Step 28, Loss: 0.02005952037870884\n",
            "Epoch 1, Step 29, Loss: 0.018476665019989014\n",
            "Epoch 1, Step 30, Loss: 0.019020944833755493\n",
            "Epoch 1, Step 31, Loss: 0.020083008334040642\n",
            "Epoch 1, Step 32, Loss: 0.01823325827717781\n",
            "Epoch 1, Step 33, Loss: 0.017342638224363327\n",
            "Epoch 1, Step 34, Loss: 0.018892932683229446\n",
            "Epoch 1, Step 35, Loss: 0.0176591444760561\n",
            "Epoch 1, Step 36, Loss: 0.016007043421268463\n",
            "Epoch 1, Step 37, Loss: 0.019339971244335175\n",
            "Epoch 1, Step 38, Loss: 0.014825426042079926\n",
            "Epoch 1, Step 39, Loss: 0.01713501289486885\n",
            "Epoch 1, Step 40, Loss: 0.020249394699931145\n",
            "Epoch 1, Step 41, Loss: 0.019205596297979355\n",
            "Epoch 1, Step 42, Loss: 0.01317733433097601\n",
            "Epoch 1, Step 43, Loss: 0.02083396725356579\n",
            "Epoch 1, Step 44, Loss: 0.017204316332936287\n",
            "Epoch 1, Step 45, Loss: 0.014823135919868946\n",
            "Epoch 1, Step 46, Loss: 0.013701722025871277\n",
            "Epoch 1, Step 47, Loss: 0.01576896756887436\n",
            "Epoch 1, Step 48, Loss: 0.014763560146093369\n",
            "Epoch 1, Step 49, Loss: 0.01223822869360447\n",
            "Epoch 1, Step 50, Loss: 0.015446342527866364\n",
            "Epoch 1, Step 51, Loss: 0.01363223884254694\n",
            "Epoch 1, Step 52, Loss: 0.012950524687767029\n",
            "Epoch 1, Step 53, Loss: 0.01738656498491764\n",
            "Epoch 1, Step 54, Loss: 0.0125766322016716\n",
            "Epoch 1, Step 55, Loss: 0.013331237249076366\n",
            "Epoch 1, Step 56, Loss: 0.011468445882201195\n",
            "Epoch 1, Step 57, Loss: 0.012198762968182564\n",
            "Epoch 1, Step 58, Loss: 0.010810618288815022\n",
            "Epoch 1, Step 59, Loss: 0.010068429633975029\n",
            "Epoch 1, Step 60, Loss: 0.010713073424994946\n",
            "Epoch 1, Step 61, Loss: 0.01298800203949213\n",
            "Epoch 1, Step 62, Loss: 0.011170613579452038\n",
            "Epoch 1, Step 63, Loss: 0.01217115018516779\n",
            "Epoch 1, Step 64, Loss: 0.010822693817317486\n",
            "Epoch 1, Step 65, Loss: 0.012496309354901314\n",
            "Epoch 1, Step 66, Loss: 0.014523465186357498\n",
            "Epoch 1, Step 67, Loss: 0.014319566078484058\n",
            "Epoch 1, Step 68, Loss: 0.016478432342410088\n",
            "Epoch 1, Step 69, Loss: 0.01437331736087799\n",
            "Epoch 1, Step 70, Loss: 0.016136212274432182\n",
            "Epoch 1, Step 71, Loss: 0.015759533271193504\n",
            "Epoch 1, Step 72, Loss: 0.015323484316468239\n",
            "Epoch 1, Step 73, Loss: 0.011855010874569416\n",
            "Epoch 1, Step 74, Loss: 0.012033980339765549\n",
            "Epoch 1, Step 75, Loss: 0.014226425439119339\n",
            "Epoch 1, Step 76, Loss: 0.015547377988696098\n",
            "Epoch 1, Step 77, Loss: 0.014137087389826775\n",
            "Epoch 1, Step 78, Loss: 0.015266643837094307\n",
            "Epoch 1, Step 79, Loss: 0.014505678787827492\n",
            "Epoch 1, Step 80, Loss: 0.01399277150630951\n",
            "Epoch 1, Step 81, Loss: 0.02191281132400036\n",
            "Epoch 1, Step 82, Loss: 0.01775209791958332\n",
            "Epoch 1, Step 83, Loss: 0.014310622587800026\n",
            "Epoch 1, Step 84, Loss: 0.015611907467246056\n",
            "Epoch 1, Step 85, Loss: 0.019015634432435036\n",
            "Train Metric MRRs: 0.019276187347280982\n",
            "Train Metric MAPs: 0.004499354059257602\n",
            "Validation Metric MRRs: 0.037346335099359175\n",
            "Validation Metric MAPs: 0.009772797504835559\n",
            "Epoch 2, Step 1, Loss: 0.06311200559139252\n",
            "Epoch 2, Step 2, Loss: 0.060385812073946\n",
            "Epoch 2, Step 3, Loss: 0.07609681785106659\n",
            "Epoch 2, Step 4, Loss: 0.030817730352282524\n",
            "Epoch 2, Step 5, Loss: 0.022217854857444763\n",
            "Epoch 2, Step 6, Loss: 0.01736331731081009\n",
            "Epoch 2, Step 7, Loss: 0.01298734825104475\n",
            "Epoch 2, Step 8, Loss: 0.012813102453947067\n",
            "Epoch 2, Step 9, Loss: 0.012569356709718704\n",
            "Epoch 2, Step 10, Loss: 0.014624782837927341\n",
            "Epoch 2, Step 11, Loss: 0.013915331102907658\n",
            "Epoch 2, Step 12, Loss: 0.01245492696762085\n",
            "Epoch 2, Step 13, Loss: 0.015632253140211105\n",
            "Epoch 2, Step 14, Loss: 0.017143838107585907\n",
            "Epoch 2, Step 15, Loss: 0.013809781521558762\n",
            "Epoch 2, Step 16, Loss: 0.01376547571271658\n",
            "Epoch 2, Step 17, Loss: 0.01477791741490364\n",
            "Epoch 2, Step 18, Loss: 0.016175519675016403\n",
            "Epoch 2, Step 19, Loss: 0.018725289031863213\n",
            "Epoch 2, Step 20, Loss: 0.018537305295467377\n",
            "Epoch 2, Step 21, Loss: 0.01751874014735222\n",
            "Epoch 2, Step 22, Loss: 0.020412934944033623\n",
            "Epoch 2, Step 23, Loss: 0.021932007744908333\n",
            "Epoch 2, Step 24, Loss: 0.0215811338275671\n",
            "Epoch 2, Step 25, Loss: 0.01946718618273735\n",
            "Epoch 2, Step 26, Loss: 0.023116637021303177\n",
            "Epoch 2, Step 27, Loss: 0.017746496945619583\n",
            "Epoch 2, Step 28, Loss: 0.018511194735765457\n",
            "Epoch 2, Step 29, Loss: 0.01839528977870941\n",
            "Epoch 2, Step 30, Loss: 0.016706405207514763\n",
            "Epoch 2, Step 31, Loss: 0.01964869350194931\n",
            "Epoch 2, Step 32, Loss: 0.014971906319260597\n",
            "Epoch 2, Step 33, Loss: 0.015082799829542637\n",
            "Epoch 2, Step 34, Loss: 0.01387748308479786\n",
            "Epoch 2, Step 35, Loss: 0.014437700621783733\n",
            "Epoch 2, Step 36, Loss: 0.012490890920162201\n",
            "Epoch 2, Step 37, Loss: 0.014930082485079765\n",
            "Epoch 2, Step 38, Loss: 0.012901471927762032\n",
            "Epoch 2, Step 39, Loss: 0.014698288403451443\n",
            "Epoch 2, Step 40, Loss: 0.014358166605234146\n",
            "Epoch 2, Step 41, Loss: 0.014080600813031197\n",
            "Epoch 2, Step 42, Loss: 0.013010744005441666\n",
            "Epoch 2, Step 43, Loss: 0.012425043620169163\n",
            "Epoch 2, Step 44, Loss: 0.01247317437082529\n",
            "Epoch 2, Step 45, Loss: 0.012211780995130539\n",
            "Epoch 2, Step 46, Loss: 0.012148505076766014\n",
            "Epoch 2, Step 47, Loss: 0.013199446722865105\n",
            "Epoch 2, Step 48, Loss: 0.011658182367682457\n",
            "Epoch 2, Step 49, Loss: 0.011062046512961388\n",
            "Epoch 2, Step 50, Loss: 0.012006282806396484\n",
            "Epoch 2, Step 51, Loss: 0.01248954702168703\n",
            "Epoch 2, Step 52, Loss: 0.011312847025692463\n",
            "Epoch 2, Step 53, Loss: 0.015271398238837719\n",
            "Epoch 2, Step 54, Loss: 0.010985448956489563\n",
            "Epoch 2, Step 55, Loss: 0.011208907701075077\n",
            "Epoch 2, Step 56, Loss: 0.010565056465566158\n",
            "Epoch 2, Step 57, Loss: 0.010040028020739555\n",
            "Epoch 2, Step 58, Loss: 0.009531555697321892\n",
            "Epoch 2, Step 59, Loss: 0.00924411416053772\n",
            "Epoch 2, Step 60, Loss: 0.010113170370459557\n",
            "Epoch 2, Step 61, Loss: 0.011610147543251514\n",
            "Epoch 2, Step 62, Loss: 0.010058415122330189\n",
            "Epoch 2, Step 63, Loss: 0.011017457582056522\n",
            "Epoch 2, Step 64, Loss: 0.00982587318867445\n",
            "Epoch 2, Step 65, Loss: 0.011806396767497063\n",
            "Epoch 2, Step 66, Loss: 0.011603896506130695\n",
            "Epoch 2, Step 67, Loss: 0.012630393728613853\n",
            "Epoch 2, Step 68, Loss: 0.013265041634440422\n",
            "Epoch 2, Step 69, Loss: 0.012998071499168873\n",
            "Epoch 2, Step 70, Loss: 0.01578882709145546\n",
            "Epoch 2, Step 71, Loss: 0.01456893514841795\n",
            "Epoch 2, Step 72, Loss: 0.0147587014362216\n",
            "Epoch 2, Step 73, Loss: 0.01170226838439703\n",
            "Epoch 2, Step 74, Loss: 0.011315830051898956\n",
            "Epoch 2, Step 75, Loss: 0.012801962904632092\n",
            "Epoch 2, Step 76, Loss: 0.014277010224759579\n",
            "Epoch 2, Step 77, Loss: 0.01308829989284277\n",
            "Epoch 2, Step 78, Loss: 0.011223578825592995\n",
            "Epoch 2, Step 79, Loss: 0.01229864452034235\n",
            "Epoch 2, Step 80, Loss: 0.012576083652675152\n",
            "Epoch 2, Step 81, Loss: 0.015911614522337914\n",
            "Epoch 2, Step 82, Loss: 0.016069158911705017\n",
            "Epoch 2, Step 83, Loss: 0.013181028887629509\n",
            "Epoch 2, Step 84, Loss: 0.014136533252894878\n",
            "Epoch 2, Step 85, Loss: 0.01722479797899723\n",
            "Train Metric MRRs: 0.029555675202113916\n",
            "Train Metric MAPs: 0.006489955937005262\n",
            "Validation Metric MRRs: 0.04507138130630232\n",
            "Validation Metric MAPs: 0.011529942171587784\n",
            "Epoch 3, Step 1, Loss: 0.05434112995862961\n",
            "Epoch 3, Step 2, Loss: 0.04380994290113449\n",
            "Epoch 3, Step 3, Loss: 0.04637310653924942\n",
            "Epoch 3, Step 4, Loss: 0.0289990846067667\n",
            "Epoch 3, Step 5, Loss: 0.020756682381033897\n",
            "Epoch 3, Step 6, Loss: 0.016357379034161568\n",
            "Epoch 3, Step 7, Loss: 0.011623406782746315\n",
            "Epoch 3, Step 8, Loss: 0.009960997849702835\n",
            "Epoch 3, Step 9, Loss: 0.009870056994259357\n",
            "Epoch 3, Step 10, Loss: 0.010565286502242088\n",
            "Epoch 3, Step 11, Loss: 0.010875021107494831\n",
            "Epoch 3, Step 12, Loss: 0.010420401580631733\n",
            "Epoch 3, Step 13, Loss: 0.010975048877298832\n",
            "Epoch 3, Step 14, Loss: 0.010846308432519436\n",
            "Epoch 3, Step 15, Loss: 0.009820738807320595\n",
            "Epoch 3, Step 16, Loss: 0.010907046496868134\n",
            "Epoch 3, Step 17, Loss: 0.0131544079631567\n",
            "Epoch 3, Step 18, Loss: 0.014694233424961567\n",
            "Epoch 3, Step 19, Loss: 0.017240474000573158\n",
            "Epoch 3, Step 20, Loss: 0.017030322924256325\n",
            "Epoch 3, Step 21, Loss: 0.015597089193761349\n",
            "Epoch 3, Step 22, Loss: 0.01835458353161812\n",
            "Epoch 3, Step 23, Loss: 0.019629577174782753\n",
            "Epoch 3, Step 24, Loss: 0.019497012719511986\n",
            "Epoch 3, Step 25, Loss: 0.017732031643390656\n",
            "Epoch 3, Step 26, Loss: 0.02003050036728382\n",
            "Epoch 3, Step 27, Loss: 0.014765499159693718\n",
            "Epoch 3, Step 28, Loss: 0.017453975975513458\n",
            "Epoch 3, Step 29, Loss: 0.015716800466179848\n",
            "Epoch 3, Step 30, Loss: 0.014519031159579754\n",
            "Epoch 3, Step 31, Loss: 0.01673402264714241\n",
            "Epoch 3, Step 32, Loss: 0.01444550883024931\n",
            "Epoch 3, Step 33, Loss: 0.014056992717087269\n",
            "Epoch 3, Step 34, Loss: 0.01301124319434166\n",
            "Epoch 3, Step 35, Loss: 0.013478166423738003\n",
            "Epoch 3, Step 36, Loss: 0.01185753382742405\n",
            "Epoch 3, Step 37, Loss: 0.013706406578421593\n",
            "Epoch 3, Step 38, Loss: 0.012899182736873627\n",
            "Epoch 3, Step 39, Loss: 0.014186419546604156\n",
            "Epoch 3, Step 40, Loss: 0.013889288529753685\n",
            "Epoch 3, Step 41, Loss: 0.012614334002137184\n",
            "Epoch 3, Step 42, Loss: 0.012159202247858047\n",
            "Epoch 3, Step 43, Loss: 0.011326083913445473\n",
            "Epoch 3, Step 44, Loss: 0.011471900157630444\n",
            "Epoch 3, Step 45, Loss: 0.011925356462597847\n",
            "Epoch 3, Step 46, Loss: 0.011460975743830204\n",
            "Epoch 3, Step 47, Loss: 0.011825131252408028\n",
            "Epoch 3, Step 48, Loss: 0.010899152606725693\n",
            "Epoch 3, Step 49, Loss: 0.010290936566889286\n",
            "Epoch 3, Step 50, Loss: 0.010855942964553833\n",
            "Epoch 3, Step 51, Loss: 0.010975190438330173\n",
            "Epoch 3, Step 52, Loss: 0.010601247660815716\n",
            "Epoch 3, Step 53, Loss: 0.014649284072220325\n",
            "Epoch 3, Step 54, Loss: 0.0107233552262187\n",
            "Epoch 3, Step 55, Loss: 0.010248190723359585\n",
            "Epoch 3, Step 56, Loss: 0.010377971455454826\n",
            "Epoch 3, Step 57, Loss: 0.00954531505703926\n",
            "Epoch 3, Step 58, Loss: 0.009253004565834999\n",
            "Epoch 3, Step 59, Loss: 0.008711041882634163\n",
            "Epoch 3, Step 60, Loss: 0.009168106131255627\n",
            "Epoch 3, Step 61, Loss: 0.011348268017172813\n",
            "Epoch 3, Step 62, Loss: 0.009669387713074684\n",
            "Epoch 3, Step 63, Loss: 0.010162275284528732\n",
            "Epoch 3, Step 64, Loss: 0.00944091472774744\n",
            "Epoch 3, Step 65, Loss: 0.011225301772356033\n",
            "Epoch 3, Step 66, Loss: 0.010919822379946709\n",
            "Epoch 3, Step 67, Loss: 0.012337121181190014\n",
            "Epoch 3, Step 68, Loss: 0.012131021358072758\n",
            "Epoch 3, Step 69, Loss: 0.012327940203249454\n",
            "Epoch 3, Step 70, Loss: 0.015564571134746075\n",
            "Epoch 3, Step 71, Loss: 0.014109048061072826\n",
            "Epoch 3, Step 72, Loss: 0.014134089462459087\n",
            "Epoch 3, Step 73, Loss: 0.011505287140607834\n",
            "Epoch 3, Step 74, Loss: 0.01101358700543642\n",
            "Epoch 3, Step 75, Loss: 0.01261665765196085\n",
            "Epoch 3, Step 76, Loss: 0.013795627281069756\n",
            "Epoch 3, Step 77, Loss: 0.012994233518838882\n",
            "Epoch 3, Step 78, Loss: 0.010582488030195236\n",
            "Epoch 3, Step 79, Loss: 0.011796974577009678\n",
            "Epoch 3, Step 80, Loss: 0.012271654792129993\n",
            "Epoch 3, Step 81, Loss: 0.015075044706463814\n",
            "Epoch 3, Step 82, Loss: 0.015249468386173248\n",
            "Epoch 3, Step 83, Loss: 0.013070656917989254\n",
            "Epoch 3, Step 84, Loss: 0.014168945141136646\n",
            "Epoch 3, Step 85, Loss: 0.01665605790913105\n",
            "Train Metric MRRs: 0.03918191113489792\n",
            "Train Metric MAPs: 0.007941495471740516\n",
            "Validation Metric MRRs: 0.05233201960717669\n",
            "Validation Metric MAPs: 0.014212430122439357\n",
            "Epoch 4, Step 1, Loss: 0.05256848409771919\n",
            "Epoch 4, Step 2, Loss: 0.04091908037662506\n",
            "Epoch 4, Step 3, Loss: 0.040565598756074905\n",
            "Epoch 4, Step 4, Loss: 0.02646114118397236\n",
            "Epoch 4, Step 5, Loss: 0.02015022002160549\n",
            "Epoch 4, Step 6, Loss: 0.01584291085600853\n",
            "Epoch 4, Step 7, Loss: 0.011178551241755486\n",
            "Epoch 4, Step 8, Loss: 0.009417932480573654\n",
            "Epoch 4, Step 9, Loss: 0.009023073129355907\n",
            "Epoch 4, Step 10, Loss: 0.009393378160893917\n",
            "Epoch 4, Step 11, Loss: 0.009143185801804066\n",
            "Epoch 4, Step 12, Loss: 0.008903909474611282\n",
            "Epoch 4, Step 13, Loss: 0.008960399776697159\n",
            "Epoch 4, Step 14, Loss: 0.00887797400355339\n",
            "Epoch 4, Step 15, Loss: 0.008737676776945591\n",
            "Epoch 4, Step 16, Loss: 0.009805689565837383\n",
            "Epoch 4, Step 17, Loss: 0.012350674718618393\n",
            "Epoch 4, Step 18, Loss: 0.01411010604351759\n",
            "Epoch 4, Step 19, Loss: 0.016904467716813087\n",
            "Epoch 4, Step 20, Loss: 0.016583649441599846\n",
            "Epoch 4, Step 21, Loss: 0.015164255164563656\n",
            "Epoch 4, Step 22, Loss: 0.01763652078807354\n",
            "Epoch 4, Step 23, Loss: 0.01928630657494068\n",
            "Epoch 4, Step 24, Loss: 0.01842326670885086\n",
            "Epoch 4, Step 25, Loss: 0.01754617504775524\n",
            "Epoch 4, Step 26, Loss: 0.019320717081427574\n",
            "Epoch 4, Step 27, Loss: 0.014496359042823315\n",
            "Epoch 4, Step 28, Loss: 0.015766778960824013\n",
            "Epoch 4, Step 29, Loss: 0.015121559612452984\n",
            "Epoch 4, Step 30, Loss: 0.014300420880317688\n",
            "Epoch 4, Step 31, Loss: 0.01686139404773712\n",
            "Epoch 4, Step 32, Loss: 0.01406426914036274\n",
            "Epoch 4, Step 33, Loss: 0.014374516904354095\n",
            "Epoch 4, Step 34, Loss: 0.012457937933504581\n",
            "Epoch 4, Step 35, Loss: 0.01330411434173584\n",
            "Epoch 4, Step 36, Loss: 0.011397019028663635\n",
            "Epoch 4, Step 37, Loss: 0.013423020020127296\n",
            "Epoch 4, Step 38, Loss: 0.011777850799262524\n",
            "Epoch 4, Step 39, Loss: 0.013955624774098396\n",
            "Epoch 4, Step 40, Loss: 0.01388867013156414\n",
            "Epoch 4, Step 41, Loss: 0.012046500109136105\n",
            "Epoch 4, Step 42, Loss: 0.011948324739933014\n",
            "Epoch 4, Step 43, Loss: 0.010842596180737019\n",
            "Epoch 4, Step 44, Loss: 0.01115647703409195\n",
            "Epoch 4, Step 45, Loss: 0.011431446298956871\n",
            "Epoch 4, Step 46, Loss: 0.011435948312282562\n",
            "Epoch 4, Step 47, Loss: 0.011721502058207989\n",
            "Epoch 4, Step 48, Loss: 0.010950896888971329\n",
            "Epoch 4, Step 49, Loss: 0.01005313079804182\n",
            "Epoch 4, Step 50, Loss: 0.01016881875693798\n",
            "Epoch 4, Step 51, Loss: 0.010859089903533459\n",
            "Epoch 4, Step 52, Loss: 0.010381165891885757\n",
            "Epoch 4, Step 53, Loss: 0.014513171277940273\n",
            "Epoch 4, Step 54, Loss: 0.010780101642012596\n",
            "Epoch 4, Step 55, Loss: 0.009906762279570103\n",
            "Epoch 4, Step 56, Loss: 0.010507776401937008\n",
            "Epoch 4, Step 57, Loss: 0.009276415221393108\n",
            "Epoch 4, Step 58, Loss: 0.009155485779047012\n",
            "Epoch 4, Step 59, Loss: 0.008531647734344006\n",
            "Epoch 4, Step 60, Loss: 0.00916915014386177\n",
            "Epoch 4, Step 61, Loss: 0.011049299500882626\n",
            "Epoch 4, Step 62, Loss: 0.009802889078855515\n",
            "Epoch 4, Step 63, Loss: 0.010468331165611744\n",
            "Epoch 4, Step 64, Loss: 0.009386773221194744\n",
            "Epoch 4, Step 65, Loss: 0.010743252001702785\n",
            "Epoch 4, Step 66, Loss: 0.010744418948888779\n",
            "Epoch 4, Step 67, Loss: 0.012037359178066254\n",
            "Epoch 4, Step 68, Loss: 0.011935871094465256\n",
            "Epoch 4, Step 69, Loss: 0.012481003999710083\n",
            "Epoch 4, Step 70, Loss: 0.015457512810826302\n",
            "Epoch 4, Step 71, Loss: 0.013857262209057808\n",
            "Epoch 4, Step 72, Loss: 0.013838965445756912\n",
            "Epoch 4, Step 73, Loss: 0.011286618188023567\n",
            "Epoch 4, Step 74, Loss: 0.010800691321492195\n",
            "Epoch 4, Step 75, Loss: 0.012478182092308998\n",
            "Epoch 4, Step 76, Loss: 0.013284987770020962\n",
            "Epoch 4, Step 77, Loss: 0.012866516597568989\n",
            "Epoch 4, Step 78, Loss: 0.010746873915195465\n",
            "Epoch 4, Step 79, Loss: 0.011565353721380234\n",
            "Epoch 4, Step 80, Loss: 0.012122982181608677\n",
            "Epoch 4, Step 81, Loss: 0.015703657642006874\n",
            "Epoch 4, Step 82, Loss: 0.01455035898834467\n",
            "Epoch 4, Step 83, Loss: 0.012826905585825443\n",
            "Epoch 4, Step 84, Loss: 0.014006794430315495\n",
            "Epoch 4, Step 85, Loss: 0.016741232946515083\n",
            "Train Metric MRRs: 0.0489206991967307\n",
            "Train Metric MAPs: 0.010605091954913784\n",
            "Validation Metric MRRs: 0.056626189676587446\n",
            "Validation Metric MAPs: 0.014031064772357917\n",
            "Epoch 5, Step 1, Loss: 0.05219689756631851\n",
            "Epoch 5, Step 2, Loss: 0.04103214293718338\n",
            "Epoch 5, Step 3, Loss: 0.04046785458922386\n",
            "Epoch 5, Step 4, Loss: 0.026828719303011894\n",
            "Epoch 5, Step 5, Loss: 0.020451243966817856\n",
            "Epoch 5, Step 6, Loss: 0.015419249422848225\n",
            "Epoch 5, Step 7, Loss: 0.010411957278847694\n",
            "Epoch 5, Step 8, Loss: 0.009076385758817196\n",
            "Epoch 5, Step 9, Loss: 0.0098502766340971\n",
            "Epoch 5, Step 10, Loss: 0.00938156433403492\n",
            "Epoch 5, Step 11, Loss: 0.009411867707967758\n",
            "Epoch 5, Step 12, Loss: 0.009252243675291538\n",
            "Epoch 5, Step 13, Loss: 0.009491056203842163\n",
            "Epoch 5, Step 14, Loss: 0.008782004937529564\n",
            "Epoch 5, Step 15, Loss: 0.008463427424430847\n",
            "Epoch 5, Step 16, Loss: 0.009909654967486858\n",
            "Epoch 5, Step 17, Loss: 0.012500193901360035\n",
            "Epoch 5, Step 18, Loss: 0.0141788674518466\n",
            "Epoch 5, Step 19, Loss: 0.01684396155178547\n",
            "Epoch 5, Step 20, Loss: 0.01659420318901539\n",
            "Epoch 5, Step 21, Loss: 0.015243412926793098\n",
            "Epoch 5, Step 22, Loss: 0.01771046780049801\n",
            "Epoch 5, Step 23, Loss: 0.018930640071630478\n",
            "Epoch 5, Step 24, Loss: 0.01839897595345974\n",
            "Epoch 5, Step 25, Loss: 0.01705487072467804\n",
            "Epoch 5, Step 26, Loss: 0.018016038462519646\n",
            "Epoch 5, Step 27, Loss: 0.01382131315767765\n",
            "Epoch 5, Step 28, Loss: 0.015984728932380676\n",
            "Epoch 5, Step 29, Loss: 0.015576955862343311\n",
            "Epoch 5, Step 30, Loss: 0.014035803265869617\n",
            "Epoch 5, Step 31, Loss: 0.01584506593644619\n",
            "Epoch 5, Step 32, Loss: 0.014146370813250542\n",
            "Epoch 5, Step 33, Loss: 0.013430108316242695\n",
            "Epoch 5, Step 34, Loss: 0.012880762107670307\n",
            "Epoch 5, Step 35, Loss: 0.013208737596869469\n",
            "Epoch 5, Step 36, Loss: 0.011320795863866806\n",
            "Epoch 5, Step 37, Loss: 0.013006002642214298\n",
            "Epoch 5, Step 38, Loss: 0.011750217527151108\n",
            "Epoch 5, Step 39, Loss: 0.01378757692873478\n",
            "Epoch 5, Step 40, Loss: 0.013300947844982147\n",
            "Epoch 5, Step 41, Loss: 0.012133565731346607\n",
            "Epoch 5, Step 42, Loss: 0.011276629753410816\n",
            "Epoch 5, Step 43, Loss: 0.01101794932037592\n",
            "Epoch 5, Step 44, Loss: 0.010911808349192142\n",
            "Epoch 5, Step 45, Loss: 0.01157644484192133\n",
            "Epoch 5, Step 46, Loss: 0.011030614376068115\n",
            "Epoch 5, Step 47, Loss: 0.011308872140944004\n",
            "Epoch 5, Step 48, Loss: 0.010599725879728794\n",
            "Epoch 5, Step 49, Loss: 0.009866251610219479\n",
            "Epoch 5, Step 50, Loss: 0.010621532797813416\n",
            "Epoch 5, Step 51, Loss: 0.01080323662608862\n",
            "Epoch 5, Step 52, Loss: 0.010087930597364902\n",
            "Epoch 5, Step 53, Loss: 0.014668933115899563\n",
            "Epoch 5, Step 54, Loss: 0.01037655584514141\n",
            "Epoch 5, Step 55, Loss: 0.00972733087837696\n",
            "Epoch 5, Step 56, Loss: 0.010333566926419735\n",
            "Epoch 5, Step 57, Loss: 0.009352421388030052\n",
            "Epoch 5, Step 58, Loss: 0.00891993846744299\n",
            "Epoch 5, Step 59, Loss: 0.008359096944332123\n",
            "Epoch 5, Step 60, Loss: 0.0090325977653265\n",
            "Epoch 5, Step 61, Loss: 0.011012397706508636\n",
            "Epoch 5, Step 62, Loss: 0.009396310895681381\n",
            "Epoch 5, Step 63, Loss: 0.0097957793623209\n",
            "Epoch 5, Step 64, Loss: 0.009088324382901192\n",
            "Epoch 5, Step 65, Loss: 0.01087625790387392\n",
            "Epoch 5, Step 66, Loss: 0.010743720456957817\n",
            "Epoch 5, Step 67, Loss: 0.012370145879685879\n",
            "Epoch 5, Step 68, Loss: 0.012129937298595905\n",
            "Epoch 5, Step 69, Loss: 0.01203036680817604\n",
            "Epoch 5, Step 70, Loss: 0.015548774972558022\n",
            "Epoch 5, Step 71, Loss: 0.013569585978984833\n",
            "Epoch 5, Step 72, Loss: 0.013516264967620373\n",
            "Epoch 5, Step 73, Loss: 0.01125905942171812\n",
            "Epoch 5, Step 74, Loss: 0.010763845406472683\n",
            "Epoch 5, Step 75, Loss: 0.01219653058797121\n",
            "Epoch 5, Step 76, Loss: 0.013026464730501175\n",
            "Epoch 5, Step 77, Loss: 0.012603862211108208\n",
            "Epoch 5, Step 78, Loss: 0.010619012638926506\n",
            "Epoch 5, Step 79, Loss: 0.011386433616280556\n",
            "Epoch 5, Step 80, Loss: 0.01218333188444376\n",
            "Epoch 5, Step 81, Loss: 0.01809404417872429\n",
            "Epoch 5, Step 82, Loss: 0.014793808571994305\n",
            "Epoch 5, Step 83, Loss: 0.012831940315663815\n",
            "Epoch 5, Step 84, Loss: 0.0143359936773777\n",
            "Epoch 5, Step 85, Loss: 0.01713443174958229\n",
            "Train Metric MRRs: 0.05821918150008243\n",
            "Train Metric MAPs: 0.010953505456958099\n",
            "Validation Metric MRRs: 0.050980374281787956\n",
            "Validation Metric MAPs: 0.012657338118722697\n",
            "Epoch 6, Step 1, Loss: 0.05023692175745964\n",
            "Epoch 6, Step 2, Loss: 0.03973851725459099\n",
            "Epoch 6, Step 3, Loss: 0.038817599415779114\n",
            "Epoch 6, Step 4, Loss: 0.02702837809920311\n",
            "Epoch 6, Step 5, Loss: 0.020423920825123787\n",
            "Epoch 6, Step 6, Loss: 0.015474720858037472\n",
            "Epoch 6, Step 7, Loss: 0.010797294788062572\n",
            "Epoch 6, Step 8, Loss: 0.008867790922522545\n",
            "Epoch 6, Step 9, Loss: 0.008599386550486088\n",
            "Epoch 6, Step 10, Loss: 0.009086660109460354\n",
            "Epoch 6, Step 11, Loss: 0.008458109572529793\n",
            "Epoch 6, Step 12, Loss: 0.008412541821599007\n",
            "Epoch 6, Step 13, Loss: 0.008203485980629921\n",
            "Epoch 6, Step 14, Loss: 0.008014325052499771\n",
            "Epoch 6, Step 15, Loss: 0.007849274203181267\n",
            "Epoch 6, Step 16, Loss: 0.009235802106559277\n",
            "Epoch 6, Step 17, Loss: 0.012075438164174557\n",
            "Epoch 6, Step 18, Loss: 0.013925166800618172\n",
            "Epoch 6, Step 19, Loss: 0.01642262190580368\n",
            "Epoch 6, Step 20, Loss: 0.016618935391306877\n",
            "Epoch 6, Step 21, Loss: 0.0158326867967844\n",
            "Epoch 6, Step 22, Loss: 0.016871215775609016\n",
            "Epoch 6, Step 23, Loss: 0.019194968044757843\n",
            "Epoch 6, Step 24, Loss: 0.01815973035991192\n",
            "Epoch 6, Step 25, Loss: 0.01715269684791565\n",
            "Epoch 6, Step 26, Loss: 0.01840507611632347\n",
            "Epoch 6, Step 27, Loss: 0.013772929087281227\n",
            "Epoch 6, Step 28, Loss: 0.015039356425404549\n",
            "Epoch 6, Step 29, Loss: 0.0147829195484519\n",
            "Epoch 6, Step 30, Loss: 0.014243713580071926\n",
            "Epoch 6, Step 31, Loss: 0.01591295562684536\n",
            "Epoch 6, Step 32, Loss: 0.01430950965732336\n",
            "Epoch 6, Step 33, Loss: 0.013674631714820862\n",
            "Epoch 6, Step 34, Loss: 0.012142336927354336\n",
            "Epoch 6, Step 35, Loss: 0.013092752546072006\n",
            "Epoch 6, Step 36, Loss: 0.011634569615125656\n",
            "Epoch 6, Step 37, Loss: 0.013573220930993557\n",
            "Epoch 6, Step 38, Loss: 0.011989939026534557\n",
            "Epoch 6, Step 39, Loss: 0.014437331818044186\n",
            "Epoch 6, Step 40, Loss: 0.013972391374409199\n",
            "Epoch 6, Step 41, Loss: 0.012153765186667442\n",
            "Epoch 6, Step 42, Loss: 0.012426656670868397\n",
            "Epoch 6, Step 43, Loss: 0.010470859706401825\n",
            "Epoch 6, Step 44, Loss: 0.010954511351883411\n",
            "Epoch 6, Step 45, Loss: 0.011423821561038494\n",
            "Epoch 6, Step 46, Loss: 0.010964326560497284\n",
            "Epoch 6, Step 47, Loss: 0.01153184100985527\n",
            "Epoch 6, Step 48, Loss: 0.010671321302652359\n",
            "Epoch 6, Step 49, Loss: 0.009715189225971699\n",
            "Epoch 6, Step 50, Loss: 0.010207017883658409\n",
            "Epoch 6, Step 51, Loss: 0.01107045542448759\n",
            "Epoch 6, Step 52, Loss: 0.010219017043709755\n",
            "Epoch 6, Step 53, Loss: 0.014498447999358177\n",
            "Epoch 6, Step 54, Loss: 0.010906616225838661\n",
            "Epoch 6, Step 55, Loss: 0.009697564877569675\n",
            "Epoch 6, Step 56, Loss: 0.010733721777796745\n",
            "Epoch 6, Step 57, Loss: 0.0093147037550807\n",
            "Epoch 6, Step 58, Loss: 0.009414063766598701\n",
            "Epoch 6, Step 59, Loss: 0.008521045558154583\n",
            "Epoch 6, Step 60, Loss: 0.009588368237018585\n",
            "Epoch 6, Step 61, Loss: 0.011031662113964558\n",
            "Epoch 6, Step 62, Loss: 0.009801087900996208\n",
            "Epoch 6, Step 63, Loss: 0.010586653836071491\n",
            "Epoch 6, Step 64, Loss: 0.009228413924574852\n",
            "Epoch 6, Step 65, Loss: 0.010442683473229408\n",
            "Epoch 6, Step 66, Loss: 0.010390146635472775\n",
            "Epoch 6, Step 67, Loss: 0.011654959991574287\n",
            "Epoch 6, Step 68, Loss: 0.012256895191967487\n",
            "Epoch 6, Step 69, Loss: 0.01266487780958414\n",
            "Epoch 6, Step 70, Loss: 0.015607464127242565\n",
            "Epoch 6, Step 71, Loss: 0.013581263832747936\n",
            "Epoch 6, Step 72, Loss: 0.013916665688157082\n",
            "Epoch 6, Step 73, Loss: 0.011071485467255116\n",
            "Epoch 6, Step 74, Loss: 0.010671824216842651\n",
            "Epoch 6, Step 75, Loss: 0.012383155524730682\n",
            "Epoch 6, Step 76, Loss: 0.01326552964746952\n",
            "Epoch 6, Step 77, Loss: 0.012614967301487923\n",
            "Epoch 6, Step 78, Loss: 0.01198999397456646\n",
            "Epoch 6, Step 79, Loss: 0.011295882984995842\n",
            "Epoch 6, Step 80, Loss: 0.012106305919587612\n",
            "Epoch 6, Step 81, Loss: 0.016850003972649574\n",
            "Epoch 6, Step 82, Loss: 0.014920281246304512\n",
            "Epoch 6, Step 83, Loss: 0.013519888743758202\n",
            "Epoch 6, Step 84, Loss: 0.013963724486529827\n",
            "Epoch 6, Step 85, Loss: 0.016716349869966507\n",
            "Train Metric MRRs: 0.058862115956319114\n",
            "Train Metric MAPs: 0.011044642979073064\n",
            "Validation Metric MRRs: 0.05865633534086222\n",
            "Validation Metric MAPs: 0.013669120921609918\n",
            "Epoch 7, Step 1, Loss: 0.0508858859539032\n",
            "Epoch 7, Step 2, Loss: 0.0407009981572628\n",
            "Epoch 7, Step 3, Loss: 0.03949807956814766\n",
            "Epoch 7, Step 4, Loss: 0.02755098231136799\n",
            "Epoch 7, Step 5, Loss: 0.020904000848531723\n",
            "Epoch 7, Step 6, Loss: 0.015399430878460407\n",
            "Epoch 7, Step 7, Loss: 0.010447323322296143\n",
            "Epoch 7, Step 8, Loss: 0.009244660846889019\n",
            "Epoch 7, Step 9, Loss: 0.009757857769727707\n",
            "Epoch 7, Step 10, Loss: 0.009706570766866207\n",
            "Epoch 7, Step 11, Loss: 0.00939077977091074\n",
            "Epoch 7, Step 12, Loss: 0.00942416675388813\n",
            "Epoch 7, Step 13, Loss: 0.009667899459600449\n",
            "Epoch 7, Step 14, Loss: 0.009307592175900936\n",
            "Epoch 7, Step 15, Loss: 0.008723103441298008\n",
            "Epoch 7, Step 16, Loss: 0.010095766745507717\n",
            "Epoch 7, Step 17, Loss: 0.012670878320932388\n",
            "Epoch 7, Step 18, Loss: 0.014017010107636452\n",
            "Epoch 7, Step 19, Loss: 0.016240639612078667\n",
            "Epoch 7, Step 20, Loss: 0.0163473691791296\n",
            "Epoch 7, Step 21, Loss: 0.015369615517556667\n",
            "Epoch 7, Step 22, Loss: 0.017773441970348358\n",
            "Epoch 7, Step 23, Loss: 0.019322874024510384\n",
            "Epoch 7, Step 24, Loss: 0.017866602167487144\n",
            "Epoch 7, Step 25, Loss: 0.016996068879961967\n",
            "Epoch 7, Step 26, Loss: 0.017690567299723625\n",
            "Epoch 7, Step 27, Loss: 0.013785571791231632\n",
            "Epoch 7, Step 28, Loss: 0.015714917331933975\n",
            "Epoch 7, Step 29, Loss: 0.015256233513355255\n",
            "Epoch 7, Step 30, Loss: 0.014110389165580273\n",
            "Epoch 7, Step 31, Loss: 0.01584833860397339\n",
            "Epoch 7, Step 32, Loss: 0.014208265580236912\n",
            "Epoch 7, Step 33, Loss: 0.013302958570420742\n",
            "Epoch 7, Step 34, Loss: 0.01210966520011425\n",
            "Epoch 7, Step 35, Loss: 0.012973252683877945\n",
            "Epoch 7, Step 36, Loss: 0.011236222460865974\n",
            "Epoch 7, Step 37, Loss: 0.012739737518131733\n",
            "Epoch 7, Step 38, Loss: 0.011546033434569836\n",
            "Epoch 7, Step 39, Loss: 0.013745453208684921\n",
            "Epoch 7, Step 40, Loss: 0.013093679212033749\n",
            "Epoch 7, Step 41, Loss: 0.011826474219560623\n",
            "Epoch 7, Step 42, Loss: 0.011572254821658134\n",
            "Epoch 7, Step 43, Loss: 0.010661348700523376\n",
            "Epoch 7, Step 44, Loss: 0.010663866065442562\n",
            "Epoch 7, Step 45, Loss: 0.01151933241635561\n",
            "Epoch 7, Step 46, Loss: 0.01090958435088396\n",
            "Epoch 7, Step 47, Loss: 0.011207770556211472\n",
            "Epoch 7, Step 48, Loss: 0.010537986643612385\n",
            "Epoch 7, Step 49, Loss: 0.009997081942856312\n",
            "Epoch 7, Step 50, Loss: 0.009798336774110794\n",
            "Epoch 7, Step 51, Loss: 0.010729518719017506\n",
            "Epoch 7, Step 52, Loss: 0.010101758874952793\n",
            "Epoch 7, Step 53, Loss: 0.014320207759737968\n",
            "Epoch 7, Step 54, Loss: 0.010248164646327496\n",
            "Epoch 7, Step 55, Loss: 0.009748702868819237\n",
            "Epoch 7, Step 56, Loss: 0.010005014948546886\n",
            "Epoch 7, Step 57, Loss: 0.009257561527192593\n",
            "Epoch 7, Step 58, Loss: 0.008801279589533806\n",
            "Epoch 7, Step 59, Loss: 0.00816535484045744\n",
            "Epoch 7, Step 60, Loss: 0.009511701762676239\n",
            "Epoch 7, Step 61, Loss: 0.01101811695843935\n",
            "Epoch 7, Step 62, Loss: 0.009318249300122261\n",
            "Epoch 7, Step 63, Loss: 0.00961713120341301\n",
            "Epoch 7, Step 64, Loss: 0.008978521451354027\n",
            "Epoch 7, Step 65, Loss: 0.010656340979039669\n",
            "Epoch 7, Step 66, Loss: 0.010354345664381981\n",
            "Epoch 7, Step 67, Loss: 0.012355850078165531\n",
            "Epoch 7, Step 68, Loss: 0.012251593172550201\n",
            "Epoch 7, Step 69, Loss: 0.012378359213471413\n",
            "Epoch 7, Step 70, Loss: 0.015904469415545464\n",
            "Epoch 7, Step 71, Loss: 0.013565387576818466\n",
            "Epoch 7, Step 72, Loss: 0.014179352670907974\n",
            "Epoch 7, Step 73, Loss: 0.01119665615260601\n",
            "Epoch 7, Step 74, Loss: 0.01041001919656992\n",
            "Epoch 7, Step 75, Loss: 0.012061555869877338\n",
            "Epoch 7, Step 76, Loss: 0.012716938741505146\n",
            "Epoch 7, Step 77, Loss: 0.012680480256676674\n",
            "Epoch 7, Step 78, Loss: 0.010219746269285679\n",
            "Epoch 7, Step 79, Loss: 0.01130002923309803\n",
            "Epoch 7, Step 80, Loss: 0.012178350239992142\n",
            "Epoch 7, Step 81, Loss: 0.0170130655169487\n",
            "Epoch 7, Step 82, Loss: 0.014709645882248878\n",
            "Epoch 7, Step 83, Loss: 0.01271568052470684\n",
            "Epoch 7, Step 84, Loss: 0.014100950211286545\n",
            "Epoch 7, Step 85, Loss: 0.016467778012156487\n",
            "Train Metric MRRs: 0.06920845188863121\n",
            "Train Metric MAPs: 0.012355142656140392\n",
            "Validation Metric MRRs: 0.05938101796262952\n",
            "Validation Metric MAPs: 0.014867781816231794\n",
            "Epoch 8, Step 1, Loss: 0.04915996640920639\n",
            "Epoch 8, Step 2, Loss: 0.039054594933986664\n",
            "Epoch 8, Step 3, Loss: 0.03794805333018303\n",
            "Epoch 8, Step 4, Loss: 0.025474952533841133\n",
            "Epoch 8, Step 5, Loss: 0.01893606036901474\n",
            "Epoch 8, Step 6, Loss: 0.015567907132208347\n",
            "Epoch 8, Step 7, Loss: 0.011084560304880142\n",
            "Epoch 8, Step 8, Loss: 0.009039731696248055\n",
            "Epoch 8, Step 9, Loss: 0.008964923210442066\n",
            "Epoch 8, Step 10, Loss: 0.009288404136896133\n",
            "Epoch 8, Step 11, Loss: 0.008855477906763554\n",
            "Epoch 8, Step 12, Loss: 0.008557972498238087\n",
            "Epoch 8, Step 13, Loss: 0.008256187662482262\n",
            "Epoch 8, Step 14, Loss: 0.007943110540509224\n",
            "Epoch 8, Step 15, Loss: 0.007784977555274963\n",
            "Epoch 8, Step 16, Loss: 0.009184299036860466\n",
            "Epoch 8, Step 17, Loss: 0.011834480799734592\n",
            "Epoch 8, Step 18, Loss: 0.014036374166607857\n",
            "Epoch 8, Step 19, Loss: 0.016397101804614067\n",
            "Epoch 8, Step 20, Loss: 0.016703123226761818\n",
            "Epoch 8, Step 21, Loss: 0.01490849256515503\n",
            "Epoch 8, Step 22, Loss: 0.01665889471769333\n",
            "Epoch 8, Step 23, Loss: 0.020828338339924812\n",
            "Epoch 8, Step 24, Loss: 0.017683593556284904\n",
            "Epoch 8, Step 25, Loss: 0.016815360635519028\n",
            "Epoch 8, Step 26, Loss: 0.017533374950289726\n",
            "Epoch 8, Step 27, Loss: 0.013526525348424911\n",
            "Epoch 8, Step 28, Loss: 0.014781814068555832\n",
            "Epoch 8, Step 29, Loss: 0.014557862654328346\n",
            "Epoch 8, Step 30, Loss: 0.014595032669603825\n",
            "Epoch 8, Step 31, Loss: 0.015598826110363007\n",
            "Epoch 8, Step 32, Loss: 0.013941265642642975\n",
            "Epoch 8, Step 33, Loss: 0.013241264037787914\n",
            "Epoch 8, Step 34, Loss: 0.012334954924881458\n",
            "Epoch 8, Step 35, Loss: 0.013170892372727394\n",
            "Epoch 8, Step 36, Loss: 0.01135243196040392\n",
            "Epoch 8, Step 37, Loss: 0.013510346412658691\n",
            "Epoch 8, Step 38, Loss: 0.011637070216238499\n",
            "Epoch 8, Step 39, Loss: 0.013537582941353321\n",
            "Epoch 8, Step 40, Loss: 0.013277735561132431\n",
            "Epoch 8, Step 41, Loss: 0.012115584686398506\n",
            "Epoch 8, Step 42, Loss: 0.011208897456526756\n",
            "Epoch 8, Step 43, Loss: 0.010604416020214558\n",
            "Epoch 8, Step 44, Loss: 0.011369854211807251\n",
            "Epoch 8, Step 45, Loss: 0.012294245883822441\n",
            "Epoch 8, Step 46, Loss: 0.011044960469007492\n",
            "Epoch 8, Step 47, Loss: 0.011005813255906105\n",
            "Epoch 8, Step 48, Loss: 0.010388805530965328\n",
            "Epoch 8, Step 49, Loss: 0.009820655919611454\n",
            "Epoch 8, Step 50, Loss: 0.009901450015604496\n",
            "Epoch 8, Step 51, Loss: 0.010995035991072655\n",
            "Epoch 8, Step 52, Loss: 0.009857040829956532\n",
            "Epoch 8, Step 53, Loss: 0.013991301879286766\n",
            "Epoch 8, Step 54, Loss: 0.010386213660240173\n",
            "Epoch 8, Step 55, Loss: 0.009826984256505966\n",
            "Epoch 8, Step 56, Loss: 0.010254137217998505\n",
            "Epoch 8, Step 57, Loss: 0.009453934617340565\n",
            "Epoch 8, Step 58, Loss: 0.009081128053367138\n",
            "Epoch 8, Step 59, Loss: 0.008103731088340282\n",
            "Epoch 8, Step 60, Loss: 0.009418252855539322\n",
            "Epoch 8, Step 61, Loss: 0.011170433834195137\n",
            "Epoch 8, Step 62, Loss: 0.009723762981593609\n",
            "Epoch 8, Step 63, Loss: 0.01047218032181263\n",
            "Epoch 8, Step 64, Loss: 0.009034413844347\n",
            "Epoch 8, Step 65, Loss: 0.01067914254963398\n",
            "Epoch 8, Step 66, Loss: 0.010565724223852158\n",
            "Epoch 8, Step 67, Loss: 0.011598632670938969\n",
            "Epoch 8, Step 68, Loss: 0.011596143245697021\n",
            "Epoch 8, Step 69, Loss: 0.012268474325537682\n",
            "Epoch 8, Step 70, Loss: 0.015548245050013065\n",
            "Epoch 8, Step 71, Loss: 0.013305455446243286\n",
            "Epoch 8, Step 72, Loss: 0.014733202755451202\n",
            "Epoch 8, Step 73, Loss: 0.010923564434051514\n",
            "Epoch 8, Step 74, Loss: 0.010521194897592068\n",
            "Epoch 8, Step 75, Loss: 0.011905454099178314\n",
            "Epoch 8, Step 76, Loss: 0.012775489129126072\n",
            "Epoch 8, Step 77, Loss: 0.012382222339510918\n",
            "Epoch 8, Step 78, Loss: 0.01023238617926836\n",
            "Epoch 8, Step 79, Loss: 0.011139743030071259\n",
            "Epoch 8, Step 80, Loss: 0.012141857296228409\n",
            "Epoch 8, Step 81, Loss: 0.014958955347537994\n",
            "Epoch 8, Step 82, Loss: 0.01439721416682005\n",
            "Epoch 8, Step 83, Loss: 0.012655780650675297\n",
            "Epoch 8, Step 84, Loss: 0.013724418357014656\n",
            "Epoch 8, Step 85, Loss: 0.016691066324710846\n",
            "Train Metric MRRs: 0.06727763176163284\n",
            "Train Metric MAPs: 0.012648513727795902\n",
            "Validation Metric MRRs: 0.05275573763755392\n",
            "Validation Metric MAPs: 0.014367819312098738\n",
            "Epoch 9, Step 1, Loss: 0.04906993359327316\n",
            "Epoch 9, Step 2, Loss: 0.03884310647845268\n",
            "Epoch 9, Step 3, Loss: 0.03856559470295906\n",
            "Epoch 9, Step 4, Loss: 0.025688081979751587\n",
            "Epoch 9, Step 5, Loss: 0.018970079720020294\n",
            "Epoch 9, Step 6, Loss: 0.015101529657840729\n",
            "Epoch 9, Step 7, Loss: 0.010254383087158203\n",
            "Epoch 9, Step 8, Loss: 0.009358130395412445\n",
            "Epoch 9, Step 9, Loss: 0.009326123632490635\n",
            "Epoch 9, Step 10, Loss: 0.009682067669928074\n",
            "Epoch 9, Step 11, Loss: 0.009588561952114105\n",
            "Epoch 9, Step 12, Loss: 0.009311172179877758\n",
            "Epoch 9, Step 13, Loss: 0.009002751670777798\n",
            "Epoch 9, Step 14, Loss: 0.00834120623767376\n",
            "Epoch 9, Step 15, Loss: 0.00806913897395134\n",
            "Epoch 9, Step 16, Loss: 0.00959963258355856\n",
            "Epoch 9, Step 17, Loss: 0.011966561898589134\n",
            "Epoch 9, Step 18, Loss: 0.013419114984571934\n",
            "Epoch 9, Step 19, Loss: 0.01580420508980751\n",
            "Epoch 9, Step 20, Loss: 0.016064617782831192\n",
            "Epoch 9, Step 21, Loss: 0.014716391451656818\n",
            "Epoch 9, Step 22, Loss: 0.01769309863448143\n",
            "Epoch 9, Step 23, Loss: 0.01889544166624546\n",
            "Epoch 9, Step 24, Loss: 0.017277345061302185\n",
            "Epoch 9, Step 25, Loss: 0.016711018979549408\n",
            "Epoch 9, Step 26, Loss: 0.017263101413846016\n",
            "Epoch 9, Step 27, Loss: 0.013423839583992958\n",
            "Epoch 9, Step 28, Loss: 0.015364677645266056\n",
            "Epoch 9, Step 29, Loss: 0.015102025121450424\n",
            "Epoch 9, Step 30, Loss: 0.013956560753285885\n",
            "Epoch 9, Step 31, Loss: 0.01524582039564848\n",
            "Epoch 9, Step 32, Loss: 0.01376450527459383\n",
            "Epoch 9, Step 33, Loss: 0.013199619017541409\n",
            "Epoch 9, Step 34, Loss: 0.011891921050846577\n",
            "Epoch 9, Step 35, Loss: 0.013075187802314758\n",
            "Epoch 9, Step 36, Loss: 0.011064662598073483\n",
            "Epoch 9, Step 37, Loss: 0.012442409992218018\n",
            "Epoch 9, Step 38, Loss: 0.011536866426467896\n",
            "Epoch 9, Step 39, Loss: 0.013505883514881134\n",
            "Epoch 9, Step 40, Loss: 0.013302660547196865\n",
            "Epoch 9, Step 41, Loss: 0.012110753916203976\n",
            "Epoch 9, Step 42, Loss: 0.012227090075612068\n",
            "Epoch 9, Step 43, Loss: 0.010645098984241486\n",
            "Epoch 9, Step 44, Loss: 0.011044291779398918\n",
            "Epoch 9, Step 45, Loss: 0.011183367110788822\n",
            "Epoch 9, Step 46, Loss: 0.01086096279323101\n",
            "Epoch 9, Step 47, Loss: 0.011031712405383587\n",
            "Epoch 9, Step 48, Loss: 0.010287942364811897\n",
            "Epoch 9, Step 49, Loss: 0.010351968929171562\n",
            "Epoch 9, Step 50, Loss: 0.010473789647221565\n",
            "Epoch 9, Step 51, Loss: 0.010851998813450336\n",
            "Epoch 9, Step 52, Loss: 0.01002622488886118\n",
            "Epoch 9, Step 53, Loss: 0.014643176458775997\n",
            "Epoch 9, Step 54, Loss: 0.010275078006088734\n",
            "Epoch 9, Step 55, Loss: 0.009461690671741962\n",
            "Epoch 9, Step 56, Loss: 0.010259571485221386\n",
            "Epoch 9, Step 57, Loss: 0.009019030258059502\n",
            "Epoch 9, Step 58, Loss: 0.008989820256829262\n",
            "Epoch 9, Step 59, Loss: 0.00822999607771635\n",
            "Epoch 9, Step 60, Loss: 0.008731716312468052\n",
            "Epoch 9, Step 61, Loss: 0.010739407502114773\n",
            "Epoch 9, Step 62, Loss: 0.009216363541781902\n",
            "Epoch 9, Step 63, Loss: 0.009459609165787697\n",
            "Epoch 9, Step 64, Loss: 0.00907629169523716\n",
            "Epoch 9, Step 65, Loss: 0.01159065030515194\n",
            "Epoch 9, Step 66, Loss: 0.01047450304031372\n",
            "Epoch 9, Step 67, Loss: 0.012125835753977299\n",
            "Epoch 9, Step 68, Loss: 0.012012255378067493\n",
            "Epoch 9, Step 69, Loss: 0.012280814349651337\n",
            "Epoch 9, Step 70, Loss: 0.015410848893225193\n",
            "Epoch 9, Step 71, Loss: 0.013400808908045292\n",
            "Epoch 9, Step 72, Loss: 0.013962121680378914\n",
            "Epoch 9, Step 73, Loss: 0.011156889609992504\n",
            "Epoch 9, Step 74, Loss: 0.010460050776600838\n",
            "Epoch 9, Step 75, Loss: 0.011915994808077812\n",
            "Epoch 9, Step 76, Loss: 0.01287986058741808\n",
            "Epoch 9, Step 77, Loss: 0.012486553750932217\n",
            "Epoch 9, Step 78, Loss: 0.01023578830063343\n",
            "Epoch 9, Step 79, Loss: 0.010918684303760529\n",
            "Epoch 9, Step 80, Loss: 0.011892479844391346\n",
            "Epoch 9, Step 81, Loss: 0.016112403944134712\n",
            "Epoch 9, Step 82, Loss: 0.014558866620063782\n",
            "Epoch 9, Step 83, Loss: 0.012372174300253391\n",
            "Epoch 9, Step 84, Loss: 0.013616607524454594\n",
            "Epoch 9, Step 85, Loss: 0.016634158790111542\n",
            "Train Metric MRRs: 0.07455128750848507\n",
            "Train Metric MAPs: 0.013376950999239056\n",
            "Validation Metric MRRs: 0.06248399057505962\n",
            "Validation Metric MAPs: 0.01478725100262871\n",
            "Epoch 10, Step 1, Loss: 0.04867792874574661\n",
            "Epoch 10, Step 2, Loss: 0.03915497660636902\n",
            "Epoch 10, Step 3, Loss: 0.03787297382950783\n",
            "Epoch 10, Step 4, Loss: 0.024720853194594383\n",
            "Epoch 10, Step 5, Loss: 0.018511487171053886\n",
            "Epoch 10, Step 6, Loss: 0.015241422690451145\n",
            "Epoch 10, Step 7, Loss: 0.01007885579019785\n",
            "Epoch 10, Step 8, Loss: 0.008993983268737793\n",
            "Epoch 10, Step 9, Loss: 0.008866437710821629\n",
            "Epoch 10, Step 10, Loss: 0.009229255840182304\n",
            "Epoch 10, Step 11, Loss: 0.008610622026026249\n",
            "Epoch 10, Step 12, Loss: 0.009114940650761127\n",
            "Epoch 10, Step 13, Loss: 0.008464666083455086\n",
            "Epoch 10, Step 14, Loss: 0.008064900524914265\n",
            "Epoch 10, Step 15, Loss: 0.007979797199368477\n",
            "Epoch 10, Step 16, Loss: 0.009390214458107948\n",
            "Epoch 10, Step 17, Loss: 0.011885336600244045\n",
            "Epoch 10, Step 18, Loss: 0.013418291695415974\n",
            "Epoch 10, Step 19, Loss: 0.016153696924448013\n",
            "Epoch 10, Step 20, Loss: 0.015971243381500244\n",
            "Epoch 10, Step 21, Loss: 0.014847295358777046\n",
            "Epoch 10, Step 22, Loss: 0.016529200598597527\n",
            "Epoch 10, Step 23, Loss: 0.0189388208091259\n",
            "Epoch 10, Step 24, Loss: 0.017537815496325493\n",
            "Epoch 10, Step 25, Loss: 0.01662321574985981\n",
            "Epoch 10, Step 26, Loss: 0.01767837442457676\n",
            "Epoch 10, Step 27, Loss: 0.013610227964818478\n",
            "Epoch 10, Step 28, Loss: 0.01525233406573534\n",
            "Epoch 10, Step 29, Loss: 0.014381315559148788\n",
            "Epoch 10, Step 30, Loss: 0.014041722752153873\n",
            "Epoch 10, Step 31, Loss: 0.015490016900002956\n",
            "Epoch 10, Step 32, Loss: 0.01367836631834507\n",
            "Epoch 10, Step 33, Loss: 0.013188222423195839\n",
            "Epoch 10, Step 34, Loss: 0.011880221776664257\n",
            "Epoch 10, Step 35, Loss: 0.012691291980445385\n",
            "Epoch 10, Step 36, Loss: 0.011619023978710175\n",
            "Epoch 10, Step 37, Loss: 0.013354546390473843\n",
            "Epoch 10, Step 38, Loss: 0.011468445882201195\n",
            "Epoch 10, Step 39, Loss: 0.013841187581419945\n",
            "Epoch 10, Step 40, Loss: 0.013074494898319244\n",
            "Epoch 10, Step 41, Loss: 0.01164543442428112\n",
            "Epoch 10, Step 42, Loss: 0.010775977745652199\n",
            "Epoch 10, Step 43, Loss: 0.010208006016910076\n",
            "Epoch 10, Step 44, Loss: 0.010446444153785706\n",
            "Epoch 10, Step 45, Loss: 0.011249225586652756\n",
            "Epoch 10, Step 46, Loss: 0.010525042191147804\n",
            "Epoch 10, Step 47, Loss: 0.010960417799651623\n",
            "Epoch 10, Step 48, Loss: 0.010252978652715683\n",
            "Epoch 10, Step 49, Loss: 0.009538368321955204\n",
            "Epoch 10, Step 50, Loss: 0.009941636584699154\n",
            "Epoch 10, Step 51, Loss: 0.010815994814038277\n",
            "Epoch 10, Step 52, Loss: 0.00975880492478609\n",
            "Epoch 10, Step 53, Loss: 0.014249658212065697\n",
            "Epoch 10, Step 54, Loss: 0.01002073846757412\n",
            "Epoch 10, Step 55, Loss: 0.009262270294129848\n",
            "Epoch 10, Step 56, Loss: 0.010369309224188328\n",
            "Epoch 10, Step 57, Loss: 0.008906371891498566\n",
            "Epoch 10, Step 58, Loss: 0.008723016828298569\n",
            "Epoch 10, Step 59, Loss: 0.008308512158691883\n",
            "Epoch 10, Step 60, Loss: 0.008932315744459629\n",
            "Epoch 10, Step 61, Loss: 0.011061652563512325\n",
            "Epoch 10, Step 62, Loss: 0.009341108612716198\n",
            "Epoch 10, Step 63, Loss: 0.009709353558719158\n",
            "Epoch 10, Step 64, Loss: 0.009137154556810856\n",
            "Epoch 10, Step 65, Loss: 0.010116702876985073\n",
            "Epoch 10, Step 66, Loss: 0.010694550350308418\n",
            "Epoch 10, Step 67, Loss: 0.011778658255934715\n",
            "Epoch 10, Step 68, Loss: 0.011582680977880955\n",
            "Epoch 10, Step 69, Loss: 0.012004061602056026\n",
            "Epoch 10, Step 70, Loss: 0.015414581634104252\n",
            "Epoch 10, Step 71, Loss: 0.013204704038798809\n",
            "Epoch 10, Step 72, Loss: 0.013060851022601128\n",
            "Epoch 10, Step 73, Loss: 0.010859928093850613\n",
            "Epoch 10, Step 74, Loss: 0.01038037147372961\n",
            "Epoch 10, Step 75, Loss: 0.012464988976716995\n",
            "Epoch 10, Step 76, Loss: 0.014046840369701385\n",
            "Epoch 10, Step 77, Loss: 0.012456201016902924\n",
            "Epoch 10, Step 78, Loss: 0.011121351271867752\n",
            "Epoch 10, Step 79, Loss: 0.011013823561370373\n",
            "Epoch 10, Step 80, Loss: 0.012315711006522179\n",
            "Epoch 10, Step 81, Loss: 0.014919108711183071\n",
            "Epoch 10, Step 82, Loss: 0.014402348548173904\n",
            "Epoch 10, Step 83, Loss: 0.013047895394265652\n",
            "Epoch 10, Step 84, Loss: 0.013451403938233852\n",
            "Epoch 10, Step 85, Loss: 0.01648322306573391\n",
            "Train Metric MRRs: 0.07390608831042425\n",
            "Train Metric MAPs: 0.013803817788800302\n",
            "Validation Metric MRRs: 0.0589518299475824\n",
            "Validation Metric MAPs: 0.014413947608285944\n",
            "Epoch 11, Step 1, Loss: 0.048931680619716644\n",
            "Epoch 11, Step 2, Loss: 0.041113995015621185\n",
            "Epoch 11, Step 3, Loss: 0.03850194066762924\n",
            "Epoch 11, Step 4, Loss: 0.025158628821372986\n",
            "Epoch 11, Step 5, Loss: 0.01963525079190731\n",
            "Epoch 11, Step 6, Loss: 0.015084904618561268\n",
            "Epoch 11, Step 7, Loss: 0.00999276340007782\n",
            "Epoch 11, Step 8, Loss: 0.008958952501416206\n",
            "Epoch 11, Step 9, Loss: 0.009677903726696968\n",
            "Epoch 11, Step 10, Loss: 0.009659282863140106\n",
            "Epoch 11, Step 11, Loss: 0.009006810374557972\n",
            "Epoch 11, Step 12, Loss: 0.009143435396254063\n",
            "Epoch 11, Step 13, Loss: 0.00892086885869503\n",
            "Epoch 11, Step 14, Loss: 0.008411549031734467\n",
            "Epoch 11, Step 15, Loss: 0.008195471949875355\n",
            "Epoch 11, Step 16, Loss: 0.00958525761961937\n",
            "Epoch 11, Step 17, Loss: 0.012013977393507957\n",
            "Epoch 11, Step 18, Loss: 0.013523292727768421\n",
            "Epoch 11, Step 19, Loss: 0.016919834539294243\n",
            "Epoch 11, Step 20, Loss: 0.015922551974654198\n",
            "Epoch 11, Step 21, Loss: 0.015318240039050579\n",
            "Epoch 11, Step 22, Loss: 0.016798770055174828\n",
            "Epoch 11, Step 23, Loss: 0.01901288703083992\n",
            "Epoch 11, Step 24, Loss: 0.018296044319868088\n",
            "Epoch 11, Step 25, Loss: 0.016639042645692825\n",
            "Epoch 11, Step 26, Loss: 0.016912218183279037\n",
            "Epoch 11, Step 27, Loss: 0.01367832999676466\n",
            "Epoch 11, Step 28, Loss: 0.015257006511092186\n",
            "Epoch 11, Step 29, Loss: 0.01460572611540556\n",
            "Epoch 11, Step 30, Loss: 0.01429468858987093\n",
            "Epoch 11, Step 31, Loss: 0.015331507660448551\n",
            "Epoch 11, Step 32, Loss: 0.013750164769589901\n",
            "Epoch 11, Step 33, Loss: 0.014122150838375092\n",
            "Epoch 11, Step 34, Loss: 0.011751983314752579\n",
            "Epoch 11, Step 35, Loss: 0.012963897548615932\n",
            "Epoch 11, Step 36, Loss: 0.01109752431511879\n",
            "Epoch 11, Step 37, Loss: 0.012873985804617405\n",
            "Epoch 11, Step 38, Loss: 0.011366019956767559\n",
            "Epoch 11, Step 39, Loss: 0.01364842802286148\n",
            "Epoch 11, Step 40, Loss: 0.012973159551620483\n",
            "Epoch 11, Step 41, Loss: 0.012061741203069687\n",
            "Epoch 11, Step 42, Loss: 0.010788816027343273\n",
            "Epoch 11, Step 43, Loss: 0.010430162772536278\n",
            "Epoch 11, Step 44, Loss: 0.010678987950086594\n",
            "Epoch 11, Step 45, Loss: 0.01171612273901701\n",
            "Epoch 11, Step 46, Loss: 0.01099368929862976\n",
            "Epoch 11, Step 47, Loss: 0.011963478289544582\n",
            "Epoch 11, Step 48, Loss: 0.010512106120586395\n",
            "Epoch 11, Step 49, Loss: 0.010069363750517368\n",
            "Epoch 11, Step 50, Loss: 0.010152226313948631\n",
            "Epoch 11, Step 51, Loss: 0.010726985521614552\n",
            "Epoch 11, Step 52, Loss: 0.009755467996001244\n",
            "Epoch 11, Step 53, Loss: 0.014209294691681862\n",
            "Epoch 11, Step 54, Loss: 0.010328319855034351\n",
            "Epoch 11, Step 55, Loss: 0.009951196610927582\n",
            "Epoch 11, Step 56, Loss: 0.009961355477571487\n",
            "Epoch 11, Step 57, Loss: 0.009032528847455978\n",
            "Epoch 11, Step 58, Loss: 0.008862725459039211\n",
            "Epoch 11, Step 59, Loss: 0.008335626684129238\n",
            "Epoch 11, Step 60, Loss: 0.008725806139409542\n",
            "Epoch 11, Step 61, Loss: 0.010959893465042114\n",
            "Epoch 11, Step 62, Loss: 0.010200356133282185\n",
            "Epoch 11, Step 63, Loss: 0.009552543051540852\n",
            "Epoch 11, Step 64, Loss: 0.00919482670724392\n",
            "Epoch 11, Step 65, Loss: 0.010626441799104214\n",
            "Epoch 11, Step 66, Loss: 0.010193217545747757\n",
            "Epoch 11, Step 67, Loss: 0.01197180524468422\n",
            "Epoch 11, Step 68, Loss: 0.011349118314683437\n",
            "Epoch 11, Step 69, Loss: 0.011838406324386597\n",
            "Epoch 11, Step 70, Loss: 0.015443799085915089\n",
            "Epoch 11, Step 71, Loss: 0.013359853066504002\n",
            "Epoch 11, Step 72, Loss: 0.013304335065186024\n",
            "Epoch 11, Step 73, Loss: 0.01097036711871624\n",
            "Epoch 11, Step 74, Loss: 0.01042766124010086\n",
            "Epoch 11, Step 75, Loss: 0.012158543802797794\n",
            "Epoch 11, Step 76, Loss: 0.012576954439282417\n",
            "Epoch 11, Step 77, Loss: 0.012344500049948692\n",
            "Epoch 11, Step 78, Loss: 0.010012052021920681\n",
            "Epoch 11, Step 79, Loss: 0.013720836490392685\n",
            "Epoch 11, Step 80, Loss: 0.011861907318234444\n",
            "Epoch 11, Step 81, Loss: 0.015074514783918858\n",
            "Epoch 11, Step 82, Loss: 0.014605991542339325\n",
            "Epoch 11, Step 83, Loss: 0.014018720015883446\n",
            "Epoch 11, Step 84, Loss: 0.013609985820949078\n",
            "Epoch 11, Step 85, Loss: 0.01638977602124214\n",
            "Train Metric MRRs: 0.07848008162063853\n",
            "Train Metric MAPs: 0.013865532077186115\n",
            "Validation Metric MRRs: 0.0484562714606795\n",
            "Validation Metric MAPs: 0.013832128976120123\n",
            "Epoch 12, Step 1, Loss: 0.04835006222128868\n",
            "Epoch 12, Step 2, Loss: 0.039271291345357895\n",
            "Epoch 12, Step 3, Loss: 0.0378786064684391\n",
            "Epoch 12, Step 4, Loss: 0.026220593601465225\n",
            "Epoch 12, Step 5, Loss: 0.019233431667089462\n",
            "Epoch 12, Step 6, Loss: 0.015375574119389057\n",
            "Epoch 12, Step 7, Loss: 0.01019193697720766\n",
            "Epoch 12, Step 8, Loss: 0.008689319714903831\n",
            "Epoch 12, Step 9, Loss: 0.00911015085875988\n",
            "Epoch 12, Step 10, Loss: 0.00932700652629137\n",
            "Epoch 12, Step 11, Loss: 0.008766956627368927\n",
            "Epoch 12, Step 12, Loss: 0.00863979384303093\n",
            "Epoch 12, Step 13, Loss: 0.008238706737756729\n",
            "Epoch 12, Step 14, Loss: 0.007868635468184948\n",
            "Epoch 12, Step 15, Loss: 0.0077125499956309795\n",
            "Epoch 12, Step 16, Loss: 0.009219301864504814\n",
            "Epoch 12, Step 17, Loss: 0.011658166535198689\n",
            "Epoch 12, Step 18, Loss: 0.013233928009867668\n",
            "Epoch 12, Step 19, Loss: 0.01585797779262066\n",
            "Epoch 12, Step 20, Loss: 0.016074903309345245\n",
            "Epoch 12, Step 21, Loss: 0.014742624014616013\n",
            "Epoch 12, Step 22, Loss: 0.0163167342543602\n",
            "Epoch 12, Step 23, Loss: 0.019274694845080376\n",
            "Epoch 12, Step 24, Loss: 0.0174251701682806\n",
            "Epoch 12, Step 25, Loss: 0.016343792900443077\n",
            "Epoch 12, Step 26, Loss: 0.016542920842766762\n",
            "Epoch 12, Step 27, Loss: 0.014073844067752361\n",
            "Epoch 12, Step 28, Loss: 0.014551392756402493\n",
            "Epoch 12, Step 29, Loss: 0.014569864608347416\n",
            "Epoch 12, Step 30, Loss: 0.014024616219103336\n",
            "Epoch 12, Step 31, Loss: 0.01535329595208168\n",
            "Epoch 12, Step 32, Loss: 0.01387654710561037\n",
            "Epoch 12, Step 33, Loss: 0.013247857801616192\n",
            "Epoch 12, Step 34, Loss: 0.01179311703890562\n",
            "Epoch 12, Step 35, Loss: 0.012614085339009762\n",
            "Epoch 12, Step 36, Loss: 0.01109535526484251\n",
            "Epoch 12, Step 37, Loss: 0.0134219229221344\n",
            "Epoch 12, Step 38, Loss: 0.011288621462881565\n",
            "Epoch 12, Step 39, Loss: 0.013488476164638996\n",
            "Epoch 12, Step 40, Loss: 0.012937677092850208\n",
            "Epoch 12, Step 41, Loss: 0.011825279332697392\n",
            "Epoch 12, Step 42, Loss: 0.01311009842902422\n",
            "Epoch 12, Step 43, Loss: 0.01076749712228775\n",
            "Epoch 12, Step 44, Loss: 0.011120661161839962\n",
            "Epoch 12, Step 45, Loss: 0.011184317991137505\n",
            "Epoch 12, Step 46, Loss: 0.010520467534661293\n",
            "Epoch 12, Step 47, Loss: 0.01089830044656992\n",
            "Epoch 12, Step 48, Loss: 0.01033464539796114\n",
            "Epoch 12, Step 49, Loss: 0.010098431259393692\n",
            "Epoch 12, Step 50, Loss: 0.010452491231262684\n",
            "Epoch 12, Step 51, Loss: 0.010975489392876625\n",
            "Epoch 12, Step 52, Loss: 0.009735412895679474\n",
            "Epoch 12, Step 53, Loss: 0.0147101990878582\n",
            "Epoch 12, Step 54, Loss: 0.010651515796780586\n",
            "Epoch 12, Step 55, Loss: 0.00998538825660944\n",
            "Epoch 12, Step 56, Loss: 0.010432417504489422\n",
            "Epoch 12, Step 57, Loss: 0.00966474786400795\n",
            "Epoch 12, Step 58, Loss: 0.009175514802336693\n",
            "Epoch 12, Step 59, Loss: 0.009110748767852783\n",
            "Epoch 12, Step 60, Loss: 0.009895986877381802\n",
            "Epoch 12, Step 61, Loss: 0.011175536550581455\n",
            "Epoch 12, Step 62, Loss: 0.009970451705157757\n",
            "Epoch 12, Step 63, Loss: 0.01063545048236847\n",
            "Epoch 12, Step 64, Loss: 0.009035865776240826\n",
            "Epoch 12, Step 65, Loss: 0.010354680940508842\n",
            "Epoch 12, Step 66, Loss: 0.01001883763819933\n",
            "Epoch 12, Step 67, Loss: 0.011541414074599743\n",
            "Epoch 12, Step 68, Loss: 0.011424015276134014\n",
            "Epoch 12, Step 69, Loss: 0.012148790061473846\n",
            "Epoch 12, Step 70, Loss: 0.015249884687364101\n",
            "Epoch 12, Step 71, Loss: 0.013238090090453625\n",
            "Epoch 12, Step 72, Loss: 0.013469728641211987\n",
            "Epoch 12, Step 73, Loss: 0.010916437953710556\n",
            "Epoch 12, Step 74, Loss: 0.010510911233723164\n",
            "Epoch 12, Step 75, Loss: 0.012552247382700443\n",
            "Epoch 12, Step 76, Loss: 0.012656878679990768\n",
            "Epoch 12, Step 77, Loss: 0.012255937792360783\n",
            "Epoch 12, Step 78, Loss: 0.010785398073494434\n",
            "Epoch 12, Step 79, Loss: 0.013071381486952305\n",
            "Epoch 12, Step 80, Loss: 0.011936557479202747\n",
            "Epoch 12, Step 81, Loss: 0.017100375145673752\n",
            "Epoch 12, Step 82, Loss: 0.015626659616827965\n",
            "Epoch 12, Step 83, Loss: 0.012454330921173096\n",
            "Epoch 12, Step 84, Loss: 0.013768871314823627\n",
            "Epoch 12, Step 85, Loss: 0.016409531235694885\n",
            "Train Metric MRRs: 0.07753514794767363\n",
            "Train Metric MAPs: 0.013894140691249047\n",
            "Validation Metric MRRs: 0.05236130314914064\n",
            "Validation Metric MAPs: 0.012605950128293112\n",
            "Epoch 13, Step 1, Loss: 0.048971496522426605\n",
            "Epoch 13, Step 2, Loss: 0.038232505321502686\n",
            "Epoch 13, Step 3, Loss: 0.03878146409988403\n",
            "Epoch 13, Step 4, Loss: 0.025434307754039764\n",
            "Epoch 13, Step 5, Loss: 0.018859419971704483\n",
            "Epoch 13, Step 6, Loss: 0.015082023106515408\n",
            "Epoch 13, Step 7, Loss: 0.010165371000766754\n",
            "Epoch 13, Step 8, Loss: 0.009131919592618942\n",
            "Epoch 13, Step 9, Loss: 0.009731225669384003\n",
            "Epoch 13, Step 10, Loss: 0.009850465692579746\n",
            "Epoch 13, Step 11, Loss: 0.009616133756935596\n",
            "Epoch 13, Step 12, Loss: 0.00930753443390131\n",
            "Epoch 13, Step 13, Loss: 0.009183143265545368\n",
            "Epoch 13, Step 14, Loss: 0.008548146113753319\n",
            "Epoch 13, Step 15, Loss: 0.008507683873176575\n",
            "Epoch 13, Step 16, Loss: 0.009797378443181515\n",
            "Epoch 13, Step 17, Loss: 0.012487475760281086\n",
            "Epoch 13, Step 18, Loss: 0.013655242510139942\n",
            "Epoch 13, Step 19, Loss: 0.015789194032549858\n",
            "Epoch 13, Step 20, Loss: 0.015692895278334618\n",
            "Epoch 13, Step 21, Loss: 0.014694434590637684\n",
            "Epoch 13, Step 22, Loss: 0.017244165763258934\n",
            "Epoch 13, Step 23, Loss: 0.019777977839112282\n",
            "Epoch 13, Step 24, Loss: 0.01943427324295044\n",
            "Epoch 13, Step 25, Loss: 0.016541626304388046\n",
            "Epoch 13, Step 26, Loss: 0.016278238967061043\n",
            "Epoch 13, Step 27, Loss: 0.013537305407226086\n",
            "Epoch 13, Step 28, Loss: 0.015364617109298706\n",
            "Epoch 13, Step 29, Loss: 0.01443053875118494\n",
            "Epoch 13, Step 30, Loss: 0.014034542255103588\n",
            "Epoch 13, Step 31, Loss: 0.015962030738592148\n",
            "Epoch 13, Step 32, Loss: 0.014771787449717522\n",
            "Epoch 13, Step 33, Loss: 0.013104286044836044\n",
            "Epoch 13, Step 34, Loss: 0.012209278531372547\n",
            "Epoch 13, Step 35, Loss: 0.012776060961186886\n",
            "Epoch 13, Step 36, Loss: 0.010950631462037563\n",
            "Epoch 13, Step 37, Loss: 0.013642200268805027\n",
            "Epoch 13, Step 38, Loss: 0.011299424804747105\n",
            "Epoch 13, Step 39, Loss: 0.013569573871791363\n",
            "Epoch 13, Step 40, Loss: 0.013053878210484982\n",
            "Epoch 13, Step 41, Loss: 0.01264582946896553\n",
            "Epoch 13, Step 42, Loss: 0.011986985802650452\n",
            "Epoch 13, Step 43, Loss: 0.010792537592351437\n",
            "Epoch 13, Step 44, Loss: 0.011060439981520176\n",
            "Epoch 13, Step 45, Loss: 0.011216403916478157\n",
            "Epoch 13, Step 46, Loss: 0.010703102685511112\n",
            "Epoch 13, Step 47, Loss: 0.011241639964282513\n",
            "Epoch 13, Step 48, Loss: 0.010416696779429913\n",
            "Epoch 13, Step 49, Loss: 0.010881016962230206\n",
            "Epoch 13, Step 50, Loss: 0.010245542973279953\n",
            "Epoch 13, Step 51, Loss: 0.010593592189252377\n",
            "Epoch 13, Step 52, Loss: 0.010755065828561783\n",
            "Epoch 13, Step 53, Loss: 0.014382626861333847\n",
            "Epoch 13, Step 54, Loss: 0.010013453662395477\n",
            "Epoch 13, Step 55, Loss: 0.009640955366194248\n",
            "Epoch 13, Step 56, Loss: 0.010239520110189915\n",
            "Epoch 13, Step 57, Loss: 0.009087313897907734\n",
            "Epoch 13, Step 58, Loss: 0.008678508922457695\n",
            "Epoch 13, Step 59, Loss: 0.008480668999254704\n",
            "Epoch 13, Step 60, Loss: 0.009316223673522472\n",
            "Epoch 13, Step 61, Loss: 0.011556381359696388\n",
            "Epoch 13, Step 62, Loss: 0.009246328845620155\n",
            "Epoch 13, Step 63, Loss: 0.009246965870261192\n",
            "Epoch 13, Step 64, Loss: 0.009227699600160122\n",
            "Epoch 13, Step 65, Loss: 0.010548142716288567\n",
            "Epoch 13, Step 66, Loss: 0.010700663551688194\n",
            "Epoch 13, Step 67, Loss: 0.011753241531550884\n",
            "Epoch 13, Step 68, Loss: 0.011975605972111225\n",
            "Epoch 13, Step 69, Loss: 0.011887973174452782\n",
            "Epoch 13, Step 70, Loss: 0.015609177760779858\n",
            "Epoch 13, Step 71, Loss: 0.013518313877284527\n",
            "Epoch 13, Step 72, Loss: 0.013296735472977161\n",
            "Epoch 13, Step 73, Loss: 0.010720107704401016\n",
            "Epoch 13, Step 74, Loss: 0.010243876837193966\n",
            "Epoch 13, Step 75, Loss: 0.01192688662558794\n",
            "Epoch 13, Step 76, Loss: 0.012383528985083103\n",
            "Epoch 13, Step 77, Loss: 0.01261487789452076\n",
            "Epoch 13, Step 78, Loss: 0.010127933695912361\n",
            "Epoch 13, Step 79, Loss: 0.011881845071911812\n",
            "Epoch 13, Step 80, Loss: 0.012217983603477478\n",
            "Epoch 13, Step 81, Loss: 0.018844932317733765\n",
            "Epoch 13, Step 82, Loss: 0.015979278832674026\n",
            "Epoch 13, Step 83, Loss: 0.012197427451610565\n",
            "Epoch 13, Step 84, Loss: 0.013685918413102627\n",
            "Epoch 13, Step 85, Loss: 0.016698196530342102\n",
            "Train Metric MRRs: 0.07934973608045073\n",
            "Train Metric MAPs: 0.013180188928783922\n",
            "Validation Metric MRRs: 0.05733093255130379\n",
            "Validation Metric MAPs: 0.014241978957676307\n",
            "Epoch 14, Step 1, Loss: 0.04743852838873863\n",
            "Epoch 14, Step 2, Loss: 0.03775931894779205\n",
            "Epoch 14, Step 3, Loss: 0.037096813321113586\n",
            "Epoch 14, Step 4, Loss: 0.024247709661722183\n",
            "Epoch 14, Step 5, Loss: 0.01932189241051674\n",
            "Epoch 14, Step 6, Loss: 0.015018627978861332\n",
            "Epoch 14, Step 7, Loss: 0.010638455860316753\n",
            "Epoch 14, Step 8, Loss: 0.00898833479732275\n",
            "Epoch 14, Step 9, Loss: 0.008856141939759254\n",
            "Epoch 14, Step 10, Loss: 0.009046832099556923\n",
            "Epoch 14, Step 11, Loss: 0.008442231453955173\n",
            "Epoch 14, Step 12, Loss: 0.00860932283103466\n",
            "Epoch 14, Step 13, Loss: 0.008203632198274136\n",
            "Epoch 14, Step 14, Loss: 0.007888157851994038\n",
            "Epoch 14, Step 15, Loss: 0.0075714061968028545\n",
            "Epoch 14, Step 16, Loss: 0.009145567193627357\n",
            "Epoch 14, Step 17, Loss: 0.011825032532215118\n",
            "Epoch 14, Step 18, Loss: 0.013009690679609776\n",
            "Epoch 14, Step 19, Loss: 0.01594744622707367\n",
            "Epoch 14, Step 20, Loss: 0.016236422583460808\n",
            "Epoch 14, Step 21, Loss: 0.014675858430564404\n",
            "Epoch 14, Step 22, Loss: 0.016217892989516258\n",
            "Epoch 14, Step 23, Loss: 0.020223412662744522\n",
            "Epoch 14, Step 24, Loss: 0.017407068982720375\n",
            "Epoch 14, Step 25, Loss: 0.01654106378555298\n",
            "Epoch 14, Step 26, Loss: 0.016999222338199615\n",
            "Epoch 14, Step 27, Loss: 0.013218524865806103\n",
            "Epoch 14, Step 28, Loss: 0.014578879810869694\n",
            "Epoch 14, Step 29, Loss: 0.01427891943603754\n",
            "Epoch 14, Step 30, Loss: 0.014837526716291904\n",
            "Epoch 14, Step 31, Loss: 0.015631593763828278\n",
            "Epoch 14, Step 32, Loss: 0.013881524093449116\n",
            "Epoch 14, Step 33, Loss: 0.013086778111755848\n",
            "Epoch 14, Step 34, Loss: 0.011713037267327309\n",
            "Epoch 14, Step 35, Loss: 0.012907365337014198\n",
            "Epoch 14, Step 36, Loss: 0.01111745834350586\n",
            "Epoch 14, Step 37, Loss: 0.01384150143712759\n",
            "Epoch 14, Step 38, Loss: 0.011185182258486748\n",
            "Epoch 14, Step 39, Loss: 0.013447355479001999\n",
            "Epoch 14, Step 40, Loss: 0.013294916599988937\n",
            "Epoch 14, Step 41, Loss: 0.011832242831587791\n",
            "Epoch 14, Step 42, Loss: 0.010826642625033855\n",
            "Epoch 14, Step 43, Loss: 0.010256125591695309\n",
            "Epoch 14, Step 44, Loss: 0.010782971046864986\n",
            "Epoch 14, Step 45, Loss: 0.011927049607038498\n",
            "Epoch 14, Step 46, Loss: 0.01065701525658369\n",
            "Epoch 14, Step 47, Loss: 0.011340055614709854\n",
            "Epoch 14, Step 48, Loss: 0.010101089254021645\n",
            "Epoch 14, Step 49, Loss: 0.010405832901597023\n",
            "Epoch 14, Step 50, Loss: 0.013195404782891273\n",
            "Epoch 14, Step 51, Loss: 0.011512957513332367\n",
            "Epoch 14, Step 52, Loss: 0.010014169849455357\n",
            "Epoch 14, Step 53, Loss: 0.013975889421999454\n",
            "Epoch 14, Step 54, Loss: 0.010110998526215553\n",
            "Epoch 14, Step 55, Loss: 0.009402580559253693\n",
            "Epoch 14, Step 56, Loss: 0.010009540244936943\n",
            "Epoch 14, Step 57, Loss: 0.010102871805429459\n",
            "Epoch 14, Step 58, Loss: 0.009504891000688076\n",
            "Epoch 14, Step 59, Loss: 0.008832262828946114\n",
            "Epoch 14, Step 60, Loss: 0.010085172951221466\n",
            "Epoch 14, Step 61, Loss: 0.011266611516475677\n",
            "Epoch 14, Step 62, Loss: 0.010255738161504269\n",
            "Epoch 14, Step 63, Loss: 0.010501837357878685\n",
            "Epoch 14, Step 64, Loss: 0.009746099822223186\n",
            "Epoch 14, Step 65, Loss: 0.010956109501421452\n",
            "Epoch 14, Step 66, Loss: 0.012311777099967003\n",
            "Epoch 14, Step 67, Loss: 0.012258035130798817\n",
            "Epoch 14, Step 68, Loss: 0.013256707228720188\n",
            "Epoch 14, Step 69, Loss: 0.013210230506956577\n",
            "Epoch 14, Step 70, Loss: 0.015767671167850494\n",
            "Epoch 14, Step 71, Loss: 0.01323873084038496\n",
            "Epoch 14, Step 72, Loss: 0.013365988619625568\n",
            "Epoch 14, Step 73, Loss: 0.010755379684269428\n",
            "Epoch 14, Step 74, Loss: 0.01049877516925335\n",
            "Epoch 14, Step 75, Loss: 0.012144365347921848\n",
            "Epoch 14, Step 76, Loss: 0.013350103981792927\n",
            "Epoch 14, Step 77, Loss: 0.012242971919476986\n",
            "Epoch 14, Step 78, Loss: 0.010299241170287132\n",
            "Epoch 14, Step 79, Loss: 0.011203248053789139\n",
            "Epoch 14, Step 80, Loss: 0.011925014667212963\n",
            "Epoch 14, Step 81, Loss: 0.01551821082830429\n",
            "Epoch 14, Step 82, Loss: 0.014994176104664803\n",
            "Epoch 14, Step 83, Loss: 0.01247755903750658\n",
            "Epoch 14, Step 84, Loss: 0.01359467301517725\n",
            "Epoch 14, Step 85, Loss: 0.016314104199409485\n",
            "Train Metric MRRs: 0.07935265593064647\n",
            "Train Metric MAPs: 0.013807193013036897\n",
            "Validation Metric MRRs: 0.05907039676327934\n",
            "Validation Metric MAPs: 0.012699464002648505\n",
            "Epoch 15, Step 1, Loss: 0.0478065051138401\n",
            "Epoch 15, Step 2, Loss: 0.03898599371314049\n",
            "Epoch 15, Step 3, Loss: 0.038643304258584976\n",
            "Epoch 15, Step 4, Loss: 0.024661732837557793\n",
            "Epoch 15, Step 5, Loss: 0.01903548464179039\n",
            "Epoch 15, Step 6, Loss: 0.0149911567568779\n",
            "Epoch 15, Step 7, Loss: 0.010176248848438263\n",
            "Epoch 15, Step 8, Loss: 0.009668766520917416\n",
            "Epoch 15, Step 9, Loss: 0.01010722853243351\n",
            "Epoch 15, Step 10, Loss: 0.010185867547988892\n",
            "Epoch 15, Step 11, Loss: 0.009785721078515053\n",
            "Epoch 15, Step 12, Loss: 0.00925921555608511\n",
            "Epoch 15, Step 13, Loss: 0.00868111103773117\n",
            "Epoch 15, Step 14, Loss: 0.008106717839837074\n",
            "Epoch 15, Step 15, Loss: 0.00806471984833479\n",
            "Epoch 15, Step 16, Loss: 0.009236311540007591\n",
            "Epoch 15, Step 17, Loss: 0.011719581671059132\n",
            "Epoch 15, Step 18, Loss: 0.01328838150948286\n",
            "Epoch 15, Step 19, Loss: 0.015656709671020508\n",
            "Epoch 15, Step 20, Loss: 0.015715384855866432\n",
            "Epoch 15, Step 21, Loss: 0.014574351720511913\n",
            "Epoch 15, Step 22, Loss: 0.017040753737092018\n",
            "Epoch 15, Step 23, Loss: 0.01891772262752056\n",
            "Epoch 15, Step 24, Loss: 0.01739863120019436\n",
            "Epoch 15, Step 25, Loss: 0.016429152339696884\n",
            "Epoch 15, Step 26, Loss: 0.01667291484773159\n",
            "Epoch 15, Step 27, Loss: 0.01327634695917368\n",
            "Epoch 15, Step 28, Loss: 0.015169288963079453\n",
            "Epoch 15, Step 29, Loss: 0.014541433192789555\n",
            "Epoch 15, Step 30, Loss: 0.014406980015337467\n",
            "Epoch 15, Step 31, Loss: 0.015250805765390396\n",
            "Epoch 15, Step 32, Loss: 0.014035645872354507\n",
            "Epoch 15, Step 33, Loss: 0.012840395793318748\n",
            "Epoch 15, Step 34, Loss: 0.011331422254443169\n",
            "Epoch 15, Step 35, Loss: 0.013252719305455685\n",
            "Epoch 15, Step 36, Loss: 0.010912773199379444\n",
            "Epoch 15, Step 37, Loss: 0.013080778531730175\n",
            "Epoch 15, Step 38, Loss: 0.01114688254892826\n",
            "Epoch 15, Step 39, Loss: 0.013846758753061295\n",
            "Epoch 15, Step 40, Loss: 0.012792653404176235\n",
            "Epoch 15, Step 41, Loss: 0.011557436548173428\n",
            "Epoch 15, Step 42, Loss: 0.011602452956140041\n",
            "Epoch 15, Step 43, Loss: 0.010721100494265556\n",
            "Epoch 15, Step 44, Loss: 0.01056143082678318\n",
            "Epoch 15, Step 45, Loss: 0.011180452071130276\n",
            "Epoch 15, Step 46, Loss: 0.010532201267778873\n",
            "Epoch 15, Step 47, Loss: 0.011065700091421604\n",
            "Epoch 15, Step 48, Loss: 0.010103000327944756\n",
            "Epoch 15, Step 49, Loss: 0.009580668061971664\n",
            "Epoch 15, Step 50, Loss: 0.011365191079676151\n",
            "Epoch 15, Step 51, Loss: 0.010785065591335297\n",
            "Epoch 15, Step 52, Loss: 0.009644581004977226\n",
            "Epoch 15, Step 53, Loss: 0.015189667232334614\n",
            "Epoch 15, Step 54, Loss: 0.009980992414057255\n",
            "Epoch 15, Step 55, Loss: 0.0093773752450943\n",
            "Epoch 15, Step 56, Loss: 0.009809145703911781\n",
            "Epoch 15, Step 57, Loss: 0.009160383604466915\n",
            "Epoch 15, Step 58, Loss: 0.009264223277568817\n",
            "Epoch 15, Step 59, Loss: 0.008173723705112934\n",
            "Epoch 15, Step 60, Loss: 0.009075767360627651\n",
            "Epoch 15, Step 61, Loss: 0.011189176701009274\n",
            "Epoch 15, Step 62, Loss: 0.009183431044220924\n",
            "Epoch 15, Step 63, Loss: 0.00961966160684824\n",
            "Epoch 15, Step 64, Loss: 0.008741721510887146\n",
            "Epoch 15, Step 65, Loss: 0.011338295415043831\n",
            "Epoch 15, Step 66, Loss: 0.010037734173238277\n",
            "Epoch 15, Step 67, Loss: 0.012348729185760021\n",
            "Epoch 15, Step 68, Loss: 0.011653325520455837\n",
            "Epoch 15, Step 69, Loss: 0.012418699450790882\n",
            "Epoch 15, Step 70, Loss: 0.01531826052814722\n",
            "Epoch 15, Step 71, Loss: 0.012926584109663963\n",
            "Epoch 15, Step 72, Loss: 0.01318487897515297\n",
            "Epoch 15, Step 73, Loss: 0.01062068622559309\n",
            "Epoch 15, Step 74, Loss: 0.010426505468785763\n",
            "Epoch 15, Step 75, Loss: 0.011859909631311893\n",
            "Epoch 15, Step 76, Loss: 0.01226069126278162\n",
            "Epoch 15, Step 77, Loss: 0.012465142644941807\n",
            "Epoch 15, Step 78, Loss: 0.011909326538443565\n",
            "Epoch 15, Step 79, Loss: 0.01141129620373249\n",
            "Epoch 15, Step 80, Loss: 0.012151585891842842\n",
            "Epoch 15, Step 81, Loss: 0.015751531347632408\n",
            "Epoch 15, Step 82, Loss: 0.014355880208313465\n",
            "Epoch 15, Step 83, Loss: 0.01279305387288332\n",
            "Epoch 15, Step 84, Loss: 0.013400490395724773\n",
            "Epoch 15, Step 85, Loss: 0.016777075827121735\n",
            "Train Metric MRRs: 0.08159321610561136\n",
            "Train Metric MAPs: 0.015092228567461436\n",
            "Validation Metric MRRs: 0.05212536518346098\n",
            "Validation Metric MAPs: 0.01155659909015687\n",
            "Epoch 16, Step 1, Loss: 0.048128433525562286\n",
            "Epoch 16, Step 2, Loss: 0.03978963568806648\n",
            "Epoch 16, Step 3, Loss: 0.038229793310165405\n",
            "Epoch 16, Step 4, Loss: 0.025330763310194016\n",
            "Epoch 16, Step 5, Loss: 0.01887022890150547\n",
            "Epoch 16, Step 6, Loss: 0.014818942174315453\n",
            "Epoch 16, Step 7, Loss: 0.010027611628174782\n",
            "Epoch 16, Step 8, Loss: 0.008940817788243294\n",
            "Epoch 16, Step 9, Loss: 0.009128699079155922\n",
            "Epoch 16, Step 10, Loss: 0.009769001975655556\n",
            "Epoch 16, Step 11, Loss: 0.009098428301513195\n",
            "Epoch 16, Step 12, Loss: 0.009250389412045479\n",
            "Epoch 16, Step 13, Loss: 0.00879104807972908\n",
            "Epoch 16, Step 14, Loss: 0.008524617180228233\n",
            "Epoch 16, Step 15, Loss: 0.008086922578513622\n",
            "Epoch 16, Step 16, Loss: 0.009561373852193356\n",
            "Epoch 16, Step 17, Loss: 0.011975681409239769\n",
            "Epoch 16, Step 18, Loss: 0.013130679726600647\n",
            "Epoch 16, Step 19, Loss: 0.01640377938747406\n",
            "Epoch 16, Step 20, Loss: 0.015606848523020744\n",
            "Epoch 16, Step 21, Loss: 0.014954843558371067\n",
            "Epoch 16, Step 22, Loss: 0.016215480864048004\n",
            "Epoch 16, Step 23, Loss: 0.01863979361951351\n",
            "Epoch 16, Step 24, Loss: 0.01750096306204796\n",
            "Epoch 16, Step 25, Loss: 0.01680701971054077\n",
            "Epoch 16, Step 26, Loss: 0.01673297956585884\n",
            "Epoch 16, Step 27, Loss: 0.013973983004689217\n",
            "Epoch 16, Step 28, Loss: 0.014567103236913681\n",
            "Epoch 16, Step 29, Loss: 0.01500685140490532\n",
            "Epoch 16, Step 30, Loss: 0.014083187095820904\n",
            "Epoch 16, Step 31, Loss: 0.01658322662115097\n",
            "Epoch 16, Step 32, Loss: 0.013644099235534668\n",
            "Epoch 16, Step 33, Loss: 0.013319974765181541\n",
            "Epoch 16, Step 34, Loss: 0.01162065751850605\n",
            "Epoch 16, Step 35, Loss: 0.01264339592307806\n",
            "Epoch 16, Step 36, Loss: 0.011246073059737682\n",
            "Epoch 16, Step 37, Loss: 0.013793026097118855\n",
            "Epoch 16, Step 38, Loss: 0.011001460254192352\n",
            "Epoch 16, Step 39, Loss: 0.013912202790379524\n",
            "Epoch 16, Step 40, Loss: 0.012877458706498146\n",
            "Epoch 16, Step 41, Loss: 0.012291875667870045\n",
            "Epoch 16, Step 42, Loss: 0.010669790208339691\n",
            "Epoch 16, Step 43, Loss: 0.010490489192306995\n",
            "Epoch 16, Step 44, Loss: 0.010525529272854328\n",
            "Epoch 16, Step 45, Loss: 0.0110938660800457\n",
            "Epoch 16, Step 46, Loss: 0.010508504696190357\n",
            "Epoch 16, Step 47, Loss: 0.01145140454173088\n",
            "Epoch 16, Step 48, Loss: 0.01005387119948864\n",
            "Epoch 16, Step 49, Loss: 0.00978181790560484\n",
            "Epoch 16, Step 50, Loss: 0.01031637191772461\n",
            "Epoch 16, Step 51, Loss: 0.011256357654929161\n",
            "Epoch 16, Step 52, Loss: 0.009815261699259281\n",
            "Epoch 16, Step 53, Loss: 0.01449541561305523\n",
            "Epoch 16, Step 54, Loss: 0.009969138540327549\n",
            "Epoch 16, Step 55, Loss: 0.00976612325757742\n",
            "Epoch 16, Step 56, Loss: 0.00988494697958231\n",
            "Epoch 16, Step 57, Loss: 0.009374098852276802\n",
            "Epoch 16, Step 58, Loss: 0.008828259073197842\n",
            "Epoch 16, Step 59, Loss: 0.008135681040585041\n",
            "Epoch 16, Step 60, Loss: 0.009330633096396923\n",
            "Epoch 16, Step 61, Loss: 0.01081856433302164\n",
            "Epoch 16, Step 62, Loss: 0.009389716200530529\n",
            "Epoch 16, Step 63, Loss: 0.009312931448221207\n",
            "Epoch 16, Step 64, Loss: 0.008894180878996849\n",
            "Epoch 16, Step 65, Loss: 0.01062569860368967\n",
            "Epoch 16, Step 66, Loss: 0.010004193522036076\n",
            "Epoch 16, Step 67, Loss: 0.01151370070874691\n",
            "Epoch 16, Step 68, Loss: 0.011134086176753044\n",
            "Epoch 16, Step 69, Loss: 0.011913581751286983\n",
            "Epoch 16, Step 70, Loss: 0.015126814134418964\n",
            "Epoch 16, Step 71, Loss: 0.012985295616090298\n",
            "Epoch 16, Step 72, Loss: 0.013157108798623085\n",
            "Epoch 16, Step 73, Loss: 0.010609131306409836\n",
            "Epoch 16, Step 74, Loss: 0.010262008756399155\n",
            "Epoch 16, Step 75, Loss: 0.0126090869307518\n",
            "Epoch 16, Step 76, Loss: 0.012502902187407017\n",
            "Epoch 16, Step 77, Loss: 0.012585792690515518\n",
            "Epoch 16, Step 78, Loss: 0.01306785736232996\n",
            "Epoch 16, Step 79, Loss: 0.011084792204201221\n",
            "Epoch 16, Step 80, Loss: 0.011833101511001587\n",
            "Epoch 16, Step 81, Loss: 0.014725608751177788\n",
            "Epoch 16, Step 82, Loss: 0.014162878505885601\n",
            "Epoch 16, Step 83, Loss: 0.012455816380679607\n",
            "Epoch 16, Step 84, Loss: 0.013516528531908989\n",
            "Epoch 16, Step 85, Loss: 0.016166431829333305\n",
            "Train Metric MRRs: 0.08099914887628955\n",
            "Train Metric MAPs: 0.014807158377860872\n",
            "Validation Metric MRRs: 0.04987854155606078\n",
            "Validation Metric MAPs: 0.012520371921168656\n",
            "Epoch 17, Step 1, Loss: 0.04725941643118858\n",
            "Epoch 17, Step 2, Loss: 0.03918568044900894\n",
            "Epoch 17, Step 3, Loss: 0.03685382381081581\n",
            "Epoch 17, Step 4, Loss: 0.024625441059470177\n",
            "Epoch 17, Step 5, Loss: 0.01795453391969204\n",
            "Epoch 17, Step 6, Loss: 0.014748910441994667\n",
            "Epoch 17, Step 7, Loss: 0.009500748477876186\n",
            "Epoch 17, Step 8, Loss: 0.009011765010654926\n",
            "Epoch 17, Step 9, Loss: 0.009232016280293465\n",
            "Epoch 17, Step 10, Loss: 0.00926312617957592\n",
            "Epoch 17, Step 11, Loss: 0.008617684245109558\n",
            "Epoch 17, Step 12, Loss: 0.008640880696475506\n",
            "Epoch 17, Step 13, Loss: 0.008343174122273922\n",
            "Epoch 17, Step 14, Loss: 0.007842843420803547\n",
            "Epoch 17, Step 15, Loss: 0.007609791588038206\n",
            "Epoch 17, Step 16, Loss: 0.009276133961975574\n",
            "Epoch 17, Step 17, Loss: 0.01169947162270546\n",
            "Epoch 17, Step 18, Loss: 0.013108174316585064\n",
            "Epoch 17, Step 19, Loss: 0.015393096022307873\n",
            "Epoch 17, Step 20, Loss: 0.015632890164852142\n",
            "Epoch 17, Step 21, Loss: 0.014394670724868774\n",
            "Epoch 17, Step 22, Loss: 0.01621992141008377\n",
            "Epoch 17, Step 23, Loss: 0.0182064026594162\n",
            "Epoch 17, Step 24, Loss: 0.01717270538210869\n",
            "Epoch 17, Step 25, Loss: 0.017071515321731567\n",
            "Epoch 17, Step 26, Loss: 0.016016187146306038\n",
            "Epoch 17, Step 27, Loss: 0.013647043146193027\n",
            "Epoch 17, Step 28, Loss: 0.014062038622796535\n",
            "Epoch 17, Step 29, Loss: 0.014473607763648033\n",
            "Epoch 17, Step 30, Loss: 0.0137193463742733\n",
            "Epoch 17, Step 31, Loss: 0.016379158943891525\n",
            "Epoch 17, Step 32, Loss: 0.013911078684031963\n",
            "Epoch 17, Step 33, Loss: 0.012905317358672619\n",
            "Epoch 17, Step 34, Loss: 0.011788041330873966\n",
            "Epoch 17, Step 35, Loss: 0.01285711582750082\n",
            "Epoch 17, Step 36, Loss: 0.010924983769655228\n",
            "Epoch 17, Step 37, Loss: 0.01393213588744402\n",
            "Epoch 17, Step 38, Loss: 0.010998505167663097\n",
            "Epoch 17, Step 39, Loss: 0.013344691134989262\n",
            "Epoch 17, Step 40, Loss: 0.012567203491926193\n",
            "Epoch 17, Step 41, Loss: 0.011798311024904251\n",
            "Epoch 17, Step 42, Loss: 0.011051245033740997\n",
            "Epoch 17, Step 43, Loss: 0.010044238530099392\n",
            "Epoch 17, Step 44, Loss: 0.010476402938365936\n",
            "Epoch 17, Step 45, Loss: 0.011063429526984692\n",
            "Epoch 17, Step 46, Loss: 0.010670045390725136\n",
            "Epoch 17, Step 47, Loss: 0.011783172376453876\n",
            "Epoch 17, Step 48, Loss: 0.009947138838469982\n",
            "Epoch 17, Step 49, Loss: 0.009988987818360329\n",
            "Epoch 17, Step 50, Loss: 0.00983136985450983\n",
            "Epoch 17, Step 51, Loss: 0.010579889640212059\n",
            "Epoch 17, Step 52, Loss: 0.009733565151691437\n",
            "Epoch 17, Step 53, Loss: 0.01426067017018795\n",
            "Epoch 17, Step 54, Loss: 0.010234535671770573\n",
            "Epoch 17, Step 55, Loss: 0.0096670500934124\n",
            "Epoch 17, Step 56, Loss: 0.009858757257461548\n",
            "Epoch 17, Step 57, Loss: 0.009062709286808968\n",
            "Epoch 17, Step 58, Loss: 0.008573456667363644\n",
            "Epoch 17, Step 59, Loss: 0.008273748680949211\n",
            "Epoch 17, Step 60, Loss: 0.00933140143752098\n",
            "Epoch 17, Step 61, Loss: 0.01079603098332882\n",
            "Epoch 17, Step 62, Loss: 0.009241672232747078\n",
            "Epoch 17, Step 63, Loss: 0.00946066528558731\n",
            "Epoch 17, Step 64, Loss: 0.008795483969151974\n",
            "Epoch 17, Step 65, Loss: 0.01010983157902956\n",
            "Epoch 17, Step 66, Loss: 0.00992543250322342\n",
            "Epoch 17, Step 67, Loss: 0.011370976455509663\n",
            "Epoch 17, Step 68, Loss: 0.011117398738861084\n",
            "Epoch 17, Step 69, Loss: 0.012198292650282383\n",
            "Epoch 17, Step 70, Loss: 0.015903117135167122\n",
            "Epoch 17, Step 71, Loss: 0.013270067051053047\n",
            "Epoch 17, Step 72, Loss: 0.01280603464692831\n",
            "Epoch 17, Step 73, Loss: 0.011086976155638695\n",
            "Epoch 17, Step 74, Loss: 0.010240890085697174\n",
            "Epoch 17, Step 75, Loss: 0.01198976393789053\n",
            "Epoch 17, Step 76, Loss: 0.012308402918279171\n",
            "Epoch 17, Step 77, Loss: 0.012491985224187374\n",
            "Epoch 17, Step 78, Loss: 0.011595849879086018\n",
            "Epoch 17, Step 79, Loss: 0.010950070805847645\n",
            "Epoch 17, Step 80, Loss: 0.011820110492408276\n",
            "Epoch 17, Step 81, Loss: 0.014283900149166584\n",
            "Epoch 17, Step 82, Loss: 0.014361996203660965\n",
            "Epoch 17, Step 83, Loss: 0.012659397907555103\n",
            "Epoch 17, Step 84, Loss: 0.013416473753750324\n",
            "Epoch 17, Step 85, Loss: 0.01656946912407875\n",
            "Train Metric MRRs: 0.08940900276516865\n",
            "Train Metric MAPs: 0.016692679196681753\n",
            "Validation Metric MRRs: 0.05554648407652258\n",
            "Validation Metric MAPs: 0.013543586461474032\n",
            "Epoch 18, Step 1, Loss: 0.04692468419671059\n",
            "Epoch 18, Step 2, Loss: 0.037141989916563034\n",
            "Epoch 18, Step 3, Loss: 0.0365796722471714\n",
            "Epoch 18, Step 4, Loss: 0.024114947766065598\n",
            "Epoch 18, Step 5, Loss: 0.017806369811296463\n",
            "Epoch 18, Step 6, Loss: 0.014735343866050243\n",
            "Epoch 18, Step 7, Loss: 0.009995308704674244\n",
            "Epoch 18, Step 8, Loss: 0.00894387997686863\n",
            "Epoch 18, Step 9, Loss: 0.009059866890311241\n",
            "Epoch 18, Step 10, Loss: 0.009311159141361713\n",
            "Epoch 18, Step 11, Loss: 0.00864403322339058\n",
            "Epoch 18, Step 12, Loss: 0.008439081721007824\n",
            "Epoch 18, Step 13, Loss: 0.008130239322781563\n",
            "Epoch 18, Step 14, Loss: 0.0077082016505301\n",
            "Epoch 18, Step 15, Loss: 0.007660632487386465\n",
            "Epoch 18, Step 16, Loss: 0.008937154896557331\n",
            "Epoch 18, Step 17, Loss: 0.011491350829601288\n",
            "Epoch 18, Step 18, Loss: 0.013061574660241604\n",
            "Epoch 18, Step 19, Loss: 0.015506245195865631\n",
            "Epoch 18, Step 20, Loss: 0.015422236174345016\n",
            "Epoch 18, Step 21, Loss: 0.0142704201862216\n",
            "Epoch 18, Step 22, Loss: 0.01623724214732647\n",
            "Epoch 18, Step 23, Loss: 0.01843482442200184\n",
            "Epoch 18, Step 24, Loss: 0.017206763848662376\n",
            "Epoch 18, Step 25, Loss: 0.016292596235871315\n",
            "Epoch 18, Step 26, Loss: 0.015822941437363625\n",
            "Epoch 18, Step 27, Loss: 0.013118095695972443\n",
            "Epoch 18, Step 28, Loss: 0.015466054901480675\n",
            "Epoch 18, Step 29, Loss: 0.014276677742600441\n",
            "Epoch 18, Step 30, Loss: 0.014076503925025463\n",
            "Epoch 18, Step 31, Loss: 0.01575460284948349\n",
            "Epoch 18, Step 32, Loss: 0.01346230786293745\n",
            "Epoch 18, Step 33, Loss: 0.012419341132044792\n",
            "Epoch 18, Step 34, Loss: 0.011318698525428772\n",
            "Epoch 18, Step 35, Loss: 0.012645186856389046\n",
            "Epoch 18, Step 36, Loss: 0.010822114534676075\n",
            "Epoch 18, Step 37, Loss: 0.012570720165967941\n",
            "Epoch 18, Step 38, Loss: 0.011041589081287384\n",
            "Epoch 18, Step 39, Loss: 0.013349846936762333\n",
            "Epoch 18, Step 40, Loss: 0.013047011569142342\n",
            "Epoch 18, Step 41, Loss: 0.012839291244745255\n",
            "Epoch 18, Step 42, Loss: 0.010308715514838696\n",
            "Epoch 18, Step 43, Loss: 0.010070673190057278\n",
            "Epoch 18, Step 44, Loss: 0.010426701046526432\n",
            "Epoch 18, Step 45, Loss: 0.0109203290194273\n",
            "Epoch 18, Step 46, Loss: 0.010352689772844315\n",
            "Epoch 18, Step 47, Loss: 0.011495329439640045\n",
            "Epoch 18, Step 48, Loss: 0.010027478449046612\n",
            "Epoch 18, Step 49, Loss: 0.009798352606594563\n",
            "Epoch 18, Step 50, Loss: 0.010039480403065681\n",
            "Epoch 18, Step 51, Loss: 0.010572941973805428\n",
            "Epoch 18, Step 52, Loss: 0.01009386032819748\n",
            "Epoch 18, Step 53, Loss: 0.013799790292978287\n",
            "Epoch 18, Step 54, Loss: 0.010161152109503746\n",
            "Epoch 18, Step 55, Loss: 0.008987185545265675\n",
            "Epoch 18, Step 56, Loss: 0.009777120314538479\n",
            "Epoch 18, Step 57, Loss: 0.008753113448619843\n",
            "Epoch 18, Step 58, Loss: 0.008614682592451572\n",
            "Epoch 18, Step 59, Loss: 0.008090035989880562\n",
            "Epoch 18, Step 60, Loss: 0.008835621178150177\n",
            "Epoch 18, Step 61, Loss: 0.010811988264322281\n",
            "Epoch 18, Step 62, Loss: 0.009062647819519043\n",
            "Epoch 18, Step 63, Loss: 0.009406155906617641\n",
            "Epoch 18, Step 64, Loss: 0.008792206645011902\n",
            "Epoch 18, Step 65, Loss: 0.010067545808851719\n",
            "Epoch 18, Step 66, Loss: 0.010320968925952911\n",
            "Epoch 18, Step 67, Loss: 0.011525790207087994\n",
            "Epoch 18, Step 68, Loss: 0.011516825295984745\n",
            "Epoch 18, Step 69, Loss: 0.011864619329571724\n",
            "Epoch 18, Step 70, Loss: 0.015376747585833073\n",
            "Epoch 18, Step 71, Loss: 0.013018065132200718\n",
            "Epoch 18, Step 72, Loss: 0.012729634530842304\n",
            "Epoch 18, Step 73, Loss: 0.010756438598036766\n",
            "Epoch 18, Step 74, Loss: 0.010308129712939262\n",
            "Epoch 18, Step 75, Loss: 0.011743629351258278\n",
            "Epoch 18, Step 76, Loss: 0.012377806007862091\n",
            "Epoch 18, Step 77, Loss: 0.012042155489325523\n",
            "Epoch 18, Step 78, Loss: 0.010022695176303387\n",
            "Epoch 18, Step 79, Loss: 0.011228316463530064\n",
            "Epoch 18, Step 80, Loss: 0.01174377091228962\n",
            "Epoch 18, Step 81, Loss: 0.014319153502583504\n",
            "Epoch 18, Step 82, Loss: 0.014412804506719112\n",
            "Epoch 18, Step 83, Loss: 0.012195021845400333\n",
            "Epoch 18, Step 84, Loss: 0.013362463563680649\n",
            "Epoch 18, Step 85, Loss: 0.017228974029421806\n",
            "Train Metric MRRs: 0.09267369570496732\n",
            "Train Metric MAPs: 0.016337897023612585\n",
            "Validation Metric MRRs: 0.06152330615217722\n",
            "Validation Metric MAPs: 0.012099481163587143\n",
            "Epoch 19, Step 1, Loss: 0.04810085520148277\n",
            "Epoch 19, Step 2, Loss: 0.036923620849847794\n",
            "Epoch 19, Step 3, Loss: 0.03736446797847748\n",
            "Epoch 19, Step 4, Loss: 0.024618985131382942\n",
            "Epoch 19, Step 5, Loss: 0.018244531005620956\n",
            "Epoch 19, Step 6, Loss: 0.015007758513092995\n",
            "Epoch 19, Step 7, Loss: 0.009426664561033249\n",
            "Epoch 19, Step 8, Loss: 0.008533128537237644\n",
            "Epoch 19, Step 9, Loss: 0.008842801675200462\n",
            "Epoch 19, Step 10, Loss: 0.00939387921243906\n",
            "Epoch 19, Step 11, Loss: 0.008894351311028004\n",
            "Epoch 19, Step 12, Loss: 0.00885063037276268\n",
            "Epoch 19, Step 13, Loss: 0.008781353011727333\n",
            "Epoch 19, Step 14, Loss: 0.008011698722839355\n",
            "Epoch 19, Step 15, Loss: 0.008273233659565449\n",
            "Epoch 19, Step 16, Loss: 0.009358669631183147\n",
            "Epoch 19, Step 17, Loss: 0.011549429036676884\n",
            "Epoch 19, Step 18, Loss: 0.012762077152729034\n",
            "Epoch 19, Step 19, Loss: 0.015120078809559345\n",
            "Epoch 19, Step 20, Loss: 0.01517587061971426\n",
            "Epoch 19, Step 21, Loss: 0.014420082792639732\n",
            "Epoch 19, Step 22, Loss: 0.016407040879130363\n",
            "Epoch 19, Step 23, Loss: 0.018050488084554672\n",
            "Epoch 19, Step 24, Loss: 0.016617819666862488\n",
            "Epoch 19, Step 25, Loss: 0.01628623716533184\n",
            "Epoch 19, Step 26, Loss: 0.01578189991414547\n",
            "Epoch 19, Step 27, Loss: 0.013464533723890781\n",
            "Epoch 19, Step 28, Loss: 0.015824126079678535\n",
            "Epoch 19, Step 29, Loss: 0.014352124184370041\n",
            "Epoch 19, Step 30, Loss: 0.014123674482107162\n",
            "Epoch 19, Step 31, Loss: 0.015482006594538689\n",
            "Epoch 19, Step 32, Loss: 0.013422026298940182\n",
            "Epoch 19, Step 33, Loss: 0.012546432204544544\n",
            "Epoch 19, Step 34, Loss: 0.011866297572851181\n",
            "Epoch 19, Step 35, Loss: 0.012574727647006512\n",
            "Epoch 19, Step 36, Loss: 0.010958555154502392\n",
            "Epoch 19, Step 37, Loss: 0.012390087358653545\n",
            "Epoch 19, Step 38, Loss: 0.01079083513468504\n",
            "Epoch 19, Step 39, Loss: 0.013343103229999542\n",
            "Epoch 19, Step 40, Loss: 0.012760700657963753\n",
            "Epoch 19, Step 41, Loss: 0.01142714824527502\n",
            "Epoch 19, Step 42, Loss: 0.010322922840714455\n",
            "Epoch 19, Step 43, Loss: 0.010383694432675838\n",
            "Epoch 19, Step 44, Loss: 0.010243561118841171\n",
            "Epoch 19, Step 45, Loss: 0.010770491324365139\n",
            "Epoch 19, Step 46, Loss: 0.010029316879808903\n",
            "Epoch 19, Step 47, Loss: 0.010471603833138943\n",
            "Epoch 19, Step 48, Loss: 0.009798861108720303\n",
            "Epoch 19, Step 49, Loss: 0.009727776050567627\n",
            "Epoch 19, Step 50, Loss: 0.009683433920145035\n",
            "Epoch 19, Step 51, Loss: 0.01023947261273861\n",
            "Epoch 19, Step 52, Loss: 0.009795131161808968\n",
            "Epoch 19, Step 53, Loss: 0.01376605499535799\n",
            "Epoch 19, Step 54, Loss: 0.00978042185306549\n",
            "Epoch 19, Step 55, Loss: 0.008849626407027245\n",
            "Epoch 19, Step 56, Loss: 0.009755419567227364\n",
            "Epoch 19, Step 57, Loss: 0.009059051983058453\n",
            "Epoch 19, Step 58, Loss: 0.009088737890124321\n",
            "Epoch 19, Step 59, Loss: 0.008729205466806889\n",
            "Epoch 19, Step 60, Loss: 0.008700652979314327\n",
            "Epoch 19, Step 61, Loss: 0.010721077211201191\n",
            "Epoch 19, Step 62, Loss: 0.00908743403851986\n",
            "Epoch 19, Step 63, Loss: 0.009448768571019173\n",
            "Epoch 19, Step 64, Loss: 0.008588474243879318\n",
            "Epoch 19, Step 65, Loss: 0.01018648874014616\n",
            "Epoch 19, Step 66, Loss: 0.0097338343039155\n",
            "Epoch 19, Step 67, Loss: 0.011571232229471207\n",
            "Epoch 19, Step 68, Loss: 0.011105484329164028\n",
            "Epoch 19, Step 69, Loss: 0.01185753382742405\n",
            "Epoch 19, Step 70, Loss: 0.015470380894839764\n",
            "Epoch 19, Step 71, Loss: 0.012904861941933632\n",
            "Epoch 19, Step 72, Loss: 0.012483222410082817\n",
            "Epoch 19, Step 73, Loss: 0.010983511805534363\n",
            "Epoch 19, Step 74, Loss: 0.010261486284434795\n",
            "Epoch 19, Step 75, Loss: 0.012909737415611744\n",
            "Epoch 19, Step 76, Loss: 0.012033908627927303\n",
            "Epoch 19, Step 77, Loss: 0.012461851350963116\n",
            "Epoch 19, Step 78, Loss: 0.010376036167144775\n",
            "Epoch 19, Step 79, Loss: 0.011740473099052906\n",
            "Epoch 19, Step 80, Loss: 0.011614198796451092\n",
            "Epoch 19, Step 81, Loss: 0.014036964625120163\n",
            "Epoch 19, Step 82, Loss: 0.015902366489171982\n",
            "Epoch 19, Step 83, Loss: 0.012015176005661488\n",
            "Epoch 19, Step 84, Loss: 0.01328182127326727\n",
            "Epoch 19, Step 85, Loss: 0.01755240187048912\n",
            "Train Metric MRRs: 0.09455538319293273\n",
            "Train Metric MAPs: 0.017146429723160748\n",
            "Validation Metric MRRs: 0.04475753023400548\n",
            "Validation Metric MAPs: 0.011753295238825\n",
            "Early stopping triggered!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.restore_best_checkpoint()\n",
        "trainer.validate('Validation')\n",
        "trainer.validate('Test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngGPW3O9MtI",
        "outputId": "a359b553-c859-437c-8a0e-efbb2f0c3e1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metric MRRs: 0.06248399057505962\n",
            "Validation Metric MAPs: 0.01478725100262871\n",
            "Test Metric MRRs: 0.09344134729319453\n",
            "Test Metric MAPs: 0.03250185273997393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.09344134729319453, 0.03250185273997393)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}