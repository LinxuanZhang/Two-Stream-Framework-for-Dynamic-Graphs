{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7IVQVEDWEWB",
        "outputId": "87723361-d780-474a-c46d-0c648a54b283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/mlds\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/mlds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import data_bitcoin as btc\n",
        "import tasker_link_prediction as t_lp\n",
        "from splitter import splitter\n",
        "from models import Baseline_node2vec\n",
        "from trainer import Trainer\n",
        "import yaml\n",
        "import os"
      ],
      "metadata": {
        "id": "ElDsah6AWVwk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep = False\n",
        "\n",
        "with open('config/config_BTC_OTC_baseline.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "model_path = config['model_path']\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "    os.mkdir(model_path + \"best_checkpoints/\")\n",
        "    os.mkdir(model_path + \"latest_checkpoints/\")\n",
        "\n",
        "with open(model_path + 'config.yaml', 'w') as file:\n",
        "    yaml.dump(config, file)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doo1WcuyWZAC",
        "outputId": "23b72275-0e8e-4b5b-a797-ee9ddd7ee8fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_config': {'adam_beta_1': 0.9,\n",
              "  'adam_beta_2': 0.999,\n",
              "  'adam_epsilon': 1e-07,\n",
              "  'adam_learning_rate': 0.005},\n",
              " 'model_path': 'models/BTC_OTC_N2V_baseline/',\n",
              " 'classifier_hidden_size': 16,\n",
              " 'ffn_fusion_size': 8,\n",
              " 'ffn_hidden_size': 8,\n",
              " 'gcn_fusion_size': 16,\n",
              " 'spatial_hidden_size': 16,\n",
              " 'spatial_input_dim': 64,\n",
              " 'temporal_hidden_size': 16,\n",
              " 'temporal_input_dim': 80,\n",
              " 'num_epochs': 1000,\n",
              " 'patience': 10,\n",
              " 'major_threshold': None,\n",
              " 'train_proportion': 0.7,\n",
              " 'dev_proportion': 0.1,\n",
              " 'data_path': 'data/BTC-OTC/',\n",
              " 'prep_data_path': 'prep_data/BTC_OTC_neg/'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = btc.Bitcoin_Dataset(config['data_path'])\n",
        "tasker = t_lp.Link_Pred_Tasker(data, path=config['prep_data_path'], prep=prep,\n",
        "                               embs_dim=config['spatial_input_dim'], temp_dim=int(config['temporal_input_dim']/10),\n",
        "                               major_threshold=config['major_threshold'], smart_neg_sampling=True)\n",
        "\n",
        "splitter_as = splitter(tasker, train_proportion = config['train_proportion'], dev_proportion = config['dev_proportion'])\n",
        "\n",
        "model= Baseline_node2vec(config['spatial_input_dim'])\n",
        "\n",
        "trainer = Trainer(model=model, splitter=splitter_as, model_path=model_path, adam_config=config['adam_config'], patience=config['patience'])\n",
        "print(trainer.patience)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unCQbLC8Wb0S",
        "outputId": "8eb8c327-8482-49f1-8e09-3ad20424735b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits sizes:  train 86 dev 14 test 28\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(config['num_epochs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuhZRFQVognD",
        "outputId": "7ff9b2d1-3625-446f-bdb2-79361a085faa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 1, Loss: 0.08455858379602432\n",
            "Epoch 1, Step 2, Loss: 0.07383275777101517\n",
            "Epoch 1, Step 3, Loss: 0.06093551218509674\n",
            "Epoch 1, Step 4, Loss: 0.060105100274086\n",
            "Epoch 1, Step 5, Loss: 0.04772182181477547\n",
            "Epoch 1, Step 6, Loss: 0.04466985911130905\n",
            "Epoch 1, Step 7, Loss: 0.03135096654295921\n",
            "Epoch 1, Step 8, Loss: 0.044529493898153305\n",
            "Epoch 1, Step 9, Loss: 0.04826757311820984\n",
            "Epoch 1, Step 10, Loss: 0.03773126378655434\n",
            "Epoch 1, Step 11, Loss: 0.03320885822176933\n",
            "Epoch 1, Step 12, Loss: 0.03334999084472656\n",
            "Epoch 1, Step 13, Loss: 0.03090774081647396\n",
            "Epoch 1, Step 14, Loss: 0.029473483562469482\n",
            "Epoch 1, Step 15, Loss: 0.03207558020949364\n",
            "Epoch 1, Step 16, Loss: 0.03376711532473564\n",
            "Epoch 1, Step 17, Loss: 0.036245182156562805\n",
            "Epoch 1, Step 18, Loss: 0.03611339256167412\n",
            "Epoch 1, Step 19, Loss: 0.0337519533932209\n",
            "Epoch 1, Step 20, Loss: 0.03942738100886345\n",
            "Epoch 1, Step 21, Loss: 0.02975546009838581\n",
            "Epoch 1, Step 22, Loss: 0.02868075482547283\n",
            "Epoch 1, Step 23, Loss: 0.036116160452365875\n",
            "Epoch 1, Step 24, Loss: 0.031061606481671333\n",
            "Epoch 1, Step 25, Loss: 0.02817654050886631\n",
            "Epoch 1, Step 26, Loss: 0.03665613383054733\n",
            "Epoch 1, Step 27, Loss: 0.02620377577841282\n",
            "Epoch 1, Step 28, Loss: 0.02951972559094429\n",
            "Epoch 1, Step 29, Loss: 0.024054529145359993\n",
            "Epoch 1, Step 30, Loss: 0.024827534332871437\n",
            "Epoch 1, Step 31, Loss: 0.025866564363241196\n",
            "Epoch 1, Step 32, Loss: 0.021649837493896484\n",
            "Epoch 1, Step 33, Loss: 0.023908372968435287\n",
            "Epoch 1, Step 34, Loss: 0.01986849121749401\n",
            "Epoch 1, Step 35, Loss: 0.021060587838292122\n",
            "Epoch 1, Step 36, Loss: 0.017186371609568596\n",
            "Epoch 1, Step 37, Loss: 0.02061993069946766\n",
            "Epoch 1, Step 38, Loss: 0.018068203702569008\n",
            "Epoch 1, Step 39, Loss: 0.02029833197593689\n",
            "Epoch 1, Step 40, Loss: 0.019157160073518753\n",
            "Epoch 1, Step 41, Loss: 0.01574805937707424\n",
            "Epoch 1, Step 42, Loss: 0.014778008684515953\n",
            "Epoch 1, Step 43, Loss: 0.015614604577422142\n",
            "Epoch 1, Step 44, Loss: 0.015607588924467564\n",
            "Epoch 1, Step 45, Loss: 0.016710324212908745\n",
            "Epoch 1, Step 46, Loss: 0.013607211410999298\n",
            "Epoch 1, Step 47, Loss: 0.01563762128353119\n",
            "Epoch 1, Step 48, Loss: 0.013573529198765755\n",
            "Epoch 1, Step 49, Loss: 0.013891194947063923\n",
            "Epoch 1, Step 50, Loss: 0.013565649278461933\n",
            "Epoch 1, Step 51, Loss: 0.014909455552697182\n",
            "Epoch 1, Step 52, Loss: 0.013571752235293388\n",
            "Epoch 1, Step 53, Loss: 0.015677016228437424\n",
            "Epoch 1, Step 54, Loss: 0.014941992238163948\n",
            "Epoch 1, Step 55, Loss: 0.013663364574313164\n",
            "Epoch 1, Step 56, Loss: 0.013548322021961212\n",
            "Epoch 1, Step 57, Loss: 0.012787374667823315\n",
            "Epoch 1, Step 58, Loss: 0.013987823389470577\n",
            "Epoch 1, Step 59, Loss: 0.012051058933138847\n",
            "Epoch 1, Step 60, Loss: 0.012242413125932217\n",
            "Epoch 1, Step 61, Loss: 0.01479198969900608\n",
            "Epoch 1, Step 62, Loss: 0.013479464687407017\n",
            "Epoch 1, Step 63, Loss: 0.023597581312060356\n",
            "Epoch 1, Step 64, Loss: 0.01372182834893465\n",
            "Epoch 1, Step 65, Loss: 0.012146825902163982\n",
            "Epoch 1, Step 66, Loss: 0.01098377350717783\n",
            "Epoch 1, Step 67, Loss: 0.01064625196158886\n",
            "Epoch 1, Step 68, Loss: 0.011640959419310093\n",
            "Epoch 1, Step 69, Loss: 0.010172510519623756\n",
            "Epoch 1, Step 70, Loss: 0.012161130085587502\n",
            "Epoch 1, Step 71, Loss: 0.012952389195561409\n",
            "Epoch 1, Step 72, Loss: 0.01147764828056097\n",
            "Epoch 1, Step 73, Loss: 0.01126559916883707\n",
            "Epoch 1, Step 74, Loss: 0.010516553185880184\n",
            "Epoch 1, Step 75, Loss: 0.009795158170163631\n",
            "Epoch 1, Step 76, Loss: 0.010605611838400364\n",
            "Epoch 1, Step 77, Loss: 0.01067462470382452\n",
            "Epoch 1, Step 78, Loss: 0.010445081628859043\n",
            "Epoch 1, Step 79, Loss: 0.009022153913974762\n",
            "Epoch 1, Step 80, Loss: 0.009935377165675163\n",
            "Epoch 1, Step 81, Loss: 0.0137306097894907\n",
            "Epoch 1, Step 82, Loss: 0.011645209044218063\n",
            "Epoch 1, Step 83, Loss: 0.011538950726389885\n",
            "Epoch 1, Step 84, Loss: 0.012137026526033878\n",
            "Epoch 1, Step 85, Loss: 0.013193115592002869\n",
            "Epoch 1, Step 86, Loss: 0.013953211717307568\n",
            "Train Metric MRRs: 0.011730491400885662\n",
            "Train Metric MAPs: 0.0027829470787503123\n",
            "Validation Metric MRRs: 0.032363033786999645\n",
            "Validation Metric MAPs: 0.005310587461816722\n",
            "Epoch 2, Step 1, Loss: 0.04237409308552742\n",
            "Epoch 2, Step 2, Loss: 0.045150090008974075\n",
            "Epoch 2, Step 3, Loss: 0.03801853209733963\n",
            "Epoch 2, Step 4, Loss: 0.031327225267887115\n",
            "Epoch 2, Step 5, Loss: 0.02109404280781746\n",
            "Epoch 2, Step 6, Loss: 0.017248328775167465\n",
            "Epoch 2, Step 7, Loss: 0.012225007638335228\n",
            "Epoch 2, Step 8, Loss: 0.010727187618613243\n",
            "Epoch 2, Step 9, Loss: 0.010426201857626438\n",
            "Epoch 2, Step 10, Loss: 0.011090926826000214\n",
            "Epoch 2, Step 11, Loss: 0.011439925990998745\n",
            "Epoch 2, Step 12, Loss: 0.009837312623858452\n",
            "Epoch 2, Step 13, Loss: 0.010098598897457123\n",
            "Epoch 2, Step 14, Loss: 0.010039032436907291\n",
            "Epoch 2, Step 15, Loss: 0.010172107256948948\n",
            "Epoch 2, Step 16, Loss: 0.011078831739723682\n",
            "Epoch 2, Step 17, Loss: 0.013784151524305344\n",
            "Epoch 2, Step 18, Loss: 0.014625663869082928\n",
            "Epoch 2, Step 19, Loss: 0.017039481550455093\n",
            "Epoch 2, Step 20, Loss: 0.018163010478019714\n",
            "Epoch 2, Step 21, Loss: 0.01634356938302517\n",
            "Epoch 2, Step 22, Loss: 0.02060113660991192\n",
            "Epoch 2, Step 23, Loss: 0.02026612125337124\n",
            "Epoch 2, Step 24, Loss: 0.019406361505389214\n",
            "Epoch 2, Step 25, Loss: 0.01862427406013012\n",
            "Epoch 2, Step 26, Loss: 0.01985367387533188\n",
            "Epoch 2, Step 27, Loss: 0.015308643691241741\n",
            "Epoch 2, Step 28, Loss: 0.017178885638713837\n",
            "Epoch 2, Step 29, Loss: 0.01590905524790287\n",
            "Epoch 2, Step 30, Loss: 0.01466758456081152\n",
            "Epoch 2, Step 31, Loss: 0.016691220924258232\n",
            "Epoch 2, Step 32, Loss: 0.014999986626207829\n",
            "Epoch 2, Step 33, Loss: 0.015890242531895638\n",
            "Epoch 2, Step 34, Loss: 0.013726111501455307\n",
            "Epoch 2, Step 35, Loss: 0.013921791687607765\n",
            "Epoch 2, Step 36, Loss: 0.012669877149164677\n",
            "Epoch 2, Step 37, Loss: 0.014224350452423096\n",
            "Epoch 2, Step 38, Loss: 0.011813337914645672\n",
            "Epoch 2, Step 39, Loss: 0.014248913154006004\n",
            "Epoch 2, Step 40, Loss: 0.014390054158866405\n",
            "Epoch 2, Step 41, Loss: 0.011585038155317307\n",
            "Epoch 2, Step 42, Loss: 0.010162408463656902\n",
            "Epoch 2, Step 43, Loss: 0.010998398996889591\n",
            "Epoch 2, Step 44, Loss: 0.010104360058903694\n",
            "Epoch 2, Step 45, Loss: 0.011049184948205948\n",
            "Epoch 2, Step 46, Loss: 0.010263173840939999\n",
            "Epoch 2, Step 47, Loss: 0.011803199537098408\n",
            "Epoch 2, Step 48, Loss: 0.010624020360410213\n",
            "Epoch 2, Step 49, Loss: 0.010237336158752441\n",
            "Epoch 2, Step 50, Loss: 0.009684626013040543\n",
            "Epoch 2, Step 51, Loss: 0.012098637409508228\n",
            "Epoch 2, Step 52, Loss: 0.010272480547428131\n",
            "Epoch 2, Step 53, Loss: 0.013231741264462471\n",
            "Epoch 2, Step 54, Loss: 0.011615597642958164\n",
            "Epoch 2, Step 55, Loss: 0.010922718793153763\n",
            "Epoch 2, Step 56, Loss: 0.011472298763692379\n",
            "Epoch 2, Step 57, Loss: 0.009978433139622211\n",
            "Epoch 2, Step 58, Loss: 0.01141936145722866\n",
            "Epoch 2, Step 59, Loss: 0.0096351969987154\n",
            "Epoch 2, Step 60, Loss: 0.01001044362783432\n",
            "Epoch 2, Step 61, Loss: 0.011873318813741207\n",
            "Epoch 2, Step 62, Loss: 0.011016050353646278\n",
            "Epoch 2, Step 63, Loss: 0.022903382778167725\n",
            "Epoch 2, Step 64, Loss: 0.010771479457616806\n",
            "Epoch 2, Step 65, Loss: 0.010049577802419662\n",
            "Epoch 2, Step 66, Loss: 0.008728661574423313\n",
            "Epoch 2, Step 67, Loss: 0.009299060329794884\n",
            "Epoch 2, Step 68, Loss: 0.010046206414699554\n",
            "Epoch 2, Step 69, Loss: 0.009028053842484951\n",
            "Epoch 2, Step 70, Loss: 0.010420826263725758\n",
            "Epoch 2, Step 71, Loss: 0.011179182678461075\n",
            "Epoch 2, Step 72, Loss: 0.010694419033825397\n",
            "Epoch 2, Step 73, Loss: 0.00984075665473938\n",
            "Epoch 2, Step 74, Loss: 0.008780374191701412\n",
            "Epoch 2, Step 75, Loss: 0.008835133165121078\n",
            "Epoch 2, Step 76, Loss: 0.009516009129583836\n",
            "Epoch 2, Step 77, Loss: 0.00929053034633398\n",
            "Epoch 2, Step 78, Loss: 0.008313865400850773\n",
            "Epoch 2, Step 79, Loss: 0.008256344124674797\n",
            "Epoch 2, Step 80, Loss: 0.008624667301774025\n",
            "Epoch 2, Step 81, Loss: 0.011923032812774181\n",
            "Epoch 2, Step 82, Loss: 0.010848641395568848\n",
            "Epoch 2, Step 83, Loss: 0.010381286963820457\n",
            "Epoch 2, Step 84, Loss: 0.01132396049797535\n",
            "Epoch 2, Step 85, Loss: 0.012167636305093765\n",
            "Epoch 2, Step 86, Loss: 0.013061579316854477\n",
            "Train Metric MRRs: 0.024579620714734487\n",
            "Train Metric MAPs: 0.004533666733865305\n",
            "Validation Metric MRRs: 0.03989134464149331\n",
            "Validation Metric MAPs: 0.006849505611448651\n",
            "Epoch 3, Step 1, Loss: 0.04095517098903656\n",
            "Epoch 3, Step 2, Loss: 0.039099905639886856\n",
            "Epoch 3, Step 3, Loss: 0.03686456382274628\n",
            "Epoch 3, Step 4, Loss: 0.027291936799883842\n",
            "Epoch 3, Step 5, Loss: 0.019274119287729263\n",
            "Epoch 3, Step 6, Loss: 0.015683500096201897\n",
            "Epoch 3, Step 7, Loss: 0.011815320700407028\n",
            "Epoch 3, Step 8, Loss: 0.009386253543198109\n",
            "Epoch 3, Step 9, Loss: 0.009308844804763794\n",
            "Epoch 3, Step 10, Loss: 0.010001680813729763\n",
            "Epoch 3, Step 11, Loss: 0.010130628943443298\n",
            "Epoch 3, Step 12, Loss: 0.00870272796601057\n",
            "Epoch 3, Step 13, Loss: 0.009243713691830635\n",
            "Epoch 3, Step 14, Loss: 0.00909288227558136\n",
            "Epoch 3, Step 15, Loss: 0.00882723368704319\n",
            "Epoch 3, Step 16, Loss: 0.009792735800147057\n",
            "Epoch 3, Step 17, Loss: 0.0126861073076725\n",
            "Epoch 3, Step 18, Loss: 0.014154256321489811\n",
            "Epoch 3, Step 19, Loss: 0.016448955982923508\n",
            "Epoch 3, Step 20, Loss: 0.017472630366683006\n",
            "Epoch 3, Step 21, Loss: 0.015847360715270042\n",
            "Epoch 3, Step 22, Loss: 0.01800614967942238\n",
            "Epoch 3, Step 23, Loss: 0.020035691559314728\n",
            "Epoch 3, Step 24, Loss: 0.01846502721309662\n",
            "Epoch 3, Step 25, Loss: 0.017904918640851974\n",
            "Epoch 3, Step 26, Loss: 0.018761372193694115\n",
            "Epoch 3, Step 27, Loss: 0.015251747332513332\n",
            "Epoch 3, Step 28, Loss: 0.015462607145309448\n",
            "Epoch 3, Step 29, Loss: 0.015096096321940422\n",
            "Epoch 3, Step 30, Loss: 0.013942757621407509\n",
            "Epoch 3, Step 31, Loss: 0.01623661071062088\n",
            "Epoch 3, Step 32, Loss: 0.014583328738808632\n",
            "Epoch 3, Step 33, Loss: 0.014855579473078251\n",
            "Epoch 3, Step 34, Loss: 0.012983622029423714\n",
            "Epoch 3, Step 35, Loss: 0.013266622088849545\n",
            "Epoch 3, Step 36, Loss: 0.012068464420735836\n",
            "Epoch 3, Step 37, Loss: 0.013280550017952919\n",
            "Epoch 3, Step 38, Loss: 0.011508587747812271\n",
            "Epoch 3, Step 39, Loss: 0.01354908011853695\n",
            "Epoch 3, Step 40, Loss: 0.013887333683669567\n",
            "Epoch 3, Step 41, Loss: 0.011168934404850006\n",
            "Epoch 3, Step 42, Loss: 0.0096631133928895\n",
            "Epoch 3, Step 43, Loss: 0.009919367730617523\n",
            "Epoch 3, Step 44, Loss: 0.009648310020565987\n",
            "Epoch 3, Step 45, Loss: 0.010238150134682655\n",
            "Epoch 3, Step 46, Loss: 0.009476677514612675\n",
            "Epoch 3, Step 47, Loss: 0.010668297298252583\n",
            "Epoch 3, Step 48, Loss: 0.009702854789793491\n",
            "Epoch 3, Step 49, Loss: 0.009559586644172668\n",
            "Epoch 3, Step 50, Loss: 0.008964751847088337\n",
            "Epoch 3, Step 51, Loss: 0.010731291957199574\n",
            "Epoch 3, Step 52, Loss: 0.009583186358213425\n",
            "Epoch 3, Step 53, Loss: 0.012543016113340855\n",
            "Epoch 3, Step 54, Loss: 0.010892526246607304\n",
            "Epoch 3, Step 55, Loss: 0.010354534722864628\n",
            "Epoch 3, Step 56, Loss: 0.010548521764576435\n",
            "Epoch 3, Step 57, Loss: 0.009325341321527958\n",
            "Epoch 3, Step 58, Loss: 0.010394603945314884\n",
            "Epoch 3, Step 59, Loss: 0.009009091183543205\n",
            "Epoch 3, Step 60, Loss: 0.009306221269071102\n",
            "Epoch 3, Step 61, Loss: 0.01129223220050335\n",
            "Epoch 3, Step 62, Loss: 0.010498018935322762\n",
            "Epoch 3, Step 63, Loss: 0.02323758229613304\n",
            "Epoch 3, Step 64, Loss: 0.009508703835308552\n",
            "Epoch 3, Step 65, Loss: 0.009289638139307499\n",
            "Epoch 3, Step 66, Loss: 0.008168591186404228\n",
            "Epoch 3, Step 67, Loss: 0.008920565247535706\n",
            "Epoch 3, Step 68, Loss: 0.009221048094332218\n",
            "Epoch 3, Step 69, Loss: 0.008732305839657784\n",
            "Epoch 3, Step 70, Loss: 0.010098169557750225\n",
            "Epoch 3, Step 71, Loss: 0.010711750015616417\n",
            "Epoch 3, Step 72, Loss: 0.010510924272239208\n",
            "Epoch 3, Step 73, Loss: 0.009441414847970009\n",
            "Epoch 3, Step 74, Loss: 0.008309904485940933\n",
            "Epoch 3, Step 75, Loss: 0.008223283104598522\n",
            "Epoch 3, Step 76, Loss: 0.008960007689893246\n",
            "Epoch 3, Step 77, Loss: 0.008928653784096241\n",
            "Epoch 3, Step 78, Loss: 0.007810375653207302\n",
            "Epoch 3, Step 79, Loss: 0.007996287196874619\n",
            "Epoch 3, Step 80, Loss: 0.008374531753361225\n",
            "Epoch 3, Step 81, Loss: 0.011468642391264439\n",
            "Epoch 3, Step 82, Loss: 0.010416432283818722\n",
            "Epoch 3, Step 83, Loss: 0.010091422125697136\n",
            "Epoch 3, Step 84, Loss: 0.011263245716691017\n",
            "Epoch 3, Step 85, Loss: 0.01194057147949934\n",
            "Epoch 3, Step 86, Loss: 0.012684968300163746\n",
            "Train Metric MRRs: 0.03414173260793244\n",
            "Train Metric MAPs: 0.005789354186501722\n",
            "Validation Metric MRRs: 0.045561131114790016\n",
            "Validation Metric MAPs: 0.007850834666698824\n",
            "Epoch 4, Step 1, Loss: 0.041195016354322433\n",
            "Epoch 4, Step 2, Loss: 0.03739010915160179\n",
            "Epoch 4, Step 3, Loss: 0.03712157532572746\n",
            "Epoch 4, Step 4, Loss: 0.026226479560136795\n",
            "Epoch 4, Step 5, Loss: 0.018819279968738556\n",
            "Epoch 4, Step 6, Loss: 0.015531698241829872\n",
            "Epoch 4, Step 7, Loss: 0.01207396574318409\n",
            "Epoch 4, Step 8, Loss: 0.009146178141236305\n",
            "Epoch 4, Step 9, Loss: 0.008862990885972977\n",
            "Epoch 4, Step 10, Loss: 0.009581063874065876\n",
            "Epoch 4, Step 11, Loss: 0.009427393786609173\n",
            "Epoch 4, Step 12, Loss: 0.008325593546032906\n",
            "Epoch 4, Step 13, Loss: 0.008869393728673458\n",
            "Epoch 4, Step 14, Loss: 0.008527126163244247\n",
            "Epoch 4, Step 15, Loss: 0.008261878974735737\n",
            "Epoch 4, Step 16, Loss: 0.00953077431768179\n",
            "Epoch 4, Step 17, Loss: 0.012272346764802933\n",
            "Epoch 4, Step 18, Loss: 0.013883434236049652\n",
            "Epoch 4, Step 19, Loss: 0.016250548884272575\n",
            "Epoch 4, Step 20, Loss: 0.017225906252861023\n",
            "Epoch 4, Step 21, Loss: 0.015681583434343338\n",
            "Epoch 4, Step 22, Loss: 0.017086852341890335\n",
            "Epoch 4, Step 23, Loss: 0.02000257559120655\n",
            "Epoch 4, Step 24, Loss: 0.01815442554652691\n",
            "Epoch 4, Step 25, Loss: 0.017763109877705574\n",
            "Epoch 4, Step 26, Loss: 0.0184614360332489\n",
            "Epoch 4, Step 27, Loss: 0.015044351108372211\n",
            "Epoch 4, Step 28, Loss: 0.014916116371750832\n",
            "Epoch 4, Step 29, Loss: 0.014762157574295998\n",
            "Epoch 4, Step 30, Loss: 0.013786195777356625\n",
            "Epoch 4, Step 31, Loss: 0.016022751107811928\n",
            "Epoch 4, Step 32, Loss: 0.01458456739783287\n",
            "Epoch 4, Step 33, Loss: 0.014297268353402615\n",
            "Epoch 4, Step 34, Loss: 0.01269564963877201\n",
            "Epoch 4, Step 35, Loss: 0.0130545012652874\n",
            "Epoch 4, Step 36, Loss: 0.011877905577421188\n",
            "Epoch 4, Step 37, Loss: 0.0129783246666193\n",
            "Epoch 4, Step 38, Loss: 0.011357016861438751\n",
            "Epoch 4, Step 39, Loss: 0.013209587894380093\n",
            "Epoch 4, Step 40, Loss: 0.013645680621266365\n",
            "Epoch 4, Step 41, Loss: 0.010899892076849937\n",
            "Epoch 4, Step 42, Loss: 0.009518442675471306\n",
            "Epoch 4, Step 43, Loss: 0.009313869290053844\n",
            "Epoch 4, Step 44, Loss: 0.009444124065339565\n",
            "Epoch 4, Step 45, Loss: 0.00990323442965746\n",
            "Epoch 4, Step 46, Loss: 0.009152526035904884\n",
            "Epoch 4, Step 47, Loss: 0.010306152515113354\n",
            "Epoch 4, Step 48, Loss: 0.009422977454960346\n",
            "Epoch 4, Step 49, Loss: 0.009225287474691868\n",
            "Epoch 4, Step 50, Loss: 0.0088038370013237\n",
            "Epoch 4, Step 51, Loss: 0.010125720873475075\n",
            "Epoch 4, Step 52, Loss: 0.00919031910598278\n",
            "Epoch 4, Step 53, Loss: 0.012273134663701057\n",
            "Epoch 4, Step 54, Loss: 0.010638165287673473\n",
            "Epoch 4, Step 55, Loss: 0.010175827890634537\n",
            "Epoch 4, Step 56, Loss: 0.010215498507022858\n",
            "Epoch 4, Step 57, Loss: 0.009035621769726276\n",
            "Epoch 4, Step 58, Loss: 0.00995088554918766\n",
            "Epoch 4, Step 59, Loss: 0.008715889416635036\n",
            "Epoch 4, Step 60, Loss: 0.009062733501195908\n",
            "Epoch 4, Step 61, Loss: 0.011150753125548363\n",
            "Epoch 4, Step 62, Loss: 0.010290104895830154\n",
            "Epoch 4, Step 63, Loss: 0.023492414504289627\n",
            "Epoch 4, Step 64, Loss: 0.008727253414690495\n",
            "Epoch 4, Step 65, Loss: 0.008978957310318947\n",
            "Epoch 4, Step 66, Loss: 0.007969235070049763\n",
            "Epoch 4, Step 67, Loss: 0.008779986761510372\n",
            "Epoch 4, Step 68, Loss: 0.008765505626797676\n",
            "Epoch 4, Step 69, Loss: 0.008582514710724354\n",
            "Epoch 4, Step 70, Loss: 0.009948085062205791\n",
            "Epoch 4, Step 71, Loss: 0.010552036575973034\n",
            "Epoch 4, Step 72, Loss: 0.010273972526192665\n",
            "Epoch 4, Step 73, Loss: 0.00924910418689251\n",
            "Epoch 4, Step 74, Loss: 0.008077826350927353\n",
            "Epoch 4, Step 75, Loss: 0.008013575337827206\n",
            "Epoch 4, Step 76, Loss: 0.00873708724975586\n",
            "Epoch 4, Step 77, Loss: 0.008727659471333027\n",
            "Epoch 4, Step 78, Loss: 0.007621730677783489\n",
            "Epoch 4, Step 79, Loss: 0.007929873652756214\n",
            "Epoch 4, Step 80, Loss: 0.008327583782374859\n",
            "Epoch 4, Step 81, Loss: 0.011204889044165611\n",
            "Epoch 4, Step 82, Loss: 0.010283000767230988\n",
            "Epoch 4, Step 83, Loss: 0.010021013207733631\n",
            "Epoch 4, Step 84, Loss: 0.011189845390617847\n",
            "Epoch 4, Step 85, Loss: 0.011809239163994789\n",
            "Epoch 4, Step 86, Loss: 0.01243545487523079\n",
            "Train Metric MRRs: 0.04963208219989682\n",
            "Train Metric MAPs: 0.006811896939857858\n",
            "Validation Metric MRRs: 0.047429348704693584\n",
            "Validation Metric MAPs: 0.007557749404694969\n",
            "Epoch 5, Step 1, Loss: 0.04089270904660225\n",
            "Epoch 5, Step 2, Loss: 0.03627265617251396\n",
            "Epoch 5, Step 3, Loss: 0.03737683966755867\n",
            "Epoch 5, Step 4, Loss: 0.025875000283122063\n",
            "Epoch 5, Step 5, Loss: 0.018621793016791344\n",
            "Epoch 5, Step 6, Loss: 0.01538866851478815\n",
            "Epoch 5, Step 7, Loss: 0.011604661121964455\n",
            "Epoch 5, Step 8, Loss: 0.00890627596527338\n",
            "Epoch 5, Step 9, Loss: 0.008624307811260223\n",
            "Epoch 5, Step 10, Loss: 0.00922804232686758\n",
            "Epoch 5, Step 11, Loss: 0.00905747339129448\n",
            "Epoch 5, Step 12, Loss: 0.008098703809082508\n",
            "Epoch 5, Step 13, Loss: 0.008577082306146622\n",
            "Epoch 5, Step 14, Loss: 0.008198904804885387\n",
            "Epoch 5, Step 15, Loss: 0.008078447543084621\n",
            "Epoch 5, Step 16, Loss: 0.009401052258908749\n",
            "Epoch 5, Step 17, Loss: 0.012153522111475468\n",
            "Epoch 5, Step 18, Loss: 0.013737689703702927\n",
            "Epoch 5, Step 19, Loss: 0.016075754538178444\n",
            "Epoch 5, Step 20, Loss: 0.016951557248830795\n",
            "Epoch 5, Step 21, Loss: 0.015467733144760132\n",
            "Epoch 5, Step 22, Loss: 0.016714787110686302\n",
            "Epoch 5, Step 23, Loss: 0.01981951855123043\n",
            "Epoch 5, Step 24, Loss: 0.018012773245573044\n",
            "Epoch 5, Step 25, Loss: 0.01746204122900963\n",
            "Epoch 5, Step 26, Loss: 0.018205106258392334\n",
            "Epoch 5, Step 27, Loss: 0.014783531427383423\n",
            "Epoch 5, Step 28, Loss: 0.014633041806519032\n",
            "Epoch 5, Step 29, Loss: 0.014559159055352211\n",
            "Epoch 5, Step 30, Loss: 0.013669977895915508\n",
            "Epoch 5, Step 31, Loss: 0.01591482013463974\n",
            "Epoch 5, Step 32, Loss: 0.01456559356302023\n",
            "Epoch 5, Step 33, Loss: 0.014044148847460747\n",
            "Epoch 5, Step 34, Loss: 0.012477987445890903\n",
            "Epoch 5, Step 35, Loss: 0.012913071550428867\n",
            "Epoch 5, Step 36, Loss: 0.01173788495361805\n",
            "Epoch 5, Step 37, Loss: 0.012822112999856472\n",
            "Epoch 5, Step 38, Loss: 0.01114159170538187\n",
            "Epoch 5, Step 39, Loss: 0.013040078803896904\n",
            "Epoch 5, Step 40, Loss: 0.013514804653823376\n",
            "Epoch 5, Step 41, Loss: 0.010759311728179455\n",
            "Epoch 5, Step 42, Loss: 0.00944496039301157\n",
            "Epoch 5, Step 43, Loss: 0.009097585454583168\n",
            "Epoch 5, Step 44, Loss: 0.009317275136709213\n",
            "Epoch 5, Step 45, Loss: 0.009740568697452545\n",
            "Epoch 5, Step 46, Loss: 0.008996081538498402\n",
            "Epoch 5, Step 47, Loss: 0.010090620256960392\n",
            "Epoch 5, Step 48, Loss: 0.00937950424849987\n",
            "Epoch 5, Step 49, Loss: 0.009056399576365948\n",
            "Epoch 5, Step 50, Loss: 0.008566558361053467\n",
            "Epoch 5, Step 51, Loss: 0.009907707571983337\n",
            "Epoch 5, Step 52, Loss: 0.008896462619304657\n",
            "Epoch 5, Step 53, Loss: 0.01214618794620037\n",
            "Epoch 5, Step 54, Loss: 0.010441032238304615\n",
            "Epoch 5, Step 55, Loss: 0.01004102360457182\n",
            "Epoch 5, Step 56, Loss: 0.010044862516224384\n",
            "Epoch 5, Step 57, Loss: 0.00891595147550106\n",
            "Epoch 5, Step 58, Loss: 0.009685651399195194\n",
            "Epoch 5, Step 59, Loss: 0.008518904447555542\n",
            "Epoch 5, Step 60, Loss: 0.00897726695984602\n",
            "Epoch 5, Step 61, Loss: 0.011067245155572891\n",
            "Epoch 5, Step 62, Loss: 0.010104367509484291\n",
            "Epoch 5, Step 63, Loss: 0.023660972714424133\n",
            "Epoch 5, Step 64, Loss: 0.008336887694895267\n",
            "Epoch 5, Step 65, Loss: 0.008844873867928982\n",
            "Epoch 5, Step 66, Loss: 0.00786266103386879\n",
            "Epoch 5, Step 67, Loss: 0.008659668266773224\n",
            "Epoch 5, Step 68, Loss: 0.008529415354132652\n",
            "Epoch 5, Step 69, Loss: 0.008541004732251167\n",
            "Epoch 5, Step 70, Loss: 0.009878999553620815\n",
            "Epoch 5, Step 71, Loss: 0.010470714420080185\n",
            "Epoch 5, Step 72, Loss: 0.010147913359105587\n",
            "Epoch 5, Step 73, Loss: 0.009151345118880272\n",
            "Epoch 5, Step 74, Loss: 0.007941697724163532\n",
            "Epoch 5, Step 75, Loss: 0.00785140972584486\n",
            "Epoch 5, Step 76, Loss: 0.008609367534518242\n",
            "Epoch 5, Step 77, Loss: 0.008628765121102333\n",
            "Epoch 5, Step 78, Loss: 0.007511121220886707\n",
            "Epoch 5, Step 79, Loss: 0.007879062555730343\n",
            "Epoch 5, Step 80, Loss: 0.008316868916153908\n",
            "Epoch 5, Step 81, Loss: 0.011024849489331245\n",
            "Epoch 5, Step 82, Loss: 0.010215923190116882\n",
            "Epoch 5, Step 83, Loss: 0.009979909285902977\n",
            "Epoch 5, Step 84, Loss: 0.011106383055448532\n",
            "Epoch 5, Step 85, Loss: 0.01173324789851904\n",
            "Epoch 5, Step 86, Loss: 0.012299166060984135\n",
            "Train Metric MRRs: 0.05862839859883781\n",
            "Train Metric MAPs: 0.007819071805785628\n",
            "Validation Metric MRRs: 0.04408275007408197\n",
            "Validation Metric MAPs: 0.007321670433865231\n",
            "Epoch 6, Step 1, Loss: 0.040473517030477524\n",
            "Epoch 6, Step 2, Loss: 0.03539144620299339\n",
            "Epoch 6, Step 3, Loss: 0.03724484518170357\n",
            "Epoch 6, Step 4, Loss: 0.025514574721455574\n",
            "Epoch 6, Step 5, Loss: 0.01845955103635788\n",
            "Epoch 6, Step 6, Loss: 0.015292281284928322\n",
            "Epoch 6, Step 7, Loss: 0.011268780566751957\n",
            "Epoch 6, Step 8, Loss: 0.008744201622903347\n",
            "Epoch 6, Step 9, Loss: 0.008510311134159565\n",
            "Epoch 6, Step 10, Loss: 0.009074081666767597\n",
            "Epoch 6, Step 11, Loss: 0.008821431547403336\n",
            "Epoch 6, Step 12, Loss: 0.007994626648724079\n",
            "Epoch 6, Step 13, Loss: 0.008425758220255375\n",
            "Epoch 6, Step 14, Loss: 0.007962229661643505\n",
            "Epoch 6, Step 15, Loss: 0.007936665788292885\n",
            "Epoch 6, Step 16, Loss: 0.009306165389716625\n",
            "Epoch 6, Step 17, Loss: 0.011979351751506329\n",
            "Epoch 6, Step 18, Loss: 0.013548447750508785\n",
            "Epoch 6, Step 19, Loss: 0.015935519710183144\n",
            "Epoch 6, Step 20, Loss: 0.01669379509985447\n",
            "Epoch 6, Step 21, Loss: 0.015310486778616905\n",
            "Epoch 6, Step 22, Loss: 0.01655232347548008\n",
            "Epoch 6, Step 23, Loss: 0.01960076205432415\n",
            "Epoch 6, Step 24, Loss: 0.017818856984376907\n",
            "Epoch 6, Step 25, Loss: 0.01723306253552437\n",
            "Epoch 6, Step 26, Loss: 0.01799452304840088\n",
            "Epoch 6, Step 27, Loss: 0.014586741104722023\n",
            "Epoch 6, Step 28, Loss: 0.014437615871429443\n",
            "Epoch 6, Step 29, Loss: 0.014451324939727783\n",
            "Epoch 6, Step 30, Loss: 0.0135417515411973\n",
            "Epoch 6, Step 31, Loss: 0.015809088945388794\n",
            "Epoch 6, Step 32, Loss: 0.014513593167066574\n",
            "Epoch 6, Step 33, Loss: 0.01392293255776167\n",
            "Epoch 6, Step 34, Loss: 0.012318630702793598\n",
            "Epoch 6, Step 35, Loss: 0.012796700932085514\n",
            "Epoch 6, Step 36, Loss: 0.011656610295176506\n",
            "Epoch 6, Step 37, Loss: 0.012736702337861061\n",
            "Epoch 6, Step 38, Loss: 0.010999258607625961\n",
            "Epoch 6, Step 39, Loss: 0.0129429642111063\n",
            "Epoch 6, Step 40, Loss: 0.013407524675130844\n",
            "Epoch 6, Step 41, Loss: 0.010686266236007214\n",
            "Epoch 6, Step 42, Loss: 0.009334920905530453\n",
            "Epoch 6, Step 43, Loss: 0.008971442468464375\n",
            "Epoch 6, Step 44, Loss: 0.00919270422309637\n",
            "Epoch 6, Step 45, Loss: 0.009629865176975727\n",
            "Epoch 6, Step 46, Loss: 0.008909568190574646\n",
            "Epoch 6, Step 47, Loss: 0.009968237951397896\n",
            "Epoch 6, Step 48, Loss: 0.009352397173643112\n",
            "Epoch 6, Step 49, Loss: 0.008925179950892925\n",
            "Epoch 6, Step 50, Loss: 0.008440125733613968\n",
            "Epoch 6, Step 51, Loss: 0.009768513031303883\n",
            "Epoch 6, Step 52, Loss: 0.00870043970644474\n",
            "Epoch 6, Step 53, Loss: 0.012070476077497005\n",
            "Epoch 6, Step 54, Loss: 0.010318269953131676\n",
            "Epoch 6, Step 55, Loss: 0.009958448819816113\n",
            "Epoch 6, Step 56, Loss: 0.009928490035235882\n",
            "Epoch 6, Step 57, Loss: 0.008847719058394432\n",
            "Epoch 6, Step 58, Loss: 0.009533802047371864\n",
            "Epoch 6, Step 59, Loss: 0.008394633419811726\n",
            "Epoch 6, Step 60, Loss: 0.008897855877876282\n",
            "Epoch 6, Step 61, Loss: 0.011025318875908852\n",
            "Epoch 6, Step 62, Loss: 0.009911565110087395\n",
            "Epoch 6, Step 63, Loss: 0.02361033484339714\n",
            "Epoch 6, Step 64, Loss: 0.00800095871090889\n",
            "Epoch 6, Step 65, Loss: 0.008765080943703651\n",
            "Epoch 6, Step 66, Loss: 0.007800727151334286\n",
            "Epoch 6, Step 67, Loss: 0.008579347282648087\n",
            "Epoch 6, Step 68, Loss: 0.00839622039347887\n",
            "Epoch 6, Step 69, Loss: 0.008502292446792126\n",
            "Epoch 6, Step 70, Loss: 0.009799569845199585\n",
            "Epoch 6, Step 71, Loss: 0.010430856607854366\n",
            "Epoch 6, Step 72, Loss: 0.00997600145637989\n",
            "Epoch 6, Step 73, Loss: 0.009103817865252495\n",
            "Epoch 6, Step 74, Loss: 0.007909659296274185\n",
            "Epoch 6, Step 75, Loss: 0.007717606145888567\n",
            "Epoch 6, Step 76, Loss: 0.008516077883541584\n",
            "Epoch 6, Step 77, Loss: 0.008564448915421963\n",
            "Epoch 6, Step 78, Loss: 0.007438379339873791\n",
            "Epoch 6, Step 79, Loss: 0.00784292072057724\n",
            "Epoch 6, Step 80, Loss: 0.008266856893897057\n",
            "Epoch 6, Step 81, Loss: 0.010923827067017555\n",
            "Epoch 6, Step 82, Loss: 0.010142453014850616\n",
            "Epoch 6, Step 83, Loss: 0.009941735304892063\n",
            "Epoch 6, Step 84, Loss: 0.011042202822864056\n",
            "Epoch 6, Step 85, Loss: 0.01167989056557417\n",
            "Epoch 6, Step 86, Loss: 0.012192759662866592\n",
            "Train Metric MRRs: 0.06347393091064976\n",
            "Train Metric MAPs: 0.008510050042923533\n",
            "Validation Metric MRRs: 0.04001869954349873\n",
            "Validation Metric MAPs: 0.007520916272912054\n",
            "Epoch 7, Step 1, Loss: 0.04008160158991814\n",
            "Epoch 7, Step 2, Loss: 0.03450246527791023\n",
            "Epoch 7, Step 3, Loss: 0.036898087710142136\n",
            "Epoch 7, Step 4, Loss: 0.025172535330057144\n",
            "Epoch 7, Step 5, Loss: 0.018324200063943863\n",
            "Epoch 7, Step 6, Loss: 0.01522889081388712\n",
            "Epoch 7, Step 7, Loss: 0.011020470410585403\n",
            "Epoch 7, Step 8, Loss: 0.008651007898151875\n",
            "Epoch 7, Step 9, Loss: 0.008437010459601879\n",
            "Epoch 7, Step 10, Loss: 0.008985929191112518\n",
            "Epoch 7, Step 11, Loss: 0.008712529204785824\n",
            "Epoch 7, Step 12, Loss: 0.007902427576482296\n",
            "Epoch 7, Step 13, Loss: 0.008307457901537418\n",
            "Epoch 7, Step 14, Loss: 0.007730184122920036\n",
            "Epoch 7, Step 15, Loss: 0.00783248245716095\n",
            "Epoch 7, Step 16, Loss: 0.009235981851816177\n",
            "Epoch 7, Step 17, Loss: 0.011816680431365967\n",
            "Epoch 7, Step 18, Loss: 0.013438938185572624\n",
            "Epoch 7, Step 19, Loss: 0.015791162848472595\n",
            "Epoch 7, Step 20, Loss: 0.016483372077345848\n",
            "Epoch 7, Step 21, Loss: 0.015162168070673943\n",
            "Epoch 7, Step 22, Loss: 0.01636495627462864\n",
            "Epoch 7, Step 23, Loss: 0.019447198137640953\n",
            "Epoch 7, Step 24, Loss: 0.01769452728331089\n",
            "Epoch 7, Step 25, Loss: 0.0170475821942091\n",
            "Epoch 7, Step 26, Loss: 0.017827974632382393\n",
            "Epoch 7, Step 27, Loss: 0.01445144321769476\n",
            "Epoch 7, Step 28, Loss: 0.0143023282289505\n",
            "Epoch 7, Step 29, Loss: 0.014389009214937687\n",
            "Epoch 7, Step 30, Loss: 0.013472041115164757\n",
            "Epoch 7, Step 31, Loss: 0.015755925327539444\n",
            "Epoch 7, Step 32, Loss: 0.014395973645150661\n",
            "Epoch 7, Step 33, Loss: 0.01378500834107399\n",
            "Epoch 7, Step 34, Loss: 0.012215567752718925\n",
            "Epoch 7, Step 35, Loss: 0.012723964639008045\n",
            "Epoch 7, Step 36, Loss: 0.011608818545937538\n",
            "Epoch 7, Step 37, Loss: 0.012608392164111137\n",
            "Epoch 7, Step 38, Loss: 0.010865493677556515\n",
            "Epoch 7, Step 39, Loss: 0.012823452241718769\n",
            "Epoch 7, Step 40, Loss: 0.013322040438652039\n",
            "Epoch 7, Step 41, Loss: 0.010627216659486294\n",
            "Epoch 7, Step 42, Loss: 0.009218931198120117\n",
            "Epoch 7, Step 43, Loss: 0.008876197971403599\n",
            "Epoch 7, Step 44, Loss: 0.009067357517778873\n",
            "Epoch 7, Step 45, Loss: 0.009569915011525154\n",
            "Epoch 7, Step 46, Loss: 0.008820709772408009\n",
            "Epoch 7, Step 47, Loss: 0.009863682091236115\n",
            "Epoch 7, Step 48, Loss: 0.009304864332079887\n",
            "Epoch 7, Step 49, Loss: 0.008844219148159027\n",
            "Epoch 7, Step 50, Loss: 0.00831780955195427\n",
            "Epoch 7, Step 51, Loss: 0.00966421514749527\n",
            "Epoch 7, Step 52, Loss: 0.008561565540730953\n",
            "Epoch 7, Step 53, Loss: 0.012015695683658123\n",
            "Epoch 7, Step 54, Loss: 0.010255700908601284\n",
            "Epoch 7, Step 55, Loss: 0.00980693381279707\n",
            "Epoch 7, Step 56, Loss: 0.009843598119914532\n",
            "Epoch 7, Step 57, Loss: 0.008781924843788147\n",
            "Epoch 7, Step 58, Loss: 0.009423719719052315\n",
            "Epoch 7, Step 59, Loss: 0.008291895501315594\n",
            "Epoch 7, Step 60, Loss: 0.008866209536790848\n",
            "Epoch 7, Step 61, Loss: 0.01098143681883812\n",
            "Epoch 7, Step 62, Loss: 0.009791928343474865\n",
            "Epoch 7, Step 63, Loss: 0.02364976890385151\n",
            "Epoch 7, Step 64, Loss: 0.00774587644264102\n",
            "Epoch 7, Step 65, Loss: 0.008671431802213192\n",
            "Epoch 7, Step 66, Loss: 0.007768250536173582\n",
            "Epoch 7, Step 67, Loss: 0.008506004698574543\n",
            "Epoch 7, Step 68, Loss: 0.00828000158071518\n",
            "Epoch 7, Step 69, Loss: 0.00842848140746355\n",
            "Epoch 7, Step 70, Loss: 0.009732455015182495\n",
            "Epoch 7, Step 71, Loss: 0.010368643328547478\n",
            "Epoch 7, Step 72, Loss: 0.009911491535604\n",
            "Epoch 7, Step 73, Loss: 0.00902402214705944\n",
            "Epoch 7, Step 74, Loss: 0.007862597703933716\n",
            "Epoch 7, Step 75, Loss: 0.007621423341333866\n",
            "Epoch 7, Step 76, Loss: 0.008427068591117859\n",
            "Epoch 7, Step 77, Loss: 0.008538839407265186\n",
            "Epoch 7, Step 78, Loss: 0.007353906519711018\n",
            "Epoch 7, Step 79, Loss: 0.007818756625056267\n",
            "Epoch 7, Step 80, Loss: 0.008246783167123795\n",
            "Epoch 7, Step 81, Loss: 0.010787908919155598\n",
            "Epoch 7, Step 82, Loss: 0.010084263049066067\n",
            "Epoch 7, Step 83, Loss: 0.00990003626793623\n",
            "Epoch 7, Step 84, Loss: 0.010967605747282505\n",
            "Epoch 7, Step 85, Loss: 0.011608805507421494\n",
            "Epoch 7, Step 86, Loss: 0.012105897068977356\n",
            "Train Metric MRRs: 0.07020267645918638\n",
            "Train Metric MAPs: 0.009012704756088702\n",
            "Validation Metric MRRs: 0.03839764863248593\n",
            "Validation Metric MAPs: 0.0077063951406130685\n",
            "Epoch 8, Step 1, Loss: 0.03963224217295647\n",
            "Epoch 8, Step 2, Loss: 0.03403933346271515\n",
            "Epoch 8, Step 3, Loss: 0.03665831312537193\n",
            "Epoch 8, Step 4, Loss: 0.024904785677790642\n",
            "Epoch 8, Step 5, Loss: 0.01821383461356163\n",
            "Epoch 8, Step 6, Loss: 0.015156121924519539\n",
            "Epoch 8, Step 7, Loss: 0.010807877406477928\n",
            "Epoch 8, Step 8, Loss: 0.008560736663639545\n",
            "Epoch 8, Step 9, Loss: 0.008400172926485538\n",
            "Epoch 8, Step 10, Loss: 0.008877516724169254\n",
            "Epoch 8, Step 11, Loss: 0.008568807505071163\n",
            "Epoch 8, Step 12, Loss: 0.007839588448405266\n",
            "Epoch 8, Step 13, Loss: 0.008218190632760525\n",
            "Epoch 8, Step 14, Loss: 0.007602946367114782\n",
            "Epoch 8, Step 15, Loss: 0.00775139918550849\n",
            "Epoch 8, Step 16, Loss: 0.009144279174506664\n",
            "Epoch 8, Step 17, Loss: 0.01174563355743885\n",
            "Epoch 8, Step 18, Loss: 0.013302955776453018\n",
            "Epoch 8, Step 19, Loss: 0.01569582335650921\n",
            "Epoch 8, Step 20, Loss: 0.01628328301012516\n",
            "Epoch 8, Step 21, Loss: 0.01506077591329813\n",
            "Epoch 8, Step 22, Loss: 0.016276784241199493\n",
            "Epoch 8, Step 23, Loss: 0.01929350383579731\n",
            "Epoch 8, Step 24, Loss: 0.017539069056510925\n",
            "Epoch 8, Step 25, Loss: 0.01686469092965126\n",
            "Epoch 8, Step 26, Loss: 0.01769259385764599\n",
            "Epoch 8, Step 27, Loss: 0.014281663112342358\n",
            "Epoch 8, Step 28, Loss: 0.014181331731379032\n",
            "Epoch 8, Step 29, Loss: 0.01434638723731041\n",
            "Epoch 8, Step 30, Loss: 0.013423744589090347\n",
            "Epoch 8, Step 31, Loss: 0.015700509771704674\n",
            "Epoch 8, Step 32, Loss: 0.014335336163640022\n",
            "Epoch 8, Step 33, Loss: 0.01372605375945568\n",
            "Epoch 8, Step 34, Loss: 0.012150589376688004\n",
            "Epoch 8, Step 35, Loss: 0.012632994912564754\n",
            "Epoch 8, Step 36, Loss: 0.01151979248970747\n",
            "Epoch 8, Step 37, Loss: 0.012524759396910667\n",
            "Epoch 8, Step 38, Loss: 0.010776313953101635\n",
            "Epoch 8, Step 39, Loss: 0.012745815329253674\n",
            "Epoch 8, Step 40, Loss: 0.013214568607509136\n",
            "Epoch 8, Step 41, Loss: 0.010584394447505474\n",
            "Epoch 8, Step 42, Loss: 0.009106443263590336\n",
            "Epoch 8, Step 43, Loss: 0.008767270483076572\n",
            "Epoch 8, Step 44, Loss: 0.00897508766502142\n",
            "Epoch 8, Step 45, Loss: 0.00951805803924799\n",
            "Epoch 8, Step 46, Loss: 0.008750404231250286\n",
            "Epoch 8, Step 47, Loss: 0.009798907674849033\n",
            "Epoch 8, Step 48, Loss: 0.009184259921312332\n",
            "Epoch 8, Step 49, Loss: 0.008797669783234596\n",
            "Epoch 8, Step 50, Loss: 0.008250748738646507\n",
            "Epoch 8, Step 51, Loss: 0.009557456709444523\n",
            "Epoch 8, Step 52, Loss: 0.008498741313815117\n",
            "Epoch 8, Step 53, Loss: 0.011974216438829899\n",
            "Epoch 8, Step 54, Loss: 0.0102100670337677\n",
            "Epoch 8, Step 55, Loss: 0.00974147766828537\n",
            "Epoch 8, Step 56, Loss: 0.009756348095834255\n",
            "Epoch 8, Step 57, Loss: 0.008749814704060555\n",
            "Epoch 8, Step 58, Loss: 0.009341242723166943\n",
            "Epoch 8, Step 59, Loss: 0.008249838836491108\n",
            "Epoch 8, Step 60, Loss: 0.008822599425911903\n",
            "Epoch 8, Step 61, Loss: 0.010929391719400883\n",
            "Epoch 8, Step 62, Loss: 0.009638103656470776\n",
            "Epoch 8, Step 63, Loss: 0.023496245965361595\n",
            "Epoch 8, Step 64, Loss: 0.007573976181447506\n",
            "Epoch 8, Step 65, Loss: 0.008603308349847794\n",
            "Epoch 8, Step 66, Loss: 0.007737547624856234\n",
            "Epoch 8, Step 67, Loss: 0.008492286317050457\n",
            "Epoch 8, Step 68, Loss: 0.00818762369453907\n",
            "Epoch 8, Step 69, Loss: 0.008378610946238041\n",
            "Epoch 8, Step 70, Loss: 0.009682883508503437\n",
            "Epoch 8, Step 71, Loss: 0.01034550555050373\n",
            "Epoch 8, Step 72, Loss: 0.009793322533369064\n",
            "Epoch 8, Step 73, Loss: 0.008981006219983101\n",
            "Epoch 8, Step 74, Loss: 0.007846545428037643\n",
            "Epoch 8, Step 75, Loss: 0.007577143143862486\n",
            "Epoch 8, Step 76, Loss: 0.008355677127838135\n",
            "Epoch 8, Step 77, Loss: 0.00850521121174097\n",
            "Epoch 8, Step 78, Loss: 0.007304695434868336\n",
            "Epoch 8, Step 79, Loss: 0.00778942322358489\n",
            "Epoch 8, Step 80, Loss: 0.00817180797457695\n",
            "Epoch 8, Step 81, Loss: 0.010709916241466999\n",
            "Epoch 8, Step 82, Loss: 0.00999187957495451\n",
            "Epoch 8, Step 83, Loss: 0.009857773780822754\n",
            "Epoch 8, Step 84, Loss: 0.010930116288363934\n",
            "Epoch 8, Step 85, Loss: 0.01154342107474804\n",
            "Epoch 8, Step 86, Loss: 0.011981310322880745\n",
            "Train Metric MRRs: 0.0741294752709426\n",
            "Train Metric MAPs: 0.00960039594195324\n",
            "Validation Metric MRRs: 0.0381179006724971\n",
            "Validation Metric MAPs: 0.007799705584941589\n",
            "Epoch 9, Step 1, Loss: 0.0391455739736557\n",
            "Epoch 9, Step 2, Loss: 0.03357573598623276\n",
            "Epoch 9, Step 3, Loss: 0.03629253804683685\n",
            "Epoch 9, Step 4, Loss: 0.024637985974550247\n",
            "Epoch 9, Step 5, Loss: 0.01809116080403328\n",
            "Epoch 9, Step 6, Loss: 0.015066622756421566\n",
            "Epoch 9, Step 7, Loss: 0.010566392913460732\n",
            "Epoch 9, Step 8, Loss: 0.008473819121718407\n",
            "Epoch 9, Step 9, Loss: 0.008374476805329323\n",
            "Epoch 9, Step 10, Loss: 0.008797239512205124\n",
            "Epoch 9, Step 11, Loss: 0.008456089533865452\n",
            "Epoch 9, Step 12, Loss: 0.0078026484698057175\n",
            "Epoch 9, Step 13, Loss: 0.00811423733830452\n",
            "Epoch 9, Step 14, Loss: 0.007493980228900909\n",
            "Epoch 9, Step 15, Loss: 0.0076416428200900555\n",
            "Epoch 9, Step 16, Loss: 0.009095081128180027\n",
            "Epoch 9, Step 17, Loss: 0.011666376143693924\n",
            "Epoch 9, Step 18, Loss: 0.013233115896582603\n",
            "Epoch 9, Step 19, Loss: 0.015590325929224491\n",
            "Epoch 9, Step 20, Loss: 0.016126805916428566\n",
            "Epoch 9, Step 21, Loss: 0.014962964691221714\n",
            "Epoch 9, Step 22, Loss: 0.016147853806614876\n",
            "Epoch 9, Step 23, Loss: 0.019200393930077553\n",
            "Epoch 9, Step 24, Loss: 0.017331918701529503\n",
            "Epoch 9, Step 25, Loss: 0.016665441915392876\n",
            "Epoch 9, Step 26, Loss: 0.017566774040460587\n",
            "Epoch 9, Step 27, Loss: 0.014177042990922928\n",
            "Epoch 9, Step 28, Loss: 0.014097622595727444\n",
            "Epoch 9, Step 29, Loss: 0.014328530058264732\n",
            "Epoch 9, Step 30, Loss: 0.013373912312090397\n",
            "Epoch 9, Step 31, Loss: 0.01562599465250969\n",
            "Epoch 9, Step 32, Loss: 0.014235254377126694\n",
            "Epoch 9, Step 33, Loss: 0.01361509133130312\n",
            "Epoch 9, Step 34, Loss: 0.012076781131327152\n",
            "Epoch 9, Step 35, Loss: 0.012559955008327961\n",
            "Epoch 9, Step 36, Loss: 0.011387590318918228\n",
            "Epoch 9, Step 37, Loss: 0.012395443394780159\n",
            "Epoch 9, Step 38, Loss: 0.01068047247827053\n",
            "Epoch 9, Step 39, Loss: 0.012678604573011398\n",
            "Epoch 9, Step 40, Loss: 0.013100157491862774\n",
            "Epoch 9, Step 41, Loss: 0.010539783164858818\n",
            "Epoch 9, Step 42, Loss: 0.009013531729578972\n",
            "Epoch 9, Step 43, Loss: 0.00870431587100029\n",
            "Epoch 9, Step 44, Loss: 0.008882042020559311\n",
            "Epoch 9, Step 45, Loss: 0.009510287083685398\n",
            "Epoch 9, Step 46, Loss: 0.008683440275490284\n",
            "Epoch 9, Step 47, Loss: 0.009712016209959984\n",
            "Epoch 9, Step 48, Loss: 0.009093052707612514\n",
            "Epoch 9, Step 49, Loss: 0.008757061325013638\n",
            "Epoch 9, Step 50, Loss: 0.008183171972632408\n",
            "Epoch 9, Step 51, Loss: 0.009506547823548317\n",
            "Epoch 9, Step 52, Loss: 0.00840239692479372\n",
            "Epoch 9, Step 53, Loss: 0.011947284452617168\n",
            "Epoch 9, Step 54, Loss: 0.010155889205634594\n",
            "Epoch 9, Step 55, Loss: 0.009601586498320103\n",
            "Epoch 9, Step 56, Loss: 0.009701603092253208\n",
            "Epoch 9, Step 57, Loss: 0.008714379742741585\n",
            "Epoch 9, Step 58, Loss: 0.009246069006621838\n",
            "Epoch 9, Step 59, Loss: 0.00818245206028223\n",
            "Epoch 9, Step 60, Loss: 0.008766086772084236\n",
            "Epoch 9, Step 61, Loss: 0.010898216627538204\n",
            "Epoch 9, Step 62, Loss: 0.009524436667561531\n",
            "Epoch 9, Step 63, Loss: 0.02344801276922226\n",
            "Epoch 9, Step 64, Loss: 0.0074617257341742516\n",
            "Epoch 9, Step 65, Loss: 0.008548500947654247\n",
            "Epoch 9, Step 66, Loss: 0.007727006915956736\n",
            "Epoch 9, Step 67, Loss: 0.008454217575490475\n",
            "Epoch 9, Step 68, Loss: 0.008111124858260155\n",
            "Epoch 9, Step 69, Loss: 0.008320285007357597\n",
            "Epoch 9, Step 70, Loss: 0.009645385667681694\n",
            "Epoch 9, Step 71, Loss: 0.010302400216460228\n",
            "Epoch 9, Step 72, Loss: 0.00972740724682808\n",
            "Epoch 9, Step 73, Loss: 0.008944482542574406\n",
            "Epoch 9, Step 74, Loss: 0.00780892139300704\n",
            "Epoch 9, Step 75, Loss: 0.007492635864764452\n",
            "Epoch 9, Step 76, Loss: 0.008306327275931835\n",
            "Epoch 9, Step 77, Loss: 0.008478356525301933\n",
            "Epoch 9, Step 78, Loss: 0.0072622597217559814\n",
            "Epoch 9, Step 79, Loss: 0.007739015854895115\n",
            "Epoch 9, Step 80, Loss: 0.008155018091201782\n",
            "Epoch 9, Step 81, Loss: 0.01062693540006876\n",
            "Epoch 9, Step 82, Loss: 0.009951514191925526\n",
            "Epoch 9, Step 83, Loss: 0.00983994361013174\n",
            "Epoch 9, Step 84, Loss: 0.01089126244187355\n",
            "Epoch 9, Step 85, Loss: 0.011458753608167171\n",
            "Epoch 9, Step 86, Loss: 0.011875559575855732\n",
            "Train Metric MRRs: 0.07799036831943801\n",
            "Train Metric MAPs: 0.009975020396456005\n",
            "Validation Metric MRRs: 0.040609993236178414\n",
            "Validation Metric MAPs: 0.008403723488275632\n",
            "Epoch 10, Step 1, Loss: 0.038763437420129776\n",
            "Epoch 10, Step 2, Loss: 0.03314109146595001\n",
            "Epoch 10, Step 3, Loss: 0.03588951751589775\n",
            "Epoch 10, Step 4, Loss: 0.02436811663210392\n",
            "Epoch 10, Step 5, Loss: 0.017934957519173622\n",
            "Epoch 10, Step 6, Loss: 0.01501938421279192\n",
            "Epoch 10, Step 7, Loss: 0.01043388806283474\n",
            "Epoch 10, Step 8, Loss: 0.008405550383031368\n",
            "Epoch 10, Step 9, Loss: 0.008333312347531319\n",
            "Epoch 10, Step 10, Loss: 0.008765697479248047\n",
            "Epoch 10, Step 11, Loss: 0.008371819742023945\n",
            "Epoch 10, Step 12, Loss: 0.007742999587208033\n",
            "Epoch 10, Step 13, Loss: 0.008044508285820484\n",
            "Epoch 10, Step 14, Loss: 0.00737049849703908\n",
            "Epoch 10, Step 15, Loss: 0.007557652425020933\n",
            "Epoch 10, Step 16, Loss: 0.009050893597304821\n",
            "Epoch 10, Step 17, Loss: 0.011595381423830986\n",
            "Epoch 10, Step 18, Loss: 0.013165503740310669\n",
            "Epoch 10, Step 19, Loss: 0.015484877862036228\n",
            "Epoch 10, Step 20, Loss: 0.016046198084950447\n",
            "Epoch 10, Step 21, Loss: 0.014869289472699165\n",
            "Epoch 10, Step 22, Loss: 0.016047900542616844\n",
            "Epoch 10, Step 23, Loss: 0.019121428951621056\n",
            "Epoch 10, Step 24, Loss: 0.017226850613951683\n",
            "Epoch 10, Step 25, Loss: 0.016531310975551605\n",
            "Epoch 10, Step 26, Loss: 0.017483551055192947\n",
            "Epoch 10, Step 27, Loss: 0.014078820124268532\n",
            "Epoch 10, Step 28, Loss: 0.014056088402867317\n",
            "Epoch 10, Step 29, Loss: 0.01428023912012577\n",
            "Epoch 10, Step 30, Loss: 0.013356807641685009\n",
            "Epoch 10, Step 31, Loss: 0.015560920350253582\n",
            "Epoch 10, Step 32, Loss: 0.01423961203545332\n",
            "Epoch 10, Step 33, Loss: 0.013532767072319984\n",
            "Epoch 10, Step 34, Loss: 0.012015435844659805\n",
            "Epoch 10, Step 35, Loss: 0.012475090101361275\n",
            "Epoch 10, Step 36, Loss: 0.011319376528263092\n",
            "Epoch 10, Step 37, Loss: 0.012334775179624557\n",
            "Epoch 10, Step 38, Loss: 0.010601433925330639\n",
            "Epoch 10, Step 39, Loss: 0.012602675706148148\n",
            "Epoch 10, Step 40, Loss: 0.013005683198571205\n",
            "Epoch 10, Step 41, Loss: 0.010534782893955708\n",
            "Epoch 10, Step 42, Loss: 0.008926793932914734\n",
            "Epoch 10, Step 43, Loss: 0.00865035317838192\n",
            "Epoch 10, Step 44, Loss: 0.008811825886368752\n",
            "Epoch 10, Step 45, Loss: 0.009484970942139626\n",
            "Epoch 10, Step 46, Loss: 0.008638249710202217\n",
            "Epoch 10, Step 47, Loss: 0.009658260270953178\n",
            "Epoch 10, Step 48, Loss: 0.009030723944306374\n",
            "Epoch 10, Step 49, Loss: 0.008658485487103462\n",
            "Epoch 10, Step 50, Loss: 0.008108259178698063\n",
            "Epoch 10, Step 51, Loss: 0.009484843350946903\n",
            "Epoch 10, Step 52, Loss: 0.00840092170983553\n",
            "Epoch 10, Step 53, Loss: 0.011871110647916794\n",
            "Epoch 10, Step 54, Loss: 0.010110409930348396\n",
            "Epoch 10, Step 55, Loss: 0.009512060321867466\n",
            "Epoch 10, Step 56, Loss: 0.009692552499473095\n",
            "Epoch 10, Step 57, Loss: 0.008688260801136494\n",
            "Epoch 10, Step 58, Loss: 0.009182647801935673\n",
            "Epoch 10, Step 59, Loss: 0.008166116662323475\n",
            "Epoch 10, Step 60, Loss: 0.00874403677880764\n",
            "Epoch 10, Step 61, Loss: 0.010870737954974174\n",
            "Epoch 10, Step 62, Loss: 0.009415283799171448\n",
            "Epoch 10, Step 63, Loss: 0.023352492600679398\n",
            "Epoch 10, Step 64, Loss: 0.007360475137829781\n",
            "Epoch 10, Step 65, Loss: 0.008485603146255016\n",
            "Epoch 10, Step 66, Loss: 0.007684860844165087\n",
            "Epoch 10, Step 67, Loss: 0.008419223129749298\n",
            "Epoch 10, Step 68, Loss: 0.00802137702703476\n",
            "Epoch 10, Step 69, Loss: 0.008261493407189846\n",
            "Epoch 10, Step 70, Loss: 0.00961955077946186\n",
            "Epoch 10, Step 71, Loss: 0.010263382457196712\n",
            "Epoch 10, Step 72, Loss: 0.009650090709328651\n",
            "Epoch 10, Step 73, Loss: 0.008878291584551334\n",
            "Epoch 10, Step 74, Loss: 0.0077810813672840595\n",
            "Epoch 10, Step 75, Loss: 0.007454369217157364\n",
            "Epoch 10, Step 76, Loss: 0.008240330964326859\n",
            "Epoch 10, Step 77, Loss: 0.008448111824691296\n",
            "Epoch 10, Step 78, Loss: 0.007213540840893984\n",
            "Epoch 10, Step 79, Loss: 0.00773335387930274\n",
            "Epoch 10, Step 80, Loss: 0.008140958845615387\n",
            "Epoch 10, Step 81, Loss: 0.010563495568931103\n",
            "Epoch 10, Step 82, Loss: 0.009886484593153\n",
            "Epoch 10, Step 83, Loss: 0.009813898243010044\n",
            "Epoch 10, Step 84, Loss: 0.010817322880029678\n",
            "Epoch 10, Step 85, Loss: 0.011388096958398819\n",
            "Epoch 10, Step 86, Loss: 0.011782729998230934\n",
            "Train Metric MRRs: 0.08135115087190736\n",
            "Train Metric MAPs: 0.010290725784964623\n",
            "Validation Metric MRRs: 0.043351379001024024\n",
            "Validation Metric MAPs: 0.008128959448776436\n",
            "Epoch 11, Step 1, Loss: 0.03839601203799248\n",
            "Epoch 11, Step 2, Loss: 0.032954566180706024\n",
            "Epoch 11, Step 3, Loss: 0.03557230159640312\n",
            "Epoch 11, Step 4, Loss: 0.024194106459617615\n",
            "Epoch 11, Step 5, Loss: 0.01787041872739792\n",
            "Epoch 11, Step 6, Loss: 0.014929937198758125\n",
            "Epoch 11, Step 7, Loss: 0.010245890356600285\n",
            "Epoch 11, Step 8, Loss: 0.008342389017343521\n",
            "Epoch 11, Step 9, Loss: 0.00832096952944994\n",
            "Epoch 11, Step 10, Loss: 0.008720365352928638\n",
            "Epoch 11, Step 11, Loss: 0.008295521140098572\n",
            "Epoch 11, Step 12, Loss: 0.007734856102615595\n",
            "Epoch 11, Step 13, Loss: 0.007996996864676476\n",
            "Epoch 11, Step 14, Loss: 0.00729283457621932\n",
            "Epoch 11, Step 15, Loss: 0.007536735851317644\n",
            "Epoch 11, Step 16, Loss: 0.009009499102830887\n",
            "Epoch 11, Step 17, Loss: 0.01154954545199871\n",
            "Epoch 11, Step 18, Loss: 0.013068906031548977\n",
            "Epoch 11, Step 19, Loss: 0.01543746143579483\n",
            "Epoch 11, Step 20, Loss: 0.01594889536499977\n",
            "Epoch 11, Step 21, Loss: 0.014814609661698341\n",
            "Epoch 11, Step 22, Loss: 0.015964874997735023\n",
            "Epoch 11, Step 23, Loss: 0.01899658516049385\n",
            "Epoch 11, Step 24, Loss: 0.017040308564901352\n",
            "Epoch 11, Step 25, Loss: 0.016418462619185448\n",
            "Epoch 11, Step 26, Loss: 0.017320001497864723\n",
            "Epoch 11, Step 27, Loss: 0.01402896735817194\n",
            "Epoch 11, Step 28, Loss: 0.014039270579814911\n",
            "Epoch 11, Step 29, Loss: 0.014276971109211445\n",
            "Epoch 11, Step 30, Loss: 0.01332065835595131\n",
            "Epoch 11, Step 31, Loss: 0.015531972981989384\n",
            "Epoch 11, Step 32, Loss: 0.014183040708303452\n",
            "Epoch 11, Step 33, Loss: 0.013505149632692337\n",
            "Epoch 11, Step 34, Loss: 0.011972552165389061\n",
            "Epoch 11, Step 35, Loss: 0.012481276877224445\n",
            "Epoch 11, Step 36, Loss: 0.011278539896011353\n",
            "Epoch 11, Step 37, Loss: 0.012312023900449276\n",
            "Epoch 11, Step 38, Loss: 0.010550795122981071\n",
            "Epoch 11, Step 39, Loss: 0.012542583979666233\n",
            "Epoch 11, Step 40, Loss: 0.012938303872942924\n",
            "Epoch 11, Step 41, Loss: 0.010481476783752441\n",
            "Epoch 11, Step 42, Loss: 0.008912082761526108\n",
            "Epoch 11, Step 43, Loss: 0.008579190820455551\n",
            "Epoch 11, Step 44, Loss: 0.008745092898607254\n",
            "Epoch 11, Step 45, Loss: 0.009469416923820972\n",
            "Epoch 11, Step 46, Loss: 0.008631125092506409\n",
            "Epoch 11, Step 47, Loss: 0.009607025422155857\n",
            "Epoch 11, Step 48, Loss: 0.008940046653151512\n",
            "Epoch 11, Step 49, Loss: 0.008595498278737068\n",
            "Epoch 11, Step 50, Loss: 0.008053272031247616\n",
            "Epoch 11, Step 51, Loss: 0.009445104748010635\n",
            "Epoch 11, Step 52, Loss: 0.008382917381823063\n",
            "Epoch 11, Step 53, Loss: 0.011818488128483295\n",
            "Epoch 11, Step 54, Loss: 0.010080615989863873\n",
            "Epoch 11, Step 55, Loss: 0.009458748623728752\n",
            "Epoch 11, Step 56, Loss: 0.009625952690839767\n",
            "Epoch 11, Step 57, Loss: 0.008663223125040531\n",
            "Epoch 11, Step 58, Loss: 0.00915110856294632\n",
            "Epoch 11, Step 59, Loss: 0.008112686686217785\n",
            "Epoch 11, Step 60, Loss: 0.00871356762945652\n",
            "Epoch 11, Step 61, Loss: 0.010840286500751972\n",
            "Epoch 11, Step 62, Loss: 0.009295421652495861\n",
            "Epoch 11, Step 63, Loss: 0.023178836330771446\n",
            "Epoch 11, Step 64, Loss: 0.00725195137783885\n",
            "Epoch 11, Step 65, Loss: 0.008406114764511585\n",
            "Epoch 11, Step 66, Loss: 0.00767174456268549\n",
            "Epoch 11, Step 67, Loss: 0.008401062339544296\n",
            "Epoch 11, Step 68, Loss: 0.007983079180121422\n",
            "Epoch 11, Step 69, Loss: 0.008223121985793114\n",
            "Epoch 11, Step 70, Loss: 0.009579239413142204\n",
            "Epoch 11, Step 71, Loss: 0.010210968554019928\n",
            "Epoch 11, Step 72, Loss: 0.009582812897861004\n",
            "Epoch 11, Step 73, Loss: 0.008823119103908539\n",
            "Epoch 11, Step 74, Loss: 0.0077340612187981606\n",
            "Epoch 11, Step 75, Loss: 0.007387464866042137\n",
            "Epoch 11, Step 76, Loss: 0.008200844749808311\n",
            "Epoch 11, Step 77, Loss: 0.008397893980145454\n",
            "Epoch 11, Step 78, Loss: 0.007150337565690279\n",
            "Epoch 11, Step 79, Loss: 0.007739219814538956\n",
            "Epoch 11, Step 80, Loss: 0.008149674162268639\n",
            "Epoch 11, Step 81, Loss: 0.010535141453146935\n",
            "Epoch 11, Step 82, Loss: 0.009842079132795334\n",
            "Epoch 11, Step 83, Loss: 0.009791497141122818\n",
            "Epoch 11, Step 84, Loss: 0.010798892937600613\n",
            "Epoch 11, Step 85, Loss: 0.01134281326085329\n",
            "Epoch 11, Step 86, Loss: 0.011706093326210976\n",
            "Train Metric MRRs: 0.08503537347443672\n",
            "Train Metric MAPs: 0.01081599342851402\n",
            "Validation Metric MRRs: 0.045330601200217285\n",
            "Validation Metric MAPs: 0.00829759256398293\n",
            "Epoch 12, Step 1, Loss: 0.037996385246515274\n",
            "Epoch 12, Step 2, Loss: 0.03268219530582428\n",
            "Epoch 12, Step 3, Loss: 0.0352623425424099\n",
            "Epoch 12, Step 4, Loss: 0.0239876601845026\n",
            "Epoch 12, Step 5, Loss: 0.01781165972352028\n",
            "Epoch 12, Step 6, Loss: 0.014808963052928448\n",
            "Epoch 12, Step 7, Loss: 0.010127203539013863\n",
            "Epoch 12, Step 8, Loss: 0.008294100873172283\n",
            "Epoch 12, Step 9, Loss: 0.008263577707111835\n",
            "Epoch 12, Step 10, Loss: 0.008632672019302845\n",
            "Epoch 12, Step 11, Loss: 0.00822674110531807\n",
            "Epoch 12, Step 12, Loss: 0.007699702866375446\n",
            "Epoch 12, Step 13, Loss: 0.007946285419166088\n",
            "Epoch 12, Step 14, Loss: 0.0072148446924984455\n",
            "Epoch 12, Step 15, Loss: 0.007475454825907946\n",
            "Epoch 12, Step 16, Loss: 0.009016493335366249\n",
            "Epoch 12, Step 17, Loss: 0.011511644348502159\n",
            "Epoch 12, Step 18, Loss: 0.012975088320672512\n",
            "Epoch 12, Step 19, Loss: 0.01539652980864048\n",
            "Epoch 12, Step 20, Loss: 0.015831496566534042\n",
            "Epoch 12, Step 21, Loss: 0.014736060984432697\n",
            "Epoch 12, Step 22, Loss: 0.015852918848395348\n",
            "Epoch 12, Step 23, Loss: 0.018877217546105385\n",
            "Epoch 12, Step 24, Loss: 0.01692924089729786\n",
            "Epoch 12, Step 25, Loss: 0.016268298029899597\n",
            "Epoch 12, Step 26, Loss: 0.017214864492416382\n",
            "Epoch 12, Step 27, Loss: 0.013919387012720108\n",
            "Epoch 12, Step 28, Loss: 0.013989336788654327\n",
            "Epoch 12, Step 29, Loss: 0.014255489222705364\n",
            "Epoch 12, Step 30, Loss: 0.013273438438773155\n",
            "Epoch 12, Step 31, Loss: 0.015423650853335857\n",
            "Epoch 12, Step 32, Loss: 0.014131266623735428\n",
            "Epoch 12, Step 33, Loss: 0.013445802964270115\n",
            "Epoch 12, Step 34, Loss: 0.011900330893695354\n",
            "Epoch 12, Step 35, Loss: 0.012435183860361576\n",
            "Epoch 12, Step 36, Loss: 0.011217664927244186\n",
            "Epoch 12, Step 37, Loss: 0.012193822301924229\n",
            "Epoch 12, Step 38, Loss: 0.010484089143574238\n",
            "Epoch 12, Step 39, Loss: 0.012513636611402035\n",
            "Epoch 12, Step 40, Loss: 0.01287888828665018\n",
            "Epoch 12, Step 41, Loss: 0.010434931144118309\n",
            "Epoch 12, Step 42, Loss: 0.008871876634657383\n",
            "Epoch 12, Step 43, Loss: 0.008506249636411667\n",
            "Epoch 12, Step 44, Loss: 0.008658554404973984\n",
            "Epoch 12, Step 45, Loss: 0.009460554458200932\n",
            "Epoch 12, Step 46, Loss: 0.008552213199436665\n",
            "Epoch 12, Step 47, Loss: 0.009559090249240398\n",
            "Epoch 12, Step 48, Loss: 0.00889155175536871\n",
            "Epoch 12, Step 49, Loss: 0.008562709204852581\n",
            "Epoch 12, Step 50, Loss: 0.007980883121490479\n",
            "Epoch 12, Step 51, Loss: 0.009442813694477081\n",
            "Epoch 12, Step 52, Loss: 0.008333582431077957\n",
            "Epoch 12, Step 53, Loss: 0.0117806326597929\n",
            "Epoch 12, Step 54, Loss: 0.010060178115963936\n",
            "Epoch 12, Step 55, Loss: 0.009413270279765129\n",
            "Epoch 12, Step 56, Loss: 0.009585574269294739\n",
            "Epoch 12, Step 57, Loss: 0.0086772870272398\n",
            "Epoch 12, Step 58, Loss: 0.009040029719471931\n",
            "Epoch 12, Step 59, Loss: 0.008087153546512127\n",
            "Epoch 12, Step 60, Loss: 0.008686961606144905\n",
            "Epoch 12, Step 61, Loss: 0.010843146592378616\n",
            "Epoch 12, Step 62, Loss: 0.00928124226629734\n",
            "Epoch 12, Step 63, Loss: 0.023105112835764885\n",
            "Epoch 12, Step 64, Loss: 0.007163959089666605\n",
            "Epoch 12, Step 65, Loss: 0.008321983739733696\n",
            "Epoch 12, Step 66, Loss: 0.007642102427780628\n",
            "Epoch 12, Step 67, Loss: 0.008376529440283775\n",
            "Epoch 12, Step 68, Loss: 0.007937907241284847\n",
            "Epoch 12, Step 69, Loss: 0.008195888251066208\n",
            "Epoch 12, Step 70, Loss: 0.009575637057423592\n",
            "Epoch 12, Step 71, Loss: 0.010176521725952625\n",
            "Epoch 12, Step 72, Loss: 0.009523184038698673\n",
            "Epoch 12, Step 73, Loss: 0.008793210610747337\n",
            "Epoch 12, Step 74, Loss: 0.007712069898843765\n",
            "Epoch 12, Step 75, Loss: 0.007366436067968607\n",
            "Epoch 12, Step 76, Loss: 0.008165821433067322\n",
            "Epoch 12, Step 77, Loss: 0.008371935226023197\n",
            "Epoch 12, Step 78, Loss: 0.00712028332054615\n",
            "Epoch 12, Step 79, Loss: 0.0076798018999397755\n",
            "Epoch 12, Step 80, Loss: 0.00813327543437481\n",
            "Epoch 12, Step 81, Loss: 0.010477131232619286\n",
            "Epoch 12, Step 82, Loss: 0.00979679450392723\n",
            "Epoch 12, Step 83, Loss: 0.009764977730810642\n",
            "Epoch 12, Step 84, Loss: 0.010785949416458607\n",
            "Epoch 12, Step 85, Loss: 0.011256418190896511\n",
            "Epoch 12, Step 86, Loss: 0.01161160971969366\n",
            "Train Metric MRRs: 0.08812122371942092\n",
            "Train Metric MAPs: 0.01108194550386585\n",
            "Validation Metric MRRs: 0.0449157479383131\n",
            "Validation Metric MAPs: 0.008508694635689639\n",
            "Epoch 13, Step 1, Loss: 0.03774012252688408\n",
            "Epoch 13, Step 2, Loss: 0.03252754732966423\n",
            "Epoch 13, Step 3, Loss: 0.034929946064949036\n",
            "Epoch 13, Step 4, Loss: 0.0238502137362957\n",
            "Epoch 13, Step 5, Loss: 0.017722144722938538\n",
            "Epoch 13, Step 6, Loss: 0.014739278703927994\n",
            "Epoch 13, Step 7, Loss: 0.009951970539987087\n",
            "Epoch 13, Step 8, Loss: 0.0082668736577034\n",
            "Epoch 13, Step 9, Loss: 0.008230352774262428\n",
            "Epoch 13, Step 10, Loss: 0.008614439517259598\n",
            "Epoch 13, Step 11, Loss: 0.008166100829839706\n",
            "Epoch 13, Step 12, Loss: 0.007715192623436451\n",
            "Epoch 13, Step 13, Loss: 0.007886824198067188\n",
            "Epoch 13, Step 14, Loss: 0.007163798902183771\n",
            "Epoch 13, Step 15, Loss: 0.007424384821206331\n",
            "Epoch 13, Step 16, Loss: 0.009012546390295029\n",
            "Epoch 13, Step 17, Loss: 0.01150458212941885\n",
            "Epoch 13, Step 18, Loss: 0.012927807867527008\n",
            "Epoch 13, Step 19, Loss: 0.015320711769163609\n",
            "Epoch 13, Step 20, Loss: 0.0158125851303339\n",
            "Epoch 13, Step 21, Loss: 0.01469802763313055\n",
            "Epoch 13, Step 22, Loss: 0.015765098854899406\n",
            "Epoch 13, Step 23, Loss: 0.01883818581700325\n",
            "Epoch 13, Step 24, Loss: 0.01680699549615383\n",
            "Epoch 13, Step 25, Loss: 0.016222430393099785\n",
            "Epoch 13, Step 26, Loss: 0.01715770550072193\n",
            "Epoch 13, Step 27, Loss: 0.013903342187404633\n",
            "Epoch 13, Step 28, Loss: 0.013962389901280403\n",
            "Epoch 13, Step 29, Loss: 0.014235187321901321\n",
            "Epoch 13, Step 30, Loss: 0.013259677216410637\n",
            "Epoch 13, Step 31, Loss: 0.015394601039588451\n",
            "Epoch 13, Step 32, Loss: 0.014143615029752254\n",
            "Epoch 13, Step 33, Loss: 0.013368992134928703\n",
            "Epoch 13, Step 34, Loss: 0.011880760081112385\n",
            "Epoch 13, Step 35, Loss: 0.012372033670544624\n",
            "Epoch 13, Step 36, Loss: 0.011135883629322052\n",
            "Epoch 13, Step 37, Loss: 0.012132049538195133\n",
            "Epoch 13, Step 38, Loss: 0.01043584942817688\n",
            "Epoch 13, Step 39, Loss: 0.01246920321136713\n",
            "Epoch 13, Step 40, Loss: 0.01282135583460331\n",
            "Epoch 13, Step 41, Loss: 0.010412591509521008\n",
            "Epoch 13, Step 42, Loss: 0.0088408924639225\n",
            "Epoch 13, Step 43, Loss: 0.008482555858790874\n",
            "Epoch 13, Step 44, Loss: 0.00861364509910345\n",
            "Epoch 13, Step 45, Loss: 0.009417684748768806\n",
            "Epoch 13, Step 46, Loss: 0.00849506352096796\n",
            "Epoch 13, Step 47, Loss: 0.009519961662590504\n",
            "Epoch 13, Step 48, Loss: 0.008861467242240906\n",
            "Epoch 13, Step 49, Loss: 0.00853703636676073\n",
            "Epoch 13, Step 50, Loss: 0.007958014495670795\n",
            "Epoch 13, Step 51, Loss: 0.009423317387700081\n",
            "Epoch 13, Step 52, Loss: 0.008307346142828465\n",
            "Epoch 13, Step 53, Loss: 0.011732298880815506\n",
            "Epoch 13, Step 54, Loss: 0.010018720291554928\n",
            "Epoch 13, Step 55, Loss: 0.009282681159675121\n",
            "Epoch 13, Step 56, Loss: 0.009545349515974522\n",
            "Epoch 13, Step 57, Loss: 0.008646015077829361\n",
            "Epoch 13, Step 58, Loss: 0.008982077240943909\n",
            "Epoch 13, Step 59, Loss: 0.008051487617194653\n",
            "Epoch 13, Step 60, Loss: 0.00866852980107069\n",
            "Epoch 13, Step 61, Loss: 0.010807566344738007\n",
            "Epoch 13, Step 62, Loss: 0.009282740764319897\n",
            "Epoch 13, Step 63, Loss: 0.022994408383965492\n",
            "Epoch 13, Step 64, Loss: 0.007120504509657621\n",
            "Epoch 13, Step 65, Loss: 0.008309820666909218\n",
            "Epoch 13, Step 66, Loss: 0.007634950336068869\n",
            "Epoch 13, Step 67, Loss: 0.008330192416906357\n",
            "Epoch 13, Step 68, Loss: 0.007883414626121521\n",
            "Epoch 13, Step 69, Loss: 0.008150577545166016\n",
            "Epoch 13, Step 70, Loss: 0.009561016224324703\n",
            "Epoch 13, Step 71, Loss: 0.01013221312314272\n",
            "Epoch 13, Step 72, Loss: 0.009503960609436035\n",
            "Epoch 13, Step 73, Loss: 0.008742982521653175\n",
            "Epoch 13, Step 74, Loss: 0.0076693263836205006\n",
            "Epoch 13, Step 75, Loss: 0.0073245917446911335\n",
            "Epoch 13, Step 76, Loss: 0.008162411861121655\n",
            "Epoch 13, Step 77, Loss: 0.008348904550075531\n",
            "Epoch 13, Step 78, Loss: 0.007090467493981123\n",
            "Epoch 13, Step 79, Loss: 0.007648603990674019\n",
            "Epoch 13, Step 80, Loss: 0.008112866431474686\n",
            "Epoch 13, Step 81, Loss: 0.010395119898021221\n",
            "Epoch 13, Step 82, Loss: 0.009758704341948032\n",
            "Epoch 13, Step 83, Loss: 0.00974164716899395\n",
            "Epoch 13, Step 84, Loss: 0.01077291276305914\n",
            "Epoch 13, Step 85, Loss: 0.011214143596589565\n",
            "Epoch 13, Step 86, Loss: 0.011587691493332386\n",
            "Train Metric MRRs: 0.09100032229791548\n",
            "Train Metric MAPs: 0.011396300928241166\n",
            "Validation Metric MRRs: 0.04497017886326797\n",
            "Validation Metric MAPs: 0.00840721138085359\n",
            "Epoch 14, Step 1, Loss: 0.037522125989198685\n",
            "Epoch 14, Step 2, Loss: 0.032410573214292526\n",
            "Epoch 14, Step 3, Loss: 0.034784577786922455\n",
            "Epoch 14, Step 4, Loss: 0.02370062842965126\n",
            "Epoch 14, Step 5, Loss: 0.017663799226284027\n",
            "Epoch 14, Step 6, Loss: 0.014728021807968616\n",
            "Epoch 14, Step 7, Loss: 0.009870607405900955\n",
            "Epoch 14, Step 8, Loss: 0.008192554116249084\n",
            "Epoch 14, Step 9, Loss: 0.008220587857067585\n",
            "Epoch 14, Step 10, Loss: 0.00859533529728651\n",
            "Epoch 14, Step 11, Loss: 0.008117991499602795\n",
            "Epoch 14, Step 12, Loss: 0.007703886367380619\n",
            "Epoch 14, Step 13, Loss: 0.00783804152160883\n",
            "Epoch 14, Step 14, Loss: 0.007099812850356102\n",
            "Epoch 14, Step 15, Loss: 0.007395435124635696\n",
            "Epoch 14, Step 16, Loss: 0.009020530618727207\n",
            "Epoch 14, Step 17, Loss: 0.011503278277814388\n",
            "Epoch 14, Step 18, Loss: 0.012855972163379192\n",
            "Epoch 14, Step 19, Loss: 0.01527349092066288\n",
            "Epoch 14, Step 20, Loss: 0.015750380232930183\n",
            "Epoch 14, Step 21, Loss: 0.014670987613499165\n",
            "Epoch 14, Step 22, Loss: 0.015675880014896393\n",
            "Epoch 14, Step 23, Loss: 0.018729232251644135\n",
            "Epoch 14, Step 24, Loss: 0.016699515283107758\n",
            "Epoch 14, Step 25, Loss: 0.01611393131315708\n",
            "Epoch 14, Step 26, Loss: 0.017039772123098373\n",
            "Epoch 14, Step 27, Loss: 0.013847103342413902\n",
            "Epoch 14, Step 28, Loss: 0.013940566219389439\n",
            "Epoch 14, Step 29, Loss: 0.014241913333535194\n",
            "Epoch 14, Step 30, Loss: 0.01323116384446621\n",
            "Epoch 14, Step 31, Loss: 0.015356065705418587\n",
            "Epoch 14, Step 32, Loss: 0.014081615023314953\n",
            "Epoch 14, Step 33, Loss: 0.013364123180508614\n",
            "Epoch 14, Step 34, Loss: 0.011830723844468594\n",
            "Epoch 14, Step 35, Loss: 0.012307739816606045\n",
            "Epoch 14, Step 36, Loss: 0.011135634034872055\n",
            "Epoch 14, Step 37, Loss: 0.012091613374650478\n",
            "Epoch 14, Step 38, Loss: 0.010370009578764439\n",
            "Epoch 14, Step 39, Loss: 0.012471488676965237\n",
            "Epoch 14, Step 40, Loss: 0.01274882536381483\n",
            "Epoch 14, Step 41, Loss: 0.010337481275200844\n",
            "Epoch 14, Step 42, Loss: 0.008818148635327816\n",
            "Epoch 14, Step 43, Loss: 0.00845376681536436\n",
            "Epoch 14, Step 44, Loss: 0.008568540215492249\n",
            "Epoch 14, Step 45, Loss: 0.009357579983770847\n",
            "Epoch 14, Step 46, Loss: 0.00849438738077879\n",
            "Epoch 14, Step 47, Loss: 0.009531507268548012\n",
            "Epoch 14, Step 48, Loss: 0.008766145445406437\n",
            "Epoch 14, Step 49, Loss: 0.008489493280649185\n",
            "Epoch 14, Step 50, Loss: 0.007902932353317738\n",
            "Epoch 14, Step 51, Loss: 0.009448346681892872\n",
            "Epoch 14, Step 52, Loss: 0.00834908802062273\n",
            "Epoch 14, Step 53, Loss: 0.011735818348824978\n",
            "Epoch 14, Step 54, Loss: 0.010012960061430931\n",
            "Epoch 14, Step 55, Loss: 0.009289774112403393\n",
            "Epoch 14, Step 56, Loss: 0.009519649669528008\n",
            "Epoch 14, Step 57, Loss: 0.008644498884677887\n",
            "Epoch 14, Step 58, Loss: 0.008920961990952492\n",
            "Epoch 14, Step 59, Loss: 0.008046318776905537\n",
            "Epoch 14, Step 60, Loss: 0.008664906024932861\n",
            "Epoch 14, Step 61, Loss: 0.010768475010991096\n",
            "Epoch 14, Step 62, Loss: 0.009221050888299942\n",
            "Epoch 14, Step 63, Loss: 0.022875921800732613\n",
            "Epoch 14, Step 64, Loss: 0.007037141360342503\n",
            "Epoch 14, Step 65, Loss: 0.008260373957455158\n",
            "Epoch 14, Step 66, Loss: 0.007620156276971102\n",
            "Epoch 14, Step 67, Loss: 0.008344712667167187\n",
            "Epoch 14, Step 68, Loss: 0.00790609885007143\n",
            "Epoch 14, Step 69, Loss: 0.008136914111673832\n",
            "Epoch 14, Step 70, Loss: 0.009572840295732021\n",
            "Epoch 14, Step 71, Loss: 0.010122889652848244\n",
            "Epoch 14, Step 72, Loss: 0.009436170570552349\n",
            "Epoch 14, Step 73, Loss: 0.008733573369681835\n",
            "Epoch 14, Step 74, Loss: 0.00762788113206625\n",
            "Epoch 14, Step 75, Loss: 0.007293246686458588\n",
            "Epoch 14, Step 76, Loss: 0.008105024695396423\n",
            "Epoch 14, Step 77, Loss: 0.008306161500513554\n",
            "Epoch 14, Step 78, Loss: 0.007046399638056755\n",
            "Epoch 14, Step 79, Loss: 0.007666248362511396\n",
            "Epoch 14, Step 80, Loss: 0.008122141472995281\n",
            "Epoch 14, Step 81, Loss: 0.010393026284873486\n",
            "Epoch 14, Step 82, Loss: 0.009736396372318268\n",
            "Epoch 14, Step 83, Loss: 0.009729359298944473\n",
            "Epoch 14, Step 84, Loss: 0.010767440311610699\n",
            "Epoch 14, Step 85, Loss: 0.011193716898560524\n",
            "Epoch 14, Step 86, Loss: 0.011576896533370018\n",
            "Train Metric MRRs: 0.09305466723095637\n",
            "Train Metric MAPs: 0.011602560565494573\n",
            "Validation Metric MRRs: 0.046022517392415536\n",
            "Validation Metric MAPs: 0.008316019883733244\n",
            "Early stopping triggered!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.restore_best_checkpoint()\n",
        "trainer.validate('Validation')\n",
        "trainer.validate('Test')"
      ],
      "metadata": {
        "id": "brUW-S9GWkh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceca965c-b855-4cf0-c470-af9e71af3d13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Metric MRRs: 0.047429348704693584\n",
            "Validation Metric MAPs: 0.007557749404694969\n",
            "Test Metric MRRs: 0.054012917455391794\n",
            "Test Metric MAPs: 0.014058892024495624\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.054012917455391794, 0.014058892024495624)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}